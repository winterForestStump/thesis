{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winterForestStump/thesis/blob/main/notebooks/rag_x_phi3_generalQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-nomic langchain langchain-core langchain-community --quiet\n",
        "%pip install -U tiktoken langchainhub chromadb langgraph tavily-python langchain-text-splitters\n",
        "%pip install sentence_transformers FlagEmbedding --quiet"
      ],
      "metadata": {
        "id": "FvVmzL2j9VE2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LlamaCpp x GPU usage\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUlkK-AQ9VE_",
        "outputId": "1fea0881-c6d4-4e69-9fd4-cca5d5124b83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.10/dist-packages (0.2.78)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IfHIpuz9VFB",
        "outputId": "a88b6186-dc51-4dea-dd61-5277a445b6bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "import chromadb\n",
        "from langchain.storage.file_system import LocalFileStore\n",
        "from langchain.storage._lc_store import create_kv_docstore\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "from FlagEmbedding import FlagReranker\n",
        "\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "4chIcfH79VFC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download microsoft/Phi-3-mini-4k-instruct-gguf Phi-3-mini-4k-instruct-fp16.gguf --local-dir ./models --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFSdx4MY9VFD",
        "outputId": "91e5ce69-c854-4c25-acf6-bbc8be552fc5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:132: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "Downloading 'Phi-3-mini-4k-instruct-fp16.gguf' to 'models/.huggingface/download/Phi-3-mini-4k-instruct-fp16.gguf.5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3.incomplete'\n",
            "Phi-3-mini-4k-instruct-fp16.gguf: 100% 7.64G/7.64G [01:21<00:00, 93.6MB/s]\n",
            "Download complete. Moving file to models/Phi-3-mini-4k-instruct-fp16.gguf\n",
            "models/Phi-3-mini-4k-instruct-fp16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP = 0\n",
        "N_CTX = 4096\n",
        "N_GPU_L = -1\n",
        "\n",
        "llm_phi3 = LlamaCpp(\n",
        "    model_path=\"/content/models/Phi-3-mini-4k-instruct-fp16.gguf\",\n",
        "    temperature=TEMP,\n",
        "    n_ctx=N_CTX,\n",
        "    n_gpu_layers = N_GPU_L,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UWQXosB9VFE",
        "outputId": "56ba3f4c-a86e-48c1-ee29-b91328e1c1fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 195 tensors from /content/models/Phi-3-mini-4k-instruct-fp16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
            "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  130 tensors\n",
            "llm_load_vocab: special tokens cache size = 323\n",
            "llm_load_vocab: token to piece cache size = 0.1687 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = phi3\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32064\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 3072\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 96\n",
            "llm_load_print_meta: n_embd_head_k    = 96\n",
            "llm_load_print_meta: n_embd_head_v    = 96\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
            "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 8192\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 3B\n",
            "llm_load_print_meta: model ftype      = F16\n",
            "llm_load_print_meta: model params     = 3.82 B\n",
            "llm_load_print_meta: model size       = 7.12 GiB (16.00 BPW) \n",
            "llm_load_print_meta: general.name     = Phi3\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   187.88 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  7100.64 MiB\n",
            "....................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1536.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1536.00 MiB, K (f16):  768.00 MiB, V (f16):  768.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =    18.75 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.88 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1286\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'general.name': 'Phi3', 'tokenizer.ggml.pre': 'default', 'phi3.embedding_length': '3072', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.feed_forward_length': '8192', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.rope.dimension_count': '96', 'tokenizer.ggml.model': 'llama', 'general.file_type': '1'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
            "' + message['content'] + '<|end|>' + '\n",
            "' + '<|assistant|>' + '\n",
            "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
            "'}}{% endif %}{% endfor %}\n",
            "Using chat eos_token: <|endoftext|>\n",
            "Using chat bos_token: <s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = pd.read_fwf(\"https://raw.githubusercontent.com/winterForestStump/thesis/main/questions/questions_ver2.txt\", names=['question'])\n",
        "questions.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA87mjiJ9VFE",
        "outputId": "cdde778a-cf50-401d-bbd7-37c331d77ef7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35 entries, 0 to 34\n",
            "Data columns (total 1 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   question  35 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 408.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"BAAI/bge-small-en-v1.5\"\n",
        "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
        "\n",
        "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={'device': 'cuda'}, #gpu\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCpr-Zyg9VFG",
        "outputId": "725f830b-229a-41b5-841d-e54e9664f3f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation"
      ],
      "metadata": {
        "id": "Dt9-e49TRv0n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Metadata company name\n",
        "prompt_metadata = PromptTemplate(\n",
        "template=\"\"\"\n",
        "  <|assistant|> You are tasked with identifying the correct spelling of the company name mentioned in the user's input by searching through the list of fixed company names in the database metadata.\n",
        "  This precise spelling will be crucial for SQL filtering purposes. \\n\n",
        "  Provide a concise response containing only the correct company name. \\n\n",
        "  Please format your response as a JSON object with only a single key 'company', WITHOUT any additional commentary. <|end|>\n",
        "  <|user|> Database metadata with company names: \\n\\n {metadata_list} \\n\\n User question: {name_of_the_company} <|end|>\n",
        "  <|assistant|>\n",
        "\"\"\",\n",
        "input_variables=[\"name_of_the_company\", \"metadata_list\"])\n",
        "\n",
        "retrieval_metadata = prompt_metadata | llm_phi3 | JsonOutputParser()"
      ],
      "metadata": {
        "id": "kJanQu9w9VFH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persistent_client = chromadb.PersistentClient('/content/drive/MyDrive/Thesis/chromadb')\n",
        "collection = persistent_client.get_or_create_collection(\"reports_l2\")\n",
        "fs = LocalFileStore('/content/drive/MyDrive/Thesis/reports_store_location')\n",
        "store = create_kv_docstore(fs)\n",
        "vectorstore = Chroma(client = persistent_client,\n",
        "                     collection_name=\"reports_l2\",\n",
        "                     embedding_function=bge_embeddings,\n",
        "                     persist_directory='/content/drive/MyDrive/Thesis/chromadb')\n",
        "vectorstore.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncJiWt939VFI",
        "outputId": "72c3e575-57e2-4502-8215-3ae92ce6b9a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = vectorstore.get()['metadatas']\n",
        "metadata_list = []\n",
        "for i in range(len(metadata)):\n",
        "  metadata_list.append(metadata[i]['company'])\n",
        "metadata_list = list(set(metadata_list))"
      ],
      "metadata": {
        "id": "Xcq5E9K19VFI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader\n",
        "llm_retrieval = llm_phi3\n",
        "\n",
        "prompt_retrieval_grader = PromptTemplate(\n",
        "    template=\"\"\"<|assistant|> You are a grader assessing relevance of a retrieved document to a user question.\n",
        "    If the document contains information related to the user question, grade it as relevant. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.<|end|>\n",
        "    <|user|> Here is the retrieved document: {document}\\n Here is the user question: {question} <|end|>\n",
        "    <|assistant|>\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader = prompt_retrieval_grader | llm_retrieval | StrOutputParser()"
      ],
      "metadata": {
        "id": "aEFPpe0M9VFL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate\n",
        "llm_generate = llm_phi3\n",
        "\n",
        "prompt_generate = PromptTemplate(\n",
        "    template=\"\"\"<|assistant|> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
        "    If you don't know the answer, just say that you don't know. Keep the answer concise <|end|>\n",
        "    <|user|> Question: {question}. \\n Context: {documents} \\n Answer: <|end|>\n",
        "    <|assistant|>\"\"\",\n",
        "    input_variables=[\"question\", \"documents\"],\n",
        ")\n",
        "\n",
        "rag_chain = prompt_generate | llm_generate | StrOutputParser()"
      ],
      "metadata": {
        "id": "hdn828f89VFM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Hallucination Grader\n",
        "llm_hallucination_grader = llm_phi3\n",
        "\n",
        "# Prompt\n",
        "prompt_hallucination_grader = PromptTemplate(\n",
        "    template=\"\"\" <|assistant|> You are a grader assessing whether an answer is grounded in / supported by a set of facts.\n",
        "    Give a binary 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts.<|end|>\n",
        "    <|user|> Here are the facts: {documents} \\n Here is the answer: {generation}  <|end|>\n",
        "    <|assistant|>\"\"\",\n",
        "    input_variables=[\"generation\", \"documents\"],\n",
        ")\n",
        "\n",
        "hallucination_grader = prompt_hallucination_grader | llm_hallucination_grader | StrOutputParser()"
      ],
      "metadata": {
        "id": "ZIub6HTG9VFM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Answer Grader\n",
        "llm_answer_grader = llm_phi3\n",
        "\n",
        "# Prompt\n",
        "prompt_answer_grader = PromptTemplate(\n",
        "    template=\"\"\"<|assistant|> You are a grader assessing whether an answer is useful to resolve a question.\n",
        "    Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question.<|end|>\n",
        "    <|user|> Here is the answer: {generation} \\n Here is the question: {question} <|end|>\n",
        "    <|assistant|>\"\"\",\n",
        "    input_variables=[\"generation\", \"question\"],\n",
        ")\n",
        "\n",
        "answer_grader = prompt_answer_grader | llm_answer_grader | StrOutputParser()"
      ],
      "metadata": {
        "id": "vWM7EZxJ9VFN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company_names = [#'coca cola', 'nike', '3M', 'amazon',\n",
        "                 #'adobe',\n",
        "                 #'amd',\n",
        "                 #'bestbuy',\n",
        "                 'jpmorgan', 'locheed martin', 'microsoft', 'paypal', 'verizon', 'walmart']"
      ],
      "metadata": {
        "id": "7xZMFSSNRCjl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PAR_CHUNKS = 20\n",
        "N_DOCS_RETURN = 2\n",
        "\n",
        "results_list = []\n",
        "\n",
        "for company_name in company_names:\n",
        "  for i in tqdm(range(len(questions))):\n",
        "    company = retrieval_metadata.invoke({\"name_of_the_company\": company_name, \"metadata_list\": metadata_list})\n",
        "\n",
        "    parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
        "    child_splitter = RecursiveCharacterTextSplitter(chunk_size=256)\n",
        "    big_chunks_retriever = ParentDocumentRetriever(\n",
        "      vectorstore=vectorstore, docstore=store, child_splitter=child_splitter, parent_splitter=parent_splitter,\n",
        "      search_kwargs={'filter': {'company': company['company']}, 'k': NUM_PAR_CHUNKS})\n",
        "\n",
        "    query = questions['question'][i]\n",
        "    passage = big_chunks_retriever.invoke(query)\n",
        "    texts = []\n",
        "    for i in range(len(passage)):\n",
        "      texts.append([query, passage[i].page_content])\n",
        "\n",
        "    scores = reranker.compute_score(texts)\n",
        "    combined = list(zip(texts, scores))\n",
        "    sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)\n",
        "    top_texts = [item[0] for item in sorted_combined[:N_DOCS_RETURN]]\n",
        "    docs = [inner_list[1] for inner_list in top_texts if len(inner_list)>1]\n",
        "\n",
        "    retrieval_grade = retrieval_grader.invoke({\"question\": query, \"document\": docs})\n",
        "    generation = rag_chain.invoke({\"context\": docs, \"question\": query})\n",
        "    hallucination_grade = hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\n",
        "    answer_grade = answer_grader.invoke({\"question\": query, \"generation\": generation})\n",
        "\n",
        "    results_list.append(pd.DataFrame({\n",
        "          'question': [query],\n",
        "          'response': [generation],\n",
        "          'context': [docs],\n",
        "          'retrieval_grade': [retrieval_grade],\n",
        "          'hallucination_grade': [hallucination_grade],\n",
        "          'answer_grade': [answer_grade]\n",
        "      }))\n",
        "\n",
        "  results = pd.concat(results_list, ignore_index=True)\n",
        "  results.to_json(f'/content/drive/MyDrive/Thesis/rag_evaluation/bge-reranker_x_phi3-4k/eval_{company}.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro7GaCz69VFO",
        "outputId": "30f7f2c0-21eb-40de-bee4-b29f23954916"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "llama_print_timings: prompt eval time =    4543.61 ms /   856 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
            "llama_print_timings:        eval time =      80.58 ms /     2 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    4637.03 ms /   858 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      57.33 ms /   104 runs   (    0.55 ms per token,  1814.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4416.88 ms /   824 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
            "llama_print_timings:        eval time =    4105.65 ms /   103 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    8651.83 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      45.65 ms /    61 runs   (    0.75 ms per token,  1336.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4863.96 ms /   911 tokens (    5.34 ms per token,   187.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2429.33 ms /    60 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    7396.14 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1470.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     974.18 ms /   191 tokens (    5.10 ms per token,   196.06 tokens per second)\n",
            "llama_print_timings:        eval time =      37.94 ms /     1 runs   (   37.94 ms per token,    26.36 tokens per second)\n",
            "llama_print_timings:       total time =    1017.91 ms /   192 tokens\n",
            " 94%|█████████▍| 33/35 [22:42<01:17, 38.66s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.05 ms /    14 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2261.04 ms /   437 tokens (    5.17 ms per token,   193.27 tokens per second)\n",
            "llama_print_timings:        eval time =     504.36 ms /    13 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2785.54 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1699.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4624.94 ms /   872 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =      39.13 ms /     1 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    4676.37 ms /   873 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.23 ms /   128 runs   (    0.57 ms per token,  1747.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4497.83 ms /   839 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
            "llama_print_timings:        eval time =    5066.21 ms /   127 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    9725.60 ms /   966 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      87.42 ms /   118 runs   (    0.74 ms per token,  1349.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5131.87 ms /   955 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4757.43 ms /   117 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =   10083.22 ms /  1072 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.37 ms /     2 runs   (    0.69 ms per token,  1458.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1080.20 ms /   210 tokens (    5.14 ms per token,   194.41 tokens per second)\n",
            "llama_print_timings:        eval time =      37.88 ms /     1 runs   (   37.88 ms per token,    26.40 tokens per second)\n",
            "llama_print_timings:       total time =    1124.06 ms /   211 tokens\n",
            " 97%|█████████▋| 34/35 [23:13<00:36, 36.41s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       7.55 ms /    14 runs   (    0.54 ms per token,  1854.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.87 ms /   437 tokens (    5.13 ms per token,   194.84 tokens per second)\n",
            "llama_print_timings:        eval time =     504.41 ms /    13 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2766.24 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.51 ms /     2 runs   (    0.76 ms per token,  1322.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4348.89 ms /   811 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =      39.56 ms /     1 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    4402.75 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     101.08 ms /   166 runs   (    0.61 ms per token,  1642.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4122.78 ms /   778 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
            "llama_print_timings:        eval time =    6553.17 ms /   165 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =   10905.69 ms /   943 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      44.05 ms /    77 runs   (    0.57 ms per token,  1747.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5002.05 ms /   923 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3054.55 ms /    76 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    8159.38 ms /   999 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1853.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1284.50 ms /   256 tokens (    5.02 ms per token,   199.30 tokens per second)\n",
            "llama_print_timings:        eval time =      75.96 ms /     2 runs   (   37.98 ms per token,    26.33 tokens per second)\n",
            "llama_print_timings:       total time =    1365.60 ms /   258 tokens\n",
            "100%|██████████| 35/35 [23:46<00:00, 40.75s/it]\n",
            "  0%|          | 0/35 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    18 runs   (    0.54 ms per token,  1842.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.08 ms /   434 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
            "llama_print_timings:        eval time =     657.35 ms /    17 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2931.14 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     130.46 ms /   231 runs   (    0.56 ms per token,  1770.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10899.78 ms /  1887 tokens (    5.78 ms per token,   173.12 tokens per second)\n",
            "llama_print_timings:        eval time =   10022.53 ms /   230 runs   (   43.58 ms per token,    22.95 tokens per second)\n",
            "llama_print_timings:       total time =   21248.80 ms /  2117 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      88.51 ms /   147 runs   (    0.60 ms per token,  1660.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10741.85 ms /  1854 tokens (    5.79 ms per token,   172.60 tokens per second)\n",
            "llama_print_timings:        eval time =    6343.92 ms /   146 runs   (   43.45 ms per token,    23.01 tokens per second)\n",
            "llama_print_timings:       total time =   17312.44 ms /  2000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     144.02 ms /   256 runs   (    0.56 ms per token,  1777.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11606.52 ms /  1987 tokens (    5.84 ms per token,   171.20 tokens per second)\n",
            "llama_print_timings:        eval time =   11197.79 ms /   255 runs   (   43.91 ms per token,    22.77 tokens per second)\n",
            "llama_print_timings:       total time =   23197.79 ms /  2242 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.26 ms /     2 runs   (    0.63 ms per token,  1593.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1159.24 ms /   231 tokens (    5.02 ms per token,   199.27 tokens per second)\n",
            "llama_print_timings:        eval time =      37.17 ms /     1 runs   (   37.17 ms per token,    26.90 tokens per second)\n",
            "llama_print_timings:       total time =    1203.03 ms /   232 tokens\n",
            "  3%|▎         | 1/35 [01:12<41:01, 72.41s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.38 ms /    18 runs   (    0.69 ms per token,  1453.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.72 ms /   434 tokens (    5.16 ms per token,   193.69 tokens per second)\n",
            "llama_print_timings:        eval time =     668.40 ms /    17 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2937.91 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     156.84 ms /   256 runs   (    0.61 ms per token,  1632.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9571.56 ms /  1688 tokens (    5.67 ms per token,   176.36 tokens per second)\n",
            "llama_print_timings:        eval time =   10997.17 ms /   256 runs   (   42.96 ms per token,    23.28 tokens per second)\n",
            "llama_print_timings:       total time =   20956.23 ms /  1944 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      57.46 ms /   110 runs   (    0.52 ms per token,  1914.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9447.92 ms /  1656 tokens (    5.71 ms per token,   175.28 tokens per second)\n",
            "llama_print_timings:        eval time =    4655.47 ms /   109 runs   (   42.71 ms per token,    23.41 tokens per second)\n",
            "llama_print_timings:       total time =   14254.79 ms /  1765 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     135.08 ms /   239 runs   (    0.57 ms per token,  1769.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10057.90 ms /  1748 tokens (    5.75 ms per token,   173.79 tokens per second)\n",
            "llama_print_timings:        eval time =   10282.59 ms /   238 runs   (   43.20 ms per token,    23.15 tokens per second)\n",
            "llama_print_timings:       total time =   20706.40 ms /  1986 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.04 ms /     2 runs   (    0.52 ms per token,  1915.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     998.52 ms /   198 tokens (    5.04 ms per token,   198.29 tokens per second)\n",
            "llama_print_timings:        eval time =      37.16 ms /     1 runs   (   37.16 ms per token,    26.91 tokens per second)\n",
            "llama_print_timings:       total time =    1040.45 ms /   199 tokens\n",
            "  6%|▌         | 2/35 [02:17<37:26, 68.09s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.38 ms /    18 runs   (    0.58 ms per token,  1733.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.04 ms /   434 tokens (    5.17 ms per token,   193.49 tokens per second)\n",
            "llama_print_timings:        eval time =     660.47 ms /    17 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2930.01 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.56 ms /     2 runs   (    0.78 ms per token,  1279.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6156.93 ms /  1128 tokens (    5.46 ms per token,   183.21 tokens per second)\n",
            "llama_print_timings:        eval time =      40.76 ms /     1 runs   (   40.76 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    6217.36 ms /  1129 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      52.64 ms /    93 runs   (    0.57 ms per token,  1766.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5926.22 ms /  1095 tokens (    5.41 ms per token,   184.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3738.63 ms /    92 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    9783.26 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.57 ms /     2 runs   (    0.79 ms per token,  1271.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6492.57 ms /  1180 tokens (    5.50 ms per token,   181.75 tokens per second)\n",
            "llama_print_timings:        eval time =      40.23 ms /     1 runs   (   40.23 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    6551.65 ms /  1181 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     876.30 ms /   171 tokens (    5.12 ms per token,   195.14 tokens per second)\n",
            "llama_print_timings:        eval time =      38.50 ms /     1 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =     918.72 ms /   172 tokens\n",
            "  9%|▊         | 3/35 [02:47<27:04, 50.75s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    18 runs   (    0.56 ms per token,  1793.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.22 ms /   434 tokens (    5.17 ms per token,   193.56 tokens per second)\n",
            "llama_print_timings:        eval time =     658.75 ms /    17 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2925.16 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     113.13 ms /   200 runs   (    0.57 ms per token,  1767.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5825.80 ms /  1066 tokens (    5.47 ms per token,   182.98 tokens per second)\n",
            "llama_print_timings:        eval time =    8116.56 ms /   199 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =   14201.33 ms /  1265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      84.44 ms /   154 runs   (    0.55 ms per token,  1823.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5609.85 ms /  1032 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
            "llama_print_timings:        eval time =    6265.97 ms /   154 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =   12072.66 ms /  1186 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      40.22 ms /    65 runs   (    0.62 ms per token,  1616.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6461.38 ms /  1176 tokens (    5.49 ms per token,   182.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2630.20 ms /    64 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =    9186.57 ms /  1240 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1198.62 ms /   235 tokens (    5.10 ms per token,   196.06 tokens per second)\n",
            "llama_print_timings:        eval time =      37.20 ms /     1 runs   (   37.20 ms per token,    26.88 tokens per second)\n",
            "llama_print_timings:       total time =    1240.98 ms /   236 tokens\n",
            " 11%|█▏        | 4/35 [03:31<24:50, 48.07s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.86 ms /    18 runs   (    0.55 ms per token,  1825.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.98 ms /   434 tokens (    5.18 ms per token,   193.15 tokens per second)\n",
            "llama_print_timings:        eval time =     658.73 ms /    17 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2928.79 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      35.60 ms /    64 runs   (    0.56 ms per token,  1797.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7910.73 ms /  1416 tokens (    5.59 ms per token,   179.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2628.99 ms /    63 runs   (   41.73 ms per token,    23.96 tokens per second)\n",
            "llama_print_timings:       total time =   10630.19 ms /  1479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      45.94 ms /    83 runs   (    0.55 ms per token,  1806.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7706.33 ms /  1383 tokens (    5.57 ms per token,   179.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3415.05 ms /    82 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
            "llama_print_timings:       total time =   11236.17 ms /  1465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      51.73 ms /    71 runs   (    0.73 ms per token,  1372.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8121.38 ms /  1456 tokens (    5.58 ms per token,   179.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2995.37 ms /    71 runs   (   42.19 ms per token,    23.70 tokens per second)\n",
            "llama_print_timings:       total time =   11248.44 ms /  1527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.56 ms per token,  1776.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     830.61 ms /   162 tokens (    5.13 ms per token,   195.04 tokens per second)\n",
            "llama_print_timings:        eval time =      37.42 ms /     1 runs   (   37.42 ms per token,    26.73 tokens per second)\n",
            "llama_print_timings:       total time =     872.93 ms /   163 tokens\n",
            " 14%|█▍        | 5/35 [04:12<22:42, 45.41s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    18 runs   (    0.53 ms per token,  1891.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.24 ms /   434 tokens (    5.17 ms per token,   193.56 tokens per second)\n",
            "llama_print_timings:        eval time =     659.92 ms /    17 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2924.48 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      83.38 ms /   153 runs   (    0.54 ms per token,  1834.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10604.44 ms /  1834 tokens (    5.78 ms per token,   172.95 tokens per second)\n",
            "llama_print_timings:        eval time =    6557.97 ms /   152 runs   (   43.14 ms per token,    23.18 tokens per second)\n",
            "llama_print_timings:       total time =   17370.48 ms /  1986 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      50.28 ms /    87 runs   (    0.58 ms per token,  1730.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10367.59 ms /  1800 tokens (    5.76 ms per token,   173.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3744.99 ms /    87 runs   (   43.05 ms per token,    23.23 tokens per second)\n",
            "llama_print_timings:       total time =   14241.29 ms /  1887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     111.67 ms /   177 runs   (    0.63 ms per token,  1585.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10850.35 ms /  1870 tokens (    5.80 ms per token,   172.34 tokens per second)\n",
            "llama_print_timings:        eval time =    7656.48 ms /   176 runs   (   43.50 ms per token,    22.99 tokens per second)\n",
            "llama_print_timings:       total time =   18796.86 ms /  2046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.09 ms /     2 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     878.04 ms /   175 tokens (    5.02 ms per token,   199.31 tokens per second)\n",
            "llama_print_timings:        eval time =      37.89 ms /     1 runs   (   37.89 ms per token,    26.39 tokens per second)\n",
            "llama_print_timings:       total time =     920.24 ms /   176 tokens\n",
            " 17%|█▋        | 6/35 [05:09<23:56, 49.52s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.12 ms /    18 runs   (    0.56 ms per token,  1778.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.90 ms /   434 tokens (    5.17 ms per token,   193.59 tokens per second)\n",
            "llama_print_timings:        eval time =     658.14 ms /    17 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2923.85 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      48.53 ms /    86 runs   (    0.56 ms per token,  1771.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12689.48 ms /  2152 tokens (    5.90 ms per token,   169.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3785.70 ms /    86 runs   (   44.02 ms per token,    22.72 tokens per second)\n",
            "llama_print_timings:       total time =   16602.91 ms /  2238 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      25.63 ms /    48 runs   (    0.53 ms per token,  1872.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12474.77 ms /  2120 tokens (    5.88 ms per token,   169.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2063.87 ms /    47 runs   (   43.91 ms per token,    22.77 tokens per second)\n",
            "llama_print_timings:       total time =   14618.49 ms /  2167 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     158.91 ms /   256 runs   (    0.62 ms per token,  1610.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12756.76 ms /  2157 tokens (    5.91 ms per token,   169.09 tokens per second)\n",
            "llama_print_timings:        eval time =   11321.72 ms /   255 runs   (   44.40 ms per token,    22.52 tokens per second)\n",
            "llama_print_timings:       total time =   24493.52 ms /  2412 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     633.51 ms /   128 tokens (    4.95 ms per token,   202.05 tokens per second)\n",
            "llama_print_timings:        eval time =      75.39 ms /     2 runs   (   37.70 ms per token,    26.53 tokens per second)\n",
            "llama_print_timings:       total time =     712.71 ms /   130 tokens\n",
            " 20%|██        | 7/35 [06:11<25:01, 53.63s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.31 ms /    18 runs   (    0.57 ms per token,  1746.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.57 ms /   434 tokens (    5.18 ms per token,   193.18 tokens per second)\n",
            "llama_print_timings:        eval time =     656.43 ms /    17 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2929.30 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2127.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5685.93 ms /  1053 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
            "llama_print_timings:        eval time =      39.94 ms /     1 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5740.31 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     106.25 ms /   168 runs   (    0.63 ms per token,  1581.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5514.30 ms /  1020 tokens (    5.41 ms per token,   184.97 tokens per second)\n",
            "llama_print_timings:        eval time =    6813.97 ms /   167 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =   12570.37 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     146.19 ms /   232 runs   (    0.63 ms per token,  1587.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6413.21 ms /  1172 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
            "llama_print_timings:        eval time =    9558.04 ms /   231 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   16313.33 ms /  1403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.06 ms /     2 runs   (    0.53 ms per token,  1892.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1287.17 ms /   254 tokens (    5.07 ms per token,   197.33 tokens per second)\n",
            "llama_print_timings:        eval time =      37.40 ms /     1 runs   (   37.40 ms per token,    26.74 tokens per second)\n",
            "llama_print_timings:       total time =    1328.90 ms /   255 tokens\n",
            " 23%|██▎       | 8/35 [06:55<22:40, 50.38s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.54 ms /    18 runs   (    0.70 ms per token,  1435.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.11 ms /   434 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
            "llama_print_timings:        eval time =     668.21 ms /    17 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2947.21 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4569.82 ms /   858 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
            "llama_print_timings:        eval time =      39.00 ms /     1 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4621.81 ms /   859 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      69.71 ms /    96 runs   (    0.73 ms per token,  1377.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4370.61 ms /   824 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3845.64 ms /    96 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    8367.05 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.65 ms /    73 runs   (    0.58 ms per token,  1711.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4855.23 ms /   908 tokens (    5.35 ms per token,   187.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2886.60 ms /    72 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    7836.86 ms /   980 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.53 ms /     2 runs   (    0.76 ms per token,  1309.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     919.46 ms /   179 tokens (    5.14 ms per token,   194.68 tokens per second)\n",
            "llama_print_timings:        eval time =      38.17 ms /     1 runs   (   38.17 ms per token,    26.20 tokens per second)\n",
            "llama_print_timings:       total time =     962.94 ms /   180 tokens\n",
            " 26%|██▌       | 9/35 [07:25<19:08, 44.17s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.17 ms /    18 runs   (    0.68 ms per token,  1479.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2276.11 ms /   434 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =     666.50 ms /    17 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2976.15 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     104.67 ms /   190 runs   (    0.55 ms per token,  1815.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10501.26 ms /  1823 tokens (    5.76 ms per token,   173.60 tokens per second)\n",
            "llama_print_timings:        eval time =    8180.29 ms /   189 runs   (   43.28 ms per token,    23.10 tokens per second)\n",
            "llama_print_timings:       total time =   18944.53 ms /  2012 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     145.95 ms /   239 runs   (    0.61 ms per token,  1637.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10331.50 ms /  1790 tokens (    5.77 ms per token,   173.26 tokens per second)\n",
            "llama_print_timings:        eval time =   10320.42 ms /   238 runs   (   43.36 ms per token,    23.06 tokens per second)\n",
            "llama_print_timings:       total time =   21031.19 ms /  2028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      84.05 ms /   142 runs   (    0.59 ms per token,  1689.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11767.06 ms /  2011 tokens (    5.85 ms per token,   170.90 tokens per second)\n",
            "llama_print_timings:        eval time =    6175.77 ms /   141 runs   (   43.80 ms per token,    22.83 tokens per second)\n",
            "llama_print_timings:       total time =   18161.87 ms /  2152 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.06 ms /     2 runs   (    0.53 ms per token,  1893.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1656.83 ms /   327 tokens (    5.07 ms per token,   197.36 tokens per second)\n",
            "llama_print_timings:        eval time =      37.57 ms /     1 runs   (   37.57 ms per token,    26.62 tokens per second)\n",
            "llama_print_timings:       total time =    1702.27 ms /   328 tokens\n",
            " 29%|██▊       | 10/35 [08:34<21:31, 51.67s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.03 ms /    18 runs   (    0.56 ms per token,  1793.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.48 ms /   434 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
            "llama_print_timings:        eval time =     656.11 ms /    17 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2921.52 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     146.49 ms /   256 runs   (    0.57 ms per token,  1747.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12695.16 ms /  2154 tokens (    5.89 ms per token,   169.67 tokens per second)\n",
            "llama_print_timings:        eval time =   11300.01 ms /   255 runs   (   44.31 ms per token,    22.57 tokens per second)\n",
            "llama_print_timings:       total time =   24373.23 ms /  2409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      52.99 ms /    74 runs   (    0.72 ms per token,  1396.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12502.21 ms /  2120 tokens (    5.90 ms per token,   169.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3285.79 ms /    74 runs   (   44.40 ms per token,    22.52 tokens per second)\n",
            "llama_print_timings:       total time =   15932.16 ms /  2194 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      55.09 ms /    68 runs   (    0.81 ms per token,  1234.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12921.92 ms /  2180 tokens (    5.93 ms per token,   168.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2977.50 ms /    67 runs   (   44.44 ms per token,    22.50 tokens per second)\n",
            "llama_print_timings:       total time =   16044.70 ms /  2247 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.56 ms per token,  1771.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     802.99 ms /   159 tokens (    5.05 ms per token,   198.01 tokens per second)\n",
            "llama_print_timings:        eval time =      37.58 ms /     1 runs   (   37.58 ms per token,    26.61 tokens per second)\n",
            "llama_print_timings:       total time =     844.38 ms /   160 tokens\n",
            " 31%|███▏      | 11/35 [09:39<22:19, 55.81s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    18 runs   (    0.54 ms per token,  1861.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.76 ms /   434 tokens (    5.17 ms per token,   193.43 tokens per second)\n",
            "llama_print_timings:        eval time =     655.77 ms /    17 runs   (   38.57 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2922.26 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     152.28 ms /   256 runs   (    0.59 ms per token,  1681.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =   14772.33 ms /  2450 tokens (    6.03 ms per token,   165.85 tokens per second)\n",
            "llama_print_timings:        eval time =   12556.06 ms /   255 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
            "llama_print_timings:       total time =   27741.03 ms /  2705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     146.34 ms /   256 runs   (    0.57 ms per token,  1749.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =   14540.00 ms /  2416 tokens (    6.02 ms per token,   166.16 tokens per second)\n",
            "llama_print_timings:        eval time =   12486.54 ms /   256 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
            "llama_print_timings:       total time =   27434.46 ms /  2672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     143.54 ms /   256 runs   (    0.56 ms per token,  1783.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16313.33 ms /  2664 tokens (    6.12 ms per token,   163.30 tokens per second)\n",
            "llama_print_timings:        eval time =   12875.10 ms /   255 runs   (   50.49 ms per token,    19.81 tokens per second)\n",
            "llama_print_timings:       total time =   29595.12 ms /  2919 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.01 ms /     2 runs   (    0.50 ms per token,  1984.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1695.51 ms /   336 tokens (    5.05 ms per token,   198.17 tokens per second)\n",
            "llama_print_timings:        eval time =      77.17 ms /     2 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    1778.82 ms /   338 tokens\n",
            " 34%|███▍      | 12/35 [11:12<25:45, 67.20s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.02 ms /    18 runs   (    0.67 ms per token,  1497.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2238.81 ms /   434 tokens (    5.16 ms per token,   193.85 tokens per second)\n",
            "llama_print_timings:        eval time =     656.97 ms /    17 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2924.55 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     146.85 ms /   256 runs   (    0.57 ms per token,  1743.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =   14757.74 ms /  2452 tokens (    6.02 ms per token,   166.15 tokens per second)\n",
            "llama_print_timings:        eval time =   12625.98 ms /   255 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
            "llama_print_timings:       total time =   27795.36 ms /  2707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     144.70 ms /   256 runs   (    0.57 ms per token,  1769.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =   14616.94 ms /  2419 tokens (    6.04 ms per token,   165.49 tokens per second)\n",
            "llama_print_timings:        eval time =   12455.71 ms /   255 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
            "llama_print_timings:       total time =   27486.13 ms /  2674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     142.67 ms /   256 runs   (    0.56 ms per token,  1794.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16277.20 ms /  2658 tokens (    6.12 ms per token,   163.30 tokens per second)\n",
            "llama_print_timings:        eval time =   12831.55 ms /   255 runs   (   50.32 ms per token,    19.87 tokens per second)\n",
            "llama_print_timings:       total time =   29516.32 ms /  2913 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      21.14 ms /    41 runs   (    0.52 ms per token,  1939.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1732.93 ms /   339 tokens (    5.11 ms per token,   195.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.61 ms /    40 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    3314.69 ms /   379 tokens\n",
            " 37%|███▋      | 13/35 [12:49<27:57, 76.25s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.89 ms /    18 runs   (    0.55 ms per token,  1819.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.28 ms /   434 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
            "llama_print_timings:        eval time =     657.06 ms /    17 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2929.72 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.14 ms /     2 runs   (    0.57 ms per token,  1757.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5443.14 ms /  1012 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
            "llama_print_timings:        eval time =      39.47 ms /     1 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    5496.00 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      41.84 ms /    55 runs   (    0.76 ms per token,  1314.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5279.04 ms /   979 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2196.80 ms /    54 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    7577.30 ms /  1033 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     139.46 ms /   217 runs   (    0.64 ms per token,  1556.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5518.21 ms /  1023 tokens (    5.39 ms per token,   185.39 tokens per second)\n",
            "llama_print_timings:        eval time =    8840.26 ms /   216 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   14693.46 ms /  1239 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.04 ms /     2 runs   (    0.52 ms per token,  1926.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     678.30 ms /   136 tokens (    4.99 ms per token,   200.50 tokens per second)\n",
            "llama_print_timings:        eval time =      37.36 ms /     1 runs   (   37.36 ms per token,    26.77 tokens per second)\n",
            "llama_print_timings:       total time =     728.10 ms /   137 tokens\n",
            " 40%|████      | 14/35 [13:26<22:30, 64.29s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    18 runs   (    0.53 ms per token,  1884.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.66 ms /   434 tokens (    5.18 ms per token,   193.18 tokens per second)\n",
            "llama_print_timings:        eval time =     659.58 ms /    17 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2928.38 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      54.93 ms /    92 runs   (    0.60 ms per token,  1674.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4907.44 ms /   906 tokens (    5.42 ms per token,   184.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3650.65 ms /    91 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    8681.38 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      82.17 ms /   121 runs   (    0.68 ms per token,  1472.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4629.83 ms /   872 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4886.81 ms /   121 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    9714.64 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1689.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5298.88 ms /   984 tokens (    5.39 ms per token,   185.70 tokens per second)\n",
            "llama_print_timings:        eval time =      80.75 ms /     2 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    5394.20 ms /   986 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.56 ms per token,  1773.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1002.76 ms /   200 tokens (    5.01 ms per token,   199.45 tokens per second)\n",
            "llama_print_timings:        eval time =      37.59 ms /     1 runs   (   37.59 ms per token,    26.60 tokens per second)\n",
            "llama_print_timings:       total time =    1044.98 ms /   201 tokens\n",
            " 43%|████▎     | 15/35 [14:00<18:21, 55.07s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    18 runs   (    0.54 ms per token,  1865.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.13 ms /   434 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
            "llama_print_timings:        eval time =     656.60 ms /    17 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2922.68 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.23 ms /    81 runs   (    0.58 ms per token,  1715.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4708.08 ms /   887 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3197.01 ms /    80 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    8005.99 ms /   967 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     121.22 ms /   202 runs   (    0.60 ms per token,  1666.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4585.75 ms /   854 tokens (    5.37 ms per token,   186.23 tokens per second)\n",
            "llama_print_timings:        eval time =    8060.08 ms /   201 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =   12913.19 ms /  1055 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.57 ms /     2 runs   (    0.78 ms per token,  1277.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5639.31 ms /  1034 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
            "llama_print_timings:        eval time =      39.83 ms /     1 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    5695.96 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1498.92 ms /   294 tokens (    5.10 ms per token,   196.14 tokens per second)\n",
            "llama_print_timings:        eval time =      37.86 ms /     1 runs   (   37.86 ms per token,    26.41 tokens per second)\n",
            "llama_print_timings:       total time =    1543.60 ms /   295 tokens\n",
            " 46%|████▌     | 16/35 [14:36<15:41, 49.53s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.91 ms /    18 runs   (    0.55 ms per token,  1816.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.31 ms /   434 tokens (    5.17 ms per token,   193.46 tokens per second)\n",
            "llama_print_timings:        eval time =     661.60 ms /    17 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2928.93 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.56 ms /     2 runs   (    0.78 ms per token,  1282.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6635.86 ms /  1208 tokens (    5.49 ms per token,   182.04 tokens per second)\n",
            "llama_print_timings:        eval time =      82.65 ms /     2 runs   (   41.33 ms per token,    24.20 tokens per second)\n",
            "llama_print_timings:       total time =    6736.63 ms /  1210 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     165.90 ms /   256 runs   (    0.65 ms per token,  1543.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6415.40 ms /  1176 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
            "llama_print_timings:        eval time =   10562.81 ms /   255 runs   (   41.42 ms per token,    24.14 tokens per second)\n",
            "llama_print_timings:       total time =   17380.96 ms /  1431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     168.19 ms /   256 runs   (    0.66 ms per token,  1522.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7876.01 ms /  1416 tokens (    5.56 ms per token,   179.79 tokens per second)\n",
            "llama_print_timings:        eval time =   10799.70 ms /   256 runs   (   42.19 ms per token,    23.70 tokens per second)\n",
            "llama_print_timings:       total time =   19074.47 ms /  1672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.11 ms /     2 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1740.63 ms /   343 tokens (    5.07 ms per token,   197.05 tokens per second)\n",
            "llama_print_timings:        eval time =      37.76 ms /     1 runs   (   37.76 ms per token,    26.49 tokens per second)\n",
            "llama_print_timings:       total time =    1785.90 ms /   344 tokens\n",
            " 49%|████▊     | 17/35 [15:28<15:01, 50.09s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      13.72 ms /    18 runs   (    0.76 ms per token,  1312.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2263.53 ms /   434 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =     665.23 ms /    17 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2962.09 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.59 ms per token,  1705.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4610.64 ms /   867 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
            "llama_print_timings:        eval time =      39.00 ms /     1 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4662.01 ms /   868 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      66.40 ms /   101 runs   (    0.66 ms per token,  1521.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4463.36 ms /   834 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4003.71 ms /   100 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    8611.87 ms /   934 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      31.70 ms /    53 runs   (    0.60 ms per token,  1671.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4998.74 ms /   932 tokens (    5.36 ms per token,   186.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2087.32 ms /    52 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7159.60 ms /   984 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.51 ms /     2 runs   (    0.76 ms per token,  1321.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     879.54 ms /   174 tokens (    5.05 ms per token,   197.83 tokens per second)\n",
            "llama_print_timings:        eval time =      38.84 ms /     1 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =     924.21 ms /   175 tokens\n",
            " 51%|█████▏    | 18/35 [15:58<12:29, 44.08s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.46 ms /    18 runs   (    0.69 ms per token,  1444.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2277.63 ms /   434 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =     661.79 ms /    17 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2971.30 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.58 ms per token,  1713.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3497.19 ms /   667 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
            "llama_print_timings:        eval time =      38.57 ms /     1 runs   (   38.57 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    3545.80 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.80 ms /    68 runs   (    0.70 ms per token,  1422.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3336.14 ms /   634 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2653.55 ms /    67 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    6099.07 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      49.41 ms /    89 runs   (    0.56 ms per token,  1801.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3691.11 ms /   699 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3478.94 ms /    88 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    7278.48 ms /   787 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2176.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     714.43 ms /   141 tokens (    5.07 ms per token,   197.36 tokens per second)\n",
            "llama_print_timings:        eval time =      37.66 ms /     1 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =     756.29 ms /   142 tokens\n",
            " 54%|█████▍    | 19/35 [16:24<10:18, 38.65s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.35 ms /    18 runs   (    0.63 ms per token,  1586.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2251.16 ms /   434 tokens (    5.19 ms per token,   192.79 tokens per second)\n",
            "llama_print_timings:        eval time =     660.76 ms /    17 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2940.42 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.60 ms per token,  1655.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4530.44 ms /   853 tokens (    5.31 ms per token,   188.28 tokens per second)\n",
            "llama_print_timings:        eval time =      39.15 ms /     1 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4581.18 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      90.74 ms /   129 runs   (    0.70 ms per token,  1421.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4356.24 ms /   820 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =    5145.08 ms /   128 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    9699.19 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.67 ms /    80 runs   (    0.60 ms per token,  1678.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5048.03 ms /   944 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3181.01 ms /    79 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    8332.23 ms /  1023 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.56 ms /     2 runs   (    0.78 ms per token,  1284.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1050.76 ms /   204 tokens (    5.15 ms per token,   194.14 tokens per second)\n",
            "llama_print_timings:        eval time =      37.74 ms /     1 runs   (   37.74 ms per token,    26.49 tokens per second)\n",
            "llama_print_timings:       total time =    1094.61 ms /   205 tokens\n",
            " 57%|█████▋    | 20/35 [16:56<09:10, 36.68s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.09 ms /    18 runs   (    0.67 ms per token,  1488.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.51 ms /   434 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     669.08 ms /    17 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2973.22 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1467.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7777.05 ms /  1395 tokens (    5.57 ms per token,   179.37 tokens per second)\n",
            "llama_print_timings:        eval time =      41.34 ms /     1 runs   (   41.34 ms per token,    24.19 tokens per second)\n",
            "llama_print_timings:       total time =    7837.77 ms /  1396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      19.11 ms /    38 runs   (    0.50 ms per token,  1988.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7601.04 ms /  1362 tokens (    5.58 ms per token,   179.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.79 ms /    37 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
            "llama_print_timings:       total time =    9198.68 ms /  1399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     128.85 ms /   236 runs   (    0.55 ms per token,  1831.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7827.12 ms /  1399 tokens (    5.59 ms per token,   178.74 tokens per second)\n",
            "llama_print_timings:        eval time =    9866.28 ms /   235 runs   (   41.98 ms per token,    23.82 tokens per second)\n",
            "llama_print_timings:       total time =   18009.55 ms /  1634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1719.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     561.48 ms /   109 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
            "llama_print_timings:        eval time =      39.56 ms /     1 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =     606.85 ms /   110 tokens\n",
            " 60%|██████    | 21/35 [17:39<09:00, 38.59s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.28 ms /    18 runs   (    0.68 ms per token,  1465.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2272.17 ms /   434 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
            "llama_print_timings:        eval time =     667.21 ms /    17 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2970.18 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4169.45 ms /   791 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =      39.29 ms /     1 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    4221.41 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.30 ms /   101 runs   (    0.73 ms per token,  1377.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3998.12 ms /   758 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3992.54 ms /   100 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    8159.84 ms /   858 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      40.74 ms /    70 runs   (    0.58 ms per token,  1718.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4532.55 ms /   853 tokens (    5.31 ms per token,   188.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2750.14 ms /    69 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7371.57 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.14 ms /     2 runs   (    0.57 ms per token,  1757.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     878.96 ms /   176 tokens (    4.99 ms per token,   200.24 tokens per second)\n",
            "llama_print_timings:        eval time =      78.45 ms /     2 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =     963.35 ms /   178 tokens\n",
            " 63%|██████▎   | 22/35 [18:06<07:36, 35.13s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.90 ms /    18 runs   (    0.66 ms per token,  1512.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2258.27 ms /   434 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =     665.52 ms /    17 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2953.05 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.27 ms /     2 runs   (    0.64 ms per token,  1573.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5310.84 ms /   989 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =      39.89 ms /     1 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    5363.89 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      16.05 ms /    22 runs   (    0.73 ms per token,  1370.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5156.29 ms /   956 tokens (    5.39 ms per token,   185.40 tokens per second)\n",
            "llama_print_timings:        eval time =     854.37 ms /    21 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    6056.69 ms /   977 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      17.74 ms /    31 runs   (    0.57 ms per token,  1747.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5259.16 ms /   975 tokens (    5.39 ms per token,   185.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1205.67 ms /    30 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    6511.11 ms /  1005 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.11 ms /     2 runs   (    0.55 ms per token,  1805.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     474.38 ms /    95 tokens (    4.99 ms per token,   200.26 tokens per second)\n",
            "llama_print_timings:        eval time =      37.35 ms /     1 runs   (   37.35 ms per token,    26.77 tokens per second)\n",
            "llama_print_timings:       total time =     515.17 ms /    96 tokens\n",
            " 66%|██████▌   | 23/35 [18:31<06:26, 32.21s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    18 runs   (    0.54 ms per token,  1837.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.88 ms /   434 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
            "llama_print_timings:        eval time =     660.48 ms /    17 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2926.73 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.06 ms /     2 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4330.29 ms /   811 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
            "llama_print_timings:        eval time =      39.05 ms /     1 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    4383.69 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      94.50 ms /   146 runs   (    0.65 ms per token,  1544.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4122.43 ms /   778 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
            "llama_print_timings:        eval time =    5798.36 ms /   145 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =   10141.92 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      85.23 ms /   143 runs   (    0.60 ms per token,  1677.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4930.61 ms /   920 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
            "llama_print_timings:        eval time =    5713.03 ms /   142 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =   10830.72 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.60 ms /     2 runs   (    0.80 ms per token,  1246.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1125.12 ms /   220 tokens (    5.11 ms per token,   195.53 tokens per second)\n",
            "llama_print_timings:        eval time =      37.64 ms /     1 runs   (   37.64 ms per token,    26.57 tokens per second)\n",
            "llama_print_timings:       total time =    1168.58 ms /   221 tokens\n",
            " 69%|██████▊   | 24/35 [19:04<05:56, 32.44s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.18 ms /    18 runs   (    0.68 ms per token,  1477.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2268.61 ms /   434 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =     664.10 ms /    17 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2963.21 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      76.38 ms /   113 runs   (    0.68 ms per token,  1479.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8004.95 ms /  1435 tokens (    5.58 ms per token,   179.26 tokens per second)\n",
            "llama_print_timings:        eval time =    4717.33 ms /   112 runs   (   42.12 ms per token,    23.74 tokens per second)\n",
            "llama_print_timings:       total time =   12906.49 ms /  1547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     134.87 ms /   218 runs   (    0.62 ms per token,  1616.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7807.95 ms /  1402 tokens (    5.57 ms per token,   179.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9141.27 ms /   217 runs   (   42.13 ms per token,    23.74 tokens per second)\n",
            "llama_print_timings:       total time =   17279.84 ms /  1619 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      80.26 ms /   133 runs   (    0.60 ms per token,  1657.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9112.07 ms /  1607 tokens (    5.67 ms per token,   176.36 tokens per second)\n",
            "llama_print_timings:        eval time =    5623.10 ms /   132 runs   (   42.60 ms per token,    23.47 tokens per second)\n",
            "llama_print_timings:       total time =   14928.83 ms /  1739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1533.52 ms /   301 tokens (    5.09 ms per token,   196.28 tokens per second)\n",
            "llama_print_timings:        eval time =      37.75 ms /     1 runs   (   37.75 ms per token,    26.49 tokens per second)\n",
            "llama_print_timings:       total time =    1579.87 ms /   302 tokens\n",
            " 71%|███████▏  | 25/35 [19:58<06:28, 38.82s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    18 runs   (    0.55 ms per token,  1815.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.51 ms /   434 tokens (    5.18 ms per token,   193.19 tokens per second)\n",
            "llama_print_timings:        eval time =     660.97 ms /    17 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2932.47 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     113.13 ms /   179 runs   (    0.63 ms per token,  1582.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7700.00 ms /  1384 tokens (    5.56 ms per token,   179.74 tokens per second)\n",
            "llama_print_timings:        eval time =    7467.25 ms /   178 runs   (   41.95 ms per token,    23.84 tokens per second)\n",
            "llama_print_timings:       total time =   15441.96 ms /  1562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      45.24 ms /    86 runs   (    0.53 ms per token,  1900.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7486.87 ms /  1351 tokens (    5.54 ms per token,   180.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3532.11 ms /    85 runs   (   41.55 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =   11132.21 ms /  1436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.40 ms /     2 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7968.70 ms /  1424 tokens (    5.60 ms per token,   178.70 tokens per second)\n",
            "llama_print_timings:        eval time =      41.78 ms /     1 runs   (   41.78 ms per token,    23.93 tokens per second)\n",
            "llama_print_timings:       total time =    8032.04 ms /  1425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      36.25 ms /    64 runs   (    0.57 ms per token,  1765.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     838.39 ms /   168 tokens (    4.99 ms per token,   200.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2434.03 ms /    64 runs   (   38.03 ms per token,    26.29 tokens per second)\n",
            "llama_print_timings:       total time =    3341.41 ms /   232 tokens\n",
            " 74%|███████▍  | 26/35 [20:42<06:03, 40.34s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    18 runs   (    0.54 ms per token,  1852.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.67 ms /   434 tokens (    5.17 ms per token,   193.52 tokens per second)\n",
            "llama_print_timings:        eval time =     658.99 ms /    17 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2924.75 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5311.77 ms /   992 tokens (    5.35 ms per token,   186.75 tokens per second)\n",
            "llama_print_timings:        eval time =      80.66 ms /     2 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5406.71 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      63.74 ms /    85 runs   (    0.75 ms per token,  1333.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5152.09 ms /   960 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3399.62 ms /    84 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    8687.90 ms /  1044 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      32.71 ms /    54 runs   (    0.61 ms per token,  1651.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5651.07 ms /  1046 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2149.37 ms /    53 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    7875.77 ms /  1099 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.55 ms /     2 runs   (    0.77 ms per token,  1291.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     794.71 ms /   154 tokens (    5.16 ms per token,   193.78 tokens per second)\n",
            "llama_print_timings:        eval time =      37.67 ms /     1 runs   (   37.67 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =     837.36 ms /   155 tokens\n",
            " 77%|███████▋  | 27/35 [21:13<05:00, 37.55s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.04 ms /    18 runs   (    0.67 ms per token,  1495.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2270.73 ms /   434 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =     664.73 ms /    17 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2965.51 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4226.44 ms /   797 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =      39.13 ms /     1 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    4276.94 ms /   798 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      82.65 ms /   111 runs   (    0.74 ms per token,  1343.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4040.68 ms /   764 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =    4411.93 ms /   110 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    8632.91 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.79 ms /   126 runs   (    0.59 ms per token,  1707.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4633.39 ms /   872 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
            "llama_print_timings:        eval time =    5051.49 ms /   126 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    9843.92 ms /   998 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.63 ms /     2 runs   (    0.81 ms per token,  1228.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     926.36 ms /   183 tokens (    5.06 ms per token,   197.55 tokens per second)\n",
            "llama_print_timings:        eval time =      38.19 ms /     1 runs   (   38.19 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =     970.92 ms /   184 tokens\n",
            " 80%|████████  | 28/35 [21:43<04:07, 35.31s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.57 ms /    18 runs   (    0.70 ms per token,  1431.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2271.05 ms /   434 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =     664.32 ms /    17 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2966.12 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5462.80 ms /  1016 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =      79.59 ms /     2 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    5556.67 ms /  1018 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      99.25 ms /   165 runs   (    0.60 ms per token,  1662.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5321.24 ms /   984 tokens (    5.41 ms per token,   184.92 tokens per second)\n",
            "llama_print_timings:        eval time =    6636.86 ms /   164 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =   12178.06 ms /  1148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      53.04 ms /    75 runs   (    0.71 ms per token,  1413.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6152.78 ms /  1128 tokens (    5.45 ms per token,   183.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3038.21 ms /    74 runs   (   41.06 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    9311.50 ms /  1202 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1285.46 ms /   256 tokens (    5.02 ms per token,   199.15 tokens per second)\n",
            "llama_print_timings:        eval time =      37.27 ms /     1 runs   (   37.27 ms per token,    26.83 tokens per second)\n",
            "llama_print_timings:       total time =    1328.57 ms /   257 tokens\n",
            " 83%|████████▎ | 29/35 [22:18<03:30, 35.14s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    18 runs   (    0.54 ms per token,  1865.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.96 ms /   434 tokens (    5.18 ms per token,   193.06 tokens per second)\n",
            "llama_print_timings:        eval time =     663.29 ms /    17 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2935.51 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.24 ms /    75 runs   (    0.56 ms per token,  1775.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8011.03 ms /  1427 tokens (    5.61 ms per token,   178.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3091.11 ms /    74 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   11207.11 ms /  1501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     133.58 ms /   249 runs   (    0.54 ms per token,  1864.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7808.98 ms /  1394 tokens (    5.60 ms per token,   178.51 tokens per second)\n",
            "llama_print_timings:        eval time =   10423.45 ms /   248 runs   (   42.03 ms per token,    23.79 tokens per second)\n",
            "llama_print_timings:       total time =   18570.75 ms /  1642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      50.93 ms /    88 runs   (    0.58 ms per token,  1727.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9287.61 ms /  1628 tokens (    5.70 ms per token,   175.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3694.93 ms /    87 runs   (   42.47 ms per token,    23.55 tokens per second)\n",
            "llama_print_timings:       total time =   13110.45 ms /  1715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.32 ms /     2 runs   (    0.66 ms per token,  1510.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1705.68 ms /   334 tokens (    5.11 ms per token,   195.82 tokens per second)\n",
            "llama_print_timings:        eval time =      38.24 ms /     1 runs   (   38.24 ms per token,    26.15 tokens per second)\n",
            "llama_print_timings:       total time =    1751.28 ms /   335 tokens\n",
            " 86%|████████▌ | 30/35 [23:09<03:20, 40.05s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.54 ms /    18 runs   (    0.70 ms per token,  1435.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2277.95 ms /   434 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     669.87 ms /    17 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2980.11 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1728.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5221.51 ms /   976 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
            "llama_print_timings:        eval time =      79.90 ms /     2 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    5314.72 ms /   978 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     107.65 ms /   173 runs   (    0.62 ms per token,  1607.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5080.91 ms /   944 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =    6948.09 ms /   172 runs   (   40.40 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   12269.58 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.34 ms /     2 runs   (    0.67 ms per token,  1492.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5999.16 ms /  1103 tokens (    5.44 ms per token,   183.86 tokens per second)\n",
            "llama_print_timings:        eval time =      40.80 ms /     1 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    6056.33 ms /  1104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.62 ms /     2 runs   (    0.81 ms per token,  1233.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1307.90 ms /   256 tokens (    5.11 ms per token,   195.73 tokens per second)\n",
            "llama_print_timings:        eval time =      76.81 ms /     2 runs   (   38.41 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    1392.20 ms /   258 tokens\n",
            " 89%|████████▊ | 31/35 [23:41<02:30, 37.53s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    18 runs   (    0.55 ms per token,  1814.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.41 ms /   434 tokens (    5.19 ms per token,   192.60 tokens per second)\n",
            "llama_print_timings:        eval time =     661.86 ms /    17 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2939.10 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1670.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5558.86 ms /  1027 tokens (    5.41 ms per token,   184.75 tokens per second)\n",
            "llama_print_timings:        eval time =      40.43 ms /     1 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    5615.34 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      65.12 ms /   109 runs   (    0.60 ms per token,  1673.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5407.87 ms /   994 tokens (    5.44 ms per token,   183.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4370.01 ms /   108 runs   (   40.46 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    9921.11 ms /  1102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.37 ms /     2 runs   (    0.69 ms per token,  1456.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5919.48 ms /  1088 tokens (    5.44 ms per token,   183.80 tokens per second)\n",
            "llama_print_timings:        eval time =      83.07 ms /     2 runs   (   41.53 ms per token,    24.08 tokens per second)\n",
            "llama_print_timings:       total time =    6019.25 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.42 ms /     2 runs   (    0.71 ms per token,  1406.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     968.38 ms /   192 tokens (    5.04 ms per token,   198.27 tokens per second)\n",
            "llama_print_timings:        eval time =      76.36 ms /     2 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    1054.26 ms /   194 tokens\n",
            " 91%|█████████▏| 32/35 [24:10<01:45, 35.00s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    18 runs   (    0.54 ms per token,  1858.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2262.25 ms /   434 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
            "llama_print_timings:        eval time =     656.65 ms /    17 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2942.69 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      25.65 ms /    46 runs   (    0.56 ms per token,  1793.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12873.29 ms /  2176 tokens (    5.92 ms per token,   169.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1984.85 ms /    45 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
            "llama_print_timings:       total time =   14939.55 ms /  2221 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      39.51 ms /    68 runs   (    0.58 ms per token,  1721.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12657.05 ms /  2143 tokens (    5.91 ms per token,   169.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2950.55 ms /    67 runs   (   44.04 ms per token,    22.71 tokens per second)\n",
            "llama_print_timings:       total time =   15714.66 ms /  2210 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     161.17 ms /   256 runs   (    0.63 ms per token,  1588.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13026.94 ms /  2194 tokens (    5.94 ms per token,   168.42 tokens per second)\n",
            "llama_print_timings:        eval time =   11358.28 ms /   255 runs   (   44.54 ms per token,    22.45 tokens per second)\n",
            "llama_print_timings:       total time =   24805.28 ms /  2449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1809.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     794.46 ms /   155 tokens (    5.13 ms per token,   195.10 tokens per second)\n",
            "llama_print_timings:        eval time =      37.54 ms /     1 runs   (   37.54 ms per token,    26.64 tokens per second)\n",
            "llama_print_timings:       total time =     836.86 ms /   156 tokens\n",
            " 94%|█████████▍| 33/35 [25:12<01:26, 43.00s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    18 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.92 ms /   434 tokens (    5.17 ms per token,   193.58 tokens per second)\n",
            "llama_print_timings:        eval time =     656.41 ms /    17 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2921.77 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.28 ms /     2 runs   (    0.64 ms per token,  1564.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5004.88 ms /   923 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
            "llama_print_timings:        eval time =      39.46 ms /     1 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5060.48 ms /   924 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     128.75 ms /   198 runs   (    0.65 ms per token,  1537.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4756.77 ms /   890 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
            "llama_print_timings:        eval time =    7949.26 ms /   197 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =   13007.64 ms /  1087 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.34 ms /     2 runs   (    0.67 ms per token,  1497.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5850.54 ms /  1076 tokens (    5.44 ms per token,   183.91 tokens per second)\n",
            "llama_print_timings:        eval time =      40.14 ms /     1 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5906.32 ms /  1077 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.22 ms /     2 runs   (    0.61 ms per token,  1638.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1408.98 ms /   280 tokens (    5.03 ms per token,   198.73 tokens per second)\n",
            "llama_print_timings:        eval time =      37.79 ms /     1 runs   (   37.79 ms per token,    26.46 tokens per second)\n",
            "llama_print_timings:       total time =    1452.30 ms /   281 tokens\n",
            " 97%|█████████▋| 34/35 [25:43<00:39, 39.58s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.30 ms /    18 runs   (    0.57 ms per token,  1747.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.80 ms /   434 tokens (    5.18 ms per token,   193.08 tokens per second)\n",
            "llama_print_timings:        eval time =     657.53 ms /    17 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2930.68 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1816.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5474.80 ms /  1014 tokens (    5.40 ms per token,   185.21 tokens per second)\n",
            "llama_print_timings:        eval time =      39.46 ms /     1 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5531.51 ms /  1015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     101.00 ms /   137 runs   (    0.74 ms per token,  1356.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5272.19 ms /   981 tokens (    5.37 ms per token,   186.07 tokens per second)\n",
            "llama_print_timings:        eval time =    5548.60 ms /   136 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =   11059.99 ms /  1117 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.23 ms /     2 runs   (    0.62 ms per token,  1624.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5936.47 ms /  1096 tokens (    5.42 ms per token,   184.62 tokens per second)\n",
            "llama_print_timings:        eval time =      81.61 ms /     2 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    6033.59 ms /  1098 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.22 ms /     2 runs   (    0.61 ms per token,  1639.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1163.17 ms /   228 tokens (    5.10 ms per token,   196.02 tokens per second)\n",
            "llama_print_timings:        eval time =      37.44 ms /     1 runs   (   37.44 ms per token,    26.71 tokens per second)\n",
            "llama_print_timings:       total time =    1206.38 ms /   229 tokens\n",
            "100%|██████████| 35/35 [26:14<00:00, 44.98s/it]\n",
            "  0%|          | 0/35 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.72 ms /    17 runs   (    0.69 ms per token,  1450.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2254.49 ms /   434 tokens (    5.19 ms per token,   192.50 tokens per second)\n",
            "llama_print_timings:        eval time =     622.86 ms /    16 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2904.91 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.30 ms /     2 runs   (    0.65 ms per token,  1532.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6292.70 ms /  1154 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
            "llama_print_timings:        eval time =      40.42 ms /     1 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    6349.44 ms /  1155 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      80.42 ms /   153 runs   (    0.53 ms per token,  1902.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6109.04 ms /  1120 tokens (    5.45 ms per token,   183.33 tokens per second)\n",
            "llama_print_timings:        eval time =    6267.92 ms /   153 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =   12568.90 ms /  1273 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      66.29 ms /   126 runs   (    0.53 ms per token,  1900.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7004.10 ms /  1260 tokens (    5.56 ms per token,   179.89 tokens per second)\n",
            "llama_print_timings:        eval time =    5183.14 ms /   125 runs   (   41.47 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   12350.93 ms /  1385 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.02 ms /     2 runs   (    0.51 ms per token,  1970.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1204.91 ms /   237 tokens (    5.08 ms per token,   196.69 tokens per second)\n",
            "llama_print_timings:        eval time =      37.47 ms /     1 runs   (   37.47 ms per token,    26.69 tokens per second)\n",
            "llama_print_timings:       total time =    1246.77 ms /   238 tokens\n",
            "  3%|▎         | 1/35 [00:42<24:14, 42.77s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.56 ms /    17 runs   (    0.68 ms per token,  1470.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2260.01 ms /   434 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
            "llama_print_timings:        eval time =     621.68 ms /    16 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2910.90 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5632.24 ms /  1045 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
            "llama_print_timings:        eval time =      39.67 ms /     1 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    5685.66 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      26.45 ms /    48 runs   (    0.55 ms per token,  1814.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5500.15 ms /  1012 tokens (    5.43 ms per token,   184.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1907.84 ms /    47 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    7477.44 ms /  1059 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      62.51 ms /   101 runs   (    0.62 ms per token,  1615.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5643.03 ms /  1042 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4070.72 ms /   100 runs   (   40.71 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    9855.20 ms /  1142 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.59 ms /     2 runs   (    0.80 ms per token,  1257.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     682.34 ms /   136 tokens (    5.02 ms per token,   199.31 tokens per second)\n",
            "llama_print_timings:        eval time =      37.66 ms /     1 runs   (   37.66 ms per token,    26.56 tokens per second)\n",
            "llama_print_timings:       total time =     728.94 ms /   137 tokens\n",
            "  6%|▌         | 2/35 [01:15<20:11, 36.73s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.43 ms /    17 runs   (    0.67 ms per token,  1486.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.12 ms /   434 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
            "llama_print_timings:        eval time =     626.62 ms /    16 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2930.87 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.22 ms /     2 runs   (    0.61 ms per token,  1633.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6796.99 ms /  1237 tokens (    5.49 ms per token,   181.99 tokens per second)\n",
            "llama_print_timings:        eval time =      41.15 ms /     1 runs   (   41.15 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =    6855.75 ms /  1238 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      54.74 ms /   103 runs   (    0.53 ms per token,  1881.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6622.45 ms /  1204 tokens (    5.50 ms per token,   181.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4199.98 ms /   102 runs   (   41.18 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =   10954.38 ms /  1306 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      40.19 ms /    63 runs   (    0.64 ms per token,  1567.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7234.22 ms /  1299 tokens (    5.57 ms per token,   179.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2568.49 ms /    62 runs   (   41.43 ms per token,    24.14 tokens per second)\n",
            "llama_print_timings:       total time =    9896.55 ms /  1361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.11 ms /     2 runs   (    0.56 ms per token,  1800.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     919.73 ms /   181 tokens (    5.08 ms per token,   196.80 tokens per second)\n",
            "llama_print_timings:        eval time =      38.27 ms /     1 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =     961.92 ms /   182 tokens\n",
            "  9%|▊         | 3/35 [01:51<19:29, 36.54s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    17 runs   (    0.56 ms per token,  1790.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.99 ms /   434 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
            "llama_print_timings:        eval time =     618.33 ms /    16 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2892.13 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4939.98 ms /   920 tokens (    5.37 ms per token,   186.24 tokens per second)\n",
            "llama_print_timings:        eval time =      79.85 ms /     2 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    5034.78 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     162.92 ms /   256 runs   (    0.64 ms per token,  1571.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4714.66 ms /   888 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =   10327.16 ms /   255 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =   15433.39 ms /  1143 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      38.55 ms /    57 runs   (    0.68 ms per token,  1478.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6166.73 ms /  1134 tokens (    5.44 ms per token,   183.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2297.30 ms /    56 runs   (   41.02 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    8556.68 ms /  1190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.49 ms /     2 runs   (    0.74 ms per token,  1346.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1756.41 ms /   338 tokens (    5.20 ms per token,   192.44 tokens per second)\n",
            "llama_print_timings:        eval time =      38.56 ms /     1 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    1803.11 ms /   339 tokens\n",
            " 11%|█▏        | 4/35 [02:28<18:59, 36.76s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    17 runs   (    0.54 ms per token,  1859.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2254.51 ms /   434 tokens (    5.19 ms per token,   192.50 tokens per second)\n",
            "llama_print_timings:        eval time =     621.39 ms /    16 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2898.46 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     140.03 ms /   256 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9676.97 ms /  1693 tokens (    5.72 ms per token,   174.95 tokens per second)\n",
            "llama_print_timings:        eval time =   10942.52 ms /   255 runs   (   42.91 ms per token,    23.30 tokens per second)\n",
            "llama_print_timings:       total time =   20992.94 ms /  1948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      41.54 ms /    80 runs   (    0.52 ms per token,  1926.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9470.56 ms /  1660 tokens (    5.71 ms per token,   175.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3366.44 ms /    79 runs   (   42.61 ms per token,    23.47 tokens per second)\n",
            "llama_print_timings:       total time =   12952.82 ms /  1739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      66.03 ms /   122 runs   (    0.54 ms per token,  1847.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9956.82 ms /  1731 tokens (    5.75 ms per token,   173.85 tokens per second)\n",
            "llama_print_timings:        eval time =    5194.73 ms /   121 runs   (   42.93 ms per token,    23.29 tokens per second)\n",
            "llama_print_timings:       total time =   15328.70 ms /  1852 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.28 ms /     2 runs   (    0.64 ms per token,  1561.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     807.17 ms /   159 tokens (    5.08 ms per token,   196.98 tokens per second)\n",
            "llama_print_timings:        eval time =      38.55 ms /     1 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =     851.27 ms /   160 tokens\n",
            " 14%|█▍        | 5/35 [03:24<21:50, 43.67s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.54 ms /    17 runs   (    0.74 ms per token,  1355.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2275.57 ms /   434 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
            "llama_print_timings:        eval time =     628.32 ms /    16 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2935.17 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     102.84 ms /   184 runs   (    0.56 ms per token,  1789.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9462.37 ms /  1661 tokens (    5.70 ms per token,   175.54 tokens per second)\n",
            "llama_print_timings:        eval time =    7824.84 ms /   183 runs   (   42.76 ms per token,    23.39 tokens per second)\n",
            "llama_print_timings:       total time =   17544.00 ms /  1844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      58.11 ms /   114 runs   (    0.51 ms per token,  1961.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9271.41 ms /  1628 tokens (    5.69 ms per token,   175.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4807.46 ms /   113 runs   (   42.54 ms per token,    23.51 tokens per second)\n",
            "llama_print_timings:       total time =   14228.08 ms /  1741 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      39.58 ms /    71 runs   (    0.56 ms per token,  1793.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9898.84 ms /  1724 tokens (    5.74 ms per token,   174.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2995.54 ms /    70 runs   (   42.79 ms per token,    23.37 tokens per second)\n",
            "llama_print_timings:       total time =   13000.37 ms /  1794 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1039.18 ms /   202 tokens (    5.14 ms per token,   194.38 tokens per second)\n",
            "llama_print_timings:        eval time =      37.38 ms /     1 runs   (   37.38 ms per token,    26.75 tokens per second)\n",
            "llama_print_timings:       total time =    1081.70 ms /   203 tokens\n",
            " 17%|█▋        | 6/35 [04:17<22:34, 46.70s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    17 runs   (    0.54 ms per token,  1866.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.10 ms /   434 tokens (    5.18 ms per token,   193.22 tokens per second)\n",
            "llama_print_timings:        eval time =     618.03 ms /    16 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2886.73 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.65 ms /    67 runs   (    0.64 ms per token,  1571.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9434.04 ms /  1660 tokens (    5.68 ms per token,   175.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2819.77 ms /    66 runs   (   42.72 ms per token,    23.41 tokens per second)\n",
            "llama_print_timings:       total time =   12366.19 ms /  1726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      46.58 ms /    85 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9271.32 ms /  1627 tokens (    5.70 ms per token,   175.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3571.00 ms /    84 runs   (   42.51 ms per token,    23.52 tokens per second)\n",
            "llama_print_timings:       total time =   12966.52 ms /  1711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     109.59 ms /   169 runs   (    0.65 ms per token,  1542.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9756.90 ms /  1701 tokens (    5.74 ms per token,   174.34 tokens per second)\n",
            "llama_print_timings:        eval time =    7218.44 ms /   168 runs   (   42.97 ms per token,    23.27 tokens per second)\n",
            "llama_print_timings:       total time =   17255.14 ms /  1869 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.58 ms /     2 runs   (    0.79 ms per token,  1264.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     844.55 ms /   166 tokens (    5.09 ms per token,   196.55 tokens per second)\n",
            "llama_print_timings:        eval time =      38.31 ms /     1 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =     888.70 ms /   167 tokens\n",
            " 20%|██        | 7/35 [05:07<22:19, 47.85s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    17 runs   (    0.59 ms per token,  1708.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2261.68 ms /   434 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
            "llama_print_timings:        eval time =     617.72 ms /    16 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2903.60 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.47 ms /     2 runs   (    0.73 ms per token,  1360.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4949.66 ms /   925 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
            "llama_print_timings:        eval time =      39.94 ms /     1 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5003.50 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      78.47 ms /   135 runs   (    0.58 ms per token,  1720.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4810.82 ms /   892 tokens (    5.39 ms per token,   185.42 tokens per second)\n",
            "llama_print_timings:        eval time =    5374.26 ms /   134 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   10365.92 ms /  1026 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.41 ms /     2 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5474.51 ms /  1011 tokens (    5.41 ms per token,   184.67 tokens per second)\n",
            "llama_print_timings:        eval time =      40.02 ms /     1 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5530.44 ms /  1012 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.63 ms /     2 runs   (    0.82 ms per token,  1225.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1138.39 ms /   221 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
            "llama_print_timings:        eval time =      38.26 ms /     1 runs   (   38.26 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    1183.44 ms /   222 tokens\n",
            " 23%|██▎       | 8/35 [05:35<18:45, 41.69s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    17 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2267.69 ms /   434 tokens (    5.23 ms per token,   191.38 tokens per second)\n",
            "llama_print_timings:        eval time =     618.46 ms /    16 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2912.22 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.49 ms /     2 runs   (    0.75 ms per token,  1340.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5694.93 ms /  1055 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
            "llama_print_timings:        eval time =      40.23 ms /     1 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5752.02 ms /  1056 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      59.49 ms /   103 runs   (    0.58 ms per token,  1731.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5551.56 ms /  1022 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4132.78 ms /   102 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    9818.78 ms /  1124 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      97.75 ms /   152 runs   (    0.64 ms per token,  1555.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6066.74 ms /  1112 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
            "llama_print_timings:        eval time =    6200.22 ms /   151 runs   (   41.06 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   12485.55 ms /  1263 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     955.97 ms /   186 tokens (    5.14 ms per token,   194.57 tokens per second)\n",
            "llama_print_timings:        eval time =      37.77 ms /     1 runs   (   37.77 ms per token,    26.47 tokens per second)\n",
            "llama_print_timings:       total time =     998.73 ms /   187 tokens\n",
            " 26%|██▌       | 9/35 [06:11<17:17, 39.92s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    17 runs   (    0.55 ms per token,  1830.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.64 ms /   434 tokens (    5.18 ms per token,   193.01 tokens per second)\n",
            "llama_print_timings:        eval time =     620.44 ms /    16 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2892.30 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      40.73 ms /    67 runs   (    0.61 ms per token,  1644.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7563.00 ms /  1366 tokens (    5.54 ms per token,   180.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2752.38 ms /    66 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
            "llama_print_timings:       total time =   10421.39 ms /  1432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      57.12 ms /    97 runs   (    0.59 ms per token,  1698.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7431.57 ms /  1333 tokens (    5.58 ms per token,   179.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3990.05 ms /    96 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =   11563.71 ms /  1429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      33.16 ms /    59 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7929.71 ms /  1412 tokens (    5.62 ms per token,   178.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2423.05 ms /    58 runs   (   41.78 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   10439.68 ms /  1470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1853.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     921.34 ms /   184 tokens (    5.01 ms per token,   199.71 tokens per second)\n",
            "llama_print_timings:        eval time =      76.40 ms /     2 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    1001.95 ms /   186 tokens\n",
            " 29%|██▊       | 10/35 [06:52<16:46, 40.26s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    17 runs   (    0.55 ms per token,  1805.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.77 ms /   434 tokens (    5.17 ms per token,   193.42 tokens per second)\n",
            "llama_print_timings:        eval time =     621.89 ms /    16 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2888.87 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     136.18 ms /   206 runs   (    0.66 ms per token,  1512.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10944.62 ms /  1891 tokens (    5.79 ms per token,   172.78 tokens per second)\n",
            "llama_print_timings:        eval time =    8931.84 ms /   205 runs   (   43.57 ms per token,    22.95 tokens per second)\n",
            "llama_print_timings:       total time =   20214.84 ms /  2096 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      99.89 ms /   175 runs   (    0.57 ms per token,  1751.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10772.82 ms /  1858 tokens (    5.80 ms per token,   172.47 tokens per second)\n",
            "llama_print_timings:        eval time =    7545.01 ms /   174 runs   (   43.36 ms per token,    23.06 tokens per second)\n",
            "llama_print_timings:       total time =   18565.14 ms /  2032 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      65.87 ms /   105 runs   (    0.63 ms per token,  1594.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11851.00 ms /  2018 tokens (    5.87 ms per token,   170.28 tokens per second)\n",
            "llama_print_timings:        eval time =    4544.18 ms /   104 runs   (   43.69 ms per token,    22.89 tokens per second)\n",
            "llama_print_timings:       total time =   16557.59 ms /  2122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.45 ms /     2 runs   (    0.72 ms per token,  1379.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1340.82 ms /   260 tokens (    5.16 ms per token,   193.91 tokens per second)\n",
            "llama_print_timings:        eval time =      37.96 ms /     1 runs   (   37.96 ms per token,    26.34 tokens per second)\n",
            "llama_print_timings:       total time =    1386.44 ms /   261 tokens\n",
            " 31%|███▏      | 11/35 [07:56<18:59, 47.49s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.24 ms /    17 runs   (    0.66 ms per token,  1512.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2269.98 ms /   434 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
            "llama_print_timings:        eval time =     627.25 ms /    16 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2926.34 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      36.81 ms /    59 runs   (    0.62 ms per token,  1602.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8731.60 ms /  1548 tokens (    5.64 ms per token,   177.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2449.48 ms /    58 runs   (   42.23 ms per token,    23.68 tokens per second)\n",
            "llama_print_timings:       total time =   11279.70 ms /  1606 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      30.31 ms /    45 runs   (    0.67 ms per token,  1484.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8504.40 ms /  1515 tokens (    5.61 ms per token,   178.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1869.12 ms /    44 runs   (   42.48 ms per token,    23.54 tokens per second)\n",
            "llama_print_timings:       total time =   10456.77 ms /  1559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     137.41 ms /   205 runs   (    0.67 ms per token,  1491.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8767.24 ms /  1550 tokens (    5.66 ms per token,   176.79 tokens per second)\n",
            "llama_print_timings:        eval time =    8689.76 ms /   204 runs   (   42.60 ms per token,    23.48 tokens per second)\n",
            "llama_print_timings:       total time =   17800.19 ms /  1754 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.61 ms per token,  1650.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     631.93 ms /   125 tokens (    5.06 ms per token,   197.81 tokens per second)\n",
            "llama_print_timings:        eval time =      37.71 ms /     1 runs   (   37.71 ms per token,    26.52 tokens per second)\n",
            "llama_print_timings:       total time =     673.91 ms /   126 tokens\n",
            " 34%|███▍      | 12/35 [08:44<18:14, 47.57s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.30 ms /    17 runs   (    0.61 ms per token,  1650.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.08 ms /   434 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
            "llama_print_timings:        eval time =     623.30 ms /    16 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2896.16 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.67 ms /     2 runs   (    0.83 ms per token,  1199.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5451.65 ms /  1008 tokens (    5.41 ms per token,   184.90 tokens per second)\n",
            "llama_print_timings:        eval time =      40.15 ms /     1 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5508.97 ms /  1009 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      28.32 ms /    46 runs   (    0.62 ms per token,  1624.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5240.41 ms /   975 tokens (    5.37 ms per token,   186.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1809.83 ms /    45 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7119.27 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     152.51 ms /   256 runs   (    0.60 ms per token,  1678.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5428.44 ms /  1006 tokens (    5.40 ms per token,   185.32 tokens per second)\n",
            "llama_print_timings:        eval time =   10415.46 ms /   255 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =   16214.80 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.09 ms /     2 runs   (    0.55 ms per token,  1829.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     672.73 ms /   131 tokens (    5.14 ms per token,   194.73 tokens per second)\n",
            "llama_print_timings:        eval time =      37.41 ms /     1 runs   (   37.41 ms per token,    26.73 tokens per second)\n",
            "llama_print_timings:       total time =     713.76 ms /   132 tokens\n",
            " 37%|███▋      | 13/35 [09:20<16:10, 44.13s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      15.09 ms /    17 runs   (    0.89 ms per token,  1126.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2260.58 ms /   434 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
            "llama_print_timings:        eval time =     623.04 ms /    16 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2916.32 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.22 ms /     2 runs   (    0.61 ms per token,  1638.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3144.88 ms /   604 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
            "llama_print_timings:        eval time =      38.73 ms /     1 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3192.91 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      32.17 ms /    52 runs   (    0.62 ms per token,  1616.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2975.14 ms /   571 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2006.23 ms /    51 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5049.76 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      76.70 ms /   116 runs   (    0.66 ms per token,  1512.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3233.57 ms /   612 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
            "llama_print_timings:        eval time =    4529.11 ms /   115 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    7928.54 ms /   727 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.24 ms /     2 runs   (    0.62 ms per token,  1614.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     670.77 ms /   133 tokens (    5.04 ms per token,   198.28 tokens per second)\n",
            "llama_print_timings:        eval time =      37.46 ms /     1 runs   (   37.46 ms per token,    26.70 tokens per second)\n",
            "llama_print_timings:       total time =     714.08 ms /   134 tokens\n",
            " 40%|████      | 14/35 [09:44<13:16, 37.91s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    17 runs   (    0.55 ms per token,  1802.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.33 ms /   434 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
            "llama_print_timings:        eval time =     616.20 ms /    16 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2887.02 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.46 ms /     2 runs   (    0.73 ms per token,  1370.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3677.80 ms /   696 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =      78.03 ms /     2 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3768.21 ms /   698 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.38 ms /   124 runs   (    0.59 ms per token,  1689.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3487.74 ms /   664 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =    4837.63 ms /   123 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    8482.81 ms /   787 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      68.05 ms /    93 runs   (    0.73 ms per token,  1366.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4147.78 ms /   779 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3691.39 ms /    92 runs   (   40.12 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    7992.64 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.19 ms /     2 runs   (    0.59 ms per token,  1680.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1039.48 ms /   203 tokens (    5.12 ms per token,   195.29 tokens per second)\n",
            "llama_print_timings:        eval time =      37.34 ms /     1 runs   (   37.34 ms per token,    26.78 tokens per second)\n",
            "llama_print_timings:       total time =    1081.55 ms /   204 tokens\n",
            " 43%|████▎     | 15/35 [10:11<11:31, 34.60s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    17 runs   (    0.55 ms per token,  1810.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.75 ms /   434 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
            "llama_print_timings:        eval time =     618.32 ms /    16 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2888.63 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.47 ms /     2 runs   (    0.73 ms per token,  1360.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4123.69 ms /   776 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =      80.33 ms /     2 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    4218.02 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      44.42 ms /    78 runs   (    0.57 ms per token,  1755.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3927.88 ms /   744 tokens (    5.28 ms per token,   189.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3037.27 ms /    77 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    7060.97 ms /   821 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      79.42 ms /   103 runs   (    0.77 ms per token,  1296.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4221.10 ms /   800 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =    4112.85 ms /   102 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    8515.60 ms /   902 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.35 ms /     2 runs   (    0.67 ms per token,  1485.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     885.94 ms /   170 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
            "llama_print_timings:        eval time =      39.47 ms /     1 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =     931.32 ms /   171 tokens\n",
            " 46%|████▌     | 16/35 [10:39<10:20, 32.63s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    17 runs   (    0.55 ms per token,  1814.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.57 ms /   434 tokens (    5.17 ms per token,   193.44 tokens per second)\n",
            "llama_print_timings:        eval time =     618.81 ms /    16 runs   (   38.68 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2885.68 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.66 ms /     2 runs   (    0.83 ms per token,  1206.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4962.61 ms /   922 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =      42.70 ms /     1 runs   (   42.70 ms per token,    23.42 tokens per second)\n",
            "llama_print_timings:       total time =    5020.19 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     127.20 ms /   209 runs   (    0.61 ms per token,  1643.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4767.69 ms /   888 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =    8422.40 ms /   209 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =   13475.58 ms /  1097 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1673.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5942.87 ms /  1082 tokens (    5.49 ms per token,   182.07 tokens per second)\n",
            "llama_print_timings:        eval time =      40.21 ms /     1 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    6005.64 ms /  1083 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.27 ms /     2 runs   (    0.63 ms per token,  1581.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1495.53 ms /   295 tokens (    5.07 ms per token,   197.25 tokens per second)\n",
            "llama_print_timings:        eval time =      37.79 ms /     1 runs   (   37.79 ms per token,    26.46 tokens per second)\n",
            "llama_print_timings:       total time =    1538.62 ms /   296 tokens\n",
            " 49%|████▊     | 17/35 [11:11<09:43, 32.42s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    17 runs   (    0.57 ms per token,  1759.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.05 ms /   434 tokens (    5.17 ms per token,   193.31 tokens per second)\n",
            "llama_print_timings:        eval time =     623.97 ms /    16 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2893.25 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.57 ms /     2 runs   (    0.78 ms per token,  1277.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4253.81 ms /   795 tokens (    5.35 ms per token,   186.89 tokens per second)\n",
            "llama_print_timings:        eval time =      39.18 ms /     1 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    4309.46 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      52.74 ms /    88 runs   (    0.60 ms per token,  1668.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4053.29 ms /   762 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3431.58 ms /    87 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    7594.66 ms /   849 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      50.32 ms /    64 runs   (    0.79 ms per token,  1271.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4493.88 ms /   847 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2543.54 ms /    63 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    7149.09 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.55 ms /     2 runs   (    0.78 ms per token,  1287.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     804.53 ms /   160 tokens (    5.03 ms per token,   198.87 tokens per second)\n",
            "llama_print_timings:        eval time =      78.75 ms /     2 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =     889.09 ms /   162 tokens\n",
            " 51%|█████▏    | 18/35 [11:36<08:35, 30.33s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    17 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2257.52 ms /   434 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
            "llama_print_timings:        eval time =     616.42 ms /    16 runs   (   38.53 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2897.94 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1690.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2882.21 ms /   558 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
            "llama_print_timings:        eval time =      38.84 ms /     1 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2930.22 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      46.39 ms /    67 runs   (    0.69 ms per token,  1444.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2748.35 ms /   525 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.55 ms /    66 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5426.52 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      46.49 ms /    79 runs   (    0.59 ms per token,  1699.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3058.61 ms /   589 tokens (    5.19 ms per token,   192.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3072.52 ms /    78 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6225.73 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.31 ms /     2 runs   (    0.66 ms per token,  1520.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     714.42 ms /   140 tokens (    5.10 ms per token,   195.96 tokens per second)\n",
            "llama_print_timings:        eval time =      37.41 ms /     1 runs   (   37.41 ms per token,    26.73 tokens per second)\n",
            "llama_print_timings:       total time =     755.97 ms /   141 tokens\n",
            " 54%|█████▍    | 19/35 [11:59<07:29, 28.08s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.67 ms /    17 runs   (    0.69 ms per token,  1456.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.91 ms /   434 tokens (    5.18 ms per token,   193.15 tokens per second)\n",
            "llama_print_timings:        eval time =     625.98 ms /    16 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2900.24 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5323.19 ms /   989 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =      39.22 ms /     1 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5377.34 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      74.40 ms /   110 runs   (    0.68 ms per token,  1478.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5169.78 ms /   956 tokens (    5.41 ms per token,   184.92 tokens per second)\n",
            "llama_print_timings:        eval time =    4419.00 ms /   109 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    9752.57 ms /  1065 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      53.77 ms /    77 runs   (    0.70 ms per token,  1432.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5753.57 ms /  1061 tokens (    5.42 ms per token,   184.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3118.25 ms /    76 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    8997.96 ms /  1137 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.48 ms /     2 runs   (    0.74 ms per token,  1352.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     928.57 ms /   184 tokens (    5.05 ms per token,   198.15 tokens per second)\n",
            "llama_print_timings:        eval time =      78.87 ms /     2 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    1014.02 ms /   186 tokens\n",
            " 57%|█████▋    | 20/35 [12:33<07:26, 29.80s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    17 runs   (    0.58 ms per token,  1738.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.70 ms /   434 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =     620.61 ms /    16 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2926.34 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.43 ms /     2 runs   (    0.72 ms per token,  1397.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7060.59 ms /  1280 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =      41.49 ms /     1 runs   (   41.49 ms per token,    24.10 tokens per second)\n",
            "llama_print_timings:       total time =    7120.14 ms /  1281 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       6.78 ms /    13 runs   (    0.52 ms per token,  1918.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6892.53 ms /  1247 tokens (    5.53 ms per token,   180.92 tokens per second)\n",
            "llama_print_timings:        eval time =     494.40 ms /    12 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
            "llama_print_timings:       total time =    7418.03 ms /  1259 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      29.93 ms /    38 runs   (    0.79 ms per token,  1269.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6950.40 ms /  1259 tokens (    5.52 ms per token,   181.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.24 ms /    37 runs   (   41.49 ms per token,    24.10 tokens per second)\n",
            "llama_print_timings:       total time =    8561.09 ms /  1296 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.27 ms /     2 runs   (    0.64 ms per token,  1569.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     443.47 ms /    84 tokens (    5.28 ms per token,   189.42 tokens per second)\n",
            "llama_print_timings:        eval time =      37.58 ms /     1 runs   (   37.58 ms per token,    26.61 tokens per second)\n",
            "llama_print_timings:       total time =     484.47 ms /    85 tokens\n",
            " 60%|██████    | 21/35 [13:02<06:55, 29.68s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    17 runs   (    0.55 ms per token,  1818.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2260.58 ms /   434 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
            "llama_print_timings:        eval time =     619.25 ms /    16 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2903.10 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      63.71 ms /   106 runs   (    0.60 ms per token,  1663.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10822.65 ms /  1871 tokens (    5.78 ms per token,   172.88 tokens per second)\n",
            "llama_print_timings:        eval time =    4534.29 ms /   105 runs   (   43.18 ms per token,    23.16 tokens per second)\n",
            "llama_print_timings:       total time =   15516.71 ms /  1976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     109.14 ms /   192 runs   (    0.57 ms per token,  1759.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10615.80 ms /  1838 tokens (    5.78 ms per token,   173.14 tokens per second)\n",
            "llama_print_timings:        eval time =    8259.65 ms /   191 runs   (   43.24 ms per token,    23.12 tokens per second)\n",
            "llama_print_timings:       total time =   19156.01 ms /  2029 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      85.47 ms /   137 runs   (    0.62 ms per token,  1603.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11835.66 ms /  2024 tokens (    5.85 ms per token,   171.01 tokens per second)\n",
            "llama_print_timings:        eval time =    5966.81 ms /   136 runs   (   43.87 ms per token,    22.79 tokens per second)\n",
            "llama_print_timings:       total time =   18027.45 ms /  2160 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.53 ms /     2 runs   (    0.76 ms per token,  1308.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1384.33 ms /   268 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
            "llama_print_timings:        eval time =      37.92 ms /     1 runs   (   37.92 ms per token,    26.37 tokens per second)\n",
            "llama_print_timings:       total time =    1428.82 ms /   269 tokens\n",
            " 63%|██████▎   | 22/35 [14:02<08:21, 38.60s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    17 runs   (    0.58 ms per token,  1732.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.39 ms /   434 tokens (    5.18 ms per token,   192.94 tokens per second)\n",
            "llama_print_timings:        eval time =     619.21 ms /    16 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2892.82 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.39 ms /     2 runs   (    0.70 ms per token,  1435.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6184.08 ms /  1131 tokens (    5.47 ms per token,   182.89 tokens per second)\n",
            "llama_print_timings:        eval time =      39.70 ms /     1 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6245.54 ms /  1132 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      21.27 ms /    37 runs   (    0.57 ms per token,  1739.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6003.75 ms /  1098 tokens (    5.47 ms per token,   182.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.47 ms /    36 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    7521.93 ms /  1134 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.60 ms /     2 runs   (    0.80 ms per token,  1252.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6175.86 ms /  1132 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
            "llama_print_timings:        eval time =      40.86 ms /     1 runs   (   40.86 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    6233.41 ms /  1133 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.57 ms /     2 runs   (    0.79 ms per token,  1272.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     560.92 ms /   110 tokens (    5.10 ms per token,   196.11 tokens per second)\n",
            "llama_print_timings:        eval time =      37.67 ms /     1 runs   (   37.67 ms per token,    26.54 tokens per second)\n",
            "llama_print_timings:       total time =     603.03 ms /   111 tokens\n",
            " 66%|██████▌   | 23/35 [14:28<06:59, 34.99s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.97 ms /    17 runs   (    0.65 ms per token,  1548.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2275.84 ms /   434 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =     621.31 ms /    16 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2926.45 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.57 ms per token,  1765.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5001.04 ms /   936 tokens (    5.34 ms per token,   187.16 tokens per second)\n",
            "llama_print_timings:        eval time =      79.96 ms /     2 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    5095.01 ms /   938 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      40.00 ms /    60 runs   (    0.67 ms per token,  1500.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4853.65 ms /   904 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2379.63 ms /    59 runs   (   40.33 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    7325.40 ms /   963 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      49.59 ms /    85 runs   (    0.58 ms per token,  1713.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5141.09 ms /   960 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3386.25 ms /    84 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    8633.83 ms /  1044 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.42 ms /     2 runs   (    0.71 ms per token,  1412.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     682.31 ms /   134 tokens (    5.09 ms per token,   196.39 tokens per second)\n",
            "llama_print_timings:        eval time =      38.45 ms /     1 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =     725.08 ms /   135 tokens\n",
            " 69%|██████▊   | 24/35 [14:56<06:01, 32.87s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.81 ms /    17 runs   (    0.69 ms per token,  1439.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2275.44 ms /   434 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =     624.25 ms /    16 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2930.87 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.61 ms per token,  1648.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5635.71 ms /  1042 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =      39.73 ms /     1 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    5690.28 ms /  1043 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      78.34 ms /   131 runs   (    0.60 ms per token,  1672.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5460.04 ms /  1008 tokens (    5.42 ms per token,   184.61 tokens per second)\n",
            "llama_print_timings:        eval time =    5312.73 ms /   131 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =   10950.67 ms /  1139 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      61.01 ms /    76 runs   (    0.80 ms per token,  1245.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6129.11 ms /  1127 tokens (    5.44 ms per token,   183.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3094.44 ms /    75 runs   (   41.26 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =    9361.46 ms /  1202 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.53 ms per token,  1874.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1078.79 ms /   214 tokens (    5.04 ms per token,   198.37 tokens per second)\n",
            "llama_print_timings:        eval time =      37.27 ms /     1 runs   (   37.27 ms per token,    26.83 tokens per second)\n",
            "llama_print_timings:       total time =    1123.07 ms /   215 tokens\n",
            " 71%|███████▏  | 25/35 [15:30<05:32, 33.21s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    17 runs   (    0.58 ms per token,  1732.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.77 ms /   434 tokens (    5.17 ms per token,   193.51 tokens per second)\n",
            "llama_print_timings:        eval time =     619.36 ms /    16 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2886.18 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.38 ms /     2 runs   (    0.69 ms per token,  1453.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5766.60 ms /  1062 tokens (    5.43 ms per token,   184.16 tokens per second)\n",
            "llama_print_timings:        eval time =      40.52 ms /     1 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    5825.41 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      34.08 ms /    60 runs   (    0.57 ms per token,  1760.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5584.45 ms /  1029 tokens (    5.43 ms per token,   184.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2392.90 ms /    59 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    8064.69 ms /  1088 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.53 ms /     2 runs   (    0.76 ms per token,  1310.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5857.87 ms /  1076 tokens (    5.44 ms per token,   183.68 tokens per second)\n",
            "llama_print_timings:        eval time =      40.21 ms /     1 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5914.09 ms /  1077 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.77 ms /     2 runs   (    0.89 ms per token,  1128.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     727.96 ms /   143 tokens (    5.09 ms per token,   196.44 tokens per second)\n",
            "llama_print_timings:        eval time =      38.03 ms /     1 runs   (   38.03 ms per token,    26.29 tokens per second)\n",
            "llama_print_timings:       total time =     775.02 ms /   144 tokens\n",
            " 74%|███████▍  | 26/35 [15:56<04:37, 30.86s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    17 runs   (    0.58 ms per token,  1729.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2273.68 ms /   434 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     623.59 ms /    16 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2924.86 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2083.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4167.91 ms /   792 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =      38.84 ms /     1 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    4217.93 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.56 ms /    65 runs   (    0.65 ms per token,  1527.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4017.86 ms /   759 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2550.71 ms /    64 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    6669.71 ms /   823 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     166.10 ms /   256 runs   (    0.65 ms per token,  1541.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4351.92 ms /   824 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =   10296.60 ms /   256 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =   15047.38 ms /  1080 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1689.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     671.73 ms /   134 tokens (    5.01 ms per token,   199.49 tokens per second)\n",
            "llama_print_timings:        eval time =      37.19 ms /     1 runs   (   37.19 ms per token,    26.89 tokens per second)\n",
            "llama_print_timings:       total time =     712.83 ms /   135 tokens\n",
            " 77%|███████▋  | 27/35 [16:29<04:12, 31.58s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    17 runs   (    0.53 ms per token,  1880.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.44 ms /   434 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
            "llama_print_timings:        eval time =     615.75 ms /    16 runs   (   38.48 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2881.14 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.50 ms /     2 runs   (    0.75 ms per token,  1329.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4695.58 ms /   880 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =      79.68 ms /     2 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4790.60 ms /   882 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.18 ms /    72 runs   (    0.59 ms per token,  1706.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4523.72 ms /   848 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2820.30 ms /    71 runs   (   39.72 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    7434.89 ms /   919 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.49 ms /    57 runs   (    0.75 ms per token,  1341.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4904.06 ms /   918 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2268.60 ms /    56 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    7267.44 ms /   974 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.44 ms /     2 runs   (    0.72 ms per token,  1391.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     728.54 ms /   144 tokens (    5.06 ms per token,   197.66 tokens per second)\n",
            "llama_print_timings:        eval time =      37.60 ms /     1 runs   (   37.60 ms per token,    26.60 tokens per second)\n",
            "llama_print_timings:       total time =     771.60 ms /   145 tokens\n",
            " 80%|████████  | 28/35 [16:54<03:28, 29.80s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    17 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2261.57 ms /   434 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
            "llama_print_timings:        eval time =     619.25 ms /    16 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2903.06 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.23 ms /     2 runs   (    0.62 ms per token,  1622.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3115.74 ms /   597 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =      39.14 ms /     1 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3164.42 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     105.64 ms /   147 runs   (    0.72 ms per token,  1391.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2933.99 ms /   564 tokens (    5.20 ms per token,   192.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5744.18 ms /   146 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    8907.42 ms /   710 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      70.37 ms /   119 runs   (    0.59 ms per token,  1690.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3632.57 ms /   690 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =    4661.35 ms /   118 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    8442.74 ms /   808 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.45 ms /     2 runs   (    0.72 ms per token,  1383.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1226.47 ms /   238 tokens (    5.15 ms per token,   194.05 tokens per second)\n",
            "llama_print_timings:        eval time =      38.16 ms /     1 runs   (   38.16 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    1273.10 ms /   239 tokens\n",
            " 83%|████████▎ | 29/35 [17:22<02:54, 29.02s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      14.30 ms /    17 runs   (    0.84 ms per token,  1188.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.95 ms /   434 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =     625.18 ms /    16 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2936.32 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      44.52 ms /    71 runs   (    0.63 ms per token,  1594.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6791.96 ms /  1240 tokens (    5.48 ms per token,   182.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2904.75 ms /    70 runs   (   41.50 ms per token,    24.10 tokens per second)\n",
            "llama_print_timings:       total time =    9807.99 ms /  1310 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      66.99 ms /   124 runs   (    0.54 ms per token,  1851.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6641.00 ms /  1207 tokens (    5.50 ms per token,   181.75 tokens per second)\n",
            "llama_print_timings:        eval time =    5071.65 ms /   123 runs   (   41.23 ms per token,    24.25 tokens per second)\n",
            "llama_print_timings:       total time =   11871.23 ms /  1330 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     105.91 ms /   183 runs   (    0.58 ms per token,  1727.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7337.03 ms /  1316 tokens (    5.58 ms per token,   179.36 tokens per second)\n",
            "llama_print_timings:        eval time =    7573.38 ms /   182 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
            "llama_print_timings:       total time =   15150.81 ms /  1498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.41 ms /     2 runs   (    0.71 ms per token,  1415.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1049.61 ms /   208 tokens (    5.05 ms per token,   198.17 tokens per second)\n",
            "llama_print_timings:        eval time =      76.32 ms /     2 runs   (   38.16 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    1131.86 ms /   210 tokens\n",
            " 86%|████████▌ | 30/35 [18:05<02:46, 33.26s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.59 ms /    17 runs   (    0.68 ms per token,  1467.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2273.40 ms /   434 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =     630.06 ms /    16 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2932.36 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.27 ms /     2 runs   (    0.64 ms per token,  1572.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4847.95 ms /   906 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
            "llama_print_timings:        eval time =      39.65 ms /     1 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4900.97 ms /   907 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.84 ms /   110 runs   (    0.67 ms per token,  1489.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4651.85 ms /   872 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4424.51 ms /   110 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    9241.06 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      74.89 ms /   113 runs   (    0.66 ms per token,  1508.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5184.56 ms /   968 tokens (    5.36 ms per token,   186.71 tokens per second)\n",
            "llama_print_timings:        eval time =    4580.85 ms /   113 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    9935.02 ms /  1081 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.46 ms /     2 runs   (    0.73 ms per token,  1368.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1011.04 ms /   194 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =      37.77 ms /     1 runs   (   37.77 ms per token,    26.47 tokens per second)\n",
            "llama_print_timings:       total time =    1055.15 ms /   195 tokens\n",
            " 89%|████████▊ | 31/35 [18:36<02:10, 32.74s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    17 runs   (    0.54 ms per token,  1852.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2270.85 ms /   434 tokens (    5.23 ms per token,   191.12 tokens per second)\n",
            "llama_print_timings:        eval time =     618.33 ms /    16 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2913.87 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.59 ms per token,  1707.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4359.32 ms /   824 tokens (    5.29 ms per token,   189.02 tokens per second)\n",
            "llama_print_timings:        eval time =      78.80 ms /     2 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    4449.69 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      79.59 ms /   121 runs   (    0.66 ms per token,  1520.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4207.31 ms /   792 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =    4803.10 ms /   120 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    9183.58 ms /   912 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      55.02 ms /    84 runs   (    0.66 ms per token,  1526.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4812.60 ms /   899 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3338.71 ms /    83 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8271.90 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.52 ms /     2 runs   (    0.76 ms per token,  1320.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1059.74 ms /   205 tokens (    5.17 ms per token,   193.44 tokens per second)\n",
            "llama_print_timings:        eval time =      38.07 ms /     1 runs   (   38.07 ms per token,    26.27 tokens per second)\n",
            "llama_print_timings:       total time =    1104.28 ms /   206 tokens\n",
            " 91%|█████████▏| 32/35 [19:05<01:34, 31.40s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.08 ms /    17 runs   (    0.65 ms per token,  1533.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.43 ms /   434 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     629.20 ms /    16 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2935.87 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      53.97 ms /    73 runs   (    0.74 ms per token,  1352.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8834.85 ms /  1567 tokens (    5.64 ms per token,   177.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3072.43 ms /    72 runs   (   42.67 ms per token,    23.43 tokens per second)\n",
            "llama_print_timings:       total time =   12042.93 ms /  1639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      51.37 ms /    75 runs   (    0.68 ms per token,  1460.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8621.56 ms /  1534 tokens (    5.62 ms per token,   177.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3143.63 ms /    74 runs   (   42.48 ms per token,    23.54 tokens per second)\n",
            "llama_print_timings:       total time =   11894.70 ms /  1608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      97.68 ms /   141 runs   (    0.69 ms per token,  1443.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9007.31 ms /  1592 tokens (    5.66 ms per token,   176.75 tokens per second)\n",
            "llama_print_timings:        eval time =    5962.25 ms /   140 runs   (   42.59 ms per token,    23.48 tokens per second)\n",
            "llama_print_timings:       total time =   15201.01 ms /  1732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.46 ms /     2 runs   (    0.73 ms per token,  1371.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     846.99 ms /   162 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =      38.57 ms /     1 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =     893.38 ms /   163 tokens\n",
            " 94%|█████████▍| 33/35 [19:50<01:11, 35.70s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    17 runs   (    0.55 ms per token,  1830.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2252.08 ms /   434 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
            "llama_print_timings:        eval time =     617.46 ms /    16 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2891.40 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.44 ms /     2 runs   (    0.72 ms per token,  1390.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3997.53 ms /   754 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =      39.04 ms /     1 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    4048.42 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      82.44 ms /   127 runs   (    0.65 ms per token,  1540.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3791.43 ms /   720 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
            "llama_print_timings:        eval time =    5047.38 ms /   127 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    9015.59 ms /   847 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      44.37 ms /    75 runs   (    0.59 ms per token,  1690.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4444.49 ms /   836 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2951.73 ms /    74 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7493.78 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.63 ms /     2 runs   (    0.81 ms per token,  1227.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1053.37 ms /   208 tokens (    5.06 ms per token,   197.46 tokens per second)\n",
            "llama_print_timings:        eval time =      75.87 ms /     2 runs   (   37.93 ms per token,    26.36 tokens per second)\n",
            "llama_print_timings:       total time =    1135.55 ms /   210 tokens\n",
            " 97%|█████████▋| 34/35 [20:17<00:32, 32.97s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.81 ms /    17 runs   (    0.69 ms per token,  1439.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2281.69 ms /   434 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =     620.28 ms /    16 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2935.70 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.56 ms per token,  1771.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5084.64 ms /   951 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =      39.88 ms /     1 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    5137.65 ms /   952 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      83.21 ms /   129 runs   (    0.65 ms per token,  1550.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4937.24 ms /   918 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
            "llama_print_timings:        eval time =    5170.51 ms /   128 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   10300.88 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     107.46 ms /   151 runs   (    0.71 ms per token,  1405.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5549.75 ms /  1026 tokens (    5.41 ms per token,   184.87 tokens per second)\n",
            "llama_print_timings:        eval time =    6137.91 ms /   150 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =   11932.77 ms /  1176 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.22 ms /     2 runs   (    0.61 ms per token,  1639.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1125.26 ms /   220 tokens (    5.11 ms per token,   195.51 tokens per second)\n",
            "llama_print_timings:        eval time =      37.38 ms /     1 runs   (   37.38 ms per token,    26.75 tokens per second)\n",
            "llama_print_timings:       total time =    1167.59 ms /   221 tokens\n",
            "100%|██████████| 35/35 [20:51<00:00, 35.76s/it]\n",
            "  0%|          | 0/35 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.78 ms /    20 runs   (    0.54 ms per token,  1855.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.53 ms /   434 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =     741.18 ms /    19 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3021.89 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.95 ms /    76 runs   (    0.57 ms per token,  1769.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7010.72 ms /  1270 tokens (    5.52 ms per token,   181.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3096.93 ms /    75 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =   10211.15 ms /  1345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      85.10 ms /   164 runs   (    0.52 ms per token,  1927.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6848.65 ms /  1237 tokens (    5.54 ms per token,   180.62 tokens per second)\n",
            "llama_print_timings:        eval time =    6754.90 ms /   163 runs   (   41.44 ms per token,    24.13 tokens per second)\n",
            "llama_print_timings:       total time =   13807.79 ms /  1400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      35.63 ms /    66 runs   (    0.54 ms per token,  1852.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7780.95 ms /  1387 tokens (    5.61 ms per token,   178.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2714.00 ms /    65 runs   (   41.75 ms per token,    23.95 tokens per second)\n",
            "llama_print_timings:       total time =   10584.72 ms /  1452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      46.78 ms /    79 runs   (    0.59 ms per token,  1688.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1249.58 ms /   248 tokens (    5.04 ms per token,   198.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2993.18 ms /    78 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    4336.43 ms /   326 tokens\n",
            "  3%|▎         | 1/35 [00:48<27:20, 48.24s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      14.52 ms /    20 runs   (    0.73 ms per token,  1377.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.54 ms /   434 tokens (    5.17 ms per token,   193.36 tokens per second)\n",
            "llama_print_timings:        eval time =     742.72 ms /    19 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3020.94 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      46.75 ms /    64 runs   (    0.73 ms per token,  1369.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7310.32 ms /  1327 tokens (    5.51 ms per token,   181.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2631.02 ms /    63 runs   (   41.76 ms per token,    23.95 tokens per second)\n",
            "llama_print_timings:       total time =   10060.77 ms /  1390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     128.84 ms /   204 runs   (    0.63 ms per token,  1583.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7134.45 ms /  1294 tokens (    5.51 ms per token,   181.37 tokens per second)\n",
            "llama_print_timings:        eval time =    8489.00 ms /   203 runs   (   41.82 ms per token,    23.91 tokens per second)\n",
            "llama_print_timings:       total time =   15944.67 ms /  1497 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     134.57 ms /   192 runs   (    0.70 ms per token,  1426.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8284.48 ms /  1480 tokens (    5.60 ms per token,   178.65 tokens per second)\n",
            "llama_print_timings:        eval time =    8103.31 ms /   191 runs   (   42.43 ms per token,    23.57 tokens per second)\n",
            "llama_print_timings:       total time =   16702.98 ms /  1671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1491.98 ms /   292 tokens (    5.11 ms per token,   195.71 tokens per second)\n",
            "llama_print_timings:        eval time =      37.73 ms /     1 runs   (   37.73 ms per token,    26.50 tokens per second)\n",
            "llama_print_timings:       total time =    1534.83 ms /   293 tokens\n",
            "  6%|▌         | 2/35 [01:42<28:31, 51.86s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.05 ms /    20 runs   (    0.55 ms per token,  1810.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.54 ms /   434 tokens (    5.18 ms per token,   193.10 tokens per second)\n",
            "llama_print_timings:        eval time =     743.17 ms /    19 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3019.25 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1816.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5679.70 ms /  1053 tokens (    5.39 ms per token,   185.40 tokens per second)\n",
            "llama_print_timings:        eval time =      39.85 ms /     1 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    5733.81 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      62.84 ms /    88 runs   (    0.71 ms per token,  1400.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5511.26 ms /  1020 tokens (    5.40 ms per token,   185.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3550.77 ms /    87 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    9204.39 ms /  1107 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      37.84 ms /    64 runs   (    0.59 ms per token,  1691.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5977.21 ms /  1100 tokens (    5.43 ms per token,   184.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2563.44 ms /    63 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    8626.10 ms /  1163 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.68 ms /     2 runs   (    0.84 ms per token,  1191.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     832.98 ms /   166 tokens (    5.02 ms per token,   199.29 tokens per second)\n",
            "llama_print_timings:        eval time =      39.61 ms /     1 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =     878.44 ms /   167 tokens\n",
            "  9%|▊         | 3/35 [02:14<22:51, 42.86s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      14.03 ms /    20 runs   (    0.70 ms per token,  1425.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2289.57 ms /   434 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     744.02 ms /    19 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3070.36 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.52 ms /     2 runs   (    0.76 ms per token,  1320.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6447.68 ms /  1184 tokens (    5.45 ms per token,   183.63 tokens per second)\n",
            "llama_print_timings:        eval time =      82.91 ms /     2 runs   (   41.45 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =    6547.11 ms /  1186 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     128.16 ms /   224 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6324.44 ms /  1152 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
            "llama_print_timings:        eval time =    9210.29 ms /   223 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
            "llama_print_timings:       total time =   15864.76 ms /  1375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      30.04 ms /    53 runs   (    0.57 ms per token,  1764.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7628.90 ms /  1365 tokens (    5.59 ms per token,   178.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2167.33 ms /    52 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
            "llama_print_timings:       total time =    9873.21 ms /  1417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1850.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1535.31 ms /   304 tokens (    5.05 ms per token,   198.01 tokens per second)\n",
            "llama_print_timings:        eval time =      76.77 ms /     2 runs   (   38.38 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    1617.32 ms /   306 tokens\n",
            " 11%|█▏        | 4/35 [02:57<22:05, 42.75s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      17.66 ms /    20 runs   (    0.88 ms per token,  1132.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2261.29 ms /   434 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
            "llama_print_timings:        eval time =     735.94 ms /    19 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3036.40 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     125.68 ms /   233 runs   (    0.54 ms per token,  1853.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10477.55 ms /  1819 tokens (    5.76 ms per token,   173.61 tokens per second)\n",
            "llama_print_timings:        eval time =   10040.64 ms /   232 runs   (   43.28 ms per token,    23.11 tokens per second)\n",
            "llama_print_timings:       total time =   20843.74 ms /  2051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      75.13 ms /   141 runs   (    0.53 ms per token,  1876.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10306.27 ms /  1786 tokens (    5.77 ms per token,   173.29 tokens per second)\n",
            "llama_print_timings:        eval time =    6031.65 ms /   140 runs   (   43.08 ms per token,    23.21 tokens per second)\n",
            "llama_print_timings:       total time =   16532.14 ms /  1926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      54.66 ms /    99 runs   (    0.55 ms per token,  1811.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11152.55 ms /  1918 tokens (    5.81 ms per token,   171.98 tokens per second)\n",
            "llama_print_timings:        eval time =    4272.51 ms /    98 runs   (   43.60 ms per token,    22.94 tokens per second)\n",
            "llama_print_timings:       total time =   15577.01 ms /  2016 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.43 ms /     2 runs   (    0.71 ms per token,  1400.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1137.34 ms /   220 tokens (    5.17 ms per token,   193.43 tokens per second)\n",
            "llama_print_timings:        eval time =      38.05 ms /     1 runs   (   38.05 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =    1181.58 ms /   221 tokens\n",
            " 14%|█▍        | 5/35 [03:58<24:46, 49.55s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.25 ms /    20 runs   (    0.56 ms per token,  1777.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2271.99 ms /   434 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =     736.55 ms /    19 runs   (   38.77 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3035.63 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.62 ms /     2 runs   (    0.81 ms per token,  1233.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5756.12 ms /  1063 tokens (    5.41 ms per token,   184.67 tokens per second)\n",
            "llama_print_timings:        eval time =      40.53 ms /     1 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    5812.71 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      50.20 ms /    95 runs   (    0.53 ms per token,  1892.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5592.56 ms /  1030 tokens (    5.43 ms per token,   184.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3811.53 ms /    94 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    9526.43 ms /  1124 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      53.23 ms /    95 runs   (    0.56 ms per token,  1784.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6056.99 ms /  1107 tokens (    5.47 ms per token,   182.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3856.62 ms /    94 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =   10044.13 ms /  1201 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.04 ms /     2 runs   (    0.52 ms per token,  1926.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     921.99 ms /   183 tokens (    5.04 ms per token,   198.48 tokens per second)\n",
            "llama_print_timings:        eval time =      37.99 ms /     1 runs   (   37.99 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =     964.32 ms /   184 tokens\n",
            " 17%|█▋        | 6/35 [04:33<21:25, 44.33s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.84 ms /    20 runs   (    0.54 ms per token,  1844.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.42 ms /   434 tokens (    5.18 ms per token,   193.02 tokens per second)\n",
            "llama_print_timings:        eval time =     735.79 ms /    19 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3009.93 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      60.44 ms /    88 runs   (    0.69 ms per token,  1456.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12058.93 ms /  2054 tokens (    5.87 ms per token,   170.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3819.79 ms /    87 runs   (   43.91 ms per token,    22.78 tokens per second)\n",
            "llama_print_timings:       total time =   16041.54 ms /  2141 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      95.39 ms /   146 runs   (    0.65 ms per token,  1530.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11825.61 ms /  2021 tokens (    5.85 ms per token,   170.90 tokens per second)\n",
            "llama_print_timings:        eval time =    6383.93 ms /   145 runs   (   44.03 ms per token,    22.71 tokens per second)\n",
            "llama_print_timings:       total time =   18466.49 ms /  2166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      38.26 ms /    66 runs   (    0.58 ms per token,  1725.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12763.10 ms /  2156 tokens (    5.92 ms per token,   168.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2865.35 ms /    65 runs   (   44.08 ms per token,    22.68 tokens per second)\n",
            "llama_print_timings:       total time =   15734.02 ms /  2221 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.59 ms per token,  1705.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1167.25 ms /   227 tokens (    5.14 ms per token,   194.47 tokens per second)\n",
            "llama_print_timings:        eval time =      37.49 ms /     1 runs   (   37.49 ms per token,    26.67 tokens per second)\n",
            "llama_print_timings:       total time =    1209.87 ms /   228 tokens\n",
            " 20%|██        | 7/35 [05:31<22:50, 48.93s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.05 ms /    20 runs   (    0.55 ms per token,  1809.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.73 ms /   434 tokens (    5.18 ms per token,   192.91 tokens per second)\n",
            "llama_print_timings:        eval time =     735.36 ms /    19 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3010.53 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1466.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4721.27 ms /   884 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =      39.18 ms /     1 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4773.92 ms /   885 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      79.04 ms /   114 runs   (    0.69 ms per token,  1442.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4533.01 ms /   851 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =    4543.57 ms /   113 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    9251.51 ms /   964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      78.26 ms /   144 runs   (    0.54 ms per token,  1840.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5109.94 ms /   949 tokens (    5.38 ms per token,   185.72 tokens per second)\n",
            "llama_print_timings:        eval time =    5771.30 ms /   143 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =   11058.86 ms /  1092 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.48 ms /     2 runs   (    0.74 ms per token,  1354.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1007.97 ms /   200 tokens (    5.04 ms per token,   198.42 tokens per second)\n",
            "llama_print_timings:        eval time =      37.73 ms /     1 runs   (   37.73 ms per token,    26.50 tokens per second)\n",
            "llama_print_timings:       total time =    1052.21 ms /   201 tokens\n",
            " 23%|██▎       | 8/35 [06:05<19:54, 44.23s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      13.61 ms /    20 runs   (    0.68 ms per token,  1469.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.11 ms /   434 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
            "llama_print_timings:        eval time =     738.25 ms /    19 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3045.65 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      26.80 ms /    39 runs   (    0.69 ms per token,  1455.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7681.05 ms /  1379 tokens (    5.57 ms per token,   179.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.70 ms /    38 runs   (   42.04 ms per token,    23.78 tokens per second)\n",
            "llama_print_timings:       total time =    9357.93 ms /  1417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      40.44 ms /    72 runs   (    0.56 ms per token,  1780.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7486.38 ms /  1346 tokens (    5.56 ms per token,   179.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2954.57 ms /    71 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
            "llama_print_timings:       total time =   10538.08 ms /  1417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.12 ms /     2 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7877.38 ms /  1405 tokens (    5.61 ms per token,   178.36 tokens per second)\n",
            "llama_print_timings:        eval time =      41.17 ms /     1 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    7942.79 ms /  1406 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1821.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     796.46 ms /   155 tokens (    5.14 ms per token,   194.61 tokens per second)\n",
            "llama_print_timings:        eval time =      37.57 ms /     1 runs   (   37.57 ms per token,    26.62 tokens per second)\n",
            "llama_print_timings:       total time =     838.59 ms /   156 tokens\n",
            " 26%|██▌       | 9/35 [06:41<18:03, 41.68s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.29 ms /    20 runs   (    0.56 ms per token,  1770.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.93 ms /   434 tokens (    5.18 ms per token,   193.07 tokens per second)\n",
            "llama_print_timings:        eval time =     735.19 ms /    19 runs   (   38.69 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3011.01 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      58.24 ms /    85 runs   (    0.69 ms per token,  1459.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9020.68 ms /  1600 tokens (    5.64 ms per token,   177.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3613.77 ms /    85 runs   (   42.51 ms per token,    23.52 tokens per second)\n",
            "llama_print_timings:       total time =   12777.75 ms /  1685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     156.71 ms /   256 runs   (    0.61 ms per token,  1633.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8865.01 ms /  1568 tokens (    5.65 ms per token,   176.88 tokens per second)\n",
            "llama_print_timings:        eval time =   10897.48 ms /   255 runs   (   42.74 ms per token,    23.40 tokens per second)\n",
            "llama_print_timings:       total time =   20166.75 ms /  1823 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     124.06 ms /   209 runs   (    0.59 ms per token,  1684.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10416.85 ms /  1807 tokens (    5.76 ms per token,   173.47 tokens per second)\n",
            "llama_print_timings:        eval time =    8992.78 ms /   208 runs   (   43.23 ms per token,    23.13 tokens per second)\n",
            "llama_print_timings:       total time =   19708.94 ms /  2015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.37 ms /     2 runs   (    0.68 ms per token,  1461.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1742.09 ms /   344 tokens (    5.06 ms per token,   197.46 tokens per second)\n",
            "llama_print_timings:        eval time =      77.27 ms /     2 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    1826.36 ms /   346 tokens\n",
            " 29%|██▊       | 10/35 [07:44<20:07, 48.30s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      14.33 ms /    20 runs   (    0.72 ms per token,  1395.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2276.26 ms /   434 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =     744.62 ms /    19 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3055.64 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      43.17 ms /    75 runs   (    0.58 ms per token,  1737.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10900.53 ms /  1885 tokens (    5.78 ms per token,   172.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3197.09 ms /    74 runs   (   43.20 ms per token,    23.15 tokens per second)\n",
            "llama_print_timings:       total time =   14208.79 ms /  1959 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     150.14 ms /   256 runs   (    0.59 ms per token,  1705.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10737.59 ms /  1852 tokens (    5.80 ms per token,   172.48 tokens per second)\n",
            "llama_print_timings:        eval time =   11110.38 ms /   255 runs   (   43.57 ms per token,    22.95 tokens per second)\n",
            "llama_print_timings:       total time =   22239.16 ms /  2107 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     115.72 ms /   169 runs   (    0.68 ms per token,  1460.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12326.55 ms /  2094 tokens (    5.89 ms per token,   169.88 tokens per second)\n",
            "llama_print_timings:        eval time =    7431.28 ms /   168 runs   (   44.23 ms per token,    22.61 tokens per second)\n",
            "llama_print_timings:       total time =   20058.20 ms /  2262 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.33 ms /     2 runs   (    0.66 ms per token,  1506.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1740.95 ms /   342 tokens (    5.09 ms per token,   196.44 tokens per second)\n",
            "llama_print_timings:        eval time =      37.93 ms /     1 runs   (   37.93 ms per token,    26.36 tokens per second)\n",
            "llama_print_timings:       total time =    1786.44 ms /   343 tokens\n",
            " 31%|███▏      | 11/35 [08:52<21:43, 54.32s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.20 ms /    20 runs   (    0.56 ms per token,  1785.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.43 ms /   434 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
            "llama_print_timings:        eval time =     735.44 ms /    19 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    3003.07 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      90.91 ms /   156 runs   (    0.58 ms per token,  1715.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11356.07 ms /  1960 tokens (    5.79 ms per token,   172.59 tokens per second)\n",
            "llama_print_timings:        eval time =    6801.13 ms /   156 runs   (   43.60 ms per token,    22.94 tokens per second)\n",
            "llama_print_timings:       total time =   18382.07 ms /  2116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      90.71 ms /   164 runs   (    0.55 ms per token,  1807.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11217.07 ms /  1928 tokens (    5.82 ms per token,   171.88 tokens per second)\n",
            "llama_print_timings:        eval time =    7113.33 ms /   163 runs   (   43.64 ms per token,    22.91 tokens per second)\n",
            "llama_print_timings:       total time =   18563.80 ms /  2091 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      39.84 ms /    65 runs   (    0.61 ms per token,  1631.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12293.65 ms /  2082 tokens (    5.90 ms per token,   169.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2818.16 ms /    64 runs   (   44.03 ms per token,    22.71 tokens per second)\n",
            "llama_print_timings:       total time =   15225.76 ms /  2146 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.49 ms /     2 runs   (    0.74 ms per token,  1345.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1260.54 ms /   244 tokens (    5.17 ms per token,   193.57 tokens per second)\n",
            "llama_print_timings:        eval time =      38.56 ms /     1 runs   (   38.56 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    1306.17 ms /   245 tokens\n",
            " 34%|███▍      | 12/35 [09:55<21:46, 56.81s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.79 ms /    20 runs   (    0.54 ms per token,  1852.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2272.06 ms /   434 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =     739.96 ms /    19 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3040.14 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.52 ms /     2 runs   (    0.76 ms per token,  1314.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3995.18 ms /   760 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
            "llama_print_timings:        eval time =      39.91 ms /     1 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    4047.42 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      33.70 ms /    56 runs   (    0.60 ms per token,  1661.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3861.94 ms /   727 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2161.73 ms /    55 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6103.23 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     136.79 ms /   199 runs   (    0.69 ms per token,  1454.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4037.88 ms /   768 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
            "llama_print_timings:        eval time =    7923.15 ms /   198 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =   12277.33 ms /   966 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     711.78 ms /   141 tokens (    5.05 ms per token,   198.09 tokens per second)\n",
            "llama_print_timings:        eval time =      37.58 ms /     1 runs   (   37.58 ms per token,    26.61 tokens per second)\n",
            "llama_print_timings:       total time =     753.77 ms /   142 tokens\n",
            " 37%|███▋      | 13/35 [10:27<18:04, 49.31s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.25 ms /    20 runs   (    0.56 ms per token,  1778.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2252.42 ms /   434 tokens (    5.19 ms per token,   192.68 tokens per second)\n",
            "llama_print_timings:        eval time =     735.25 ms /    19 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3014.13 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.53 ms /     2 runs   (    0.77 ms per token,  1305.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4722.69 ms /   879 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
            "llama_print_timings:        eval time =      39.73 ms /     1 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4777.56 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      26.59 ms /    44 runs   (    0.60 ms per token,  1655.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4506.69 ms /   846 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1713.90 ms /    43 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    6285.01 ms /   889 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     100.93 ms /   145 runs   (    0.70 ms per token,  1436.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4687.92 ms /   879 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =    5823.10 ms /   144 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =   10730.66 ms /  1023 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.02 ms /     2 runs   (    0.51 ms per token,  1958.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     635.08 ms /   125 tokens (    5.08 ms per token,   196.82 tokens per second)\n",
            "llama_print_timings:        eval time =      37.71 ms /     1 runs   (   37.71 ms per token,    26.52 tokens per second)\n",
            "llama_print_timings:       total time =     677.30 ms /   126 tokens\n",
            " 40%|████      | 14/35 [10:58<15:17, 43.67s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.96 ms /    20 runs   (    0.55 ms per token,  1824.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.40 ms /   434 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
            "llama_print_timings:        eval time =     738.32 ms /    19 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3011.50 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.50 ms /     2 runs   (    0.75 ms per token,  1336.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4768.33 ms /   887 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
            "llama_print_timings:        eval time =      40.02 ms /     1 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    4824.60 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      85.20 ms /   147 runs   (    0.58 ms per token,  1725.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4543.32 ms /   854 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
            "llama_print_timings:        eval time =    5847.26 ms /   146 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =   10576.72 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     157.97 ms /   256 runs   (    0.62 ms per token,  1620.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5392.46 ms /   992 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
            "llama_print_timings:        eval time =   10383.20 ms /   255 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =   16154.33 ms /  1247 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.47 ms /     2 runs   (    0.74 ms per token,  1359.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1179.28 ms /   226 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =      37.65 ms /     1 runs   (   37.65 ms per token,    26.56 tokens per second)\n",
            "llama_print_timings:       total time =    1224.77 ms /   227 tokens\n",
            " 43%|████▎     | 15/35 [11:37<14:04, 42.23s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.36 ms /    20 runs   (    0.57 ms per token,  1760.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2264.78 ms /   434 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =     740.14 ms /    19 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3033.11 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.59 ms /     2 runs   (    0.80 ms per token,  1255.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6380.51 ms /  1166 tokens (    5.47 ms per token,   182.74 tokens per second)\n",
            "llama_print_timings:        eval time =      41.15 ms /     1 runs   (   41.15 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =    6441.13 ms /  1167 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.76 ms /   129 runs   (    0.57 ms per token,  1748.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6187.67 ms /  1133 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
            "llama_print_timings:        eval time =    5237.62 ms /   128 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =   11592.10 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      67.96 ms /   114 runs   (    0.60 ms per token,  1677.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6853.24 ms /  1240 tokens (    5.53 ms per token,   180.94 tokens per second)\n",
            "llama_print_timings:        eval time =    4669.57 ms /   113 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
            "llama_print_timings:       total time =   11675.76 ms /  1353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1819.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1122.03 ms /   221 tokens (    5.08 ms per token,   196.96 tokens per second)\n",
            "llama_print_timings:        eval time =      37.41 ms /     1 runs   (   37.41 ms per token,    26.73 tokens per second)\n",
            "llama_print_timings:       total time =    1164.12 ms /   222 tokens\n",
            " 46%|████▌     | 16/35 [12:15<13:01, 41.13s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      14.02 ms /    20 runs   (    0.70 ms per token,  1427.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.37 ms /   434 tokens (    5.19 ms per token,   192.60 tokens per second)\n",
            "llama_print_timings:        eval time =     742.91 ms /    19 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3031.25 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      83.13 ms /   117 runs   (    0.71 ms per token,  1407.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6782.11 ms /  1237 tokens (    5.48 ms per token,   182.39 tokens per second)\n",
            "llama_print_timings:        eval time =    4817.20 ms /   116 runs   (   41.53 ms per token,    24.08 tokens per second)\n",
            "llama_print_timings:       total time =   11799.50 ms /  1353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     150.54 ms /   256 runs   (    0.59 ms per token,  1700.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6607.58 ms /  1204 tokens (    5.49 ms per token,   182.22 tokens per second)\n",
            "llama_print_timings:        eval time =   10599.62 ms /   255 runs   (   41.57 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =   17610.32 ms /  1459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      34.84 ms /    49 runs   (    0.71 ms per token,  1406.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8079.05 ms /  1445 tokens (    5.59 ms per token,   178.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2028.60 ms /    48 runs   (   42.26 ms per token,    23.66 tokens per second)\n",
            "llama_print_timings:       total time =   10200.49 ms /  1493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1765.79 ms /   343 tokens (    5.15 ms per token,   194.25 tokens per second)\n",
            "llama_print_timings:        eval time =      37.92 ms /     1 runs   (   37.92 ms per token,    26.37 tokens per second)\n",
            "llama_print_timings:       total time =    1811.25 ms /   344 tokens\n",
            " 49%|████▊     | 17/35 [13:05<13:05, 43.67s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.04 ms /    20 runs   (    0.55 ms per token,  1810.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.56 ms /   434 tokens (    5.17 ms per token,   193.27 tokens per second)\n",
            "llama_print_timings:        eval time =     735.11 ms /    19 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    3008.09 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.28 ms /     2 runs   (    0.64 ms per token,  1557.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4547.72 ms /   852 tokens (    5.34 ms per token,   187.35 tokens per second)\n",
            "llama_print_timings:        eval time =      39.89 ms /     1 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    4600.85 ms /   853 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      23.93 ms /    44 runs   (    0.54 ms per token,  1839.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4396.12 ms /   819 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1700.68 ms /    43 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6158.45 ms /   862 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      72.86 ms /   113 runs   (    0.64 ms per token,  1550.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4575.70 ms /   860 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
            "llama_print_timings:        eval time =    4498.89 ms /   112 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    9238.30 ms /   972 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.39 ms /     2 runs   (    0.70 ms per token,  1437.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     602.83 ms /   117 tokens (    5.15 ms per token,   194.08 tokens per second)\n",
            "llama_print_timings:        eval time =      37.95 ms /     1 runs   (   37.95 ms per token,    26.35 tokens per second)\n",
            "llama_print_timings:       total time =     645.39 ms /   118 tokens\n",
            " 51%|█████▏    | 18/35 [13:32<10:57, 38.66s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.96 ms /    20 runs   (    0.55 ms per token,  1824.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2272.83 ms /   434 tokens (    5.24 ms per token,   190.95 tokens per second)\n",
            "llama_print_timings:        eval time =     739.20 ms /    19 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3038.76 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4946.95 ms /   925 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
            "llama_print_timings:        eval time =      40.01 ms /     1 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    4999.81 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      52.17 ms /    91 runs   (    0.57 ms per token,  1744.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4826.83 ms /   892 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3601.08 ms /    90 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    8544.66 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.60 ms per token,  1654.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5275.57 ms /   980 tokens (    5.38 ms per token,   185.76 tokens per second)\n",
            "llama_print_timings:        eval time =      39.54 ms /     1 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    5328.59 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.52 ms /     2 runs   (    0.76 ms per token,  1317.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     835.16 ms /   164 tokens (    5.09 ms per token,   196.37 tokens per second)\n",
            "llama_print_timings:        eval time =      37.93 ms /     1 runs   (   37.93 ms per token,    26.37 tokens per second)\n",
            "llama_print_timings:       total time =     878.84 ms /   165 tokens\n",
            " 54%|█████▍    | 19/35 [13:58<09:21, 35.11s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      18.93 ms /    20 runs   (    0.95 ms per token,  1056.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.23 ms /   434 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =     748.02 ms /    19 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3073.79 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1818.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3724.19 ms /   712 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
            "llama_print_timings:        eval time =      79.74 ms /     2 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    3814.05 ms /   714 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.96 ms /    99 runs   (    0.75 ms per token,  1338.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3550.35 ms /   680 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3903.55 ms /    98 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7614.82 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      58.04 ms /    97 runs   (    0.60 ms per token,  1671.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4095.12 ms /   774 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3806.98 ms /    96 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    8023.58 ms /   870 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.25 ms /     2 runs   (    0.63 ms per token,  1596.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     876.48 ms /   174 tokens (    5.04 ms per token,   198.52 tokens per second)\n",
            "llama_print_timings:        eval time =      39.21 ms /     1 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =     920.33 ms /   175 tokens\n",
            " 57%|█████▋    | 20/35 [14:26<08:14, 32.93s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      13.60 ms /    20 runs   (    0.68 ms per token,  1471.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2262.87 ms /   434 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =     742.78 ms /    19 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3040.51 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     141.58 ms /   256 runs   (    0.55 ms per token,  1808.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10159.86 ms /  1773 tokens (    5.73 ms per token,   174.51 tokens per second)\n",
            "llama_print_timings:        eval time =   11020.26 ms /   255 runs   (   43.22 ms per token,    23.14 tokens per second)\n",
            "llama_print_timings:       total time =   21542.89 ms /  2028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      43.01 ms /    87 runs   (    0.49 ms per token,  2022.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10010.55 ms /  1740 tokens (    5.75 ms per token,   173.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3690.68 ms /    86 runs   (   42.91 ms per token,    23.30 tokens per second)\n",
            "llama_print_timings:       total time =   13819.68 ms /  1826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      49.99 ms /    97 runs   (    0.52 ms per token,  1940.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10565.56 ms /  1826 tokens (    5.79 ms per token,   172.83 tokens per second)\n",
            "llama_print_timings:        eval time =    4135.49 ms /    96 runs   (   43.08 ms per token,    23.21 tokens per second)\n",
            "llama_print_timings:       total time =   14834.02 ms /  1922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     794.17 ms /   158 tokens (    5.03 ms per token,   198.95 tokens per second)\n",
            "llama_print_timings:        eval time =      37.73 ms /     1 runs   (   37.73 ms per token,    26.50 tokens per second)\n",
            "llama_print_timings:       total time =     835.80 ms /   159 tokens\n",
            " 60%|██████    | 21/35 [15:26<09:32, 40.87s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      14.31 ms /    20 runs   (    0.72 ms per token,  1397.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2268.92 ms /   434 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =     748.57 ms /    19 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3053.29 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      33.97 ms /    48 runs   (    0.71 ms per token,  1412.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7312.52 ms /  1327 tokens (    5.51 ms per token,   181.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1960.12 ms /    47 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
            "llama_print_timings:       total time =    9358.79 ms /  1374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      49.68 ms /    88 runs   (    0.56 ms per token,  1771.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7151.05 ms /  1294 tokens (    5.53 ms per token,   180.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3597.48 ms /    87 runs   (   41.35 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =   10869.86 ms /  1381 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7679.14 ms /  1376 tokens (    5.58 ms per token,   179.19 tokens per second)\n",
            "llama_print_timings:        eval time =      40.88 ms /     1 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    7742.50 ms /  1377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.24 ms /     2 runs   (    0.62 ms per token,  1615.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     836.73 ms /   164 tokens (    5.10 ms per token,   196.00 tokens per second)\n",
            "llama_print_timings:        eval time =      37.68 ms /     1 runs   (   37.68 ms per token,    26.54 tokens per second)\n",
            "llama_print_timings:       total time =     879.31 ms /   165 tokens\n",
            " 63%|██████▎   | 22/35 [16:02<08:34, 39.61s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.00 ms /    20 runs   (    0.55 ms per token,  1818.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.46 ms /   434 tokens (    5.18 ms per token,   192.93 tokens per second)\n",
            "llama_print_timings:        eval time =     735.86 ms /    19 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3010.47 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.46 ms /     2 runs   (    0.73 ms per token,  1370.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4537.30 ms /   845 tokens (    5.37 ms per token,   186.23 tokens per second)\n",
            "llama_print_timings:        eval time =      39.77 ms /     1 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    4591.79 ms /   846 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      22.84 ms /    39 runs   (    0.59 ms per token,  1707.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4323.33 ms /   812 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.81 ms /    38 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5875.92 ms /   850 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      85.11 ms /   114 runs   (    0.75 ms per token,  1339.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4495.90 ms /   848 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =    4564.58 ms /   113 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    9255.36 ms /   961 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     554.58 ms /   112 tokens (    4.95 ms per token,   201.95 tokens per second)\n",
            "llama_print_timings:        eval time =      37.33 ms /     1 runs   (   37.33 ms per token,    26.79 tokens per second)\n",
            "llama_print_timings:       total time =     596.44 ms /   113 tokens\n",
            " 66%|██████▌   | 23/35 [16:29<07:07, 35.62s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.84 ms /    20 runs   (    0.54 ms per token,  1844.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.17 ms /   434 tokens (    5.17 ms per token,   193.39 tokens per second)\n",
            "llama_print_timings:        eval time =     738.80 ms /    19 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3008.91 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.34 ms /     2 runs   (    0.67 ms per token,  1494.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4779.67 ms /   895 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =      40.04 ms /     1 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    4833.35 ms /   896 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      68.87 ms /   117 runs   (    0.59 ms per token,  1698.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4613.65 ms /   862 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4635.95 ms /   116 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    9402.48 ms /   978 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      84.34 ms /   126 runs   (    0.67 ms per token,  1494.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5251.07 ms /   975 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
            "llama_print_timings:        eval time =    5071.03 ms /   125 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =   10511.24 ms /  1100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     957.35 ms /   191 tokens (    5.01 ms per token,   199.51 tokens per second)\n",
            "llama_print_timings:        eval time =      37.95 ms /     1 runs   (   37.95 ms per token,    26.35 tokens per second)\n",
            "llama_print_timings:       total time =    1000.13 ms /   192 tokens\n",
            " 69%|██████▊   | 24/35 [17:01<06:19, 34.52s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.87 ms /    20 runs   (    0.54 ms per token,  1839.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.68 ms /   434 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
            "llama_print_timings:        eval time =     736.37 ms /    19 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3008.56 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.19 ms /     2 runs   (    0.60 ms per token,  1676.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5137.90 ms /   948 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =      39.75 ms /     1 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    5193.71 ms /   949 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      91.24 ms /   147 runs   (    0.62 ms per token,  1611.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4900.04 ms /   915 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    5878.95 ms /   146 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =   10986.63 ms /  1061 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.19 ms /     2 runs   (    0.59 ms per token,  1684.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5687.12 ms /  1048 tokens (    5.43 ms per token,   184.28 tokens per second)\n",
            "llama_print_timings:        eval time =      81.69 ms /     2 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    5784.56 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1719.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1165.21 ms /   230 tokens (    5.07 ms per token,   197.39 tokens per second)\n",
            "llama_print_timings:        eval time =      37.55 ms /     1 runs   (   37.55 ms per token,    26.63 tokens per second)\n",
            "llama_print_timings:       total time =    1208.21 ms /   231 tokens\n",
            " 71%|███████▏  | 25/35 [17:30<05:30, 33.02s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.64 ms /    20 runs   (    0.53 ms per token,  1880.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.47 ms /   434 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
            "llama_print_timings:        eval time =     739.81 ms /    19 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3012.23 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      54.51 ms /    93 runs   (    0.59 ms per token,  1706.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5961.80 ms /  1096 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3789.77 ms /    93 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    9879.78 ms /  1189 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      57.66 ms /    96 runs   (    0.60 ms per token,  1664.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5792.01 ms /  1064 tokens (    5.44 ms per token,   183.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3884.48 ms /    95 runs   (   40.89 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    9810.81 ms /  1159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.93 ms /   106 runs   (    0.70 ms per token,  1433.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6264.90 ms /  1147 tokens (    5.46 ms per token,   183.08 tokens per second)\n",
            "llama_print_timings:        eval time =    4337.51 ms /   105 runs   (   41.31 ms per token,    24.21 tokens per second)\n",
            "llama_print_timings:       total time =   10775.28 ms /  1252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      23.20 ms /    38 runs   (    0.61 ms per token,  1637.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     927.52 ms /   179 tokens (    5.18 ms per token,   192.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1410.51 ms /    37 runs   (   38.12 ms per token,    26.23 tokens per second)\n",
            "llama_print_timings:       total time =    2388.06 ms /   216 tokens\n",
            " 74%|███████▍  | 26/35 [18:10<05:15, 35.09s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.04 ms /    20 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.26 ms /   434 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
            "llama_print_timings:        eval time =     739.33 ms /    19 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3013.86 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.53 ms per token,  1874.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7329.64 ms /  1320 tokens (    5.55 ms per token,   180.09 tokens per second)\n",
            "llama_print_timings:        eval time =      40.49 ms /     1 runs   (   40.49 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    7390.94 ms /  1321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      44.48 ms /    63 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7080.49 ms /  1287 tokens (    5.50 ms per token,   181.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2587.79 ms /    62 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
            "llama_print_timings:       total time =    9777.02 ms /  1349 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      65.96 ms /   110 runs   (    0.60 ms per token,  1667.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7512.49 ms /  1351 tokens (    5.56 ms per token,   179.83 tokens per second)\n",
            "llama_print_timings:        eval time =    4545.07 ms /   109 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
            "llama_print_timings:       total time =   12213.28 ms /  1460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.50 ms /     2 runs   (    0.75 ms per token,  1331.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     677.92 ms /   132 tokens (    5.14 ms per token,   194.71 tokens per second)\n",
            "llama_print_timings:        eval time =      38.11 ms /     1 runs   (   38.11 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =     721.39 ms /   133 tokens\n",
            " 77%|███████▋  | 27/35 [18:48<04:48, 36.03s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      15.70 ms /    20 runs   (    0.79 ms per token,  1273.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.60 ms /   434 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =     748.01 ms /    19 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3064.66 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.49 ms /     2 runs   (    0.74 ms per token,  1344.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7281.24 ms /  1320 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =      83.16 ms /     2 runs   (   41.58 ms per token,    24.05 tokens per second)\n",
            "llama_print_timings:       total time =    7382.80 ms /  1322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      86.00 ms /   142 runs   (    0.61 ms per token,  1651.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7142.02 ms /  1288 tokens (    5.55 ms per token,   180.34 tokens per second)\n",
            "llama_print_timings:        eval time =    5847.25 ms /   141 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =   13543.24 ms /  1429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      62.16 ms /   103 runs   (    0.60 ms per token,  1657.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8037.12 ms /  1428 tokens (    5.63 ms per token,   177.68 tokens per second)\n",
            "llama_print_timings:        eval time =    4276.06 ms /   102 runs   (   41.92 ms per token,    23.85 tokens per second)\n",
            "llama_print_timings:       total time =   12460.57 ms /  1530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.58 ms per token,  1713.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1080.84 ms /   214 tokens (    5.05 ms per token,   197.99 tokens per second)\n",
            "llama_print_timings:        eval time =      37.44 ms /     1 runs   (   37.44 ms per token,    26.71 tokens per second)\n",
            "llama_print_timings:       total time =    1123.09 ms /   215 tokens\n",
            " 80%|████████  | 28/35 [19:30<04:24, 37.80s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      13.73 ms /    20 runs   (    0.69 ms per token,  1456.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2258.81 ms /   434 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
            "llama_print_timings:        eval time =     741.73 ms /    19 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3033.45 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.60 ms per token,  1654.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4122.58 ms /   778 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
            "llama_print_timings:        eval time =      39.29 ms /     1 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    4173.51 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      77.22 ms /   112 runs   (    0.69 ms per token,  1450.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3908.94 ms /   744 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4463.27 ms /   112 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    8559.26 ms /   856 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      67.39 ms /   113 runs   (    0.60 ms per token,  1676.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4459.01 ms /   836 tokens (    5.33 ms per token,   187.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4466.78 ms /   112 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    9071.68 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1039.09 ms /   203 tokens (    5.12 ms per token,   195.36 tokens per second)\n",
            "llama_print_timings:        eval time =      37.39 ms /     1 runs   (   37.39 ms per token,    26.75 tokens per second)\n",
            "llama_print_timings:       total time =    1081.71 ms /   204 tokens\n",
            " 83%|████████▎ | 29/35 [20:00<03:32, 35.46s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      13.90 ms /    20 runs   (    0.69 ms per token,  1439.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2267.85 ms /   434 tokens (    5.23 ms per token,   191.37 tokens per second)\n",
            "llama_print_timings:        eval time =     749.74 ms /    19 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3050.33 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.29 ms /     2 runs   (    0.64 ms per token,  1555.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5592.95 ms /  1034 tokens (    5.41 ms per token,   184.88 tokens per second)\n",
            "llama_print_timings:        eval time =      41.02 ms /     1 runs   (   41.02 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    5649.34 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      29.52 ms /    47 runs   (    0.63 ms per token,  1592.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5405.77 ms /  1000 tokens (    5.41 ms per token,   184.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1912.15 ms /    47 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    7394.75 ms /  1047 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     168.47 ms /   256 runs   (    0.66 ms per token,  1519.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5560.22 ms /  1032 tokens (    5.39 ms per token,   185.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10493.65 ms /   256 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =   16453.38 ms /  1288 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.11 ms /     2 runs   (    0.56 ms per token,  1800.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     670.94 ms /   132 tokens (    5.08 ms per token,   196.74 tokens per second)\n",
            "llama_print_timings:        eval time =      37.62 ms /     1 runs   (   37.62 ms per token,    26.58 tokens per second)\n",
            "llama_print_timings:       total time =     712.99 ms /   133 tokens\n",
            " 86%|████████▌ | 30/35 [20:38<03:00, 36.16s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.58 ms /    20 runs   (    0.58 ms per token,  1727.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.70 ms /   434 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
            "llama_print_timings:        eval time =     737.54 ms /    19 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3009.07 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.56 ms per token,  1776.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3598.77 ms /   680 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =      77.63 ms /     2 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3692.13 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      80.17 ms /   139 runs   (    0.58 ms per token,  1733.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3374.41 ms /   648 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
            "llama_print_timings:        eval time =    5434.61 ms /   138 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    8982.55 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.93 ms /   113 runs   (    0.65 ms per token,  1528.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4127.77 ms /   773 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4453.51 ms /   112 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    8742.70 ms /   885 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.57 ms per token,  1743.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1124.45 ms /   223 tokens (    5.04 ms per token,   198.32 tokens per second)\n",
            "llama_print_timings:        eval time =      37.31 ms /     1 runs   (   37.31 ms per token,    26.80 tokens per second)\n",
            "llama_print_timings:       total time =    1168.22 ms /   224 tokens\n",
            " 89%|████████▊ | 31/35 [21:08<02:16, 34.24s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.88 ms /    20 runs   (    0.54 ms per token,  1838.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.59 ms /   434 tokens (    5.18 ms per token,   193.10 tokens per second)\n",
            "llama_print_timings:        eval time =     734.88 ms /    19 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    3009.20 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6737.24 ms /  1230 tokens (    5.48 ms per token,   182.57 tokens per second)\n",
            "llama_print_timings:        eval time =      40.60 ms /     1 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    6793.35 ms /  1231 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      75.40 ms /   128 runs   (    0.59 ms per token,  1697.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6590.84 ms /  1197 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5243.81 ms /   127 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =   12008.41 ms /  1324 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.43 ms /     2 runs   (    0.72 ms per token,  1394.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7257.91 ms /  1311 tokens (    5.54 ms per token,   180.63 tokens per second)\n",
            "llama_print_timings:        eval time =      41.36 ms /     1 runs   (   41.36 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =    7317.94 ms /  1312 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.51 ms /     2 runs   (    0.76 ms per token,  1321.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1095.26 ms /   212 tokens (    5.17 ms per token,   193.56 tokens per second)\n",
            "llama_print_timings:        eval time =      37.77 ms /     1 runs   (   37.77 ms per token,    26.47 tokens per second)\n",
            "llama_print_timings:       total time =    1139.82 ms /   213 tokens\n",
            " 91%|█████████▏| 32/35 [21:43<01:43, 34.53s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    20 runs   (    0.54 ms per token,  1842.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2278.52 ms /   434 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =     737.08 ms /    19 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3045.01 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.34 ms /     2 runs   (    0.67 ms per token,  1494.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4583.74 ms /   864 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =      39.57 ms /     1 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    4635.61 ms /   865 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      52.71 ms /    85 runs   (    0.62 ms per token,  1612.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4439.03 ms /   831 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3363.91 ms /    84 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    7922.56 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      36.47 ms /    67 runs   (    0.54 ms per token,  1837.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4810.88 ms /   899 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2638.12 ms /    66 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    7531.04 ms /   965 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.27 ms /     2 runs   (    0.64 ms per token,  1574.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     883.64 ms /   172 tokens (    5.14 ms per token,   194.65 tokens per second)\n",
            "llama_print_timings:        eval time =      38.66 ms /     1 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =     926.96 ms /   173 tokens\n",
            " 94%|█████████▍| 33/35 [22:10<01:04, 32.25s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      18.06 ms /    20 runs   (    0.90 ms per token,  1107.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2277.07 ms /   434 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =     737.29 ms /    19 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    3054.08 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1466.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3502.05 ms /   671 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =      38.60 ms /     1 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    3551.21 ms /   672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      77.09 ms /   109 runs   (    0.71 ms per token,  1413.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3323.10 ms /   638 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
            "llama_print_timings:        eval time =    4280.36 ms /   108 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    7775.57 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      38.83 ms /    64 runs   (    0.61 ms per token,  1648.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3865.99 ms /   735 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2491.69 ms /    63 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6442.54 ms /   798 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.06 ms /     2 runs   (    0.53 ms per token,  1883.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     960.82 ms /   191 tokens (    5.03 ms per token,   198.79 tokens per second)\n",
            "llama_print_timings:        eval time =      37.80 ms /     1 runs   (   37.80 ms per token,    26.45 tokens per second)\n",
            "llama_print_timings:       total time =    1004.16 ms /   192 tokens\n",
            " 97%|█████████▋| 34/35 [22:35<00:30, 30.05s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      11.06 ms /    20 runs   (    0.55 ms per token,  1808.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.96 ms /   434 tokens (    5.18 ms per token,   192.89 tokens per second)\n",
            "llama_print_timings:        eval time =     735.43 ms /    19 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3010.95 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       0.89 ms /     2 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4480.48 ms /   842 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =      39.05 ms /     1 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    4531.87 ms /   843 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     137.16 ms /   198 runs   (    0.69 ms per token,  1443.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4264.13 ms /   808 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =    7964.13 ms /   198 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =   12538.07 ms /  1006 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.24 ms /    67 runs   (    0.71 ms per token,  1418.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5331.46 ms /   986 tokens (    5.41 ms per token,   184.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2688.13 ms /    66 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    8126.16 ms /  1052 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.49 ms /     2 runs   (    0.74 ms per token,  1344.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1474.38 ms /   288 tokens (    5.12 ms per token,   195.34 tokens per second)\n",
            "llama_print_timings:        eval time =      77.63 ms /     2 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    1561.68 ms /   290 tokens\n",
            "100%|██████████| 35/35 [23:10<00:00, 39.72s/it]\n",
            "  0%|          | 0/35 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    15 runs   (    0.57 ms per token,  1744.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2273.04 ms /   434 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
            "llama_print_timings:        eval time =     539.58 ms /    14 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2834.75 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.35 ms /     2 runs   (    0.68 ms per token,  1476.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6265.13 ms /  1144 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =      82.57 ms /     2 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =    6368.82 ms /  1146 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      51.11 ms /    97 runs   (    0.53 ms per token,  1897.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6042.62 ms /  1112 tokens (    5.43 ms per token,   184.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3924.20 ms /    96 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =   10092.55 ms /  1208 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      38.48 ms /    67 runs   (    0.57 ms per token,  1741.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6618.69 ms /  1195 tokens (    5.54 ms per token,   180.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2714.18 ms /    66 runs   (   41.12 ms per token,    24.32 tokens per second)\n",
            "llama_print_timings:       total time =    9429.27 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.09 ms /     2 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     923.81 ms /   181 tokens (    5.10 ms per token,   195.93 tokens per second)\n",
            "llama_print_timings:        eval time =      38.34 ms /     1 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =     967.96 ms /   182 tokens\n",
            "  3%|▎         | 1/35 [00:36<20:25, 36.06s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.54 ms /    15 runs   (    0.57 ms per token,  1757.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.41 ms /   434 tokens (    5.18 ms per token,   192.94 tokens per second)\n",
            "llama_print_timings:        eval time =     540.17 ms /    14 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2811.05 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      50.52 ms /    70 runs   (    0.72 ms per token,  1385.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8913.70 ms /  1581 tokens (    5.64 ms per token,   177.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2942.44 ms /    69 runs   (   42.64 ms per token,    23.45 tokens per second)\n",
            "llama_print_timings:       total time =   11986.36 ms /  1650 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      84.86 ms /   131 runs   (    0.65 ms per token,  1543.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8736.21 ms /  1548 tokens (    5.64 ms per token,   177.19 tokens per second)\n",
            "llama_print_timings:        eval time =    5554.98 ms /   130 runs   (   42.73 ms per token,    23.40 tokens per second)\n",
            "llama_print_timings:       total time =   14509.45 ms /  1678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      84.50 ms /   127 runs   (    0.67 ms per token,  1502.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9452.55 ms /  1661 tokens (    5.69 ms per token,   175.72 tokens per second)\n",
            "llama_print_timings:        eval time =    5414.11 ms /   126 runs   (   42.97 ms per token,    23.27 tokens per second)\n",
            "llama_print_timings:       total time =   15078.96 ms /  1787 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1119.74 ms /   219 tokens (    5.11 ms per token,   195.58 tokens per second)\n",
            "llama_print_timings:        eval time =      37.19 ms /     1 runs   (   37.19 ms per token,    26.89 tokens per second)\n",
            "llama_print_timings:       total time =    1162.16 ms /   220 tokens\n",
            "  6%|▌         | 2/35 [01:28<25:05, 45.62s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       7.91 ms /    15 runs   (    0.53 ms per token,  1896.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.41 ms /   434 tokens (    5.17 ms per token,   193.46 tokens per second)\n",
            "llama_print_timings:        eval time =     540.87 ms /    14 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2804.80 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.28 ms /    84 runs   (    0.56 ms per token,  1776.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10329.28 ms /  1796 tokens (    5.75 ms per token,   173.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3562.80 ms /    83 runs   (   42.93 ms per token,    23.30 tokens per second)\n",
            "llama_print_timings:       total time =   14014.71 ms /  1879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      54.78 ms /   109 runs   (    0.50 ms per token,  1989.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10149.46 ms /  1763 tokens (    5.76 ms per token,   173.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4641.22 ms /   108 runs   (   42.97 ms per token,    23.27 tokens per second)\n",
            "llama_print_timings:       total time =   14935.20 ms /  1871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      99.82 ms /   160 runs   (    0.62 ms per token,  1602.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10793.41 ms /  1864 tokens (    5.79 ms per token,   172.70 tokens per second)\n",
            "llama_print_timings:        eval time =    6914.82 ms /   159 runs   (   43.49 ms per token,    22.99 tokens per second)\n",
            "llama_print_timings:       total time =   17968.88 ms /  2023 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.62 ms /     2 runs   (    0.81 ms per token,  1233.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     966.25 ms /   187 tokens (    5.17 ms per token,   193.53 tokens per second)\n",
            "llama_print_timings:        eval time =      37.90 ms /     1 runs   (   37.90 ms per token,    26.39 tokens per second)\n",
            "llama_print_timings:       total time =    1010.20 ms /   188 tokens\n",
            "  9%|▊         | 3/35 [02:24<26:50, 50.32s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.12 ms /    15 runs   (    0.54 ms per token,  1848.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2260.86 ms /   434 tokens (    5.21 ms per token,   191.96 tokens per second)\n",
            "llama_print_timings:        eval time =     541.90 ms /    14 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2824.56 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.40 ms /     2 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5722.56 ms /  1055 tokens (    5.42 ms per token,   184.36 tokens per second)\n",
            "llama_print_timings:        eval time =      40.55 ms /     1 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    5781.77 ms /  1056 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     122.93 ms /   210 runs   (    0.59 ms per token,  1708.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5504.56 ms /  1022 tokens (    5.39 ms per token,   185.66 tokens per second)\n",
            "llama_print_timings:        eval time =    8535.34 ms /   209 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =   14355.30 ms /  1231 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.41 ms /    74 runs   (    0.57 ms per token,  1744.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6713.48 ms /  1221 tokens (    5.50 ms per token,   181.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3009.26 ms /    73 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =    9820.25 ms /  1294 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.53 ms /     2 runs   (    0.77 ms per token,  1305.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1497.11 ms /   291 tokens (    5.14 ms per token,   194.37 tokens per second)\n",
            "llama_print_timings:        eval time =      37.97 ms /     1 runs   (   37.97 ms per token,    26.33 tokens per second)\n",
            "llama_print_timings:       total time =    1541.70 ms /   292 tokens\n",
            " 11%|█▏        | 4/35 [03:03<23:48, 46.07s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.42 ms /    15 runs   (    0.69 ms per token,  1440.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2283.42 ms /   434 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =     548.32 ms /    14 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2859.09 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     142.28 ms /   256 runs   (    0.56 ms per token,  1799.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9762.86 ms /  1709 tokens (    5.71 ms per token,   175.05 tokens per second)\n",
            "llama_print_timings:        eval time =   10963.77 ms /   255 runs   (   43.00 ms per token,    23.26 tokens per second)\n",
            "llama_print_timings:       total time =   21085.68 ms /  1964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      26.51 ms /    51 runs   (    0.52 ms per token,  1924.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9596.47 ms /  1676 tokens (    5.73 ms per token,   174.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2132.36 ms /    50 runs   (   42.65 ms per token,    23.45 tokens per second)\n",
            "llama_print_timings:       total time =   11810.09 ms /  1726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      89.05 ms /   164 runs   (    0.54 ms per token,  1841.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9843.34 ms /  1718 tokens (    5.73 ms per token,   174.53 tokens per second)\n",
            "llama_print_timings:        eval time =    6989.93 ms /   163 runs   (   42.88 ms per token,    23.32 tokens per second)\n",
            "llama_print_timings:       total time =   17053.30 ms /  1881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.30 ms /     2 runs   (    0.65 ms per token,  1536.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     678.84 ms /   130 tokens (    5.22 ms per token,   191.50 tokens per second)\n",
            "llama_print_timings:        eval time =      37.91 ms /     1 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
            "llama_print_timings:       total time =     721.80 ms /   131 tokens\n",
            " 14%|█▍        | 5/35 [04:02<25:20, 50.67s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.18 ms /    15 runs   (    0.68 ms per token,  1474.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2276.85 ms /   434 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     549.96 ms /    14 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2853.56 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      51.01 ms /    85 runs   (    0.60 ms per token,  1666.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9636.94 ms /  1690 tokens (    5.70 ms per token,   175.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3585.25 ms /    84 runs   (   42.68 ms per token,    23.43 tokens per second)\n",
            "llama_print_timings:       total time =   13348.78 ms /  1774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      95.18 ms /   154 runs   (    0.62 ms per token,  1617.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9405.37 ms /  1656 tokens (    5.68 ms per token,   176.07 tokens per second)\n",
            "llama_print_timings:        eval time =    6599.39 ms /   154 runs   (   42.85 ms per token,    23.34 tokens per second)\n",
            "llama_print_timings:       total time =   16237.03 ms /  1810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      76.39 ms /   134 runs   (    0.57 ms per token,  1754.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10321.50 ms /  1792 tokens (    5.76 ms per token,   173.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5772.85 ms /   134 runs   (   43.08 ms per token,    23.21 tokens per second)\n",
            "llama_print_timings:       total time =   16278.13 ms /  1926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.59 ms per token,  1705.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1248.10 ms /   242 tokens (    5.16 ms per token,   193.90 tokens per second)\n",
            "llama_print_timings:        eval time =      37.38 ms /     1 runs   (   37.38 ms per token,    26.75 tokens per second)\n",
            "llama_print_timings:       total time =    1290.64 ms /   243 tokens\n",
            " 17%|█▋        | 6/35 [04:57<25:10, 52.08s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      12.09 ms /    15 runs   (    0.81 ms per token,  1240.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.20 ms /   434 tokens (    5.18 ms per token,   193.22 tokens per second)\n",
            "llama_print_timings:        eval time =     548.71 ms /    14 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2822.21 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     128.35 ms /   231 runs   (    0.56 ms per token,  1799.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12021.09 ms /  2055 tokens (    5.85 ms per token,   170.95 tokens per second)\n",
            "llama_print_timings:        eval time =   10130.80 ms /   230 runs   (   44.05 ms per token,    22.70 tokens per second)\n",
            "llama_print_timings:       total time =   22480.01 ms /  2285 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     106.23 ms /   173 runs   (    0.61 ms per token,  1628.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11879.37 ms /  2022 tokens (    5.88 ms per token,   170.21 tokens per second)\n",
            "llama_print_timings:        eval time =    7591.61 ms /   172 runs   (   44.14 ms per token,    22.66 tokens per second)\n",
            "llama_print_timings:       total time =   19759.95 ms /  2194 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.64 ms /    82 runs   (    0.58 ms per token,  1721.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12936.17 ms /  2184 tokens (    5.92 ms per token,   168.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3576.17 ms /    81 runs   (   44.15 ms per token,    22.65 tokens per second)\n",
            "llama_print_timings:       total time =   16637.27 ms /  2265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1282.28 ms /   254 tokens (    5.05 ms per token,   198.08 tokens per second)\n",
            "llama_print_timings:        eval time =      37.16 ms /     1 runs   (   37.16 ms per token,    26.91 tokens per second)\n",
            "llama_print_timings:       total time =    1325.13 ms /   255 tokens\n",
            " 20%|██        | 7/35 [06:07<26:58, 57.79s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    15 runs   (    0.57 ms per token,  1749.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.72 ms /   434 tokens (    5.16 ms per token,   193.69 tokens per second)\n",
            "llama_print_timings:        eval time =     539.77 ms /    14 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2801.51 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.54 ms /    75 runs   (    0.63 ms per token,  1577.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7842.96 ms /  1416 tokens (    5.54 ms per token,   180.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3098.03 ms /    74 runs   (   41.87 ms per token,    23.89 tokens per second)\n",
            "llama_print_timings:       total time =   11056.57 ms /  1490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      69.59 ms /   132 runs   (    0.53 ms per token,  1896.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7698.39 ms /  1383 tokens (    5.57 ms per token,   179.65 tokens per second)\n",
            "llama_print_timings:        eval time =    5475.01 ms /   131 runs   (   41.79 ms per token,    23.93 tokens per second)\n",
            "llama_print_timings:       total time =   13349.72 ms /  1514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      42.78 ms /    74 runs   (    0.58 ms per token,  1729.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8476.46 ms /  1499 tokens (    5.65 ms per token,   176.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3075.12 ms /    73 runs   (   42.12 ms per token,    23.74 tokens per second)\n",
            "llama_print_timings:       total time =   11660.75 ms /  1572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.12 ms /     2 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1124.03 ms /   218 tokens (    5.16 ms per token,   193.94 tokens per second)\n",
            "llama_print_timings:        eval time =      37.28 ms /     1 runs   (   37.28 ms per token,    26.82 tokens per second)\n",
            "llama_print_timings:       total time =    1168.25 ms /   219 tokens\n",
            " 23%|██▎       | 8/35 [06:51<24:08, 53.64s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.26 ms /    15 runs   (    0.68 ms per token,  1461.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2263.49 ms /   434 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =     546.37 ms /    14 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2835.67 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1819.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6731.85 ms /  1230 tokens (    5.47 ms per token,   182.71 tokens per second)\n",
            "llama_print_timings:        eval time =      40.61 ms /     1 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    6789.12 ms /  1231 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      59.16 ms /   106 runs   (    0.56 ms per token,  1791.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6599.97 ms /  1197 tokens (    5.51 ms per token,   181.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4321.70 ms /   105 runs   (   41.16 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =   11058.57 ms /  1302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      64.00 ms /    99 runs   (    0.65 ms per token,  1546.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7167.57 ms /  1290 tokens (    5.56 ms per token,   179.98 tokens per second)\n",
            "llama_print_timings:        eval time =    4080.22 ms /    98 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
            "llama_print_timings:       total time =   11393.16 ms /  1388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.26 ms /     2 runs   (    0.63 ms per token,  1586.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     957.70 ms /   189 tokens (    5.07 ms per token,   197.35 tokens per second)\n",
            "llama_print_timings:        eval time =      37.52 ms /     1 runs   (   37.52 ms per token,    26.66 tokens per second)\n",
            "llama_print_timings:       total time =    1000.01 ms /   190 tokens\n",
            " 26%|██▌       | 9/35 [07:30<21:15, 49.05s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.52 ms /    15 runs   (    0.57 ms per token,  1759.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.31 ms /   434 tokens (    5.18 ms per token,   193.21 tokens per second)\n",
            "llama_print_timings:        eval time =     541.79 ms /    14 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2809.35 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.88 ms /    68 runs   (    0.70 ms per token,  1420.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9460.22 ms /  1670 tokens (    5.66 ms per token,   176.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2874.85 ms /    67 runs   (   42.91 ms per token,    23.31 tokens per second)\n",
            "llama_print_timings:       total time =   12460.06 ms /  1737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     157.56 ms /   256 runs   (    0.62 ms per token,  1624.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9288.22 ms /  1637 tokens (    5.67 ms per token,   176.24 tokens per second)\n",
            "llama_print_timings:        eval time =   10951.03 ms /   255 runs   (   42.95 ms per token,    23.29 tokens per second)\n",
            "llama_print_timings:       total time =   20645.52 ms /  1892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     162.75 ms /   256 runs   (    0.64 ms per token,  1572.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10889.54 ms /  1876 tokens (    5.80 ms per token,   172.28 tokens per second)\n",
            "llama_print_timings:        eval time =   11105.00 ms /   255 runs   (   43.55 ms per token,    22.96 tokens per second)\n",
            "llama_print_timings:       total time =   22417.50 ms /  2131 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.05 ms /     2 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1751.63 ms /   344 tokens (    5.09 ms per token,   196.39 tokens per second)\n",
            "llama_print_timings:        eval time =      77.18 ms /     2 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    1835.59 ms /   346 tokens\n",
            " 29%|██▊       | 10/35 [08:37<22:43, 54.53s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.20 ms /    15 runs   (    0.55 ms per token,  1829.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.73 ms /   434 tokens (    5.17 ms per token,   193.51 tokens per second)\n",
            "llama_print_timings:        eval time =     540.56 ms /    14 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2806.47 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      43.65 ms /    75 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10329.20 ms /  1794 tokens (    5.76 ms per token,   173.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3175.08 ms /    74 runs   (   42.91 ms per token,    23.31 tokens per second)\n",
            "llama_print_timings:       total time =   13616.33 ms /  1868 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     142.66 ms /   221 runs   (    0.65 ms per token,  1549.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10108.43 ms /  1760 tokens (    5.74 ms per token,   174.11 tokens per second)\n",
            "llama_print_timings:        eval time =    9557.16 ms /   221 runs   (   43.25 ms per token,    23.12 tokens per second)\n",
            "llama_print_timings:       total time =   20033.93 ms /  1981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      54.44 ms /    70 runs   (    0.78 ms per token,  1285.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11456.45 ms /  1967 tokens (    5.82 ms per token,   171.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3031.65 ms /    69 runs   (   43.94 ms per token,    22.76 tokens per second)\n",
            "llama_print_timings:       total time =   14633.76 ms /  2036 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1579.77 ms /   306 tokens (    5.16 ms per token,   193.70 tokens per second)\n",
            "llama_print_timings:        eval time =      37.59 ms /     1 runs   (   37.59 ms per token,    26.60 tokens per second)\n",
            "llama_print_timings:       total time =    1626.65 ms /   307 tokens\n",
            " 31%|███▏      | 11/35 [09:35<22:10, 55.46s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.27 ms /    15 runs   (    0.55 ms per token,  1813.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2251.04 ms /   434 tokens (    5.19 ms per token,   192.80 tokens per second)\n",
            "llama_print_timings:        eval time =     539.20 ms /    14 runs   (   38.51 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2811.09 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6253.43 ms /  1140 tokens (    5.49 ms per token,   182.30 tokens per second)\n",
            "llama_print_timings:        eval time =      40.09 ms /     1 runs   (   40.09 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    6310.78 ms /  1141 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      47.93 ms /    83 runs   (    0.58 ms per token,  1731.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6015.78 ms /  1107 tokens (    5.43 ms per token,   184.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3344.16 ms /    82 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    9470.08 ms /  1189 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      35.34 ms /    64 runs   (    0.55 ms per token,  1811.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6502.95 ms /  1180 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2583.05 ms /    63 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    9172.12 ms /  1243 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.01 ms /     2 runs   (    0.50 ms per token,  1986.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     836.22 ms /   163 tokens (    5.13 ms per token,   194.93 tokens per second)\n",
            "llama_print_timings:        eval time =      37.94 ms /     1 runs   (   37.94 ms per token,    26.36 tokens per second)\n",
            "llama_print_timings:       total time =     878.76 ms /   164 tokens\n",
            " 34%|███▍      | 12/35 [10:09<18:45, 48.93s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.12 ms /    15 runs   (    0.54 ms per token,  1847.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.31 ms /   434 tokens (    5.18 ms per token,   193.21 tokens per second)\n",
            "llama_print_timings:        eval time =     539.88 ms /    14 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2807.21 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.23 ms /     2 runs   (    0.61 ms per token,  1632.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6913.52 ms /  1258 tokens (    5.50 ms per token,   181.96 tokens per second)\n",
            "llama_print_timings:        eval time =      40.67 ms /     1 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    6970.33 ms /  1259 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      21.57 ms /    38 runs   (    0.57 ms per token,  1761.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6757.36 ms /  1224 tokens (    5.52 ms per token,   181.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.50 ms /    38 runs   (   41.25 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =    8384.02 ms /  1262 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     122.55 ms /   181 runs   (    0.68 ms per token,  1476.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6861.40 ms /  1248 tokens (    5.50 ms per token,   181.89 tokens per second)\n",
            "llama_print_timings:        eval time =    7514.69 ms /   180 runs   (   41.75 ms per token,    23.95 tokens per second)\n",
            "llama_print_timings:       total time =   14662.11 ms /  1428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       0.99 ms /     2 runs   (    0.49 ms per token,  2020.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     631.08 ms /   123 tokens (    5.13 ms per token,   194.90 tokens per second)\n",
            "llama_print_timings:        eval time =      37.09 ms /     1 runs   (   37.09 ms per token,    26.96 tokens per second)\n",
            "llama_print_timings:       total time =     672.22 ms /   124 tokens\n",
            " 37%|███▋      | 13/35 [10:49<16:57, 46.25s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.01 ms /    15 runs   (    0.53 ms per token,  1873.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2251.07 ms /   434 tokens (    5.19 ms per token,   192.80 tokens per second)\n",
            "llama_print_timings:        eval time =     541.57 ms /    14 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2814.05 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.14 ms /     2 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5670.36 ms /  1042 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
            "llama_print_timings:        eval time =      39.76 ms /     1 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    5729.61 ms /  1043 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     111.98 ms /   159 runs   (    0.70 ms per token,  1419.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5413.51 ms /  1008 tokens (    5.37 ms per token,   186.20 tokens per second)\n",
            "llama_print_timings:        eval time =    6491.35 ms /   159 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =   12164.97 ms /  1167 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      50.10 ms /    79 runs   (    0.63 ms per token,  1576.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6311.37 ms /  1157 tokens (    5.45 ms per token,   183.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3200.07 ms /    78 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    9627.20 ms /  1235 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1465.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1226.82 ms /   240 tokens (    5.11 ms per token,   195.63 tokens per second)\n",
            "llama_print_timings:        eval time =      38.05 ms /     1 runs   (   38.05 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =    1272.77 ms /   241 tokens\n",
            " 40%|████      | 14/35 [11:25<15:10, 43.34s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    15 runs   (    0.60 ms per token,  1672.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.84 ms /   434 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =     546.68 ms /    14 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2846.25 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.09 ms /     2 runs   (    0.54 ms per token,  1839.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4676.49 ms /   876 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
            "llama_print_timings:        eval time =      39.16 ms /     1 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4728.73 ms /   877 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      88.61 ms /   145 runs   (    0.61 ms per token,  1636.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4521.80 ms /   843 tokens (    5.36 ms per token,   186.43 tokens per second)\n",
            "llama_print_timings:        eval time =    5768.53 ms /   144 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =   10484.90 ms /   987 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      51.89 ms /    74 runs   (    0.70 ms per token,  1426.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5276.33 ms /   979 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2969.60 ms /    73 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    8367.43 ms /  1052 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.60 ms /     2 runs   (    0.80 ms per token,  1252.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1139.62 ms /   224 tokens (    5.09 ms per token,   196.56 tokens per second)\n",
            "llama_print_timings:        eval time =      37.86 ms /     1 runs   (   37.86 ms per token,    26.41 tokens per second)\n",
            "llama_print_timings:       total time =    1183.31 ms /   225 tokens\n",
            " 43%|████▎     | 15/35 [11:56<13:11, 39.59s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.44 ms /    15 runs   (    0.56 ms per token,  1776.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2255.19 ms /   434 tokens (    5.20 ms per token,   192.44 tokens per second)\n",
            "llama_print_timings:        eval time =     544.47 ms /    14 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2824.43 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      50.09 ms /    65 runs   (    0.77 ms per token,  1297.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4958.74 ms /   928 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2594.57 ms /    64 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    7664.38 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      73.58 ms /   128 runs   (    0.57 ms per token,  1739.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4769.89 ms /   895 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =    5092.29 ms /   127 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =   10024.08 ms /  1022 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.30 ms /     2 runs   (    0.65 ms per token,  1539.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5431.50 ms /  1000 tokens (    5.43 ms per token,   184.11 tokens per second)\n",
            "llama_print_timings:        eval time =      79.78 ms /     2 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    5527.80 ms /  1002 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1122.19 ms /   220 tokens (    5.10 ms per token,   196.05 tokens per second)\n",
            "llama_print_timings:        eval time =      37.35 ms /     1 runs   (   37.35 ms per token,    26.77 tokens per second)\n",
            "llama_print_timings:       total time =    1163.82 ms /   221 tokens\n",
            " 46%|████▌     | 16/35 [12:27<11:44, 37.08s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.28 ms /    15 runs   (    0.55 ms per token,  1812.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.27 ms /   434 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
            "llama_print_timings:        eval time =     543.12 ms /    14 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2811.16 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.52 ms /     2 runs   (    0.76 ms per token,  1318.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5025.41 ms /   930 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
            "llama_print_timings:        eval time =      41.59 ms /     1 runs   (   41.59 ms per token,    24.05 tokens per second)\n",
            "llama_print_timings:       total time =    5082.60 ms /   931 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     137.28 ms /   223 runs   (    0.62 ms per token,  1624.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4784.97 ms /   896 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =    8999.43 ms /   223 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =   14109.86 ms /  1119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.17 ms /     2 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6015.52 ms /  1104 tokens (    5.45 ms per token,   183.53 tokens per second)\n",
            "llama_print_timings:        eval time =      40.20 ms /     1 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    6071.96 ms /  1105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1577.18 ms /   309 tokens (    5.10 ms per token,   195.92 tokens per second)\n",
            "llama_print_timings:        eval time =      37.79 ms /     1 runs   (   37.79 ms per token,    26.46 tokens per second)\n",
            "llama_print_timings:       total time =    1620.54 ms /   310 tokens\n",
            " 49%|████▊     | 17/35 [13:00<10:43, 35.76s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.22 ms /    15 runs   (    0.55 ms per token,  1825.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.43 ms /   434 tokens (    5.18 ms per token,   193.20 tokens per second)\n",
            "llama_print_timings:        eval time =     540.84 ms /    14 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2808.81 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.11 ms /     2 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6927.35 ms /  1251 tokens (    5.54 ms per token,   180.59 tokens per second)\n",
            "llama_print_timings:        eval time =      40.33 ms /     1 runs   (   40.33 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    6985.76 ms /  1252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      66.24 ms /    92 runs   (    0.72 ms per token,  1388.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6698.68 ms /  1218 tokens (    5.50 ms per token,   181.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3781.45 ms /    91 runs   (   41.55 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =   10637.91 ms /  1309 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7237.73 ms /  1307 tokens (    5.54 ms per token,   180.58 tokens per second)\n",
            "llama_print_timings:        eval time =      40.64 ms /     1 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    7299.08 ms /  1308 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1467.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     835.21 ms /   165 tokens (    5.06 ms per token,   197.56 tokens per second)\n",
            "llama_print_timings:        eval time =      38.02 ms /     1 runs   (   38.02 ms per token,    26.30 tokens per second)\n",
            "llama_print_timings:       total time =     878.80 ms /   166 tokens\n",
            " 51%|█████▏    | 18/35 [13:32<09:45, 34.45s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.38 ms /    15 runs   (    0.69 ms per token,  1445.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2251.61 ms /   434 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =     549.41 ms /    14 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2826.18 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.60 ms per token,  1652.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5075.35 ms /   952 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
            "llama_print_timings:        eval time =      39.70 ms /     1 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    5128.30 ms /   953 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      60.17 ms /    96 runs   (    0.63 ms per token,  1595.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4938.28 ms /   919 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3827.96 ms /    95 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    8901.15 ms /  1014 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      57.41 ms /    89 runs   (    0.65 ms per token,  1550.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5468.32 ms /  1012 tokens (    5.40 ms per token,   185.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3592.89 ms /    88 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    9195.52 ms /  1100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.53 ms /     2 runs   (    0.76 ms per token,  1310.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     846.61 ms /   168 tokens (    5.04 ms per token,   198.44 tokens per second)\n",
            "llama_print_timings:        eval time =      78.90 ms /     2 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =     931.16 ms /   170 tokens\n",
            " 54%|█████▍    | 19/35 [14:06<09:09, 34.35s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    15 runs   (    0.58 ms per token,  1731.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2271.45 ms /   434 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
            "llama_print_timings:        eval time =     539.24 ms /    14 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2835.38 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.14 ms /     2 runs   (    0.57 ms per token,  1749.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4489.81 ms /   842 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =      39.02 ms /     1 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4540.69 ms /   843 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      64.93 ms /   109 runs   (    0.60 ms per token,  1678.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4325.71 ms /   808 tokens (    5.35 ms per token,   186.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4342.65 ms /   109 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    8808.29 ms /   917 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      61.91 ms /    90 runs   (    0.69 ms per token,  1453.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4866.98 ms /   912 tokens (    5.34 ms per token,   187.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3644.91 ms /    90 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    8653.09 ms /  1002 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.64 ms /     2 runs   (    0.82 ms per token,  1218.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     940.10 ms /   184 tokens (    5.11 ms per token,   195.72 tokens per second)\n",
            "llama_print_timings:        eval time =      38.33 ms /     1 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =     991.21 ms /   185 tokens\n",
            " 57%|█████▋    | 20/35 [14:35<08:14, 32.97s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.51 ms /    15 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.18 ms /   434 tokens (    5.18 ms per token,   192.96 tokens per second)\n",
            "llama_print_timings:        eval time =     541.84 ms /    14 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2813.02 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      68.47 ms /   126 runs   (    0.54 ms per token,  1840.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10917.81 ms /  1887 tokens (    5.79 ms per token,   172.84 tokens per second)\n",
            "llama_print_timings:        eval time =    5408.61 ms /   125 runs   (   43.27 ms per token,    23.11 tokens per second)\n",
            "llama_print_timings:       total time =   16501.30 ms /  2012 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       7.59 ms /    16 runs   (    0.47 ms per token,  2107.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10739.73 ms /  1854 tokens (    5.79 ms per token,   172.63 tokens per second)\n",
            "llama_print_timings:        eval time =     648.14 ms /    15 runs   (   43.21 ms per token,    23.14 tokens per second)\n",
            "llama_print_timings:       total time =   11429.08 ms /  1869 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      76.81 ms /   138 runs   (    0.56 ms per token,  1796.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10855.92 ms /  1869 tokens (    5.81 ms per token,   172.16 tokens per second)\n",
            "llama_print_timings:        eval time =    5936.98 ms /   137 runs   (   43.34 ms per token,    23.08 tokens per second)\n",
            "llama_print_timings:       total time =   16982.85 ms /  2006 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.05 ms /     2 runs   (    0.53 ms per token,  1895.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     434.15 ms /    87 tokens (    4.99 ms per token,   200.39 tokens per second)\n",
            "llama_print_timings:        eval time =      37.00 ms /     1 runs   (   37.00 ms per token,    27.03 tokens per second)\n",
            "llama_print_timings:       total time =     474.71 ms /    88 tokens\n",
            " 60%|██████    | 21/35 [15:29<09:09, 39.23s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.54 ms /    15 runs   (    0.70 ms per token,  1423.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2276.42 ms /   434 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =     551.83 ms /    14 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2854.53 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6822.95 ms /  1242 tokens (    5.49 ms per token,   182.03 tokens per second)\n",
            "llama_print_timings:        eval time =      40.26 ms /     1 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    6879.81 ms /  1243 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     152.66 ms /   256 runs   (    0.60 ms per token,  1676.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6648.77 ms /  1208 tokens (    5.50 ms per token,   181.69 tokens per second)\n",
            "llama_print_timings:        eval time =   10612.94 ms /   256 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   17649.74 ms /  1464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     167.08 ms /   256 runs   (    0.65 ms per token,  1532.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8196.47 ms /  1460 tokens (    5.61 ms per token,   178.13 tokens per second)\n",
            "llama_print_timings:        eval time =   10796.77 ms /   255 runs   (   42.34 ms per token,    23.62 tokens per second)\n",
            "llama_print_timings:       total time =   19413.48 ms /  1715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.24 ms /     2 runs   (    0.62 ms per token,  1611.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1696.33 ms /   333 tokens (    5.09 ms per token,   196.31 tokens per second)\n",
            "llama_print_timings:        eval time =      38.02 ms /     1 runs   (   38.02 ms per token,    26.30 tokens per second)\n",
            "llama_print_timings:       total time =    1741.06 ms /   334 tokens\n",
            " 63%|██████▎   | 22/35 [16:22<09:23, 43.32s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.17 ms /    15 runs   (    0.54 ms per token,  1836.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.26 ms /   434 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
            "llama_print_timings:        eval time =     541.36 ms /    14 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2809.47 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5011.07 ms /   936 tokens (    5.35 ms per token,   186.79 tokens per second)\n",
            "llama_print_timings:        eval time =      80.32 ms /     2 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    5105.77 ms /   938 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      23.22 ms /    37 runs   (    0.63 ms per token,  1593.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4813.31 ms /   904 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1442.23 ms /    36 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    6312.87 ms /   940 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.18 ms /     2 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5098.33 ms /   938 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
            "llama_print_timings:        eval time =      39.50 ms /     1 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5153.12 ms /   939 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.01 ms /     2 runs   (    0.50 ms per token,  1984.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     554.78 ms /   110 tokens (    5.04 ms per token,   198.28 tokens per second)\n",
            "llama_print_timings:        eval time =      37.47 ms /     1 runs   (   37.47 ms per token,    26.69 tokens per second)\n",
            "llama_print_timings:       total time =     595.88 ms /   111 tokens\n",
            " 66%|██████▌   | 23/35 [16:47<07:34, 37.85s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.45 ms /    15 runs   (    0.56 ms per token,  1774.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.70 ms /   434 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
            "llama_print_timings:        eval time =     540.78 ms /    14 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2810.99 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      25.92 ms /    43 runs   (    0.60 ms per token,  1658.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8933.20 ms /  1574 tokens (    5.68 ms per token,   176.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1775.53 ms /    42 runs   (   42.27 ms per token,    23.65 tokens per second)\n",
            "llama_print_timings:       total time =   10779.94 ms /  1616 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      66.29 ms /    98 runs   (    0.68 ms per token,  1478.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8708.86 ms /  1541 tokens (    5.65 ms per token,   176.95 tokens per second)\n",
            "llama_print_timings:        eval time =    4117.21 ms /    97 runs   (   42.45 ms per token,    23.56 tokens per second)\n",
            "llama_print_timings:       total time =   12980.71 ms /  1638 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      80.69 ms /   125 runs   (    0.65 ms per token,  1549.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9306.77 ms /  1635 tokens (    5.69 ms per token,   175.68 tokens per second)\n",
            "llama_print_timings:        eval time =    5295.54 ms /   124 runs   (   42.71 ms per token,    23.42 tokens per second)\n",
            "llama_print_timings:       total time =   14801.44 ms /  1759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.21 ms /     2 runs   (    0.61 ms per token,  1648.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     872.53 ms /   172 tokens (    5.07 ms per token,   197.13 tokens per second)\n",
            "llama_print_timings:        eval time =      38.01 ms /     1 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
            "llama_print_timings:       total time =     914.52 ms /   173 tokens\n",
            " 69%|██████▊   | 24/35 [17:33<07:22, 40.23s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    15 runs   (    0.59 ms per token,  1685.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.23 ms /   434 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
            "llama_print_timings:        eval time =     544.16 ms /    14 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2821.44 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      70.50 ms /   114 runs   (    0.62 ms per token,  1617.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9339.71 ms /  1645 tokens (    5.68 ms per token,   176.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4814.73 ms /   113 runs   (   42.61 ms per token,    23.47 tokens per second)\n",
            "llama_print_timings:       total time =   14335.82 ms /  1758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     155.52 ms /   256 runs   (    0.61 ms per token,  1646.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9168.21 ms /  1612 tokens (    5.69 ms per token,   175.83 tokens per second)\n",
            "llama_print_timings:        eval time =   10931.49 ms /   255 runs   (   42.87 ms per token,    23.33 tokens per second)\n",
            "llama_print_timings:       total time =   20511.23 ms /  1867 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     150.59 ms /   242 runs   (    0.62 ms per token,  1607.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10727.05 ms /  1856 tokens (    5.78 ms per token,   173.02 tokens per second)\n",
            "llama_print_timings:        eval time =   10469.76 ms /   241 runs   (   43.44 ms per token,    23.02 tokens per second)\n",
            "llama_print_timings:       total time =   21572.72 ms /  2097 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     2 runs   (    2.23 ms per token,   449.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1767.80 ms /   340 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
            "llama_print_timings:        eval time =      38.55 ms /     1 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    1819.23 ms /   341 tokens\n",
            " 71%|███████▏  | 25/35 [18:39<07:59, 47.91s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.37 ms /    15 runs   (    0.69 ms per token,  1446.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.04 ms /   434 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =     543.83 ms /    14 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2851.34 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      94.03 ms /   137 runs   (    0.69 ms per token,  1456.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8415.78 ms /  1498 tokens (    5.62 ms per token,   178.00 tokens per second)\n",
            "llama_print_timings:        eval time =    5751.45 ms /   136 runs   (   42.29 ms per token,    23.65 tokens per second)\n",
            "llama_print_timings:       total time =   14386.52 ms /  1634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      75.00 ms /   108 runs   (    0.69 ms per token,  1440.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8170.97 ms /  1464 tokens (    5.58 ms per token,   179.17 tokens per second)\n",
            "llama_print_timings:        eval time =    4563.11 ms /   108 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
            "llama_print_timings:       total time =   12915.78 ms /  1572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      64.51 ms /    88 runs   (    0.73 ms per token,  1364.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8759.85 ms /  1560 tokens (    5.62 ms per token,   178.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3701.49 ms /    87 runs   (   42.55 ms per token,    23.50 tokens per second)\n",
            "llama_print_timings:       total time =   12624.11 ms /  1647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      32.79 ms /    54 runs   (    0.61 ms per token,  1646.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     971.90 ms /   191 tokens (    5.09 ms per token,   196.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2016.97 ms /    53 runs   (   38.06 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =    3051.68 ms /   244 tokens\n",
            " 74%|███████▍  | 26/35 [19:27<07:12, 48.01s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    15 runs   (    0.57 ms per token,  1753.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.03 ms /   434 tokens (    5.17 ms per token,   193.57 tokens per second)\n",
            "llama_print_timings:        eval time =     541.08 ms /    14 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2804.70 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.57 ms per token,  1768.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5547.55 ms /  1024 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =      80.49 ms /     2 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5647.47 ms /  1026 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      52.91 ms /    94 runs   (    0.56 ms per token,  1776.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5317.77 ms /   992 tokens (    5.36 ms per token,   186.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3752.91 ms /    93 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    9188.72 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.13 ms /     2 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5934.01 ms /  1087 tokens (    5.46 ms per token,   183.18 tokens per second)\n",
            "llama_print_timings:        eval time =      39.90 ms /     1 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5990.54 ms /  1088 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.27 ms /     2 runs   (    0.64 ms per token,  1569.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     833.68 ms /   163 tokens (    5.11 ms per token,   195.52 tokens per second)\n",
            "llama_print_timings:        eval time =      38.06 ms /     1 runs   (   38.06 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =     880.06 ms /   164 tokens\n",
            " 77%|███████▋  | 27/35 [19:56<05:39, 42.44s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       7.87 ms /    15 runs   (    0.52 ms per token,  1906.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.16 ms /   434 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
            "llama_print_timings:        eval time =     540.85 ms /    14 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2804.46 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.49 ms /     2 runs   (    0.74 ms per token,  1344.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5552.09 ms /  1019 tokens (    5.45 ms per token,   183.53 tokens per second)\n",
            "llama_print_timings:        eval time =      40.40 ms /     1 runs   (   40.40 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    5608.95 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      55.62 ms /    95 runs   (    0.59 ms per token,  1708.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5328.70 ms /   986 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3803.09 ms /    94 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    9254.13 ms /  1080 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.12 ms /     2 runs   (    0.56 ms per token,  1787.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5897.87 ms /  1079 tokens (    5.47 ms per token,   182.95 tokens per second)\n",
            "llama_print_timings:        eval time =      40.06 ms /     1 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    5954.07 ms /  1080 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.36 ms /     2 runs   (    0.68 ms per token,  1472.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     838.03 ms /   167 tokens (    5.02 ms per token,   199.28 tokens per second)\n",
            "llama_print_timings:        eval time =      37.61 ms /     1 runs   (   37.61 ms per token,    26.59 tokens per second)\n",
            "llama_print_timings:       total time =     880.60 ms /   168 tokens\n",
            " 80%|████████  | 28/35 [20:24<04:26, 38.03s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.08 ms /    15 runs   (    0.54 ms per token,  1857.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2250.86 ms /   434 tokens (    5.19 ms per token,   192.82 tokens per second)\n",
            "llama_print_timings:        eval time =     539.74 ms /    14 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2811.48 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      37.74 ms /    65 runs   (    0.58 ms per token,  1722.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7023.67 ms /  1266 tokens (    5.55 ms per token,   180.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2637.67 ms /    64 runs   (   41.21 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =    9754.50 ms /  1330 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      67.49 ms /    91 runs   (    0.74 ms per token,  1348.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6752.15 ms /  1232 tokens (    5.48 ms per token,   182.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3788.10 ms /    91 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
            "llama_print_timings:       total time =   10700.97 ms /  1323 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      58.51 ms /    91 runs   (    0.64 ms per token,  1555.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7188.81 ms /  1303 tokens (    5.52 ms per token,   181.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3745.17 ms /    90 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
            "llama_print_timings:       total time =   11071.65 ms /  1393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.45 ms /     2 runs   (    0.72 ms per token,  1381.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     934.35 ms /   182 tokens (    5.13 ms per token,   194.79 tokens per second)\n",
            "llama_print_timings:        eval time =      38.73 ms /     1 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =     978.70 ms /   183 tokens\n",
            " 83%|████████▎ | 29/35 [21:04<03:51, 38.57s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    15 runs   (    0.64 ms per token,  1558.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2281.96 ms /   434 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =     543.04 ms /    14 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2850.96 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     152.84 ms /   256 runs   (    0.60 ms per token,  1674.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11936.34 ms /  2040 tokens (    5.85 ms per token,   170.91 tokens per second)\n",
            "llama_print_timings:        eval time =   11290.07 ms /   256 runs   (   44.10 ms per token,    22.67 tokens per second)\n",
            "llama_print_timings:       total time =   23645.83 ms /  2296 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     155.64 ms /   256 runs   (    0.61 ms per token,  1644.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11725.22 ms /  2008 tokens (    5.84 ms per token,   171.25 tokens per second)\n",
            "llama_print_timings:        eval time =   11222.46 ms /   255 runs   (   44.01 ms per token,    22.72 tokens per second)\n",
            "llama_print_timings:       total time =   23344.94 ms /  2263 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     156.77 ms /   256 runs   (    0.61 ms per token,  1632.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13406.22 ms /  2250 tokens (    5.96 ms per token,   167.83 tokens per second)\n",
            "llama_print_timings:        eval time =   11563.34 ms /   255 runs   (   45.35 ms per token,    22.05 tokens per second)\n",
            "llama_print_timings:       total time =   25397.43 ms /  2505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.09 ms /     2 runs   (    0.54 ms per token,  1836.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1738.35 ms /   342 tokens (    5.08 ms per token,   196.74 tokens per second)\n",
            "llama_print_timings:        eval time =      37.53 ms /     1 runs   (   37.53 ms per token,    26.65 tokens per second)\n",
            "llama_print_timings:       total time =    1784.09 ms /   343 tokens\n",
            " 86%|████████▌ | 30/35 [22:25<04:16, 51.33s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.33 ms /    15 runs   (    0.56 ms per token,  1800.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.73 ms /   434 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
            "llama_print_timings:        eval time =     537.93 ms /    14 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2800.41 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.12 ms /     2 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3711.77 ms /   709 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
            "llama_print_timings:        eval time =      38.80 ms /     1 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    3760.93 ms /   710 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      67.89 ms /   104 runs   (    0.65 ms per token,  1531.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3544.79 ms /   676 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4082.38 ms /   103 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    7774.20 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      51.06 ms /    86 runs   (    0.59 ms per token,  1684.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4076.80 ms /   766 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3357.59 ms /    85 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7545.56 ms /   851 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.26 ms /     2 runs   (    0.63 ms per token,  1586.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     961.03 ms /   188 tokens (    5.11 ms per token,   195.62 tokens per second)\n",
            "llama_print_timings:        eval time =      38.00 ms /     1 runs   (   38.00 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =    1003.65 ms /   189 tokens\n",
            " 89%|████████▊ | 31/35 [22:53<02:56, 44.19s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.29 ms /    15 runs   (    0.55 ms per token,  1810.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.38 ms /   434 tokens (    5.18 ms per token,   193.20 tokens per second)\n",
            "llama_print_timings:        eval time =     541.34 ms /    14 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2809.14 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1668.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4694.40 ms /   879 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =      39.58 ms /     1 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4746.89 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      90.24 ms /   126 runs   (    0.72 ms per token,  1396.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4496.64 ms /   846 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =    5048.33 ms /   125 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    9748.11 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     113.78 ms /   177 runs   (    0.64 ms per token,  1555.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5158.55 ms /   958 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =    7136.86 ms /   176 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =   12554.38 ms /  1134 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.54 ms /     2 runs   (    0.77 ms per token,  1302.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1097.90 ms /   210 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =      37.78 ms /     1 runs   (   37.78 ms per token,    26.47 tokens per second)\n",
            "llama_print_timings:       total time =    1142.48 ms /   211 tokens\n",
            " 91%|█████████▏| 32/35 [23:28<02:04, 41.50s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.27 ms /    15 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2268.96 ms /   434 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =     545.62 ms /    14 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2836.66 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.50 ms /     2 runs   (    0.75 ms per token,  1331.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6424.09 ms /  1172 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
            "llama_print_timings:        eval time =      40.48 ms /     1 runs   (   40.48 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    6482.44 ms /  1173 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      72.52 ms /   131 runs   (    0.55 ms per token,  1806.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6241.68 ms /  1139 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
            "llama_print_timings:        eval time =    5318.00 ms /   130 runs   (   40.91 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =   11727.08 ms /  1269 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     121.57 ms /   203 runs   (    0.60 ms per token,  1669.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6944.56 ms /  1253 tokens (    5.54 ms per token,   180.43 tokens per second)\n",
            "llama_print_timings:        eval time =    8367.21 ms /   202 runs   (   41.42 ms per token,    24.14 tokens per second)\n",
            "llama_print_timings:       total time =   15587.52 ms /  1455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.50 ms /     2 runs   (    0.75 ms per token,  1335.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1134.64 ms /   218 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
            "llama_print_timings:        eval time =      38.04 ms /     1 runs   (   38.04 ms per token,    26.29 tokens per second)\n",
            "llama_print_timings:       total time =    1181.01 ms /   219 tokens\n",
            " 94%|█████████▍| 33/35 [24:10<01:23, 41.67s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      10.66 ms /    15 runs   (    0.71 ms per token,  1407.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.54 ms /   434 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     547.21 ms /    14 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2851.20 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.60 ms /     2 runs   (    0.80 ms per token,  1253.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7046.64 ms /  1280 tokens (    5.51 ms per token,   181.65 tokens per second)\n",
            "llama_print_timings:        eval time =      82.99 ms /     2 runs   (   41.50 ms per token,    24.10 tokens per second)\n",
            "llama_print_timings:       total time =    7149.73 ms /  1282 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      76.05 ms /   127 runs   (    0.60 ms per token,  1669.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6890.03 ms /  1248 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
            "llama_print_timings:        eval time =    5214.36 ms /   126 runs   (   41.38 ms per token,    24.16 tokens per second)\n",
            "llama_print_timings:       total time =   12278.92 ms /  1374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =     133.29 ms /   214 runs   (    0.62 ms per token,  1605.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7642.48 ms /  1363 tokens (    5.61 ms per token,   178.35 tokens per second)\n",
            "llama_print_timings:        eval time =    8943.51 ms /   213 runs   (   41.99 ms per token,    23.82 tokens per second)\n",
            "llama_print_timings:       total time =   16907.02 ms /  1576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.48 ms /     2 runs   (    0.74 ms per token,  1355.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1057.94 ms /   208 tokens (    5.09 ms per token,   196.61 tokens per second)\n",
            "llama_print_timings:        eval time =      77.02 ms /     2 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    1141.41 ms /   210 tokens\n",
            " 97%|█████████▋| 34/35 [24:56<00:43, 43.00s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       8.24 ms /    15 runs   (    0.55 ms per token,  1820.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2263.57 ms /   434 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =     539.39 ms /    14 runs   (   38.53 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2824.37 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.91 ms /     2 runs   (    0.95 ms per token,  1048.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5841.88 ms /  1077 tokens (    5.42 ms per token,   184.36 tokens per second)\n",
            "llama_print_timings:        eval time =      39.94 ms /     1 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5897.69 ms /  1078 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      94.03 ms /   172 runs   (    0.55 ms per token,  1829.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5683.15 ms /  1044 tokens (    5.44 ms per token,   183.70 tokens per second)\n",
            "llama_print_timings:        eval time =    6960.28 ms /   171 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =   12860.28 ms /  1215 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =      83.18 ms /   138 runs   (    0.60 ms per token,  1658.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6602.63 ms /  1195 tokens (    5.53 ms per token,   180.99 tokens per second)\n",
            "llama_print_timings:        eval time =    5635.56 ms /   137 runs   (   41.14 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =   12426.59 ms /  1332 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     463.94 ms\n",
            "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1327.98 ms /   263 tokens (    5.05 ms per token,   198.05 tokens per second)\n",
            "llama_print_timings:        eval time =      37.84 ms /     1 runs   (   37.84 ms per token,    26.42 tokens per second)\n",
            "llama_print_timings:       total time =    1372.32 ms /   264 tokens\n",
            "100%|██████████| 35/35 [25:35<00:00, 43.89s/it]\n"
          ]
        }
      ]
    }
  ]
}