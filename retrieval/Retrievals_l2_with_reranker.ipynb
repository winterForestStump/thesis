{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winterForestStump/thesis/blob/main/retrieval/Retrievals_l2_with_reranker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running on GPU"
      ],
      "metadata": {
        "id": "qoICBk9nYWVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-community --quiet\n",
        "!pip install sentence_transformers FlagEmbedding chromadb --quiet"
      ],
      "metadata": {
        "id": "bA_Wbt2JYhss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "import chromadb\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.storage._lc_store import create_kv_docstore\n",
        "from langchain.storage.file_system import LocalFileStore\n",
        "from FlagEmbedding import FlagReranker\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "CkIx7XzeZGNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JTgfERVmZDKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ae4e23-a21c-4995-ac06-2f6217c851b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"BAAI/bge-small-en-v1.5\"\n",
        "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
        "\n",
        "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={'device': 'cuda'},\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "XU0B6jPtZJdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75637f2f-8373-4a9c-d46e-08a33ac54d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persistent_client = chromadb.PersistentClient('/content/drive/MyDrive/Thesis/chromadb')\n",
        "fs = LocalFileStore('/content/drive/MyDrive/Thesis/reports_store_location')\n",
        "store = create_kv_docstore(fs)\n",
        "\n",
        "collection = persistent_client.get_or_create_collection('reports_l2')\n",
        "vectorstore = Chroma(client = persistent_client, collection_name='reports_l2', embedding_function=bge_embeddings,\n",
        "                    persist_directory='/content/drive/MyDrive/Thesis/chromadb')\n",
        "vectorstore.persist()"
      ],
      "metadata": {
        "id": "VhQaf7cnZMLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890ec863-6164-4b00-f2ac-f6ebfee9b1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation"
      ],
      "metadata": {
        "id": "aKvQ8PG8agmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=256)"
      ],
      "metadata": {
        "id": "DHwx_a4KcLxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_reranker(company: str, num_parent: int, num_rerank: int):\n",
        "\n",
        "  '''\n",
        "  Retrive a lot of parent chunks using company name filter and number of chunks, rerank them with bge-reranker\n",
        "  '''\n",
        "\n",
        "  # Get questions\n",
        "  questions = pd.read_fwf(\"https://raw.githubusercontent.com/winterForestStump/thesis/main/questions/questions_ver2.txt\", names=['question'])\n",
        "\n",
        "  # Initialize a retriever\n",
        "  big_chunks_retriever = ParentDocumentRetriever(vectorstore=vectorstore, docstore=store,\n",
        "                                                 child_splitter=child_splitter, parent_splitter=parent_splitter,\n",
        "                                                 search_kwargs={'filter': {'company': company}, 'k': num_parent})\n",
        "\n",
        "  # Invoke retriever without company name in the question\n",
        "  results_list = []\n",
        "\n",
        "  for i in tqdm(range(len(questions))):\n",
        "    approach = f'reranked_{company}'\n",
        "    query = questions['question'][i]\n",
        "\n",
        "    response = big_chunks_retriever.invoke(query)\n",
        "\n",
        "    texts = []\n",
        "    for j in range(len(response)):\n",
        "      texts.append([query, response[j].page_content])\n",
        "    scores = reranker.compute_score(texts)\n",
        "    combined = list(zip(texts, scores))\n",
        "    sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    top_texts = [item[0] for item in sorted_combined[:num_rerank]]\n",
        "\n",
        "    results_list.append(pd.DataFrame({\n",
        "        'question': query,\n",
        "        'context': [top_texts]\n",
        "    }))\n",
        "  results = pd.concat(results_list, ignore_index=True)\n",
        "\n",
        "  results.to_json(f'/content/drive/MyDrive/Thesis/retrievals/reranked/results_{approach}.json')"
      ],
      "metadata": {
        "id": "mFD_AxduZRWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "companies = ['COCA COLA CO', 'AMAZON COM INC', 'PayPal Holdings, Inc.', 'GENERAL MILLS INC', 'Walmart Inc.', 'PEPSICO INC',\n",
        "             'Kraft Heinz Co', 'Amcor plc', 'Square, Inc.', '3M CO', 'MICROSOFT CORP', 'Ulta Beauty, Inc.', 'AES CORP']\n",
        "\n",
        "for comp in companies:\n",
        "  compute_reranker(comp, 10, 2)"
      ],
      "metadata": {
        "id": "fXjXGYcmced0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bec317-584e-4bd0-8365-ecaf0bfce5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [02:59<00:00,  5.14s/it]\n",
            "100%|██████████| 35/35 [02:01<00:00,  3.46s/it]\n",
            "100%|██████████| 35/35 [01:52<00:00,  3.21s/it]\n",
            "100%|██████████| 35/35 [02:17<00:00,  3.94s/it]\n",
            "100%|██████████| 35/35 [02:21<00:00,  4.06s/it]\n",
            "100%|██████████| 35/35 [02:17<00:00,  3.92s/it]\n",
            "100%|██████████| 35/35 [01:52<00:00,  3.21s/it]\n",
            "100%|██████████| 35/35 [02:30<00:00,  4.30s/it]\n",
            "100%|██████████| 35/35 [02:18<00:00,  3.96s/it]\n",
            "100%|██████████| 35/35 [02:38<00:00,  4.52s/it]\n",
            "100%|██████████| 35/35 [02:08<00:00,  3.66s/it]\n",
            "100%|██████████| 35/35 [01:42<00:00,  2.94s/it]\n",
            "100%|██████████| 35/35 [01:54<00:00,  3.27s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Thesis/retrievals/reranked/'\n",
        "\n",
        "dataframes = []\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.json'):\n",
        "        approach_name = file_name\n",
        "        dataframes.append(approach_name)"
      ],
      "metadata": {
        "id": "uwYQejPEdCq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataframes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01xiwqJ-dICm",
        "outputId": "96b7e5fa-4dab-40e1-a5a0-8f2dddb9eeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2LGEJLd+JZkxDIWMirjgX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}