{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrxWpPSSNa/ukHywnftfFU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winterForestStump/thesis/blob/main/retrieval/Retrievals_approaches_evaluation_phi3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqMqPVKIzJy0",
        "outputId": "48372de5-82b4-4ceb-ce3d-f099ca62d190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.75.tar.gz (48.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.75-cp310-cp310-linux_x86_64.whl size=76330307 sha256=634454f0e770ad26a674e9fbe0ebf715ed56ade37dbb083b8f64dd1b88288821\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/df/9a/e4bb2e48bfa64fb174f0f786296c8507dbebea2a112f1adf8d\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.75\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download microsoft/Phi-3-mini-4k-instruct-gguf Phi-3-mini-4k-instruct-fp16.gguf --local-dir ./models --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBCZobiVzKeq",
        "outputId": "b366bf5c-87bc-44ab-8ca8-8358eab2c212"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "downloading https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf to /root/.cache/huggingface/hub/tmpfyp_gdsx\n",
            "Phi-3-mini-4k-instruct-fp16.gguf: 100% 7.64G/7.64G [01:22<00:00, 93.0MB/s]\n",
            "./models/Phi-3-mini-4k-instruct-fp16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCqrdCON0gMn",
        "outputId": "3e45b049-6f0f-4869-f6de-f523866a2a9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-community --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B4eLZEi3ZND",
        "outputId": "8fc7ce17-dd33-4d47-c1f2-68f3625c2121"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from json import JSONDecodeError\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "vdNwMqueoQF5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP = 0\n",
        "N_CTX = 4096\n",
        "N_GPU_L = -1\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/models/Phi-3-mini-4k-instruct-fp16.gguf\",\n",
        "    temperature=TEMP,\n",
        "    n_ctx=N_CTX,\n",
        "    n_gpu_layers = N_GPU_L,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RRPjbl3zOj7",
        "outputId": "e75b9905-7d52-4643-e13f-b35740da3b0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 195 tensors from /content/models/Phi-3-mini-4k-instruct-fp16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
            "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  130 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 323/32064 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = phi3\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32064\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 3072\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 96\n",
            "llm_load_print_meta: n_embd_head_k    = 96\n",
            "llm_load_print_meta: n_embd_head_v    = 96\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
            "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 8192\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 3B\n",
            "llm_load_print_meta: model ftype      = F16\n",
            "llm_load_print_meta: model params     = 3.82 B\n",
            "llm_load_print_meta: model size       = 7.12 GiB (16.00 BPW) \n",
            "llm_load_print_meta: general.name     = Phi3\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
            "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   187.88 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  7100.64 MiB\n",
            "....................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1536.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1536.00 MiB, K (f16):  768.00 MiB, V (f16):  768.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =    18.75 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.88 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1286\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'general.name': 'Phi3', 'tokenizer.ggml.pre': 'default', 'phi3.embedding_length': '3072', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.feed_forward_length': '8192', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.rope.dimension_count': '96', 'tokenizer.ggml.model': 'llama', 'general.file_type': '1'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
            "' + message['content'] + '<|end|>' + '\n",
            "' + '<|assistant|>' + '\n",
            "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
            "'}}{% endif %}{% endfor %}\n",
            "Using chat eos_token: <|endoftext|>\n",
            "Using chat bos_token: <s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader for approach 1\n",
        "\n",
        "prompt_1 = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    <|assistant|> You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question, grade it as relevant.\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. <|end|>\n",
        "    <|user|> Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: {question} <|end|>\n",
        "    <|assistant|>\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader_1 = prompt_1 | llm | JsonOutputParser()"
      ],
      "metadata": {
        "id": "B0cVnmRczRED"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader for approach 2\n",
        "\n",
        "prompt_2 = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    <|assistant|> You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question, grade it as relevant.\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. <|end|>\n",
        "    <|user|> Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: {question_name} <|end|>\n",
        "    <|assistant|>\n",
        "    \"\"\",\n",
        "    input_variables=[\"question_name\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader_2 = prompt_2 | llm | JsonOutputParser()"
      ],
      "metadata": {
        "id": "fjWWD4DP67nA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Thesis/retrievers/'\n",
        "\n",
        "dataframes = []\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.json'):\n",
        "        approach_name = file_name\n",
        "        dataframes.append(approach_name)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZJdMhlofa0M8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_results(approach_number:int, distance: str):\n",
        "  results_list = []\n",
        "\n",
        "  for i in range(len(dataframes)):\n",
        "\n",
        "    if approach_number == 1:\n",
        "      approach = pd.read_json(os.path.join(folder_path + dataframes[i]))\n",
        "      try:\n",
        "        for j in range(len(approach)):\n",
        "          question = approach['question'][j]\n",
        "          doc_txt = approach[distance][j]['page_content']\n",
        "          try:\n",
        "            answer = retrieval_grader_1.invoke({\"question\": question, \"document\": doc_txt})\n",
        "            results_list.append(pd.DataFrame({\"approach\": 1,\"distance\": distance, \"question\": question, \"answer\": [answer], \"document\": doc_txt}))\n",
        "          except JSONDecodeError as e:\n",
        "            print(f\"JSONDecodeError occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "          except OutputParserException as e:\n",
        "            print(f\"OutputParserException occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "      except KeyError as e:\n",
        "        print(f\"KeyError occurred: {e}. Skipping approach {approach_number} for dataframe {dataframes[i]}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    elif approach_number == 2:\n",
        "      approach = pd.read_json(os.path.join(folder_path + dataframes[i]))\n",
        "      try:\n",
        "        for j in range(len(approach)):\n",
        "          question = approach['question_name'][j]\n",
        "          doc_txt = approach[distance][j]['page_content']\n",
        "          try:\n",
        "            answer = retrieval_grader_2.invoke({\"question_name\": question, \"document\": doc_txt})\n",
        "            results_list.append(pd.DataFrame({\"approach\": 2,\"distance\": distance, \"question\": question, \"answer\": [answer], \"document\": doc_txt}))\n",
        "          except JSONDecodeError as e:\n",
        "            print(f\"JSONDecodeError occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "          except OutputParserException as e:\n",
        "            print(f\"OutputParserException occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "      except KeyError as e:\n",
        "        print(f\"KeyError occurred: {e}. Skipping approach {approach_number} for dataframe {dataframes[i]}\")\n",
        "        continue\n",
        "\n",
        "  if results_list:\n",
        "    results = pd.concat(results_list, ignore_index=True)\n",
        "    score = 0\n",
        "    for i in range(len(results)):\n",
        "      if (results['answer'][i] is not None) and (results['answer'][i]['score'] == 'yes'):\n",
        "        score += 1\n",
        "    total_score = score/len(results)\n",
        "    print(f'Total score for approach {approach_number} and distance function {distance} is {total_score}')\n",
        "  else:\n",
        "    print(f\"No results to concatenate for approach {approach_number} and distance {distance}\")"
      ],
      "metadata": {
        "id": "ucfAHsBia0JX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(1, 'cosine')"
      ],
      "metadata": {
        "id": "EHHf1hr-3XM6",
        "outputId": "9a18db09-52c8-4f3c-ec11-0629fc5ad760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.78 ms /     7 runs   (    0.97 ms per token,  1032.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4510.92 ms /   792 tokens (    5.70 ms per token,   175.57 tokens per second)\n",
            "llama_print_timings:        eval time =     298.50 ms /     6 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
            "llama_print_timings:       total time =    5298.46 ms /   798 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       8.28 ms /     7 runs   (    1.18 ms per token,   845.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3427.63 ms /   613 tokens (    5.59 ms per token,   178.84 tokens per second)\n",
            "llama_print_timings:        eval time =     236.69 ms /     6 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4125.97 ms /   619 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     6 runs   (    0.67 ms per token,  1499.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4377.25 ms /   776 tokens (    5.64 ms per token,   177.28 tokens per second)\n",
            "llama_print_timings:        eval time =     192.98 ms /     5 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    5219.96 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.58 ms /     7 runs   (    0.51 ms per token,  1955.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3407.82 ms /   663 tokens (    5.14 ms per token,   194.55 tokens per second)\n",
            "llama_print_timings:        eval time =     225.96 ms /     6 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =    3856.85 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     7 runs   (    0.51 ms per token,  1979.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2926.90 ms /   572 tokens (    5.12 ms per token,   195.43 tokens per second)\n",
            "llama_print_timings:        eval time =     225.73 ms /     6 runs   (   37.62 ms per token,    26.58 tokens per second)\n",
            "llama_print_timings:       total time =    3328.12 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1685.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2628.14 ms /   516 tokens (    5.09 ms per token,   196.34 tokens per second)\n",
            "llama_print_timings:        eval time =     225.86 ms /     6 runs   (   37.64 ms per token,    26.57 tokens per second)\n",
            "llama_print_timings:       total time =    3015.33 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.34 ms /   445 tokens (    5.12 ms per token,   195.23 tokens per second)\n",
            "llama_print_timings:        eval time =     226.93 ms /     6 runs   (   37.82 ms per token,    26.44 tokens per second)\n",
            "llama_print_timings:       total time =    2745.19 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1728.62 ms /   340 tokens (    5.08 ms per token,   196.69 tokens per second)\n",
            "llama_print_timings:        eval time =     222.42 ms /     6 runs   (   37.07 ms per token,    26.98 tokens per second)\n",
            "llama_print_timings:       total time =    2092.72 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     7 runs   (    0.51 ms per token,  1960.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3363.31 ms /   654 tokens (    5.14 ms per token,   194.45 tokens per second)\n",
            "llama_print_timings:        eval time =     227.97 ms /     6 runs   (   37.99 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =    3793.61 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1698.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.00 ms /   523 tokens (    5.11 ms per token,   195.51 tokens per second)\n",
            "llama_print_timings:        eval time =     225.16 ms /     6 runs   (   37.53 ms per token,    26.65 tokens per second)\n",
            "llama_print_timings:       total time =    3062.29 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     6 runs   (    0.62 ms per token,  1614.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4045.75 ms /   774 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =     193.60 ms /     5 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    4564.53 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1765.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2275.17 ms /   444 tokens (    5.12 ms per token,   195.15 tokens per second)\n",
            "llama_print_timings:        eval time =     226.29 ms /     6 runs   (   37.72 ms per token,    26.51 tokens per second)\n",
            "llama_print_timings:       total time =    2680.23 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1694.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2010.37 ms /   398 tokens (    5.05 ms per token,   197.97 tokens per second)\n",
            "llama_print_timings:        eval time =     224.98 ms /     6 runs   (   37.50 ms per token,    26.67 tokens per second)\n",
            "llama_print_timings:       total time =    2368.29 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2135.10 ms /   422 tokens (    5.06 ms per token,   197.65 tokens per second)\n",
            "llama_print_timings:        eval time =     224.07 ms /     6 runs   (   37.35 ms per token,    26.78 tokens per second)\n",
            "llama_print_timings:       total time =    2494.81 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1692.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     867.99 ms /   173 tokens (    5.02 ms per token,   199.31 tokens per second)\n",
            "llama_print_timings:        eval time =     219.83 ms /     6 runs   (   36.64 ms per token,    27.29 tokens per second)\n",
            "llama_print_timings:       total time =    1158.09 ms /   179 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.05 ms /     7 runs   (    0.72 ms per token,  1387.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3398.76 ms /   651 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
            "llama_print_timings:        eval time =     230.49 ms /     6 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    3900.35 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1839.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.80 ms /   440 tokens (    5.10 ms per token,   196.27 tokens per second)\n",
            "llama_print_timings:        eval time =     263.65 ms /     7 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =    2700.33 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1918.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3590.80 ms /   692 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
            "llama_print_timings:        eval time =     189.74 ms /     5 runs   (   37.95 ms per token,    26.35 tokens per second)\n",
            "llama_print_timings:       total time =    3982.41 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1849.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2731.04 ms /   531 tokens (    5.14 ms per token,   194.43 tokens per second)\n",
            "llama_print_timings:        eval time =     227.75 ms /     6 runs   (   37.96 ms per token,    26.35 tokens per second)\n",
            "llama_print_timings:       total time =    3120.63 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1571.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3184.99 ms /   614 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
            "llama_print_timings:        eval time =     230.49 ms /     6 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    3686.90 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3923.34 ms /   751 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
            "llama_print_timings:        eval time =     229.85 ms /     6 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    4415.38 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1756.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5758.33 ms /  1077 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =     197.20 ms /     5 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6288.89 ms /  1082 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1514.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.08 ms /   397 tokens (    5.77 ms per token,   173.28 tokens per second)\n",
            "llama_print_timings:        eval time =     243.02 ms /     6 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    3001.71 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1796.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2005.92 ms /   390 tokens (    5.14 ms per token,   194.42 tokens per second)\n",
            "llama_print_timings:        eval time =     224.92 ms /     6 runs   (   37.49 ms per token,    26.68 tokens per second)\n",
            "llama_print_timings:       total time =    2390.89 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1717.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2273.49 ms /   444 tokens (    5.12 ms per token,   195.29 tokens per second)\n",
            "llama_print_timings:        eval time =     227.59 ms /     6 runs   (   37.93 ms per token,    26.36 tokens per second)\n",
            "llama_print_timings:       total time =    2641.39 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1853.60 ms /   365 tokens (    5.08 ms per token,   196.91 tokens per second)\n",
            "llama_print_timings:        eval time =     227.45 ms /     6 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
            "llama_print_timings:       total time =    2205.36 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1720.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2447.36 ms /   479 tokens (    5.11 ms per token,   195.72 tokens per second)\n",
            "llama_print_timings:        eval time =     226.02 ms /     6 runs   (   37.67 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =    2821.67 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.66 ms /     7 runs   (    0.67 ms per token,  1501.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1458.72 ms /   275 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =     228.29 ms /     6 runs   (   38.05 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =    1831.18 ms /   281 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2476.66 ms /   479 tokens (    5.17 ms per token,   193.41 tokens per second)\n",
            "llama_print_timings:        eval time =     228.67 ms /     6 runs   (   38.11 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =    2947.84 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1658.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.76 ms /   424 tokens (    5.08 ms per token,   196.68 tokens per second)\n",
            "llama_print_timings:        eval time =     266.10 ms /     7 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
            "llama_print_timings:       total time =    2563.15 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1680.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2796.24 ms /   544 tokens (    5.14 ms per token,   194.55 tokens per second)\n",
            "llama_print_timings:        eval time =     269.04 ms /     7 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    3238.70 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     7 runs   (    0.49 ms per token,  2031.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2707.62 ms /   525 tokens (    5.16 ms per token,   193.90 tokens per second)\n",
            "llama_print_timings:        eval time =     231.22 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    3106.38 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1433.24 ms /   269 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =     230.34 ms /     6 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    1815.84 ms /   275 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2093.53 ms /   407 tokens (    5.14 ms per token,   194.41 tokens per second)\n",
            "llama_print_timings:        eval time =     225.00 ms /     6 runs   (   37.50 ms per token,    26.67 tokens per second)\n",
            "llama_print_timings:       total time =    2516.91 ms /   413 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.30 ms /     7 runs   (    0.61 ms per token,  1628.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2035.79 ms /   399 tokens (    5.10 ms per token,   195.99 tokens per second)\n",
            "llama_print_timings:        eval time =     229.06 ms /     6 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    2400.78 ms /   405 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     472.83 ms /    93 tokens (    5.08 ms per token,   196.69 tokens per second)\n",
            "llama_print_timings:        eval time =     223.87 ms /     6 runs   (   37.31 ms per token,    26.80 tokens per second)\n",
            "llama_print_timings:       total time =     743.71 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1687.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2588.70 ms /   503 tokens (    5.15 ms per token,   194.31 tokens per second)\n",
            "llama_print_timings:        eval time =     226.89 ms /     6 runs   (   37.82 ms per token,    26.44 tokens per second)\n",
            "llama_print_timings:       total time =    2977.93 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1781.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.26 ms /   420 tokens (    5.13 ms per token,   194.78 tokens per second)\n",
            "llama_print_timings:        eval time =     228.17 ms /     6 runs   (   38.03 ms per token,    26.30 tokens per second)\n",
            "llama_print_timings:       total time =    2519.64 ms /   426 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.59 ms /     7 runs   (    0.66 ms per token,  1525.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2391.92 ms /   462 tokens (    5.18 ms per token,   193.15 tokens per second)\n",
            "llama_print_timings:        eval time =     230.36 ms /     6 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2859.53 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1842.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3077.37 ms /   588 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
            "llama_print_timings:        eval time =     192.71 ms /     5 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    3498.49 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2672.80 ms /   515 tokens (    5.19 ms per token,   192.68 tokens per second)\n",
            "llama_print_timings:        eval time =     227.31 ms /     6 runs   (   37.89 ms per token,    26.40 tokens per second)\n",
            "llama_print_timings:       total time =    3068.10 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     7 runs   (    0.49 ms per token,  2024.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3329.89 ms /   640 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =     271.38 ms /     7 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3799.97 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.55 ms per token,  1803.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3046.55 ms /   579 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =     192.85 ms /     5 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    3536.76 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     7 runs   (    0.51 ms per token,  1969.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2635.88 ms /   507 tokens (    5.20 ms per token,   192.35 tokens per second)\n",
            "llama_print_timings:        eval time =     227.91 ms /     6 runs   (   37.98 ms per token,    26.33 tokens per second)\n",
            "llama_print_timings:       total time =    3044.24 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3241.01 ms /   621 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =     230.87 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    3663.98 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1447.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3911.70 ms /   741 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =     234.67 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4411.92 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3268.80 ms /   621 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
            "llama_print_timings:        eval time =     231.29 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    3779.55 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.56 ms per token,  1801.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1621.94 ms /   319 tokens (    5.08 ms per token,   196.68 tokens per second)\n",
            "llama_print_timings:        eval time =     188.89 ms /     5 runs   (   37.78 ms per token,    26.47 tokens per second)\n",
            "llama_print_timings:       total time =    1917.60 ms /   324 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1788.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     223.64 ms /     6 runs   (   37.27 ms per token,    26.83 tokens per second)\n",
            "llama_print_timings:       total time =     245.27 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.61 ms /   478 tokens (    5.16 ms per token,   193.95 tokens per second)\n",
            "llama_print_timings:        eval time =     229.36 ms /     6 runs   (   38.23 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    2847.41 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1661.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2126.75 ms /   412 tokens (    5.16 ms per token,   193.72 tokens per second)\n",
            "llama_print_timings:        eval time =     225.66 ms /     6 runs   (   37.61 ms per token,    26.59 tokens per second)\n",
            "llama_print_timings:       total time =    2493.94 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1505.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2223.25 ms /   432 tokens (    5.15 ms per token,   194.31 tokens per second)\n",
            "llama_print_timings:        eval time =     229.25 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2660.39 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1671.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2312.65 ms /   443 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =     226.84 ms /     6 runs   (   37.81 ms per token,    26.45 tokens per second)\n",
            "llama_print_timings:       total time =    2754.46 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1951.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2771.60 ms /   536 tokens (    5.17 ms per token,   193.39 tokens per second)\n",
            "llama_print_timings:        eval time =     268.64 ms /     7 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    3210.21 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1777.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4733.41 ms /   888 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =     196.94 ms /     5 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5199.53 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1614.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2847.79 ms /   544 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
            "llama_print_timings:        eval time =     270.96 ms /     7 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    3408.03 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2520.08 ms /   488 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
            "llama_print_timings:        eval time =     228.07 ms /     6 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
            "llama_print_timings:       total time =    2916.77 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2174.20 ms /   423 tokens (    5.14 ms per token,   194.55 tokens per second)\n",
            "llama_print_timings:        eval time =     228.53 ms /     6 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    2542.90 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.24 ms /   424 tokens (    5.14 ms per token,   194.74 tokens per second)\n",
            "llama_print_timings:        eval time =     229.10 ms /     6 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    2547.50 ms /   430 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.32 ms /     7 runs   (    0.90 ms per token,  1107.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2175.88 ms /   421 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
            "llama_print_timings:        eval time =     231.71 ms /     6 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2566.85 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.77 ms /     7 runs   (    0.68 ms per token,  1466.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2176.34 ms /   414 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
            "llama_print_timings:        eval time =     231.88 ms /     6 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2655.81 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1763.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2267.84 ms /   439 tokens (    5.17 ms per token,   193.58 tokens per second)\n",
            "llama_print_timings:        eval time =     226.99 ms /     6 runs   (   37.83 ms per token,    26.43 tokens per second)\n",
            "llama_print_timings:       total time =    2650.46 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2141.82 ms /   414 tokens (    5.17 ms per token,   193.29 tokens per second)\n",
            "llama_print_timings:        eval time =     229.35 ms /     6 runs   (   38.22 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    2517.72 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1658.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2389.20 ms /   458 tokens (    5.22 ms per token,   191.70 tokens per second)\n",
            "llama_print_timings:        eval time =     231.05 ms /     6 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2778.01 ms /   464 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.53 ms /     7 runs   (    0.65 ms per token,  1543.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2754.76 ms /   520 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =     233.41 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    3273.27 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3491.75 ms /   659 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     232.64 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3960.51 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1832.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2307.24 ms /   442 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
            "llama_print_timings:        eval time =     230.44 ms /     6 runs   (   38.41 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2686.95 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2219.60 ms /   426 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
            "llama_print_timings:        eval time =     228.53 ms /     6 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    2589.50 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.67 ms /     7 runs   (    0.67 ms per token,  1500.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2058.06 ms /   394 tokens (    5.22 ms per token,   191.44 tokens per second)\n",
            "llama_print_timings:        eval time =     231.62 ms /     6 runs   (   38.60 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2479.53 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1789.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3291.53 ms /   620 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =     194.57 ms /     5 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3778.68 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1886.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3584.73 ms /   676 tokens (    5.30 ms per token,   188.58 tokens per second)\n",
            "llama_print_timings:        eval time =     196.13 ms /     5 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    4004.69 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2569.35 ms /   490 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
            "llama_print_timings:        eval time =     232.90 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2969.35 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1482.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3163.71 ms /   596 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     234.83 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3711.10 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1839.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4322.92 ms /   808 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =     276.88 ms /     7 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    4928.18 ms /   815 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1809.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2748.83 ms /   528 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
            "llama_print_timings:        eval time =     232.61 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3157.66 ms /   534 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2145.06 ms /   416 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
            "llama_print_timings:        eval time =     229.35 ms /     6 runs   (   38.22 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    2523.94 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     7 runs   (    0.65 ms per token,  1536.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1797.51 ms /   344 tokens (    5.23 ms per token,   191.38 tokens per second)\n",
            "llama_print_timings:        eval time =     271.12 ms /     7 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2256.96 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1629.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2209.32 ms /   423 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     229.20 ms /     6 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    2674.02 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1649.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2493.84 ms /   479 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =     229.77 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2890.50 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.36 ms /   418 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     230.69 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2586.42 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1713.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5378.42 ms /   987 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
            "llama_print_timings:        eval time =     200.60 ms /     5 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    5978.14 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     7 runs   (    0.51 ms per token,  1965.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3374.98 ms /   637 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =     235.02 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3853.12 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2747.60 ms /   525 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =     232.26 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    3158.47 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1681.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2548.26 ms /   486 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
            "llama_print_timings:        eval time =     234.54 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2947.55 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1506.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.17 ms /   419 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =     231.46 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2641.51 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2078.02 ms /   395 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =     229.63 ms /     6 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2510.79 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1645.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2708.82 ms /   517 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =     231.59 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    3123.30 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1869.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2799.20 ms /   535 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =     232.44 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3215.60 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1448.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2712.80 ms /   520 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =     234.20 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3144.39 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1677.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2568.80 ms /   482 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =     232.52 ms /     6 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3077.01 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.33 ms /     7 runs   (    0.62 ms per token,  1617.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2316.62 ms /   445 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =     229.19 ms /     6 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    2699.65 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1699.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2014.78 ms /   387 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
            "llama_print_timings:        eval time =     229.12 ms /     6 runs   (   38.19 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    2383.67 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1739.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2447.29 ms /   469 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =     232.78 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2843.12 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     7 runs   (    0.69 ms per token,  1451.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.56 ms /   525 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     234.04 ms /     6 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3230.18 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1640.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2569.59 ms /   488 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =     233.68 ms /     6 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3042.12 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2931.52 ms /   560 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
            "llama_print_timings:        eval time =     232.57 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3356.71 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1805.58 ms /   350 tokens (    5.16 ms per token,   193.84 tokens per second)\n",
            "llama_print_timings:        eval time =     226.42 ms /     6 runs   (   37.74 ms per token,    26.50 tokens per second)\n",
            "llama_print_timings:       total time =    2156.38 ms /   356 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1512.18 ms /   296 tokens (    5.11 ms per token,   195.74 tokens per second)\n",
            "llama_print_timings:        eval time =     226.19 ms /     6 runs   (   37.70 ms per token,    26.53 tokens per second)\n",
            "llama_print_timings:       total time =    1841.90 ms /   302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     7 runs   (    0.70 ms per token,  1425.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1596.99 ms /   312 tokens (    5.12 ms per token,   195.37 tokens per second)\n",
            "llama_print_timings:        eval time =     230.25 ms /     6 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    1956.88 ms /   318 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.61 ms /     7 runs   (    0.66 ms per token,  1518.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1607.65 ms /   310 tokens (    5.19 ms per token,   192.83 tokens per second)\n",
            "llama_print_timings:        eval time =     229.06 ms /     6 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    2030.45 ms /   316 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1826.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1143.33 ms /   224 tokens (    5.10 ms per token,   195.92 tokens per second)\n",
            "llama_print_timings:        eval time =     268.16 ms /     7 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    1526.07 ms /   231 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1867.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.00 ms /   440 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
            "llama_print_timings:        eval time =     229.17 ms /     6 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    2657.51 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2364.44 ms /   451 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =     231.10 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2749.25 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1979.50 ms /   380 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
            "llama_print_timings:        eval time =     231.60 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2347.49 ms /   386 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.29 ms /     7 runs   (    0.76 ms per token,  1324.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2767.55 ms /   522 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     235.27 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3264.68 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1640.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1918.45 ms /   366 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =     231.94 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2376.49 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1650.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1559.11 ms /   300 tokens (    5.20 ms per token,   192.42 tokens per second)\n",
            "llama_print_timings:        eval time =     228.45 ms /     6 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =    1904.26 ms /   306 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.48 ms /   366 tokens (    5.18 ms per token,   192.99 tokens per second)\n",
            "llama_print_timings:        eval time =     229.19 ms /     6 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    2255.39 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1702.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.94 ms /   423 tokens (    5.20 ms per token,   192.37 tokens per second)\n",
            "llama_print_timings:        eval time =     231.67 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2580.22 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.73 ms /     7 runs   (    0.68 ms per token,  1479.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2760.24 ms /   522 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =     234.33 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3195.51 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2582.01 ms /   484 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =     234.80 ms /     6 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3079.70 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3474.27 ms /   654 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =     236.07 ms /     6 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3926.69 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1918.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.09 ms /   418 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
            "llama_print_timings:        eval time =     229.99 ms /     6 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2573.59 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1630.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     704.46 ms /   135 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =     231.91 ms /     6 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    1001.32 ms /   141 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.53 ms /     7 runs   (    0.93 ms per token,  1071.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2948.93 ms /   559 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =     235.11 ms /     6 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3433.10 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1825.49 ms /   349 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
            "llama_print_timings:        eval time =     229.93 ms /     6 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2248.03 ms /   355 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1894.73 ms /   363 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =     227.98 ms /     6 runs   (   38.00 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =    2246.80 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2804.40 ms /   531 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
            "llama_print_timings:        eval time =     233.65 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3208.90 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2717.43 ms /   517 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
            "llama_print_timings:        eval time =     232.58 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3126.97 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.60 ms /     7 runs   (    0.66 ms per token,  1521.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2734.48 ms /   520 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =     275.41 ms /     7 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3284.22 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1665.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1566.08 ms /   304 tokens (    5.15 ms per token,   194.12 tokens per second)\n",
            "llama_print_timings:        eval time =     231.74 ms /     6 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    1940.65 ms /   310 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2715.73 ms /   516 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     233.47 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3123.10 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1633.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1853.66 ms /   359 tokens (    5.16 ms per token,   193.67 tokens per second)\n",
            "llama_print_timings:        eval time =     229.59 ms /     6 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2210.55 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1679.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1369.26 ms /   259 tokens (    5.29 ms per token,   189.15 tokens per second)\n",
            "llama_print_timings:        eval time =     226.96 ms /     6 runs   (   37.83 ms per token,    26.44 tokens per second)\n",
            "llama_print_timings:       total time =    1699.09 ms /   265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1787.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4900.48 ms /   902 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
            "llama_print_timings:        eval time =     239.65 ms /     6 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5540.25 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3111.80 ms /   588 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =     235.28 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3540.43 ms /   594 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2626.38 ms /   499 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     235.15 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3035.72 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     955.98 ms /   184 tokens (    5.20 ms per token,   192.47 tokens per second)\n",
            "llama_print_timings:        eval time =     226.59 ms /     6 runs   (   37.76 ms per token,    26.48 tokens per second)\n",
            "llama_print_timings:       total time =    1260.51 ms /   190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     7 runs   (    0.71 ms per token,  1399.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.45 ms /   408 tokens (    5.18 ms per token,   192.87 tokens per second)\n",
            "llama_print_timings:        eval time =     232.81 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2526.90 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1649.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2468.99 ms /   467 tokens (    5.29 ms per token,   189.15 tokens per second)\n",
            "llama_print_timings:        eval time =     231.23 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2953.52 ms /   473 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1849.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2929.04 ms /   556 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
            "llama_print_timings:        eval time =     232.89 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3345.51 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2894.03 ms /   551 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
            "llama_print_timings:        eval time =     233.79 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3315.14 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.21 ms /     4 runs   (    0.55 ms per token,  1814.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5408.04 ms /   986 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
            "llama_print_timings:        eval time =     121.14 ms /     3 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    5955.06 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1637.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2757.22 ms /   526 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     233.31 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3171.42 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.03 ms /     6 runs   (    0.51 ms per token,  1978.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3645.78 ms /   687 tokens (    5.31 ms per token,   188.44 tokens per second)\n",
            "llama_print_timings:        eval time =     195.79 ms /     5 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4061.31 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1791.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5363.92 ms /   979 tokens (    5.48 ms per token,   182.52 tokens per second)\n",
            "llama_print_timings:        eval time =     201.75 ms /     5 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5992.29 ms /   984 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2760.99 ms /   527 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =     233.97 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3174.98 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1835.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3694.14 ms /   691 tokens (    5.35 ms per token,   187.05 tokens per second)\n",
            "llama_print_timings:        eval time =     195.36 ms /     5 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4114.01 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     173.91 ms /    28 tokens (    6.21 ms per token,   161.01 tokens per second)\n",
            "llama_print_timings:        eval time =     234.19 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =     442.56 ms /    34 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4350.59 ms /   806 tokens (    5.40 ms per token,   185.26 tokens per second)\n",
            "llama_print_timings:        eval time =     237.84 ms /     6 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    4970.56 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1777.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3427.31 ms /   648 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =     272.86 ms /     7 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3919.20 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.60 ms /     6 runs   (    0.60 ms per token,  1668.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4973.26 ms /   915 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
            "llama_print_timings:        eval time =     200.82 ms /     5 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    5484.47 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1677.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3352.66 ms /   626 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
            "llama_print_timings:        eval time =     235.77 ms /     6 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3886.89 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1916.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4975.16 ms /   917 tokens (    5.43 ms per token,   184.32 tokens per second)\n",
            "llama_print_timings:        eval time =     199.73 ms /     5 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    5462.54 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1487.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3298.39 ms /   623 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
            "llama_print_timings:        eval time =     234.85 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3774.68 ms /   629 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2561.46 ms /   486 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =     233.25 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3054.36 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1766.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.77 ms /   365 tokens (    5.20 ms per token,   192.43 tokens per second)\n",
            "llama_print_timings:        eval time =     227.51 ms /     6 runs   (   37.92 ms per token,    26.37 tokens per second)\n",
            "llama_print_timings:       total time =    2256.68 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1822.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.20 ms /   437 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =     231.50 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2669.87 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.15 ms /     6 runs   (    0.52 ms per token,  1905.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3695.10 ms /   691 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
            "llama_print_timings:        eval time =     196.39 ms /     5 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    4114.55 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1569.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2038.94 ms /   388 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =     231.69 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2502.15 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1825.87 ms /   352 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
            "llama_print_timings:        eval time =     231.50 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2219.55 ms /   358 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.98 ms /   416 tokens (    5.18 ms per token,   192.95 tokens per second)\n",
            "llama_print_timings:        eval time =     271.85 ms /     7 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2570.65 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1815.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2940.32 ms /   557 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =     235.38 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3362.14 ms /   563 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1689.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2541.45 ms /   482 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
            "llama_print_timings:        eval time =     232.82 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2941.49 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.79 ms /     7 runs   (    0.68 ms per token,  1459.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1442.89 ms /   276 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =     230.94 ms /     6 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    1849.60 ms /   282 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.89 ms /     7 runs   (    0.70 ms per token,  1432.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.54 ms /    24 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     269.31 ms /     7 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =     449.23 ms /    31 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1797.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1403.75 ms /   268 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =     228.55 ms /     6 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    1778.67 ms /   274 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1825.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1348.83 ms /   259 tokens (    5.21 ms per token,   192.02 tokens per second)\n",
            "llama_print_timings:        eval time =     228.00 ms /     6 runs   (   38.00 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =    1675.03 ms /   265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.44 ms /     7 runs   (    0.63 ms per token,  1575.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.74 ms /   472 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =     272.25 ms /     7 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2903.54 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2544.79 ms /   486 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
            "llama_print_timings:        eval time =     231.76 ms /     6 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2945.34 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1756.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.32 ms /    19 tokens (    6.60 ms per token,   151.61 tokens per second)\n",
            "llama_print_timings:        eval time =     232.37 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =     392.76 ms /    25 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1573.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2423.69 ms /   459 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =     232.68 ms /     6 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2881.06 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1650.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1699.10 ms /   325 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =     231.46 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2109.93 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2458.30 ms /   466 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =     233.22 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2851.34 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1672.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1224.72 ms /   238 tokens (    5.15 ms per token,   194.33 tokens per second)\n",
            "llama_print_timings:        eval time =     229.98 ms /     6 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    1549.19 ms /   244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1867.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     806.74 ms /   155 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
            "llama_print_timings:        eval time =     226.79 ms /     6 runs   (   37.80 ms per token,    26.46 tokens per second)\n",
            "llama_print_timings:       total time =    1105.33 ms /   161 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1902.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2725.79 ms /   519 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     232.38 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3139.06 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2824.96 ms /   530 tokens (    5.33 ms per token,   187.61 tokens per second)\n",
            "llama_print_timings:        eval time =     236.07 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3339.02 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.70 ms /     7 runs   (    0.67 ms per token,  1490.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.73 ms /   432 tokens (    5.21 ms per token,   192.02 tokens per second)\n",
            "llama_print_timings:        eval time =     232.97 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2654.37 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1739.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.34 ms /   411 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     230.10 ms /     6 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2537.88 ms /   417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1836.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3838.44 ms /   719 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
            "llama_print_timings:        eval time =     195.96 ms /     5 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4274.47 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.66 ms /     7 runs   (    0.67 ms per token,  1503.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2123.86 ms /   408 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =     271.90 ms /     7 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2605.83 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2259.02 ms /   432 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =     231.79 ms /     6 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2711.65 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1811.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1599.26 ms /   307 tokens (    5.21 ms per token,   191.96 tokens per second)\n",
            "llama_print_timings:        eval time =     232.26 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    1948.16 ms /   313 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1948.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2721.24 ms /   517 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
            "llama_print_timings:        eval time =     234.37 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3134.07 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.94 ms /   464 tokens (    5.21 ms per token,   191.98 tokens per second)\n",
            "llama_print_timings:        eval time =     270.30 ms /     7 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2854.47 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.81 ms /     7 runs   (    0.69 ms per token,  1454.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2599.54 ms /   490 tokens (    5.31 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =     233.49 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3086.72 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2732.47 ms /   517 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =     233.45 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3210.78 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.15 ms /     6 runs   (    0.53 ms per token,  1904.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3527.27 ms /   664 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =     236.44 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    4000.38 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     6 runs   (    0.58 ms per token,  1711.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3385.15 ms /   637 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =     198.02 ms /     5 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    3792.98 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.70 ms /     7 runs   (    0.67 ms per token,  1488.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2477.12 ms /   472 tokens (    5.25 ms per token,   190.54 tokens per second)\n",
            "llama_print_timings:        eval time =     273.82 ms /     7 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3024.75 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1819.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1773.66 ms /   344 tokens (    5.16 ms per token,   193.95 tokens per second)\n",
            "llama_print_timings:        eval time =     232.39 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2143.63 ms /   350 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.28 ms /     7 runs   (    0.61 ms per token,  1635.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     207.81 ms /    36 tokens (    5.77 ms per token,   173.23 tokens per second)\n",
            "llama_print_timings:        eval time =     230.29 ms /     6 runs   (   38.38 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =     477.13 ms /    42 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2898.95 ms /   548 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
            "llama_print_timings:        eval time =     235.32 ms /     6 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3325.54 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1913.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3703.40 ms /   696 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =     196.74 ms /     5 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    4123.46 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.20 ms /     7 runs   (    0.74 ms per token,  1346.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2303.06 ms /   440 tokens (    5.23 ms per token,   191.05 tokens per second)\n",
            "llama_print_timings:        eval time =     232.50 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2788.19 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1651.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2165.22 ms /   416 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
            "llama_print_timings:        eval time =     270.05 ms /     7 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2621.21 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1896.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2894.65 ms /   547 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =     233.00 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3307.58 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.93 ms /    13 runs   (    0.53 ms per token,  1876.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3970.24 ms /   740 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =     473.10 ms /    12 runs   (   39.42 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    4707.19 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.33 ms /     7 runs   (    0.76 ms per token,  1314.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1447.81 ms /   280 tokens (    5.17 ms per token,   193.40 tokens per second)\n",
            "llama_print_timings:        eval time =     268.96 ms /     7 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    1902.04 ms /   287 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1696.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2515.17 ms /   478 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =     231.26 ms /     6 runs   (   38.54 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2979.41 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2281.86 ms /   435 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =     229.48 ms /     6 runs   (   38.25 ms per token,    26.15 tokens per second)\n",
            "llama_print_timings:       total time =    2662.38 ms /   441 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     6 runs   (    0.64 ms per token,  1558.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4191.98 ms /   778 tokens (    5.39 ms per token,   185.59 tokens per second)\n",
            "llama_print_timings:        eval time =     199.46 ms /     5 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    4654.48 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4814.48 ms /   886 tokens (    5.43 ms per token,   184.03 tokens per second)\n",
            "llama_print_timings:        eval time =     199.81 ms /     5 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    5424.68 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1853.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4841.82 ms /   895 tokens (    5.41 ms per token,   184.85 tokens per second)\n",
            "llama_print_timings:        eval time =     201.51 ms /     5 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5324.24 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     6 runs   (    0.67 ms per token,  1503.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3803.41 ms /   712 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =     237.17 ms /     6 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    4365.14 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.26 ms /     7 runs   (    0.61 ms per token,  1642.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2379.70 ms /   452 tokens (    5.26 ms per token,   189.94 tokens per second)\n",
            "llama_print_timings:        eval time =     233.89 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2818.78 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1945.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4980.65 ms /   920 tokens (    5.41 ms per token,   184.71 tokens per second)\n",
            "llama_print_timings:        eval time =     199.40 ms /     5 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    5471.60 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     7 runs   (    0.68 ms per token,  1474.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.57 ms /   523 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =     233.56 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    3194.13 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1842.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4624.06 ms /   856 tokens (    5.40 ms per token,   185.12 tokens per second)\n",
            "llama_print_timings:        eval time =     199.29 ms /     5 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    5207.57 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1893.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3382.68 ms /   638 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     195.82 ms /     5 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3787.65 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1484.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4663.34 ms /   864 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =     281.04 ms /     7 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5290.01 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1874.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4998.80 ms /   920 tokens (    5.43 ms per token,   184.04 tokens per second)\n",
            "llama_print_timings:        eval time =     240.24 ms /     6 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    5600.20 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5400.31 ms /   987 tokens (    5.47 ms per token,   182.77 tokens per second)\n",
            "llama_print_timings:        eval time =     200.68 ms /     5 runs   (   40.14 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    5924.25 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1873.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5515.41 ms /  1002 tokens (    5.50 ms per token,   181.67 tokens per second)\n",
            "llama_print_timings:        eval time =     200.64 ms /     5 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    6169.26 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4194.17 ms /   780 tokens (    5.38 ms per token,   185.97 tokens per second)\n",
            "llama_print_timings:        eval time =     197.48 ms /     5 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    4648.45 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1483.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4298.39 ms /   795 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =     238.46 ms /     6 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    4885.53 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      66.01 ms /   110 runs   (    0.60 ms per token,  1666.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5988.38 ms /  1083 tokens (    5.53 ms per token,   180.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4440.11 ms /   109 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =   11257.94 ms /  1192 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.97 ms /     7 runs   (    0.71 ms per token,  1408.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2135.67 ms /   402 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =     235.59 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2658.57 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     100.27 ms /   151 runs   (    0.66 ms per token,  1505.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5376.67 ms /   979 tokens (    5.49 ms per token,   182.08 tokens per second)\n",
            "llama_print_timings:        eval time =    6075.60 ms /   150 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =   12554.13 ms /  1129 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1693.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4543.20 ms /   835 tokens (    5.44 ms per token,   183.79 tokens per second)\n",
            "llama_print_timings:        eval time =     197.58 ms /     5 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    5128.29 ms /   840 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.49 ms /     6 runs   (    0.58 ms per token,  1717.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4289.26 ms /   795 tokens (    5.40 ms per token,   185.35 tokens per second)\n",
            "llama_print_timings:        eval time =     198.06 ms /     5 runs   (   39.61 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4774.60 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     7 runs   (    0.69 ms per token,  1457.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2638.68 ms /   499 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =     234.28 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3112.69 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2170.50 ms /   416 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     233.51 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2636.05 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      47.82 ms /    85 runs   (    0.56 ms per token,  1777.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5319.67 ms /   975 tokens (    5.46 ms per token,   183.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3392.54 ms /    84 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    9339.77 ms /  1059 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1491.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2693.24 ms /   507 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =     234.87 ms /     6 runs   (   39.15 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3227.53 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1648.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.37 ms /   454 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
            "llama_print_timings:        eval time =     232.39 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2766.22 ms /   460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.28 ms /     7 runs   (    0.61 ms per token,  1637.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1640.38 ms /   316 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
            "llama_print_timings:        eval time =     232.52 ms /     6 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    1989.11 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1858.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2720.03 ms /   518 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =     236.00 ms /     6 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3132.73 ms /   524 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1477.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2196.55 ms /   418 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =     231.60 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2606.50 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1787.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3267.54 ms /   612 tokens (    5.34 ms per token,   187.30 tokens per second)\n",
            "llama_print_timings:        eval time =     197.04 ms /     5 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3767.15 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2546.24 ms /   488 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     271.17 ms /     7 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2988.60 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.99 ms /     6 runs   (    0.50 ms per token,  2005.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3876.81 ms /   723 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =     198.29 ms /     5 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4322.76 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.78 ms /     7 runs   (    0.68 ms per token,  1465.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1690.50 ms /   328 tokens (    5.15 ms per token,   194.03 tokens per second)\n",
            "llama_print_timings:        eval time =     270.87 ms /     7 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2114.75 ms /   335 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.92 ms /     6 runs   (    0.49 ms per token,  2052.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4626.70 ms /   850 tokens (    5.44 ms per token,   183.72 tokens per second)\n",
            "llama_print_timings:        eval time =     200.70 ms /     5 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5202.57 ms /   855 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1882.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.30 ms /   502 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =     236.30 ms /     6 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3044.94 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1786.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2153.33 ms /   412 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =     229.66 ms /     6 runs   (   38.28 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2535.19 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1527.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1687.11 ms /   327 tokens (    5.16 ms per token,   193.82 tokens per second)\n",
            "llama_print_timings:        eval time =     231.94 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2055.73 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1713.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5329.62 ms /   975 tokens (    5.47 ms per token,   182.94 tokens per second)\n",
            "llama_print_timings:        eval time =     201.78 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5956.01 ms /   980 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1681.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5259.53 ms /   965 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =     241.63 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5822.10 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1550.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1903.63 ms /   363 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     234.73 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2330.17 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1569.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1455.64 ms /   266 tokens (    5.47 ms per token,   182.74 tokens per second)\n",
            "llama_print_timings:        eval time =     237.59 ms /     6 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    1875.41 ms /   272 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1679.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.18 ms /   564 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =     234.64 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3427.34 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2658.81 ms /   501 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =     236.05 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3071.93 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.23 ms /     7 runs   (    0.60 ms per token,  1654.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.07 ms /    20 tokens (    6.40 ms per token,   156.16 tokens per second)\n",
            "llama_print_timings:        eval time =     232.10 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =     394.12 ms /    26 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2701.22 ms /   507 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =     194.22 ms /     5 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3067.83 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1817.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4175.93 ms /   776 tokens (    5.38 ms per token,   185.83 tokens per second)\n",
            "llama_print_timings:        eval time =     236.16 ms /     6 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    4807.01 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.26 ms /    11 runs   (    0.57 ms per token,  1756.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4244.31 ms /   792 tokens (    5.36 ms per token,   186.60 tokens per second)\n",
            "llama_print_timings:        eval time =     439.37 ms /    11 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    4969.89 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's dividend history and how sustainable are the dividend payouts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1768.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     177.57 ms /    29 tokens (    6.12 ms per token,   163.31 tokens per second)\n",
            "llama_print_timings:        eval time =     236.38 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =     450.00 ms /    35 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     6 runs   (    0.63 ms per token,  1578.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3978.52 ms /   743 tokens (    5.35 ms per token,   186.75 tokens per second)\n",
            "llama_print_timings:        eval time =     202.35 ms /     5 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    4486.99 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3620.47 ms /   677 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
            "llama_print_timings:        eval time =     195.19 ms /     5 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4106.43 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1819.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2544.07 ms /   483 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =     235.12 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2949.39 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.55 ms /   444 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
            "llama_print_timings:        eval time =     231.05 ms /     6 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2720.57 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1494.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2511.44 ms /   480 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =     274.76 ms /     7 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2992.26 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2745.98 ms /   520 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =     272.73 ms /     7 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3306.90 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1835.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4816.37 ms /   887 tokens (    5.43 ms per token,   184.16 tokens per second)\n",
            "llama_print_timings:        eval time =     202.16 ms /     5 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    5305.42 ms /   892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     6 runs   (    0.70 ms per token,  1422.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3867.95 ms /   719 tokens (    5.38 ms per token,   185.89 tokens per second)\n",
            "llama_print_timings:        eval time =     199.24 ms /     5 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4325.31 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3924.61 ms /   723 tokens (    5.43 ms per token,   184.22 tokens per second)\n",
            "llama_print_timings:        eval time =     239.03 ms /     6 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4521.65 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1654.77 ms /   320 tokens (    5.17 ms per token,   193.38 tokens per second)\n",
            "llama_print_timings:        eval time =     232.23 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2006.51 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1844.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3864.67 ms /   719 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
            "llama_print_timings:        eval time =     238.93 ms /     6 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    4344.17 ms /   725 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     7 runs   (    0.65 ms per token,  1534.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1695.20 ms /   325 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
            "llama_print_timings:        eval time =     232.80 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2072.58 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1889.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4471.88 ms /   824 tokens (    5.43 ms per token,   184.26 tokens per second)\n",
            "llama_print_timings:        eval time =     240.06 ms /     6 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5106.89 ms /   830 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2120.95 ms /   405 tokens (    5.24 ms per token,   190.95 tokens per second)\n",
            "llama_print_timings:        eval time =     232.47 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2498.65 ms /   411 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1692.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     266.36 ms /     7 runs   (   38.05 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =     292.12 ms /     7 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1649.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1987.75 ms /   378 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =     230.47 ms /     6 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2361.96 ms /   384 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     726.92 ms /   135 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =     236.30 ms /     6 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    1033.43 ms /   141 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.02 ms /     6 runs   (    0.50 ms per token,  1984.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4181.85 ms /   776 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =     237.92 ms /     6 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4808.51 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1812.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3304.42 ms /   605 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
            "llama_print_timings:        eval time =     198.93 ms /     5 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    3713.27 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1757.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2547.01 ms /   486 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     233.84 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2957.06 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.50 ms /     7 runs   (    0.64 ms per token,  1555.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2375.62 ms /   453 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2809.14 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1706.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2555.02 ms /   483 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =     234.94 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3046.78 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1786.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.03 ms /   472 tokens (    5.21 ms per token,   191.95 tokens per second)\n",
            "llama_print_timings:        eval time =     273.25 ms /     7 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2900.40 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.60 ms /   415 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =     230.07 ms /     6 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2543.47 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     6 runs   (    0.62 ms per token,  1623.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5921.78 ms /  1074 tokens (    5.51 ms per token,   181.36 tokens per second)\n",
            "llama_print_timings:        eval time =     206.30 ms /     5 runs   (   41.26 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =    6584.22 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1818.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5769.34 ms /  1044 tokens (    5.53 ms per token,   180.96 tokens per second)\n",
            "llama_print_timings:        eval time =     202.79 ms /     5 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    6339.03 ms /  1049 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     6 runs   (    0.62 ms per token,  1609.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3654.29 ms /   687 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
            "llama_print_timings:        eval time =     197.36 ms /     5 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    4091.41 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1749.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3718.72 ms /   696 tokens (    5.34 ms per token,   187.16 tokens per second)\n",
            "llama_print_timings:        eval time =     198.12 ms /     5 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4268.75 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2282.00 ms /   435 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =     229.41 ms /     6 runs   (   38.23 ms per token,    26.15 tokens per second)\n",
            "llama_print_timings:       total time =    2676.39 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1783.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.74 ms /   446 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =     231.64 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2721.77 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1659.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2632.38 ms /   504 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     272.92 ms /     7 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3086.97 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1516.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2606.12 ms /   494 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     235.78 ms /     6 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3133.38 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2858.07 ms /   541 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
            "llama_print_timings:        eval time =     234.26 ms /     6 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3297.22 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1620.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2630.22 ms /   502 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =     235.97 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3041.30 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     6 runs   (    0.68 ms per token,  1461.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3932.20 ms /   736 tokens (    5.34 ms per token,   187.17 tokens per second)\n",
            "llama_print_timings:        eval time =     237.98 ms /     6 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    4439.86 ms /   742 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.55 ms per token,  1833.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3905.55 ms /   727 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
            "llama_print_timings:        eval time =     198.44 ms /     5 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4461.01 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.58 ms /   439 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
            "llama_print_timings:        eval time =     232.23 ms /     6 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2670.44 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.07 ms /   450 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =     231.80 ms /     6 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2764.24 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1802.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2203.85 ms /   424 tokens (    5.20 ms per token,   192.39 tokens per second)\n",
            "llama_print_timings:        eval time =     271.13 ms /     7 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2634.07 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1516.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2563.27 ms /   488 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =     273.80 ms /     7 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3140.84 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.77 ms /    13 runs   (    0.52 ms per token,  1920.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3525.03 ms /   662 tokens (    5.32 ms per token,   187.80 tokens per second)\n",
            "llama_print_timings:        eval time =     473.15 ms /    12 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    4247.04 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.69 ms /   445 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
            "llama_print_timings:        eval time =     230.10 ms /     6 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2717.07 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.21 ms /   446 tokens (    5.22 ms per token,   191.48 tokens per second)\n",
            "llama_print_timings:        eval time =     233.88 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2726.42 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1551.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2347.58 ms /   443 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
            "llama_print_timings:        eval time =     233.58 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2835.73 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1822.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2120.32 ms /   408 tokens (    5.20 ms per token,   192.42 tokens per second)\n",
            "llama_print_timings:        eval time =     269.99 ms /     7 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2581.84 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1832.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.93 ms /   474 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
            "llama_print_timings:        eval time =     231.94 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2899.96 ms /   480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1770.96 ms /   340 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
            "llama_print_timings:        eval time =     233.66 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2131.93 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1981.87 ms /   379 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =     230.20 ms /     6 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2353.61 ms /   385 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1574.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1695.37 ms /   327 tokens (    5.18 ms per token,   192.88 tokens per second)\n",
            "llama_print_timings:        eval time =     232.03 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2108.23 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1808.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1913.07 ms /   366 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
            "llama_print_timings:        eval time =     227.96 ms /     6 runs   (   37.99 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =    2360.36 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1768.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1684.75 ms /   322 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =     233.74 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2036.00 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1720.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1243.19 ms /   239 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
            "llama_print_timings:        eval time =     229.40 ms /     6 runs   (   38.23 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    1565.14 ms /   245 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.40 ms /   459 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =     231.58 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2816.75 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1803.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2010.24 ms /   384 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =     268.64 ms /     7 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2423.80 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.11 ms /     7 runs   (    0.73 ms per token,  1369.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2870.57 ms /   544 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =     277.51 ms /     7 runs   (   39.64 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    3456.78 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1949.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2990.90 ms /   562 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
            "llama_print_timings:        eval time =     234.02 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3444.61 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.06 ms /     6 runs   (    0.51 ms per token,  1963.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.13 ms /    22 tokens (    5.87 ms per token,   170.37 tokens per second)\n",
            "llama_print_timings:        eval time =     192.85 ms /     5 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =     350.08 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3119.90 ms /   587 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =     194.31 ms /     5 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3518.47 ms /   592 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.70 ms /     7 runs   (    0.67 ms per token,  1490.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3162.75 ms /   594 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =     234.91 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3625.26 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2651.52 ms /   503 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =     231.33 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    3168.36 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.95 ms /     6 runs   (    0.49 ms per token,  2031.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.09 ms /   532 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =     196.26 ms /     5 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3189.20 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1835.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5551.96 ms /  1016 tokens (    5.46 ms per token,   183.00 tokens per second)\n",
            "llama_print_timings:        eval time =     243.28 ms /     6 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    6125.88 ms /  1022 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.44 ms /     7 runs   (    0.63 ms per token,  1575.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2739.85 ms /   516 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =     235.46 ms /     6 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3284.76 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3701.26 ms /   693 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
            "llama_print_timings:        eval time =     236.24 ms /     6 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4187.11 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1900.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3514.80 ms /   660 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =     233.66 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3969.48 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1543.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.28 ms /   437 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =     232.15 ms /     6 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2708.57 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1772.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2445.25 ms /   462 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =     231.20 ms /     6 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2940.46 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.99 ms /   365 tokens (    5.20 ms per token,   192.41 tokens per second)\n",
            "llama_print_timings:        eval time =     230.89 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2270.21 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1790.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3699.64 ms /   695 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =     235.50 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    4175.01 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     7 runs   (    0.69 ms per token,  1451.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.51 ms /   564 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =     235.18 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3443.37 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3142.23 ms /   587 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
            "llama_print_timings:        eval time =     233.19 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3734.74 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.50 ms /   435 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =     230.89 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2670.31 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1612.28 ms /   306 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =     231.49 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    1963.10 ms /   312 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.71 ms /   374 tokens (    5.19 ms per token,   192.81 tokens per second)\n",
            "llama_print_timings:        eval time =     228.46 ms /     6 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =    2307.36 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.86 ms /     7 runs   (    0.69 ms per token,  1441.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2323.36 ms /   443 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =     233.42 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2733.57 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     7 runs   (    0.71 ms per token,  1400.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     433.06 ms /    78 tokens (    5.55 ms per token,   180.12 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =     749.01 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1819.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2741.37 ms /   520 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =     235.12 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3250.19 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.80 ms /   443 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =     230.03 ms /     6 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2717.43 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1859.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3562.97 ms /   670 tokens (    5.32 ms per token,   188.05 tokens per second)\n",
            "llama_print_timings:        eval time =     197.50 ms /     5 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3994.33 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     6 runs   (    0.70 ms per token,  1431.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3364.07 ms /   630 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =     196.76 ms /     5 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3841.99 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2467.07 ms /   467 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
            "llama_print_timings:        eval time =     232.92 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2937.04 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1785.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2239.94 ms /   427 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =     231.12 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2629.38 ms /   433 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "Total score for approach 1 and distance function cosine is 0.6194968553459119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(1, 'ip')"
      ],
      "metadata": {
        "id": "fw_TIsTV3dTg",
        "outputId": "f36c9641-b680-4758-92bd-79cf010335d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1701.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3557.86 ms /   659 tokens (    5.40 ms per token,   185.22 tokens per second)\n",
            "llama_print_timings:        eval time =     235.15 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4049.39 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3269.19 ms /   613 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =     232.45 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3795.72 ms /   619 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1857.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4151.31 ms /   776 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =     197.00 ms /     5 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    4601.88 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1897.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3517.07 ms /   663 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =     236.43 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3979.89 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     7 runs   (    0.51 ms per token,  1977.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3050.13 ms /   572 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =     231.86 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    3594.52 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     7 runs   (    0.51 ms per token,  1962.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2717.37 ms /   516 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =     231.41 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    3118.33 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1895.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2326.08 ms /   445 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =     232.24 ms /     6 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2714.86 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1768.93 ms /   340 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =     229.64 ms /     6 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2122.80 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1622.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3486.74 ms /   654 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
            "llama_print_timings:        eval time =     236.84 ms /     6 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    4023.45 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1658.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2769.10 ms /   523 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =     234.64 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3211.62 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1897.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4151.94 ms /   774 tokens (    5.36 ms per token,   186.42 tokens per second)\n",
            "llama_print_timings:        eval time =     196.65 ms /     5 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    4597.06 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1873.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.36 ms /   444 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     230.01 ms /     6 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2709.08 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /     7 runs   (    0.63 ms per token,  1581.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2083.07 ms /   398 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =     232.10 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2544.76 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2212.36 ms /   422 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =     231.31 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2630.20 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     891.06 ms /   173 tokens (    5.15 ms per token,   194.15 tokens per second)\n",
            "llama_print_timings:        eval time =     227.99 ms /     6 runs   (   38.00 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =    1192.90 ms /   179 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1890.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3474.28 ms /   651 tokens (    5.34 ms per token,   187.38 tokens per second)\n",
            "llama_print_timings:        eval time =     237.28 ms /     6 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3923.66 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1929.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.14 ms /   440 tokens (    5.19 ms per token,   192.55 tokens per second)\n",
            "llama_print_timings:        eval time =     273.08 ms /     7 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2714.06 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.02 ms /     6 runs   (    0.50 ms per token,  1984.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3715.10 ms /   692 tokens (    5.37 ms per token,   186.27 tokens per second)\n",
            "llama_print_timings:        eval time =     198.57 ms /     5 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4245.33 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1942.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2806.70 ms /   531 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =     234.48 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3218.44 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3249.53 ms /   614 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =     234.95 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3674.81 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4025.56 ms /   751 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
            "llama_print_timings:        eval time =     237.70 ms /     6 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4584.32 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     6 runs   (    0.62 ms per token,  1600.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5940.41 ms /  1077 tokens (    5.52 ms per token,   181.30 tokens per second)\n",
            "llama_print_timings:        eval time =     201.23 ms /     5 runs   (   40.25 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    6532.67 ms /  1082 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1761.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2065.21 ms /   397 tokens (    5.20 ms per token,   192.23 tokens per second)\n",
            "llama_print_timings:        eval time =     228.33 ms /     6 runs   (   38.06 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =    2427.47 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1532.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2037.54 ms /   390 tokens (    5.22 ms per token,   191.41 tokens per second)\n",
            "llama_print_timings:        eval time =     232.54 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2420.56 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1482.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2341.24 ms /   444 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     232.61 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2843.01 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.17 ms /   365 tokens (    5.19 ms per token,   192.49 tokens per second)\n",
            "llama_print_timings:        eval time =     226.85 ms /     6 runs   (   37.81 ms per token,    26.45 tokens per second)\n",
            "llama_print_timings:       total time =    2252.44 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1648.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.27 ms /   479 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     234.98 ms /     6 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2891.68 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1688.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1483.01 ms /   275 tokens (    5.39 ms per token,   185.43 tokens per second)\n",
            "llama_print_timings:        eval time =     233.22 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    1821.95 ms /   281 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1865.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2498.30 ms /   479 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =     232.22 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2893.26 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.68 ms /     7 runs   (    0.67 ms per token,  1496.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2214.37 ms /   424 tokens (    5.22 ms per token,   191.48 tokens per second)\n",
            "llama_print_timings:        eval time =     272.16 ms /     7 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2742.38 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2858.80 ms /   544 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =     272.46 ms /     7 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    3330.33 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     7 runs   (    0.47 ms per token,  2116.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2754.30 ms /   525 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     234.62 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3164.61 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     7 runs   (    0.47 ms per token,  2147.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1447.82 ms /   269 tokens (    5.38 ms per token,   185.80 tokens per second)\n",
            "llama_print_timings:        eval time =     232.11 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    1778.01 ms /   275 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     7 runs   (    0.63 ms per token,  1593.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2108.14 ms /   407 tokens (    5.18 ms per token,   193.06 tokens per second)\n",
            "llama_print_timings:        eval time =     232.99 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2497.30 ms /   413 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.99 ms /     7 runs   (    0.71 ms per token,  1403.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2085.03 ms /   399 tokens (    5.23 ms per token,   191.36 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2563.14 ms /   405 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1624.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     485.73 ms /    93 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
            "llama_print_timings:        eval time =     224.34 ms /     6 runs   (   37.39 ms per token,    26.75 tokens per second)\n",
            "llama_print_timings:       total time =     782.22 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1803.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2625.27 ms /   503 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =     231.99 ms /     6 runs   (   38.66 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    3018.41 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1773.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2190.50 ms /   420 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =     231.95 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2560.95 ms /   426 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1826.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2407.27 ms /   462 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
            "llama_print_timings:        eval time =     232.63 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2796.60 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     6 runs   (    0.63 ms per token,  1578.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3121.38 ms /   588 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =     195.58 ms /     5 runs   (   39.12 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3605.48 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2721.31 ms /   515 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
            "llama_print_timings:        eval time =     233.25 ms /     6 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3181.55 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1875.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3380.43 ms /   640 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =     275.71 ms /     7 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3882.79 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.88 ms /     6 runs   (    0.48 ms per token,  2085.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3066.43 ms /   579 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =     195.65 ms /     5 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3455.47 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1671.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2682.82 ms /   507 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
            "llama_print_timings:        eval time =     234.33 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3198.16 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1760.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3290.05 ms /   621 tokens (    5.30 ms per token,   188.75 tokens per second)\n",
            "llama_print_timings:        eval time =     234.94 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3745.92 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1722.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3961.14 ms /   741 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
            "llama_print_timings:        eval time =     235.70 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    4437.29 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.78 ms /     7 runs   (    0.68 ms per token,  1465.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3299.47 ms /   621 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =     238.17 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3803.67 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1683.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1656.37 ms /   319 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =     192.70 ms /     5 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2034.82 ms /   324 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1808.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     225.71 ms /     6 runs   (   37.62 ms per token,    26.58 tokens per second)\n",
            "llama_print_timings:       total time =     247.93 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2497.69 ms /   478 tokens (    5.23 ms per token,   191.38 tokens per second)\n",
            "llama_print_timings:        eval time =     231.60 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2893.20 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2149.63 ms /   412 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     232.14 ms /     6 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2522.96 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2237.67 ms /   432 tokens (    5.18 ms per token,   193.06 tokens per second)\n",
            "llama_print_timings:        eval time =     232.01 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2614.90 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.97 ms /     7 runs   (    0.71 ms per token,  1409.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.57 ms /   443 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =     232.18 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2775.44 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.58 ms /     7 runs   (    0.51 ms per token,  1953.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2819.21 ms /   536 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =     271.77 ms /     7 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3331.91 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4790.05 ms /   888 tokens (    5.39 ms per token,   185.38 tokens per second)\n",
            "llama_print_timings:        eval time =     200.06 ms /     5 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5273.66 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1610.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2850.75 ms /   544 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =     273.59 ms /     7 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3325.91 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1707.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2561.41 ms /   488 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     233.28 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3066.13 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1866.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2197.85 ms /   423 tokens (    5.20 ms per token,   192.46 tokens per second)\n",
            "llama_print_timings:        eval time =     230.37 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2572.40 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1807.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2196.71 ms /   424 tokens (    5.18 ms per token,   193.02 tokens per second)\n",
            "llama_print_timings:        eval time =     228.84 ms /     6 runs   (   38.14 ms per token,    26.22 tokens per second)\n",
            "llama_print_timings:       total time =    2570.38 ms /   430 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.95 ms /   421 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
            "llama_print_timings:        eval time =     229.77 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2569.15 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.06 ms /     7 runs   (    0.72 ms per token,  1383.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2180.18 ms /   414 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =     232.69 ms /     6 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2577.10 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1667.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2300.44 ms /   439 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =     231.59 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2778.67 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1789.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.75 ms /   414 tokens (    5.21 ms per token,   191.87 tokens per second)\n",
            "llama_print_timings:        eval time =     229.07 ms /     6 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    2528.23 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1787.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2410.41 ms /   458 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =     232.97 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2803.49 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1891.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2715.25 ms /   520 tokens (    5.22 ms per token,   191.51 tokens per second)\n",
            "llama_print_timings:        eval time =     234.82 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3121.66 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.53 ms /     7 runs   (    0.65 ms per token,  1544.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3524.21 ms /   659 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
            "llama_print_timings:        eval time =     236.65 ms /     6 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4081.92 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.29 ms /   442 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =     230.68 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2723.67 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2234.85 ms /   426 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =     230.49 ms /     6 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2611.44 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2061.97 ms /   394 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =     231.00 ms /     6 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2428.27 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     6 runs   (    0.64 ms per token,  1569.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3288.43 ms /   620 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =     195.48 ms /     5 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3722.82 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1934.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3613.97 ms /   676 tokens (    5.35 ms per token,   187.05 tokens per second)\n",
            "llama_print_timings:        eval time =     198.02 ms /     5 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    4104.92 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2579.08 ms /   490 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
            "llama_print_timings:        eval time =     230.61 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2968.48 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.55 ms /     7 runs   (    0.51 ms per token,  1970.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3160.72 ms /   596 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =     233.90 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3596.39 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1862.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4343.71 ms /   808 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
            "llama_print_timings:        eval time =     276.93 ms /     7 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    5018.75 ms /   815 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1802.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.10 ms /   528 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =     231.77 ms /     6 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    3173.82 ms /   534 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2152.75 ms /   416 tokens (    5.17 ms per token,   193.24 tokens per second)\n",
            "llama_print_timings:        eval time =     230.14 ms /     6 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    2523.12 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1793.73 ms /   344 tokens (    5.21 ms per token,   191.78 tokens per second)\n",
            "llama_print_timings:        eval time =     269.95 ms /     7 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2189.78 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1508.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.67 ms /   423 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =     232.22 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2615.30 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2519.67 ms /   479 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =     231.90 ms /     6 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    3010.42 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1761.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2206.24 ms /   418 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =     231.82 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2593.72 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.58 ms per token,  1738.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5398.81 ms /   987 tokens (    5.47 ms per token,   182.82 tokens per second)\n",
            "llama_print_timings:        eval time =     201.66 ms /     5 runs   (   40.33 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    5914.29 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1675.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3403.20 ms /   637 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
            "llama_print_timings:        eval time =     236.75 ms /     6 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3983.48 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1805.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2766.28 ms /   525 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =     235.86 ms /     6 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3192.06 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1818.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2564.19 ms /   486 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =     234.47 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2961.29 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1805.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2197.16 ms /   419 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =     232.47 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2584.14 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1475.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2073.46 ms /   395 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =     233.05 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2506.10 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2739.99 ms /   517 tokens (    5.30 ms per token,   188.69 tokens per second)\n",
            "llama_print_timings:        eval time =     233.21 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3239.63 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1869.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2815.03 ms /   535 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =     233.46 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3245.02 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2723.78 ms /   520 tokens (    5.24 ms per token,   190.91 tokens per second)\n",
            "llama_print_timings:        eval time =     232.56 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3151.69 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1486.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2566.14 ms /   482 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =     234.56 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3010.13 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2345.99 ms /   445 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =     232.97 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2846.86 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1640.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2024.35 ms /   387 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     228.88 ms /     6 runs   (   38.15 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    2400.68 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1776.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2458.79 ms /   469 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =     230.47 ms /     6 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2866.65 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.82 ms /   525 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =     235.83 ms /     6 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3173.41 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.88 ms /     7 runs   (    0.70 ms per token,  1434.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2572.01 ms /   488 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =     234.59 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3044.97 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1842.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2949.75 ms /   560 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =     232.51 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3429.82 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1861.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1809.61 ms /   350 tokens (    5.17 ms per token,   193.41 tokens per second)\n",
            "llama_print_timings:        eval time =     228.99 ms /     6 runs   (   38.16 ms per token,    26.20 tokens per second)\n",
            "llama_print_timings:       total time =    2161.89 ms /   356 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1792.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1514.92 ms /   296 tokens (    5.12 ms per token,   195.39 tokens per second)\n",
            "llama_print_timings:        eval time =     231.62 ms /     6 runs   (   38.60 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    1853.16 ms /   302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1794.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1596.47 ms /   312 tokens (    5.12 ms per token,   195.43 tokens per second)\n",
            "llama_print_timings:        eval time =     232.82 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    1944.01 ms /   318 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1539.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1595.99 ms /   310 tokens (    5.15 ms per token,   194.24 tokens per second)\n",
            "llama_print_timings:        eval time =     231.86 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    1944.34 ms /   316 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.76 ms /     7 runs   (    0.97 ms per token,  1035.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1146.55 ms /   224 tokens (    5.12 ms per token,   195.37 tokens per second)\n",
            "llama_print_timings:        eval time =     267.68 ms /     7 runs   (   38.24 ms per token,    26.15 tokens per second)\n",
            "llama_print_timings:       total time =    1575.18 ms /   231 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1807.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2295.50 ms /   440 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =     231.81 ms /     6 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2741.93 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2367.29 ms /   451 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
            "llama_print_timings:        eval time =     232.88 ms /     6 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2774.34 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1979.85 ms /   380 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
            "llama_print_timings:        eval time =     229.00 ms /     6 runs   (   38.17 ms per token,    26.20 tokens per second)\n",
            "llama_print_timings:       total time =    2347.03 ms /   386 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1878.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2758.66 ms /   522 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =     234.30 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3173.05 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1513.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1905.63 ms /   366 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
            "llama_print_timings:        eval time =     231.00 ms /     6 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2347.51 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1844.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1565.28 ms /   300 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     227.34 ms /     6 runs   (   37.89 ms per token,    26.39 tokens per second)\n",
            "llama_print_timings:       total time =    1971.62 ms /   306 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1750.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1894.28 ms /   366 tokens (    5.18 ms per token,   193.21 tokens per second)\n",
            "llama_print_timings:        eval time =     229.60 ms /     6 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2260.43 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1765.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.64 ms /   423 tokens (    5.19 ms per token,   192.65 tokens per second)\n",
            "llama_print_timings:        eval time =     232.07 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2583.44 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1922.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2758.49 ms /   522 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     234.30 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3181.21 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1551.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2564.75 ms /   484 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
            "llama_print_timings:        eval time =     233.69 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3035.36 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3475.50 ms /   654 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =     233.14 ms /     6 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3981.52 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1926.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2188.98 ms /   418 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =     228.58 ms /     6 runs   (   38.10 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    2562.83 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1798.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     703.52 ms /   135 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
            "llama_print_timings:        eval time =     230.71 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    1002.07 ms /   141 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1795.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2938.77 ms /   559 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =     233.22 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3363.59 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1449.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1824.02 ms /   349 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =     231.17 ms /     6 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2250.56 ms /   355 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1903.79 ms /   363 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =     228.72 ms /     6 runs   (   38.12 ms per token,    26.23 tokens per second)\n",
            "llama_print_timings:       total time =    2331.38 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2802.85 ms /   531 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =     231.13 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    3211.68 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1703.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2715.00 ms /   517 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =     233.86 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3123.29 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.87 ms /     7 runs   (    0.70 ms per token,  1436.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.58 ms /   520 tokens (    5.23 ms per token,   191.21 tokens per second)\n",
            "llama_print_timings:        eval time =     274.17 ms /     7 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3190.15 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1449.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1568.82 ms /   304 tokens (    5.16 ms per token,   193.78 tokens per second)\n",
            "llama_print_timings:        eval time =     230.08 ms /     6 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    1997.80 ms /   310 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2721.20 ms /   516 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
            "llama_print_timings:        eval time =     231.97 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    3181.00 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1852.92 ms /   359 tokens (    5.16 ms per token,   193.75 tokens per second)\n",
            "llama_print_timings:        eval time =     229.17 ms /     6 runs   (   38.19 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    2218.41 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1364.70 ms /   259 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =     228.53 ms /     6 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    1694.93 ms /   265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.50 ms /     7 runs   (    0.64 ms per token,  1556.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4887.53 ms /   902 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
            "llama_print_timings:        eval time =     240.40 ms /     6 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    5488.23 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1883.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3121.76 ms /   588 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =     231.88 ms /     6 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    3614.45 ms /   594 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2625.86 ms /   499 tokens (    5.26 ms per token,   190.03 tokens per second)\n",
            "llama_print_timings:        eval time =     233.88 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3034.75 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     952.71 ms /   184 tokens (    5.18 ms per token,   193.13 tokens per second)\n",
            "llama_print_timings:        eval time =     230.82 ms /     6 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    1256.15 ms /   190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1660.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2109.80 ms /   408 tokens (    5.17 ms per token,   193.38 tokens per second)\n",
            "llama_print_timings:        eval time =     230.49 ms /     6 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2484.43 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.06 ms /     7 runs   (    0.72 ms per token,  1384.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.96 ms /   467 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
            "llama_print_timings:        eval time =     232.20 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2931.77 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2940.25 ms /   556 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
            "llama_print_timings:        eval time =     234.54 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3411.51 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1830.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2892.72 ms /   551 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =     233.13 ms /     6 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3314.06 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.71 ms /     4 runs   (    0.68 ms per token,  1474.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5392.88 ms /   986 tokens (    5.47 ms per token,   182.83 tokens per second)\n",
            "llama_print_timings:        eval time =     120.45 ms /     3 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5888.14 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1551.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2775.05 ms /   526 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     233.29 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3257.86 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /     6 runs   (    0.52 ms per token,  1929.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3647.16 ms /   687 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =     197.78 ms /     5 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    4068.60 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     6 runs   (    0.62 ms per token,  1610.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5348.24 ms /   979 tokens (    5.46 ms per token,   183.05 tokens per second)\n",
            "llama_print_timings:        eval time =     201.16 ms /     5 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5912.91 ms /   984 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1783.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2774.17 ms /   527 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =     230.79 ms /     6 runs   (   38.47 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    3247.68 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.06 ms /     6 runs   (    0.51 ms per token,  1961.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3692.82 ms /   691 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =     195.17 ms /     5 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4115.55 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     173.85 ms /    28 tokens (    6.21 ms per token,   161.05 tokens per second)\n",
            "llama_print_timings:        eval time =     235.85 ms /     6 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =     448.19 ms /    34 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /     7 runs   (    0.63 ms per token,  1581.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4333.40 ms /   806 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
            "llama_print_timings:        eval time =     239.11 ms /     6 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    4879.40 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3441.46 ms /   648 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =     274.88 ms /     7 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    4002.52 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1949.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4973.33 ms /   915 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
            "llama_print_timings:        eval time =     199.23 ms /     5 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    5470.25 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.77 ms /     7 runs   (    0.68 ms per token,  1466.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3333.42 ms /   626 tokens (    5.32 ms per token,   187.80 tokens per second)\n",
            "llama_print_timings:        eval time =     235.60 ms /     6 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3829.90 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1805.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4986.06 ms /   917 tokens (    5.44 ms per token,   183.91 tokens per second)\n",
            "llama_print_timings:        eval time =     199.51 ms /     5 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5556.67 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3293.53 ms /   623 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =     234.62 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3740.24 ms /   629 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1564.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2541.40 ms /   486 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =     235.00 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2957.16 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.78 ms /     7 runs   (    0.68 ms per token,  1465.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1908.30 ms /   365 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =     230.65 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2362.61 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.52 ms per token,  1941.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.70 ms /   437 tokens (    5.23 ms per token,   191.11 tokens per second)\n",
            "llama_print_timings:        eval time =     230.65 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2684.04 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1945.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3693.35 ms /   691 tokens (    5.34 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =     194.86 ms /     5 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4113.41 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2020.86 ms /   388 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =     229.54 ms /     6 runs   (   38.26 ms per token,    26.14 tokens per second)\n",
            "llama_print_timings:       total time =    2382.71 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1484.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1814.37 ms /   352 tokens (    5.15 ms per token,   194.01 tokens per second)\n",
            "llama_print_timings:        eval time =     231.24 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2209.82 ms /   358 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1793.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2169.22 ms /   416 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
            "llama_print_timings:        eval time =     271.03 ms /     7 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2686.85 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1757.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2934.69 ms /   557 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =     231.84 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    3348.74 ms /   563 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2538.61 ms /   482 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =     232.51 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2932.57 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1818.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1429.25 ms /   276 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
            "llama_print_timings:        eval time =     226.60 ms /     6 runs   (   37.77 ms per token,    26.48 tokens per second)\n",
            "llama_print_timings:       total time =    1759.65 ms /   282 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     124.13 ms /    24 tokens (    5.17 ms per token,   193.34 tokens per second)\n",
            "llama_print_timings:        eval time =     265.71 ms /     7 runs   (   37.96 ms per token,    26.34 tokens per second)\n",
            "llama_print_timings:       total time =     420.92 ms /    31 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1504.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1390.41 ms /   268 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =     229.29 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    1744.29 ms /   274 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1568.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1354.19 ms /   259 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
            "llama_print_timings:        eval time =     229.50 ms /     6 runs   (   38.25 ms per token,    26.14 tokens per second)\n",
            "llama_print_timings:       total time =    1752.02 ms /   265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1794.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2466.20 ms /   472 tokens (    5.22 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =     273.67 ms /     7 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2937.24 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2541.45 ms /   486 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =     235.68 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2937.01 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.43 ms /    19 tokens (    6.60 ms per token,   151.48 tokens per second)\n",
            "llama_print_timings:        eval time =     231.30 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =     387.15 ms /    25 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1906.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2409.02 ms /   459 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =     233.90 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2793.30 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     7 runs   (    0.70 ms per token,  1425.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1680.01 ms /   325 tokens (    5.17 ms per token,   193.45 tokens per second)\n",
            "llama_print_timings:        eval time =     235.29 ms /     6 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2046.86 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1477.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2469.86 ms /   466 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =     232.50 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2987.44 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1222.05 ms /   238 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
            "llama_print_timings:        eval time =     224.95 ms /     6 runs   (   37.49 ms per token,    26.67 tokens per second)\n",
            "llama_print_timings:       total time =    1538.71 ms /   244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     806.16 ms /   155 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =     237.51 ms /     6 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    1121.52 ms /   161 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1947.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2718.23 ms /   519 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
            "llama_print_timings:        eval time =     231.15 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    3116.43 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     7 runs   (    0.49 ms per token,  2048.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2806.09 ms /   530 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =     233.84 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3212.56 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.03 ms /     7 runs   (    0.72 ms per token,  1391.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.11 ms /   432 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =     232.90 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2713.67 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.25 ms /   411 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
            "llama_print_timings:        eval time =     230.59 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2586.11 ms /   417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1880.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3828.40 ms /   719 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =     195.38 ms /     5 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4245.44 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1723.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2111.12 ms /   408 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
            "llama_print_timings:        eval time =     270.42 ms /     7 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2522.03 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1484.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.16 ms /   432 tokens (    5.19 ms per token,   192.67 tokens per second)\n",
            "llama_print_timings:        eval time =     232.24 ms /     6 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2652.52 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1493.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1608.53 ms /   307 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =     229.94 ms /     6 runs   (   38.32 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2039.81 ms /   313 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1906.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.98 ms /   517 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =     234.48 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3148.01 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1866.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.95 ms /   464 tokens (    5.20 ms per token,   192.22 tokens per second)\n",
            "llama_print_timings:        eval time =     271.06 ms /     7 runs   (   38.72 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2846.30 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1811.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2583.91 ms /   490 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     233.66 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2998.80 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.03 ms /     7 runs   (    0.72 ms per token,  1391.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.03 ms /   517 tokens (    5.27 ms per token,   189.65 tokens per second)\n",
            "llama_print_timings:        eval time =     233.54 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    3210.39 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.97 ms /     6 runs   (    0.49 ms per token,  2022.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3529.06 ms /   664 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =     233.97 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4041.61 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1842.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3380.36 ms /   637 tokens (    5.31 ms per token,   188.44 tokens per second)\n",
            "llama_print_timings:        eval time =     194.46 ms /     5 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    3781.28 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.08 ms /   472 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =     270.82 ms /     7 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2894.90 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1565.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1779.44 ms /   344 tokens (    5.17 ms per token,   193.32 tokens per second)\n",
            "llama_print_timings:        eval time =     230.44 ms /     6 runs   (   38.41 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2191.44 ms /   350 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1512.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     208.46 ms /    36 tokens (    5.79 ms per token,   172.70 tokens per second)\n",
            "llama_print_timings:        eval time =     230.18 ms /     6 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =     495.99 ms /    42 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2900.75 ms /   548 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =     231.42 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    3364.03 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1863.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3693.90 ms /   696 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =     195.38 ms /     5 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4110.34 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2282.09 ms /   440 tokens (    5.19 ms per token,   192.81 tokens per second)\n",
            "llama_print_timings:        eval time =     232.07 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2663.06 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.07 ms /     7 runs   (    0.72 ms per token,  1379.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2163.92 ms /   416 tokens (    5.20 ms per token,   192.24 tokens per second)\n",
            "llama_print_timings:        eval time =     270.10 ms /     7 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2643.10 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1916.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2901.66 ms /   547 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =     231.51 ms /     6 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    3370.31 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.62 ms /    13 runs   (    0.51 ms per token,  1962.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3965.49 ms /   740 tokens (    5.36 ms per token,   186.61 tokens per second)\n",
            "llama_print_timings:        eval time =     474.81 ms /    12 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    4706.12 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1431.18 ms /   280 tokens (    5.11 ms per token,   195.64 tokens per second)\n",
            "llama_print_timings:        eval time =     266.06 ms /     7 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
            "llama_print_timings:       total time =    1802.25 ms /   287 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     7 runs   (    0.71 ms per token,  1401.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2503.84 ms /   478 tokens (    5.24 ms per token,   190.91 tokens per second)\n",
            "llama_print_timings:        eval time =     236.31 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2946.84 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.38 ms /   435 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =     232.88 ms /     6 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2753.11 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1860.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4192.44 ms /   778 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =     196.03 ms /     5 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    4642.13 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4792.27 ms /   886 tokens (    5.41 ms per token,   184.88 tokens per second)\n",
            "llama_print_timings:        eval time =     199.65 ms /     5 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5301.76 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1920.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4851.04 ms /   895 tokens (    5.42 ms per token,   184.50 tokens per second)\n",
            "llama_print_timings:        eval time =     201.40 ms /     5 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5424.39 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1819.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3784.95 ms /   712 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
            "llama_print_timings:        eval time =     236.68 ms /     6 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4250.65 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     7 runs   (    0.70 ms per token,  1425.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2368.33 ms /   452 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =     233.50 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2768.29 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.04 ms /     6 runs   (    0.51 ms per token,  1971.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4992.52 ms /   920 tokens (    5.43 ms per token,   184.28 tokens per second)\n",
            "llama_print_timings:        eval time =     199.04 ms /     5 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    5589.97 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2757.83 ms /   523 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     232.38 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3163.45 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4610.85 ms /   856 tokens (    5.39 ms per token,   185.65 tokens per second)\n",
            "llama_print_timings:        eval time =     200.15 ms /     5 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    5113.45 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3393.98 ms /   638 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
            "llama_print_timings:        eval time =     194.69 ms /     5 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3890.84 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     7 runs   (    0.50 ms per token,  1985.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4651.65 ms /   864 tokens (    5.38 ms per token,   185.74 tokens per second)\n",
            "llama_print_timings:        eval time =     279.33 ms /     7 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5208.74 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.44 ms /     7 runs   (    0.78 ms per token,  1287.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4983.04 ms /   920 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
            "llama_print_timings:        eval time =     240.09 ms /     6 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5620.34 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.98 ms /     6 runs   (    0.50 ms per token,  2016.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5399.36 ms /   987 tokens (    5.47 ms per token,   182.80 tokens per second)\n",
            "llama_print_timings:        eval time =     200.05 ms /     5 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5927.76 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     6 runs   (    0.64 ms per token,  1574.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5488.74 ms /  1002 tokens (    5.48 ms per token,   182.56 tokens per second)\n",
            "llama_print_timings:        eval time =     202.59 ms /     5 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    6061.70 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1885.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4197.08 ms /   780 tokens (    5.38 ms per token,   185.84 tokens per second)\n",
            "llama_print_timings:        eval time =     196.25 ms /     5 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    4699.84 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1707.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4278.01 ms /   795 tokens (    5.38 ms per token,   185.83 tokens per second)\n",
            "llama_print_timings:        eval time =     238.21 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4769.81 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      61.76 ms /   110 runs   (    0.56 ms per token,  1781.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5980.93 ms /  1083 tokens (    5.52 ms per token,   181.08 tokens per second)\n",
            "llama_print_timings:        eval time =    4434.43 ms /   109 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =   11236.79 ms /  1192 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2103.66 ms /   402 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =     228.27 ms /     6 runs   (   38.05 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =    2477.73 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      86.29 ms /   151 runs   (    0.57 ms per token,  1749.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5358.40 ms /   979 tokens (    5.47 ms per token,   182.70 tokens per second)\n",
            "llama_print_timings:        eval time =    6056.99 ms /   150 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   12355.73 ms /  1129 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     6 runs   (    0.65 ms per token,  1545.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4512.71 ms /   835 tokens (    5.40 ms per token,   185.03 tokens per second)\n",
            "llama_print_timings:        eval time =     199.31 ms /     5 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    5076.90 ms /   840 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1892.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4281.20 ms /   795 tokens (    5.39 ms per token,   185.70 tokens per second)\n",
            "llama_print_timings:        eval time =     196.71 ms /     5 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    4759.83 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1795.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2625.21 ms /   499 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =     232.06 ms /     6 runs   (   38.68 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    3024.70 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2147.63 ms /   416 tokens (    5.16 ms per token,   193.70 tokens per second)\n",
            "llama_print_timings:        eval time =     228.03 ms /     6 runs   (   38.00 ms per token,    26.31 tokens per second)\n",
            "llama_print_timings:       total time =    2504.77 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      47.73 ms /    85 runs   (    0.56 ms per token,  1780.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5313.61 ms /   975 tokens (    5.45 ms per token,   183.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3384.18 ms /    84 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    9354.34 ms /  1059 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2666.30 ms /   507 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
            "llama_print_timings:        eval time =     235.40 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3052.16 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.85 ms /     7 runs   (    0.69 ms per token,  1442.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2379.12 ms /   454 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =     234.49 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2814.47 ms /   460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1858.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1650.38 ms /   316 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
            "llama_print_timings:        eval time =     228.27 ms /     6 runs   (   38.04 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =    2045.02 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1863.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2723.46 ms /   518 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
            "llama_print_timings:        eval time =     232.44 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3119.77 ms /   524 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.35 ms /   418 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
            "llama_print_timings:        eval time =     230.79 ms /     6 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2558.37 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1836.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3257.09 ms /   612 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
            "llama_print_timings:        eval time =     198.51 ms /     5 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3634.01 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.20 ms /     7 runs   (    0.74 ms per token,  1345.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2568.06 ms /   488 tokens (    5.26 ms per token,   190.03 tokens per second)\n",
            "llama_print_timings:        eval time =     275.55 ms /     7 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3104.81 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.82 ms /     6 runs   (    0.47 ms per token,  2125.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3911.86 ms /   723 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =     196.13 ms /     5 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    4341.12 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1693.48 ms /   328 tokens (    5.16 ms per token,   193.68 tokens per second)\n",
            "llama_print_timings:        eval time =     273.93 ms /     7 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2076.19 ms /   335 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4635.81 ms /   850 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
            "llama_print_timings:        eval time =     201.19 ms /     5 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5125.08 ms /   855 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     7 runs   (    0.51 ms per token,  1959.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2657.34 ms /   502 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =     236.63 ms /     6 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3125.64 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2165.57 ms /   412 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
            "llama_print_timings:        eval time =     232.22 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2530.42 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1873.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1694.57 ms /   327 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
            "llama_print_timings:        eval time =     236.85 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2038.25 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     6 runs   (    0.70 ms per token,  1436.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5352.40 ms /   975 tokens (    5.49 ms per token,   182.16 tokens per second)\n",
            "llama_print_timings:        eval time =     202.92 ms /     5 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    5895.14 ms /   980 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1863.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5302.59 ms /   965 tokens (    5.49 ms per token,   181.99 tokens per second)\n",
            "llama_print_timings:        eval time =     244.05 ms /     6 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    5884.22 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1904.99 ms /   363 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =     228.43 ms /     6 runs   (   38.07 ms per token,    26.27 tokens per second)\n",
            "llama_print_timings:       total time =    2251.86 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1825.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1451.57 ms /   266 tokens (    5.46 ms per token,   183.25 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    1784.73 ms /   272 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.73 ms /     7 runs   (    0.68 ms per token,  1478.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3000.84 ms /   564 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
            "llama_print_timings:        eval time =     236.46 ms /     6 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3479.70 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.25 ms /   501 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =     235.62 ms /     6 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3105.09 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.36 ms /    20 tokens (    6.37 ms per token,   157.03 tokens per second)\n",
            "llama_print_timings:        eval time =     234.34 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =     394.27 ms /    26 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1683.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2707.67 ms /   507 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =     196.24 ms /     5 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3058.59 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1857.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4163.28 ms /   776 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =     239.60 ms /     6 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    4635.42 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.77 ms /    11 runs   (    0.52 ms per token,  1907.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4277.82 ms /   792 tokens (    5.40 ms per token,   185.14 tokens per second)\n",
            "llama_print_timings:        eval time =     439.46 ms /    11 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    5096.49 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's dividend history and how sustainable are the dividend payouts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1824.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     177.52 ms /    29 tokens (    6.12 ms per token,   163.36 tokens per second)\n",
            "llama_print_timings:        eval time =     238.20 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =     448.69 ms /    35 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1839.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3978.04 ms /   743 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
            "llama_print_timings:        eval time =     196.06 ms /     5 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    4398.90 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     6 runs   (    0.65 ms per token,  1528.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3614.39 ms /   677 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
            "llama_print_timings:        eval time =     198.02 ms /     5 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    4034.25 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2563.87 ms /   483 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     231.13 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    3036.36 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.69 ms /   444 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =     231.63 ms /     6 runs   (   38.60 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2703.61 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2510.22 ms /   480 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
            "llama_print_timings:        eval time =     273.68 ms /     7 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2949.08 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.61 ms /   520 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =     276.77 ms /     7 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3158.35 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1879.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4824.38 ms /   887 tokens (    5.44 ms per token,   183.86 tokens per second)\n",
            "llama_print_timings:        eval time =     200.37 ms /     5 runs   (   40.07 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    5399.98 ms /   892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1889.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3849.11 ms /   719 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =     198.46 ms /     5 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4261.32 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1505.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3896.11 ms /   723 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =     237.94 ms /     6 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4356.80 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1509.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1658.91 ms /   320 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
            "llama_print_timings:        eval time =     232.50 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2076.03 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1760.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3860.42 ms /   719 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =     238.65 ms /     6 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    4354.20 ms /   725 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1689.47 ms /   325 tokens (    5.20 ms per token,   192.37 tokens per second)\n",
            "llama_print_timings:        eval time =     231.66 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2027.97 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     6 runs   (    0.63 ms per token,  1588.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4447.19 ms /   824 tokens (    5.40 ms per token,   185.29 tokens per second)\n",
            "llama_print_timings:        eval time =     242.12 ms /     6 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    4937.65 ms /   830 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.66 ms /     7 runs   (    0.67 ms per token,  1501.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2128.24 ms /   405 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =     233.04 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2590.97 ms /   411 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.73 ms /     7 runs   (    0.68 ms per token,  1478.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     270.07 ms /     7 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =     304.52 ms /     7 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1611.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1987.91 ms /   378 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
            "llama_print_timings:        eval time =     232.63 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2356.17 ms /   384 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     725.49 ms /   135 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
            "llama_print_timings:        eval time =     234.77 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    1021.08 ms /   141 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.03 ms /     6 runs   (    0.51 ms per token,  1979.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4166.65 ms /   776 tokens (    5.37 ms per token,   186.24 tokens per second)\n",
            "llama_print_timings:        eval time =     237.57 ms /     6 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4633.87 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     6 runs   (    0.73 ms per token,  1362.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3317.12 ms /   605 tokens (    5.48 ms per token,   182.39 tokens per second)\n",
            "llama_print_timings:        eval time =     198.74 ms /     5 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    3777.24 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1843.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2569.58 ms /   486 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
            "llama_print_timings:        eval time =     232.89 ms /     6 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3014.36 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2379.17 ms /   453 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     231.69 ms /     6 runs   (   38.62 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2751.70 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2549.37 ms /   483 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =     232.66 ms /     6 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2929.74 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1507.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2471.31 ms /   472 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =     273.92 ms /     7 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2920.02 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1475.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2178.27 ms /   415 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     233.42 ms /     6 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2652.90 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.04 ms /     6 runs   (    0.51 ms per token,  1973.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5944.42 ms /  1074 tokens (    5.53 ms per token,   180.67 tokens per second)\n",
            "llama_print_timings:        eval time =     203.99 ms /     5 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    6452.31 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     6 runs   (    0.61 ms per token,  1642.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5791.39 ms /  1044 tokens (    5.55 ms per token,   180.27 tokens per second)\n",
            "llama_print_timings:        eval time =     203.58 ms /     5 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    6410.91 ms /  1049 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     6 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3668.86 ms /   687 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =     197.32 ms /     5 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    4076.65 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.55 ms per token,  1833.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3711.75 ms /   696 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =     200.59 ms /     5 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    4115.38 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.27 ms /     7 runs   (    0.75 ms per token,  1328.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2293.24 ms /   435 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =     232.76 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2700.59 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.96 ms /     7 runs   (    0.99 ms per token,  1006.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2358.72 ms /   446 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =     235.80 ms /     6 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    2887.98 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1781.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2645.12 ms /   504 tokens (    5.25 ms per token,   190.54 tokens per second)\n",
            "llama_print_timings:        eval time =     275.80 ms /     7 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3091.52 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1723.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2593.58 ms /   494 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =     235.15 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2981.93 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1776.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2860.91 ms /   541 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
            "llama_print_timings:        eval time =     233.78 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3260.43 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.88 ms /     7 runs   (    0.70 ms per token,  1433.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2650.97 ms /   502 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =     236.27 ms /     6 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3152.29 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.55 ms per token,  1803.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3946.18 ms /   736 tokens (    5.36 ms per token,   186.51 tokens per second)\n",
            "llama_print_timings:        eval time =     239.84 ms /     6 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    4439.81 ms /   742 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3892.48 ms /   727 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =     197.03 ms /     5 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    4305.06 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.79 ms /     7 runs   (    0.68 ms per token,  1462.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2292.87 ms /   439 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     232.72 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2690.72 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.26 ms /     7 runs   (    0.61 ms per token,  1644.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2401.55 ms /   450 tokens (    5.34 ms per token,   187.38 tokens per second)\n",
            "llama_print_timings:        eval time =     230.67 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2886.48 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2205.35 ms /   424 tokens (    5.20 ms per token,   192.26 tokens per second)\n",
            "llama_print_timings:        eval time =     271.30 ms /     7 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2614.66 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2553.33 ms /   488 tokens (    5.23 ms per token,   191.12 tokens per second)\n",
            "llama_print_timings:        eval time =     273.39 ms /     7 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2979.45 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.44 ms /    13 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3528.11 ms /   662 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =     476.43 ms /    12 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4234.96 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     7 runs   (    0.65 ms per token,  1536.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2346.25 ms /   445 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
            "llama_print_timings:        eval time =     233.14 ms /     6 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2822.77 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1678.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2336.81 ms /   446 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =     232.51 ms /     6 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2721.90 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.47 ms /   443 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =     234.13 ms /     6 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2705.55 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2117.68 ms /   408 tokens (    5.19 ms per token,   192.66 tokens per second)\n",
            "llama_print_timings:        eval time =     270.75 ms /     7 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2523.30 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.79 ms /     7 runs   (    0.68 ms per token,  1460.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2508.84 ms /   474 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
            "llama_print_timings:        eval time =     233.59 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2921.87 ms /   480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1492.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1782.04 ms /   340 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =     231.72 ms /     6 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2210.68 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1990.58 ms /   379 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     228.56 ms /     6 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    2363.52 ms /   385 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1690.63 ms /   327 tokens (    5.17 ms per token,   193.42 tokens per second)\n",
            "llama_print_timings:        eval time =     231.39 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2030.83 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1766.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1900.52 ms /   366 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
            "llama_print_timings:        eval time =     227.99 ms /     6 runs   (   38.00 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =    2244.38 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1547.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.40 ms /   322 tokens (    5.23 ms per token,   191.05 tokens per second)\n",
            "llama_print_timings:        eval time =     232.64 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2035.69 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1246.25 ms /   239 tokens (    5.21 ms per token,   191.78 tokens per second)\n",
            "llama_print_timings:        eval time =     230.90 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    1562.52 ms /   245 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.73 ms /     7 runs   (    0.68 ms per token,  1481.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2437.68 ms /   459 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =     233.91 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2924.43 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2017.41 ms /   384 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
            "llama_print_timings:        eval time =     270.74 ms /     7 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2427.72 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1685.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2862.08 ms /   544 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =     273.48 ms /     7 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3305.40 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     7 runs   (    0.48 ms per token,  2065.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.31 ms /   562 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =     235.12 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3397.20 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1859.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.37 ms /    22 tokens (    5.84 ms per token,   171.38 tokens per second)\n",
            "llama_print_timings:        eval time =     194.34 ms /     5 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =     350.53 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.99 ms /     6 runs   (    0.83 ms per token,  1202.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3134.15 ms /   587 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
            "llama_print_timings:        eval time =     196.02 ms /     5 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3615.73 ms /   592 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1844.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3168.96 ms /   594 tokens (    5.33 ms per token,   187.44 tokens per second)\n",
            "llama_print_timings:        eval time =     235.58 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3602.44 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2638.43 ms /   503 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
            "llama_print_timings:        eval time =     232.14 ms /     6 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    3026.09 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.05 ms /     6 runs   (    0.51 ms per token,  1965.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2814.97 ms /   532 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =     197.12 ms /     5 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3173.67 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1917.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5579.18 ms /  1016 tokens (    5.49 ms per token,   182.11 tokens per second)\n",
            "llama_print_timings:        eval time =     243.69 ms /     6 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    6228.90 ms /  1022 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.82 ms /   516 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     235.04 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3121.56 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1670.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3707.26 ms /   693 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =     236.49 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    4155.93 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1931.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3537.51 ms /   660 tokens (    5.36 ms per token,   186.57 tokens per second)\n",
            "llama_print_timings:        eval time =     235.37 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    4081.47 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     7 runs   (    0.63 ms per token,  1593.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.42 ms /   437 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =     233.01 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2661.48 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1797.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2434.81 ms /   462 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =     230.67 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2817.92 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1900.37 ms /   365 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =     232.04 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2254.79 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1567.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3724.00 ms /   695 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
            "llama_print_timings:        eval time =     238.26 ms /     6 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4265.05 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2993.07 ms /   564 tokens (    5.31 ms per token,   188.44 tokens per second)\n",
            "llama_print_timings:        eval time =     232.98 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3414.98 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1808.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3123.06 ms /   587 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
            "llama_print_timings:        eval time =     233.82 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3540.64 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.69 ms /   435 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
            "llama_print_timings:        eval time =     231.99 ms /     6 runs   (   38.66 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2655.64 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.97 ms /     7 runs   (    0.71 ms per token,  1407.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1620.26 ms /   306 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =     232.41 ms /     6 runs   (   38.74 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2009.95 ms /   312 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1693.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1956.38 ms /   374 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     233.21 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2386.90 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.48 ms /     7 runs   (    0.64 ms per token,  1562.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.67 ms /   443 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =     231.83 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2707.26 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     429.03 ms /    78 tokens (    5.50 ms per token,   181.80 tokens per second)\n",
            "llama_print_timings:        eval time =     234.05 ms /     6 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =     709.08 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.98 ms /   520 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     234.40 ms /     6 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3125.71 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1817.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.89 ms /   443 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =     229.28 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2691.24 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1765.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3596.43 ms /   670 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =     199.87 ms /     5 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    4106.74 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1783.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3366.28 ms /   630 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
            "llama_print_timings:        eval time =     195.54 ms /     5 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3755.47 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.01 ms /   467 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
            "llama_print_timings:        eval time =     232.08 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2837.80 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.32 ms /   427 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
            "llama_print_timings:        eval time =     231.67 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2611.35 ms /   433 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "Total score for approach 1 and distance function ip is 0.6194968553459119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(1, 'l2')"
      ],
      "metadata": {
        "id": "Oae2_wwp3gmq",
        "outputId": "7afd1206-f5e8-4405-9e89-e8e576bbb17d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     7 runs   (    0.49 ms per token,  2042.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3548.58 ms /   659 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =     235.74 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    4100.69 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3258.13 ms /   613 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =     235.61 ms /     6 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3680.07 ms /   619 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1851.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4161.10 ms /   776 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =     197.97 ms /     5 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4575.35 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1620.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3542.76 ms /   663 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
            "llama_print_timings:        eval time =     237.04 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    4106.53 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1918.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3035.18 ms /   572 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =     234.47 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3446.02 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     7 runs   (    0.50 ms per token,  1981.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2722.64 ms /   516 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =     233.73 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3108.73 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1906.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.32 ms /   445 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =     230.86 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2695.04 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1492.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1776.11 ms /   340 tokens (    5.22 ms per token,   191.43 tokens per second)\n",
            "llama_print_timings:        eval time =     231.47 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2184.58 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.44 ms /     7 runs   (    0.49 ms per token,  2037.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3492.66 ms /   654 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =     236.84 ms /     6 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    3991.71 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1795.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2766.66 ms /   523 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =     235.38 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3156.32 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.78 ms /     6 runs   (    0.80 ms per token,  1254.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4161.42 ms /   774 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =     199.02 ms /     5 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    4597.88 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1574.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2351.03 ms /   444 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =     237.27 ms /     6 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2851.04 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1759.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2075.57 ms /   398 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =     233.58 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2441.35 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1784.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.40 ms /   422 tokens (    5.21 ms per token,   191.78 tokens per second)\n",
            "llama_print_timings:        eval time =     230.08 ms /     6 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2560.98 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     893.60 ms /   173 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
            "llama_print_timings:        eval time =     227.60 ms /     6 runs   (   37.93 ms per token,    26.36 tokens per second)\n",
            "llama_print_timings:       total time =    1188.71 ms /   179 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3478.89 ms /   651 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =     237.98 ms /     6 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    3913.15 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     7 runs   (    0.68 ms per token,  1472.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2304.98 ms /   440 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =     273.63 ms /     7 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2840.05 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1924.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3712.91 ms /   692 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
            "llama_print_timings:        eval time =     195.93 ms /     5 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4129.05 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     7 runs   (    0.50 ms per token,  1984.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2813.93 ms /   531 tokens (    5.30 ms per token,   188.70 tokens per second)\n",
            "llama_print_timings:        eval time =     233.86 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3212.65 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.66 ms /     7 runs   (    0.67 ms per token,  1502.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3258.32 ms /   614 tokens (    5.31 ms per token,   188.44 tokens per second)\n",
            "llama_print_timings:        eval time =     235.82 ms /     6 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3702.24 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1917.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4035.67 ms /   751 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
            "llama_print_timings:        eval time =     238.70 ms /     6 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    4598.65 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1748.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5939.97 ms /  1077 tokens (    5.52 ms per token,   181.31 tokens per second)\n",
            "llama_print_timings:        eval time =     201.78 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    6445.44 ms /  1082 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.49 ms /     7 runs   (    0.64 ms per token,  1558.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2073.69 ms /   397 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =     231.79 ms /     6 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2468.90 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2057.57 ms /   390 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =     231.23 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2495.58 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1703.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.41 ms /   444 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     229.84 ms /     6 runs   (   38.31 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2694.34 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1898.99 ms /   365 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =     228.78 ms /     6 runs   (   38.13 ms per token,    26.23 tokens per second)\n",
            "llama_print_timings:       total time =    2242.77 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2505.99 ms /   479 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =     236.59 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    2890.92 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1489.48 ms /   275 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
            "llama_print_timings:        eval time =     231.70 ms /     6 runs   (   38.62 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    1818.38 ms /   281 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1567.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2520.69 ms /   479 tokens (    5.26 ms per token,   190.03 tokens per second)\n",
            "llama_print_timings:        eval time =     234.55 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3022.87 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2211.20 ms /   424 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =     270.07 ms /     7 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2629.64 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1790.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2861.47 ms /   544 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
            "llama_print_timings:        eval time =     272.97 ms /     7 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3301.23 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     7 runs   (    0.48 ms per token,  2066.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2768.01 ms /   525 tokens (    5.27 ms per token,   189.67 tokens per second)\n",
            "llama_print_timings:        eval time =     235.69 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3163.29 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1456.75 ms /   269 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =     237.81 ms /     6 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    1820.50 ms /   275 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1629.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2129.07 ms /   407 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =     232.92 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2584.47 ms /   413 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2076.29 ms /   399 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =     229.83 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2431.44 ms /   405 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     480.95 ms /    93 tokens (    5.17 ms per token,   193.37 tokens per second)\n",
            "llama_print_timings:        eval time =     226.88 ms /     6 runs   (   37.81 ms per token,    26.45 tokens per second)\n",
            "llama_print_timings:       total time =     752.34 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1842.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2638.12 ms /   503 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =     236.46 ms /     6 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3026.79 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1853.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.14 ms /   420 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     233.03 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2563.98 ms /   426 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1531.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2430.80 ms /   462 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
            "llama_print_timings:        eval time =     233.19 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2879.60 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3130.29 ms /   588 tokens (    5.32 ms per token,   187.84 tokens per second)\n",
            "llama_print_timings:        eval time =     194.11 ms /     5 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3546.55 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1931.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.40 ms /   515 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
            "llama_print_timings:        eval time =     234.98 ms /     6 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3121.52 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     7 runs   (    0.49 ms per token,  2050.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3392.25 ms /   640 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =     274.25 ms /     7 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3854.46 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3094.15 ms /   579 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =     196.14 ms /     5 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3561.67 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     7 runs   (    0.50 ms per token,  2016.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2681.01 ms /   507 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =     236.43 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3081.42 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1849.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3302.06 ms /   621 tokens (    5.32 ms per token,   188.06 tokens per second)\n",
            "llama_print_timings:        eval time =     236.96 ms /     6 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3726.05 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1589.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3980.59 ms /   741 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
            "llama_print_timings:        eval time =     238.25 ms /     6 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4461.10 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1832.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3316.15 ms /   621 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =     236.56 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3812.46 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1811.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1644.06 ms /   319 tokens (    5.15 ms per token,   194.03 tokens per second)\n",
            "llama_print_timings:        eval time =     195.54 ms /     5 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    1941.89 ms /   324 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     6 runs   (    0.61 ms per token,  1651.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     225.98 ms /     6 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =     246.57 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1840.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2507.70 ms /   478 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     236.02 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2888.00 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1773.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.75 ms /   412 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =     233.23 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2528.54 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1505.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2256.48 ms /   432 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =     232.70 ms /     6 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2703.31 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2341.13 ms /   443 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =     232.32 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2763.49 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     7 runs   (    0.50 ms per token,  1995.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2819.08 ms /   536 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
            "llama_print_timings:        eval time =     274.30 ms /     7 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3256.61 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     6 runs   (    0.62 ms per token,  1603.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4808.41 ms /   888 tokens (    5.41 ms per token,   184.68 tokens per second)\n",
            "llama_print_timings:        eval time =     200.44 ms /     5 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    5259.60 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1871.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2877.00 ms /   544 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =     276.64 ms /     7 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3431.75 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2552.74 ms /   488 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     234.22 ms /     6 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2938.36 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2205.54 ms /   423 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =     231.19 ms /     6 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2581.86 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1777.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2206.35 ms /   424 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =     233.04 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2581.88 ms /   430 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1612.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2207.65 ms /   421 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =     234.06 ms /     6 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2621.67 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2197.39 ms /   414 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =     235.16 ms /     6 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2650.72 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1677.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.66 ms /   439 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =     234.31 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2672.20 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1679.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2170.14 ms /   414 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     232.49 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2554.18 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1768.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2422.29 ms /   458 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =     235.91 ms /     6 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2829.62 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1542.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2742.84 ms /   520 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =     235.18 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3231.25 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1679.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3534.62 ms /   659 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
            "llama_print_timings:        eval time =     238.40 ms /     6 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4035.55 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1660.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2334.06 ms /   442 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =     234.41 ms /     6 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2728.23 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1638.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.47 ms /   426 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =     233.66 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2633.00 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1511.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2073.23 ms /   394 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     232.13 ms /     6 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2465.67 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1783.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3325.45 ms /   620 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
            "llama_print_timings:        eval time =     195.39 ms /     5 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3831.34 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1825.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3619.39 ms /   676 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =     198.25 ms /     5 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4038.21 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1772.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2592.78 ms /   490 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =     235.34 ms /     6 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3008.42 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.88 ms /     7 runs   (    0.70 ms per token,  1434.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3187.65 ms /   596 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
            "llama_print_timings:        eval time =     235.72 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3734.44 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1794.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4371.65 ms /   808 tokens (    5.41 ms per token,   184.83 tokens per second)\n",
            "llama_print_timings:        eval time =     279.52 ms /     7 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5022.53 ms /   815 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.30 ms /     7 runs   (    0.61 ms per token,  1626.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2778.95 ms /   528 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     235.08 ms /     6 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3226.49 ms /   534 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1687.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2166.26 ms /   416 tokens (    5.21 ms per token,   192.04 tokens per second)\n",
            "llama_print_timings:        eval time =     231.91 ms /     6 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2572.10 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /     7 runs   (    1.25 ms per token,   800.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1816.27 ms /   344 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =     273.56 ms /     7 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2300.87 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2217.78 ms /   423 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =     229.95 ms /     6 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2655.02 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1645.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2512.93 ms /   479 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     235.92 ms /     6 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2905.05 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2213.68 ms /   418 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =     230.60 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2597.01 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     6 runs   (    0.65 ms per token,  1533.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5429.10 ms /   987 tokens (    5.50 ms per token,   181.80 tokens per second)\n",
            "llama_print_timings:        eval time =     203.35 ms /     5 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    6054.02 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1900.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3397.67 ms /   637 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
            "llama_print_timings:        eval time =     234.17 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3866.54 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.82 ms /   525 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
            "llama_print_timings:        eval time =     235.27 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3166.76 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2568.25 ms /   486 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     234.63 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2957.50 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1477.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2213.88 ms /   419 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
            "llama_print_timings:        eval time =     233.09 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2687.89 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1687.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2087.29 ms /   395 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =     233.09 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2534.47 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1704.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2729.93 ms /   517 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =     233.67 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3149.55 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1808.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2824.28 ms /   535 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =     233.17 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3259.49 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1516.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2736.51 ms /   520 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =     237.02 ms /     6 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    3197.42 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.38 ms /     7 runs   (    0.63 ms per token,  1597.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2595.72 ms /   482 tokens (    5.39 ms per token,   185.69 tokens per second)\n",
            "llama_print_timings:        eval time =     235.62 ms /     6 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3105.22 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1768.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2336.44 ms /   445 tokens (    5.25 ms per token,   190.46 tokens per second)\n",
            "llama_print_timings:        eval time =     234.87 ms /     6 runs   (   39.15 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2731.24 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2030.91 ms /   387 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =     232.99 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2406.55 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.33 ms /     7 runs   (    0.62 ms per token,  1615.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2467.20 ms /   469 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
            "llama_print_timings:        eval time =     232.38 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2889.52 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.97 ms /     7 runs   (    0.71 ms per token,  1407.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2789.43 ms /   525 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =     236.55 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3311.28 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1631.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2590.14 ms /   488 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =     235.67 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3073.13 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1703.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2952.97 ms /   560 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     234.95 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3380.87 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1760.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1820.44 ms /   350 tokens (    5.20 ms per token,   192.26 tokens per second)\n",
            "llama_print_timings:        eval time =     233.24 ms /     6 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2200.89 ms /   356 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1522.68 ms /   296 tokens (    5.14 ms per token,   194.39 tokens per second)\n",
            "llama_print_timings:        eval time =     228.50 ms /     6 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =    1869.80 ms /   302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1491.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1613.66 ms /   312 tokens (    5.17 ms per token,   193.35 tokens per second)\n",
            "llama_print_timings:        eval time =     232.12 ms /     6 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2021.05 ms /   318 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.13 ms /     7 runs   (    0.73 ms per token,  1363.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1616.16 ms /   310 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
            "llama_print_timings:        eval time =     231.70 ms /     6 runs   (   38.62 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2048.26 ms /   316 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1146.35 ms /   224 tokens (    5.12 ms per token,   195.40 tokens per second)\n",
            "llama_print_timings:        eval time =     266.49 ms /     7 runs   (   38.07 ms per token,    26.27 tokens per second)\n",
            "llama_print_timings:       total time =    1513.48 ms /   231 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1613.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2296.78 ms /   440 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
            "llama_print_timings:        eval time =     232.38 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2700.28 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1649.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2380.38 ms /   451 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
            "llama_print_timings:        eval time =     232.84 ms /     6 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2793.35 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1990.25 ms /   380 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
            "llama_print_timings:        eval time =     231.50 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2365.27 ms /   386 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.04 ms /     7 runs   (    0.72 ms per token,  1388.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2788.71 ms /   522 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
            "llama_print_timings:        eval time =     235.20 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3357.27 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1911.82 ms /   366 tokens (    5.22 ms per token,   191.44 tokens per second)\n",
            "llama_print_timings:        eval time =     233.26 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2333.65 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1664.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1564.93 ms /   300 tokens (    5.22 ms per token,   191.70 tokens per second)\n",
            "llama_print_timings:        eval time =     229.04 ms /     6 runs   (   38.17 ms per token,    26.20 tokens per second)\n",
            "llama_print_timings:       total time =    1925.79 ms /   306 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1587.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1906.73 ms /   366 tokens (    5.21 ms per token,   191.95 tokens per second)\n",
            "llama_print_timings:        eval time =     230.71 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2298.81 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2209.36 ms /   423 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     233.15 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2618.71 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     7 runs   (    0.73 ms per token,  1372.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2786.75 ms /   522 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
            "llama_print_timings:        eval time =     235.74 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3301.94 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1625.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2586.25 ms /   484 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
            "llama_print_timings:        eval time =     234.28 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3053.52 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1678.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3486.89 ms /   654 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
            "llama_print_timings:        eval time =     238.80 ms /     6 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    3951.30 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2205.20 ms /   418 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     231.11 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2593.50 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     705.71 ms /   135 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =     234.28 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    1007.97 ms /   141 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.68 ms /     7 runs   (    0.67 ms per token,  1496.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2967.24 ms /   559 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     235.98 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3518.64 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1825.94 ms /   349 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =     233.49 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2217.68 ms /   355 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1638.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1903.85 ms /   363 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =     230.97 ms /     6 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2269.43 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1671.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2816.87 ms /   531 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =     232.42 ms /     6 runs   (   38.74 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3240.26 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.02 ms /     7 runs   (    1.00 ms per token,   997.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2727.49 ms /   517 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     239.51 ms /     6 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    3164.43 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.49 ms /     7 runs   (    0.64 ms per token,  1559.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2756.24 ms /   520 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
            "llama_print_timings:        eval time =     273.77 ms /     7 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3358.67 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1549.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1565.56 ms /   304 tokens (    5.15 ms per token,   194.18 tokens per second)\n",
            "llama_print_timings:        eval time =     229.94 ms /     6 runs   (   38.32 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    1920.56 ms /   310 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1681.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2730.16 ms /   516 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =     234.32 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3160.13 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1621.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1862.25 ms /   359 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
            "llama_print_timings:        eval time =     233.08 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2229.58 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1372.01 ms /   259 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =     230.39 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    1701.88 ms /   265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1695.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4929.20 ms /   902 tokens (    5.46 ms per token,   182.99 tokens per second)\n",
            "llama_print_timings:        eval time =     241.42 ms /     6 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5597.30 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1796.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3127.99 ms /   588 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
            "llama_print_timings:        eval time =     235.25 ms /     6 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3560.36 ms /   594 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1682.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2640.92 ms /   499 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =     235.80 ms /     6 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3046.02 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     961.64 ms /   184 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =     233.15 ms /     6 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    1271.30 ms /   190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.79 ms /     7 runs   (    0.68 ms per token,  1462.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2132.47 ms /   408 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =     233.48 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2599.51 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1631.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2473.25 ms /   467 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =     234.70 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2927.49 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1845.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2952.42 ms /   556 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
            "llama_print_timings:        eval time =     236.01 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3391.97 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2911.53 ms /   551 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
            "llama_print_timings:        eval time =     236.33 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3347.44 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.19 ms /     4 runs   (    0.55 ms per token,  1823.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5443.74 ms /   986 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
            "llama_print_timings:        eval time =     121.79 ms /     3 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    6003.23 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1663.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2776.63 ms /   526 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =     234.30 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3191.44 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3669.31 ms /   687 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
            "llama_print_timings:        eval time =     197.24 ms /     5 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4083.66 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1838.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5393.19 ms /   979 tokens (    5.51 ms per token,   181.53 tokens per second)\n",
            "llama_print_timings:        eval time =     201.93 ms /     5 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    6052.55 ms /   984 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1672.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2780.32 ms /   527 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     235.92 ms /     6 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3208.67 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3714.71 ms /   691 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
            "llama_print_timings:        eval time =     196.98 ms /     5 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    4149.84 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     176.09 ms /    28 tokens (    6.29 ms per token,   159.01 tokens per second)\n",
            "llama_print_timings:        eval time =     235.24 ms /     6 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =     447.41 ms /    34 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1795.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4371.48 ms /   806 tokens (    5.42 ms per token,   184.38 tokens per second)\n",
            "llama_print_timings:        eval time =     240.24 ms /     6 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    5025.98 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1658.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3446.26 ms /   648 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
            "llama_print_timings:        eval time =     277.98 ms /     7 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    3941.35 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     6 runs   (    0.67 ms per token,  1489.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5004.91 ms /   915 tokens (    5.47 ms per token,   182.82 tokens per second)\n",
            "llama_print_timings:        eval time =     203.33 ms /     5 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    5508.85 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.43 ms /     7 runs   (    0.63 ms per token,  1579.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3373.95 ms /   626 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
            "llama_print_timings:        eval time =     236.58 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3953.07 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     6 runs   (    0.61 ms per token,  1646.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5004.40 ms /   917 tokens (    5.46 ms per token,   183.24 tokens per second)\n",
            "llama_print_timings:        eval time =     201.80 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5514.93 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     7 runs   (    0.69 ms per token,  1458.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3315.30 ms /   623 tokens (    5.32 ms per token,   187.92 tokens per second)\n",
            "llama_print_timings:        eval time =     235.94 ms /     6 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3784.00 ms /   629 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.66 ms /     7 runs   (    0.67 ms per token,  1503.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2576.92 ms /   486 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =     234.77 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3125.72 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1905.22 ms /   365 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =     234.33 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2276.11 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1905.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2292.58 ms /   437 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     234.45 ms /     6 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2676.83 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.05 ms /     6 runs   (    0.51 ms per token,  1969.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3714.39 ms /   691 tokens (    5.38 ms per token,   186.03 tokens per second)\n",
            "llama_print_timings:        eval time =     196.96 ms /     5 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    4147.42 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     7 runs   (    0.69 ms per token,  1458.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2042.36 ms /   388 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
            "llama_print_timings:        eval time =     232.89 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2486.82 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1815.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1832.03 ms /   352 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
            "llama_print_timings:        eval time =     233.95 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2253.75 ms /   358 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1705.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2166.61 ms /   416 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =     273.37 ms /     7 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2596.97 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2953.28 ms /   557 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =     236.36 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3379.54 ms /   563 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1690.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2553.89 ms /   482 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     232.92 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2960.07 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     7 runs   (    0.69 ms per token,  1453.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1451.16 ms /   276 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =     230.40 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    1850.24 ms /   282 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.89 ms /     7 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.78 ms /    24 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     269.32 ms /     7 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =     451.44 ms /    31 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1402.28 ms /   268 tokens (    5.23 ms per token,   191.12 tokens per second)\n",
            "llama_print_timings:        eval time =     227.36 ms /     6 runs   (   37.89 ms per token,    26.39 tokens per second)\n",
            "llama_print_timings:       total time =    1799.71 ms /   274 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1859.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1352.58 ms /   259 tokens (    5.22 ms per token,   191.49 tokens per second)\n",
            "llama_print_timings:        eval time =     227.47 ms /     6 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
            "llama_print_timings:       total time =    1679.58 ms /   265 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2470.63 ms /   472 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =     273.77 ms /     7 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2913.47 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2552.33 ms /   486 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =     233.68 ms /     6 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2940.34 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1832.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     124.46 ms /    19 tokens (    6.55 ms per token,   152.66 tokens per second)\n",
            "llama_print_timings:        eval time =     233.97 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =     387.20 ms /    25 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.76 ms /     7 runs   (    0.68 ms per token,  1469.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2425.45 ms /   459 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =     237.21 ms /     6 runs   (   39.53 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2869.48 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.37 ms /     7 runs   (    0.62 ms per token,  1601.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1703.41 ms /   325 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =     229.30 ms /     6 runs   (   38.22 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2126.78 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.62 ms /   466 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     236.12 ms /     6 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2843.36 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1226.01 ms /   238 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
            "llama_print_timings:        eval time =     227.70 ms /     6 runs   (   37.95 ms per token,    26.35 tokens per second)\n",
            "llama_print_timings:       total time =    1539.48 ms /   244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1807.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     808.01 ms /   155 tokens (    5.21 ms per token,   191.83 tokens per second)\n",
            "llama_print_timings:        eval time =     235.38 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    1107.51 ms /   161 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1934.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2730.35 ms /   519 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
            "llama_print_timings:        eval time =     233.60 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    3127.35 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2829.43 ms /   530 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
            "llama_print_timings:        eval time =     235.76 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3312.49 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2259.80 ms /   432 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     235.22 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2673.75 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.74 ms /   411 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =     233.73 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2525.90 ms /   417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1699.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3848.36 ms /   719 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
            "llama_print_timings:        eval time =     199.45 ms /     5 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    4267.30 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1548.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2118.45 ms /   408 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =     271.57 ms /     7 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2564.20 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1849.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2259.30 ms /   432 tokens (    5.23 ms per token,   191.21 tokens per second)\n",
            "llama_print_timings:        eval time =     229.93 ms /     6 runs   (   38.32 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2714.72 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.41 ms /   307 tokens (    5.22 ms per token,   191.59 tokens per second)\n",
            "llama_print_timings:        eval time =     231.29 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    1944.66 ms /   313 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1906.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.12 ms /   517 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =     237.07 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    3120.39 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2419.94 ms /   464 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =     272.50 ms /     7 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2843.94 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     7 runs   (    0.69 ms per token,  1457.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2596.19 ms /   490 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =     234.88 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3050.10 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2733.22 ms /   517 tokens (    5.29 ms per token,   189.15 tokens per second)\n",
            "llama_print_timings:        eval time =     234.09 ms /     6 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3188.58 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1883.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3526.65 ms /   664 tokens (    5.31 ms per token,   188.28 tokens per second)\n",
            "llama_print_timings:        eval time =     238.53 ms /     6 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    3964.50 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1855.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3390.39 ms /   637 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =     198.41 ms /     5 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    3774.42 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1516.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2476.51 ms /   472 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =     273.70 ms /     7 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2993.01 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1780.86 ms /   344 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
            "llama_print_timings:        eval time =     233.45 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2165.54 ms /   350 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     208.38 ms /    36 tokens (    5.79 ms per token,   172.76 tokens per second)\n",
            "llama_print_timings:        eval time =     227.21 ms /     6 runs   (   37.87 ms per token,    26.41 tokens per second)\n",
            "llama_print_timings:       total time =     470.36 ms /    42 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2903.69 ms /   548 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     234.55 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3316.62 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1841.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3711.90 ms /   696 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =     199.39 ms /     5 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    4122.27 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.88 ms /     7 runs   (    0.70 ms per token,  1433.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2301.96 ms /   440 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =     232.86 ms /     6 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2754.61 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1681.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2170.46 ms /   416 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     271.97 ms /     7 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2627.92 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1916.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2901.07 ms /   547 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
            "llama_print_timings:        eval time =     234.69 ms /     6 runs   (   39.12 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3309.32 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.93 ms /    13 runs   (    0.53 ms per token,  1875.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3980.70 ms /   740 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
            "llama_print_timings:        eval time =     474.19 ms /    12 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    4691.87 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.70 ms /     7 runs   (    0.67 ms per token,  1489.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1441.45 ms /   280 tokens (    5.15 ms per token,   194.25 tokens per second)\n",
            "llama_print_timings:        eval time =     271.02 ms /     7 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    1864.95 ms /   287 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2524.76 ms /   478 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =     235.36 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2986.94 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1688.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.53 ms /   435 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =     231.06 ms /     6 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2665.38 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.54 ms per token,  1866.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4208.24 ms /   778 tokens (    5.41 ms per token,   184.88 tokens per second)\n",
            "llama_print_timings:        eval time =     199.58 ms /     5 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    4639.22 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4824.40 ms /   886 tokens (    5.45 ms per token,   183.65 tokens per second)\n",
            "llama_print_timings:        eval time =     201.19 ms /     5 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5404.67 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1853.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4861.61 ms /   895 tokens (    5.43 ms per token,   184.10 tokens per second)\n",
            "llama_print_timings:        eval time =     200.08 ms /     5 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5321.13 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     6 runs   (    0.67 ms per token,  1492.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3801.74 ms /   712 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
            "llama_print_timings:        eval time =     238.96 ms /     6 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    4262.63 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1509.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2395.56 ms /   452 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
            "llama_print_timings:        eval time =     234.60 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2899.41 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1901.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5005.03 ms /   920 tokens (    5.44 ms per token,   183.82 tokens per second)\n",
            "llama_print_timings:        eval time =     200.29 ms /     5 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    5479.17 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2772.92 ms /   523 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     233.25 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3169.68 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.02 ms /     6 runs   (    0.50 ms per token,  1990.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4642.00 ms /   856 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
            "llama_print_timings:        eval time =     199.78 ms /     5 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    5219.85 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3397.01 ms /   638 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =     195.05 ms /     5 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3782.64 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1912.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4677.15 ms /   864 tokens (    5.41 ms per token,   184.73 tokens per second)\n",
            "llama_print_timings:        eval time =     282.12 ms /     7 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5217.92 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1889.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5029.26 ms /   920 tokens (    5.47 ms per token,   182.93 tokens per second)\n",
            "llama_print_timings:        eval time =     241.16 ms /     6 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    5672.22 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1915.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5424.62 ms /   987 tokens (    5.50 ms per token,   181.95 tokens per second)\n",
            "llama_print_timings:        eval time =     201.77 ms /     5 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5907.93 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1877.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5535.99 ms /  1002 tokens (    5.52 ms per token,   181.00 tokens per second)\n",
            "llama_print_timings:        eval time =     202.41 ms /     5 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    6153.68 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1777.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4212.81 ms /   780 tokens (    5.40 ms per token,   185.15 tokens per second)\n",
            "llama_print_timings:        eval time =     199.53 ms /     5 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    4636.56 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.95 ms /     7 runs   (    0.71 ms per token,  1415.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4303.95 ms /   795 tokens (    5.41 ms per token,   184.71 tokens per second)\n",
            "llama_print_timings:        eval time =     242.16 ms /     6 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    4800.49 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      62.74 ms /   110 runs   (    0.57 ms per token,  1753.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6024.55 ms /  1083 tokens (    5.56 ms per token,   179.76 tokens per second)\n",
            "llama_print_timings:        eval time =    4472.56 ms /   109 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =   11289.22 ms /  1192 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1536.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2118.26 ms /   402 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =     232.72 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2526.33 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      87.35 ms /   151 runs   (    0.58 ms per token,  1728.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5390.53 ms /   979 tokens (    5.51 ms per token,   181.61 tokens per second)\n",
            "llama_print_timings:        eval time =    6116.44 ms /   150 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =   12372.79 ms /  1129 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.44 ms /     6 runs   (    0.57 ms per token,  1742.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4558.48 ms /   835 tokens (    5.46 ms per token,   183.17 tokens per second)\n",
            "llama_print_timings:        eval time =     199.36 ms /     5 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    5128.31 ms /   840 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1817.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4303.46 ms /   795 tokens (    5.41 ms per token,   184.73 tokens per second)\n",
            "llama_print_timings:        eval time =     198.61 ms /     5 runs   (   39.72 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4735.74 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2640.92 ms /   499 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =     233.46 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3032.84 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1610.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2178.90 ms /   416 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =     235.40 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2646.56 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      48.13 ms /    85 runs   (    0.57 ms per token,  1765.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5346.38 ms /   975 tokens (    5.48 ms per token,   182.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3415.37 ms /    84 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    9349.18 ms /  1059 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     7 runs   (    0.72 ms per token,  1397.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2691.10 ms /   507 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
            "llama_print_timings:        eval time =     235.58 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3163.49 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1564.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2398.38 ms /   454 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
            "llama_print_timings:        eval time =     232.30 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2852.78 ms /   460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1649.00 ms /   316 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =     231.00 ms /     6 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    1998.06 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2731.67 ms /   518 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     235.86 ms /     6 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3132.30 ms /   524 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1861.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2204.17 ms /   418 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     229.81 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2570.29 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     6 runs   (    0.65 ms per token,  1541.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3274.20 ms /   612 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
            "llama_print_timings:        eval time =     197.29 ms /     5 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3761.18 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1725.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2560.45 ms /   488 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =     272.03 ms /     7 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3009.77 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.99 ms /     6 runs   (    0.50 ms per token,  2006.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3892.00 ms /   723 tokens (    5.38 ms per token,   185.77 tokens per second)\n",
            "llama_print_timings:        eval time =     199.43 ms /     5 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    4306.95 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1692.08 ms /   328 tokens (    5.16 ms per token,   193.84 tokens per second)\n",
            "llama_print_timings:        eval time =     272.22 ms /     7 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2080.52 ms /   335 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.02 ms /     6 runs   (    0.50 ms per token,  1983.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4638.91 ms /   850 tokens (    5.46 ms per token,   183.23 tokens per second)\n",
            "llama_print_timings:        eval time =     201.58 ms /     5 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5211.50 ms /   855 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1618.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2642.24 ms /   502 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
            "llama_print_timings:        eval time =     234.88 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3043.38 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1881.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.44 ms /   412 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =     233.15 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2532.67 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1690.61 ms /   327 tokens (    5.17 ms per token,   193.42 tokens per second)\n",
            "llama_print_timings:        eval time =     232.18 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2031.06 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.53 ms per token,  1870.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5347.10 ms /   975 tokens (    5.48 ms per token,   182.34 tokens per second)\n",
            "llama_print_timings:        eval time =     201.77 ms /     5 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5940.85 ms /   980 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5280.07 ms /   965 tokens (    5.47 ms per token,   182.76 tokens per second)\n",
            "llama_print_timings:        eval time =     243.35 ms /     6 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    5804.86 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1901.10 ms /   363 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
            "llama_print_timings:        eval time =     228.62 ms /     6 runs   (   38.10 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =    2248.08 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.49 ms /     7 runs   (    0.64 ms per token,  1558.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1453.36 ms /   266 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
            "llama_print_timings:        eval time =     236.23 ms /     6 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    1838.10 ms /   272 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3004.38 ms /   564 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =     233.85 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3487.33 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1608.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2667.39 ms /   501 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =     237.10 ms /     6 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    3066.27 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.71 ms /    20 tokens (    6.39 ms per token,   156.60 tokens per second)\n",
            "llama_print_timings:        eval time =     231.59 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =     388.00 ms /    26 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.60 ms per token,  1679.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2710.78 ms /   507 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =     193.85 ms /     5 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3061.21 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     6 runs   (    0.63 ms per token,  1581.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4181.47 ms /   776 tokens (    5.39 ms per token,   185.58 tokens per second)\n",
            "llama_print_timings:        eval time =     241.64 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    4761.58 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.83 ms /    11 runs   (    0.53 ms per token,  1885.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4260.73 ms /   792 tokens (    5.38 ms per token,   185.88 tokens per second)\n",
            "llama_print_timings:        eval time =     438.44 ms /    11 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    4961.56 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's dividend history and how sustainable are the dividend payouts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1876.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     177.47 ms /    29 tokens (    6.12 ms per token,   163.41 tokens per second)\n",
            "llama_print_timings:        eval time =     237.06 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =     447.52 ms /    35 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3984.24 ms /   743 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =     198.73 ms /     5 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    4394.35 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1837.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3635.58 ms /   677 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
            "llama_print_timings:        eval time =     197.24 ms /     5 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4149.39 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2551.02 ms /   483 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =     236.88 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2948.94 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1691.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2333.99 ms /   444 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
            "llama_print_timings:        eval time =     234.27 ms /     6 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2711.84 ms /   450 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1800.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2509.33 ms /   480 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
            "llama_print_timings:        eval time =     273.06 ms /     7 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2936.16 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1475.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2743.26 ms /   520 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =     275.00 ms /     7 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3279.39 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1813.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4814.90 ms /   887 tokens (    5.43 ms per token,   184.22 tokens per second)\n",
            "llama_print_timings:        eval time =     201.71 ms /     5 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    5310.71 ms /   892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1838.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3849.14 ms /   719 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =     196.62 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    4256.44 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1567.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3900.03 ms /   723 tokens (    5.39 ms per token,   185.38 tokens per second)\n",
            "llama_print_timings:        eval time =     238.58 ms /     6 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    4485.36 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1648.13 ms /   320 tokens (    5.15 ms per token,   194.16 tokens per second)\n",
            "llama_print_timings:        eval time =     234.68 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    1991.63 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1796.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3846.51 ms /   719 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
            "llama_print_timings:        eval time =     236.48 ms /     6 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    4300.07 ms /   725 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1756.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1687.06 ms /   325 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
            "llama_print_timings:        eval time =     232.37 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2028.49 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.55 ms per token,  1802.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4455.03 ms /   824 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =     240.31 ms /     6 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    5054.13 ms /   830 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1621.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.06 ms /   405 tokens (    5.22 ms per token,   191.48 tokens per second)\n",
            "llama_print_timings:        eval time =     230.13 ms /     6 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    2479.58 ms /   411 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     270.15 ms /     7 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =     295.93 ms /     7 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1678.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1983.61 ms /   378 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =     231.27 ms /     6 runs   (   38.54 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2340.42 ms /   384 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     724.92 ms /   135 tokens (    5.37 ms per token,   186.23 tokens per second)\n",
            "llama_print_timings:        eval time =     234.90 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    1018.56 ms /   141 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     6 runs   (    0.61 ms per token,  1641.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4169.22 ms /   776 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
            "llama_print_timings:        eval time =     239.53 ms /     6 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    4689.93 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /     6 runs   (    0.52 ms per token,  1928.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3326.67 ms /   605 tokens (    5.50 ms per token,   181.86 tokens per second)\n",
            "llama_print_timings:        eval time =     200.06 ms /     5 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    3791.34 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1803.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2550.06 ms /   486 tokens (    5.25 ms per token,   190.58 tokens per second)\n",
            "llama_print_timings:        eval time =     233.56 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2935.49 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1813.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.98 ms /   453 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =     234.83 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2748.73 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.85 ms /     7 runs   (    0.69 ms per token,  1442.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2551.57 ms /   483 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =     234.15 ms /     6 runs   (   39.02 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2962.73 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1844.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2492.50 ms /   472 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =     273.05 ms /     7 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3023.54 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.61 ms /   415 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
            "llama_print_timings:        eval time =     230.36 ms /     6 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2518.75 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.99 ms /     6 runs   (    0.50 ms per token,  2008.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5940.93 ms /  1074 tokens (    5.53 ms per token,   180.78 tokens per second)\n",
            "llama_print_timings:        eval time =     203.37 ms /     5 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    6456.07 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1924.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5801.77 ms /  1044 tokens (    5.56 ms per token,   179.95 tokens per second)\n",
            "llama_print_timings:        eval time =     202.41 ms /     5 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    6434.24 ms /  1049 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.55 ms per token,  1802.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3666.26 ms /   687 tokens (    5.34 ms per token,   187.38 tokens per second)\n",
            "llama_print_timings:        eval time =     199.96 ms /     5 runs   (   39.99 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    4092.28 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     6 runs   (    0.76 ms per token,  1312.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3719.01 ms /   696 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
            "llama_print_timings:        eval time =     198.71 ms /     5 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    4203.23 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2307.59 ms /   435 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =     234.31 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2793.40 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2333.84 ms /   446 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =     234.66 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2710.04 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2639.93 ms /   504 tokens (    5.24 ms per token,   190.91 tokens per second)\n",
            "llama_print_timings:        eval time =     274.63 ms /     7 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3072.34 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1777.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2594.93 ms /   494 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =     233.94 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2985.66 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1610.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2876.58 ms /   541 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
            "llama_print_timings:        eval time =     236.31 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3385.93 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2644.83 ms /   502 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =     237.47 ms /     6 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    3059.60 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1916.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3938.64 ms /   736 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
            "llama_print_timings:        eval time =     239.70 ms /     6 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    4392.92 ms /   742 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     6 runs   (    0.66 ms per token,  1509.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3898.57 ms /   727 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =     199.40 ms /     5 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    4359.81 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2310.56 ms /   439 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     234.61 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2767.36 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2379.01 ms /   450 tokens (    5.29 ms per token,   189.15 tokens per second)\n",
            "llama_print_timings:        eval time =     229.83 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2756.15 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1768.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2207.06 ms /   424 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
            "llama_print_timings:        eval time =     270.77 ms /     7 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2616.58 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1813.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2557.29 ms /   488 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =     275.05 ms /     7 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3006.92 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.67 ms /    13 runs   (    0.59 ms per token,  1693.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3551.09 ms /   662 tokens (    5.36 ms per token,   186.42 tokens per second)\n",
            "llama_print_timings:        eval time =     475.26 ms /    12 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    4394.20 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2335.31 ms /   445 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =     234.84 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2720.92 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2336.30 ms /   446 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =     233.97 ms /     6 runs   (   38.99 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2714.71 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1632.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2335.10 ms /   443 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =     232.23 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2715.34 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1608.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2124.49 ms /   408 tokens (    5.21 ms per token,   192.05 tokens per second)\n",
            "llama_print_timings:        eval time =     272.12 ms /     7 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2574.05 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1692.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2517.73 ms /   474 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =     234.29 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2996.14 ms /   480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1765.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1773.14 ms /   340 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =     233.83 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2121.27 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1770.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1989.32 ms /   379 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     229.50 ms /     6 runs   (   38.25 ms per token,    26.14 tokens per second)\n",
            "llama_print_timings:       total time =    2348.70 ms /   385 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1784.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1692.59 ms /   327 tokens (    5.18 ms per token,   193.20 tokens per second)\n",
            "llama_print_timings:        eval time =     234.18 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2044.82 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1756.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1906.82 ms /   366 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2266.35 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     7 runs   (    0.72 ms per token,  1396.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1698.00 ms /   322 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2117.48 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.23 ms /     7 runs   (    0.60 ms per token,  1654.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1254.45 ms /   239 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     228.46 ms /     6 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =    1628.36 ms /   245 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2420.55 ms /   459 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     233.81 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2806.35 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2016.59 ms /   384 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =     271.12 ms /     7 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2427.19 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2866.03 ms /   544 tokens (    5.27 ms per token,   189.81 tokens per second)\n",
            "llama_print_timings:        eval time =     275.99 ms /     7 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3314.38 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3003.69 ms /   562 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
            "llama_print_timings:        eval time =     236.90 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    3507.38 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     6 runs   (    0.62 ms per token,  1619.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.31 ms /    22 tokens (    5.88 ms per token,   170.13 tokens per second)\n",
            "llama_print_timings:        eval time =     197.56 ms /     5 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =     371.54 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1806.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3135.32 ms /   587 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =     195.00 ms /     5 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3536.19 ms /   592 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1706.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3170.00 ms /   594 tokens (    5.34 ms per token,   187.38 tokens per second)\n",
            "llama_print_timings:        eval time =     233.36 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    3594.63 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2643.07 ms /   503 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
            "llama_print_timings:        eval time =     234.90 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3038.30 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2829.69 ms /   532 tokens (    5.32 ms per token,   188.01 tokens per second)\n",
            "llama_print_timings:        eval time =     195.54 ms /     5 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3309.08 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5573.77 ms /  1016 tokens (    5.49 ms per token,   182.28 tokens per second)\n",
            "llama_print_timings:        eval time =     243.99 ms /     6 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    6125.05 ms /  1022 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1850.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2727.59 ms /   516 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =     236.51 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3128.82 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.48 ms /     7 runs   (    0.64 ms per token,  1561.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3725.72 ms /   693 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
            "llama_print_timings:        eval time =     237.25 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    4290.92 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1878.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3530.26 ms /   660 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =     237.79 ms /     6 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    3973.15 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2292.02 ms /   437 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =     228.62 ms /     6 runs   (   38.10 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =    2659.93 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2436.38 ms /   462 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     231.95 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2815.24 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1504.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1910.96 ms /   365 tokens (    5.24 ms per token,   191.00 tokens per second)\n",
            "llama_print_timings:        eval time =     231.93 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2337.88 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1843.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3723.45 ms /   695 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =     236.63 ms /     6 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    4224.43 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1768.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2993.96 ms /   564 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =     234.86 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3400.35 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1668.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3124.51 ms /   587 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
            "llama_print_timings:        eval time =     235.81 ms /     6 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3537.61 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.60 ms /     7 runs   (    0.66 ms per token,  1521.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2304.42 ms /   435 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =     234.53 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2792.40 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1622.26 ms /   306 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =     233.79 ms /     6 runs   (   38.96 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    1988.82 ms /   312 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1854.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1944.89 ms /   374 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
            "llama_print_timings:        eval time =     233.00 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2303.59 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1698.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.97 ms /   443 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =     231.10 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2703.63 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     428.44 ms /    78 tokens (    5.49 ms per token,   182.05 tokens per second)\n",
            "llama_print_timings:        eval time =     230.03 ms /     6 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =     704.40 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1610.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2731.47 ms /   520 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =     236.86 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    3148.59 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1552.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2348.66 ms /   443 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =     233.84 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2839.29 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1818.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3576.50 ms /   670 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =     199.68 ms /     5 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    3978.83 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3368.62 ms /   630 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =     195.07 ms /     5 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3749.58 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1539.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.82 ms /   467 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
            "llama_print_timings:        eval time =     233.30 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2869.94 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.42 ms /     7 runs   (    1.06 ms per token,   944.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2259.36 ms /   427 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =     233.06 ms /     6 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2752.14 ms /   433 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "Total score for approach 1 and distance function l2 is 0.6194968553459119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(2, 'cosine')"
      ],
      "metadata": {
        "id": "GFsk-Yx53iMu",
        "outputId": "43ff9364-dd38-4165-998c-9d72bc120e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.01 ms /     6 runs   (    0.50 ms per token,  1992.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5996.84 ms /  1083 tokens (    5.54 ms per token,   180.60 tokens per second)\n",
            "llama_print_timings:        eval time =     202.60 ms /     5 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    6517.91 ms /  1088 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1588.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5049.03 ms /   926 tokens (    5.45 ms per token,   183.40 tokens per second)\n",
            "llama_print_timings:        eval time =     242.53 ms /     6 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    5655.96 ms /   932 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1918.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4400.37 ms /   814 tokens (    5.41 ms per token,   184.98 tokens per second)\n",
            "llama_print_timings:        eval time =     241.02 ms /     6 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    4914.75 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1770.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5083.31 ms /   930 tokens (    5.47 ms per token,   182.95 tokens per second)\n",
            "llama_print_timings:        eval time =     240.97 ms /     6 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    5597.73 ms /   936 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.30 ms /     7 runs   (    0.61 ms per token,  1626.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2744.25 ms /   520 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =     235.28 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3248.32 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1795.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2727.65 ms /   516 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =     237.33 ms /     6 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    3143.79 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1845.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5041.14 ms /   923 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
            "llama_print_timings:        eval time =     241.61 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5552.78 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1552.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4363.25 ms /   807 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =     240.34 ms /     6 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    4955.86 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      56.06 ms /    96 runs   (    0.58 ms per token,  1712.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5945.44 ms /  1078 tokens (    5.52 ms per token,   181.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3888.16 ms /    95 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   10457.36 ms /  1173 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1868.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5012.49 ms /   920 tokens (    5.45 ms per token,   183.54 tokens per second)\n",
            "llama_print_timings:        eval time =     281.29 ms /     7 runs   (   40.18 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    5679.07 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1926.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5994.48 ms /  1087 tokens (    5.51 ms per token,   181.33 tokens per second)\n",
            "llama_print_timings:        eval time =     204.36 ms /     5 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    6510.87 ms /  1092 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1839.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4730.54 ms /   870 tokens (    5.44 ms per token,   183.91 tokens per second)\n",
            "llama_print_timings:        eval time =     240.02 ms /     6 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    5345.02 ms /   876 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1912.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4074.13 ms /   759 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =     198.94 ms /     5 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4496.46 ms /   764 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.37 ms /     9 runs   (    0.71 ms per token,  1412.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3984.07 ms /   743 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =     317.89 ms /     8 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4556.14 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5342.07 ms /   976 tokens (    5.47 ms per token,   182.70 tokens per second)\n",
            "llama_print_timings:        eval time =     241.91 ms /     6 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5967.42 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5233.50 ms /   958 tokens (    5.46 ms per token,   183.05 tokens per second)\n",
            "llama_print_timings:        eval time =     243.06 ms /     6 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    5765.39 ms /   964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      64.98 ms /   101 runs   (    0.64 ms per token,  1554.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1311.92 ms /   254 tokens (    5.17 ms per token,   193.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3842.89 ms /   100 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    5699.68 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5368.00 ms /   978 tokens (    5.49 ms per token,   182.19 tokens per second)\n",
            "llama_print_timings:        eval time =     203.36 ms /     5 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    5862.58 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1889.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6010.20 ms /  1088 tokens (    5.52 ms per token,   181.03 tokens per second)\n",
            "llama_print_timings:        eval time =     245.11 ms /     6 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    6682.78 ms /  1094 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.43 ms /     9 runs   (    0.60 ms per token,  1657.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4025.47 ms /   747 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =     316.71 ms /     8 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4585.29 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2508.18 ms /   478 tokens (    5.25 ms per token,   190.58 tokens per second)\n",
            "llama_print_timings:        eval time =     231.34 ms /     6 runs   (   38.56 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2889.56 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      62.55 ms /   107 runs   (    0.58 ms per token,  1710.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4133.50 ms /   768 tokens (    5.38 ms per token,   185.80 tokens per second)\n",
            "llama_print_timings:        eval time =    4232.87 ms /   106 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    9052.93 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     152.46 ms /   256 runs   (    0.60 ms per token,  1679.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2899.77 ms /   546 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10073.65 ms /   255 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   14155.77 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      49.43 ms /    79 runs   (    0.63 ms per token,  1598.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5995.25 ms /  1086 tokens (    5.52 ms per token,   181.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3195.73 ms /    78 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    9881.25 ms /  1164 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1777.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.46 ms /   525 tokens (    5.28 ms per token,   189.50 tokens per second)\n",
            "llama_print_timings:        eval time =     234.21 ms /     6 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3164.35 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1573.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2681.17 ms /   507 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
            "llama_print_timings:        eval time =     233.17 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3073.50 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1568.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2556.40 ms /   487 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =     235.32 ms /     6 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2990.95 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1564.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1544.45 ms /   283 tokens (    5.46 ms per token,   183.24 tokens per second)\n",
            "llama_print_timings:        eval time =     234.40 ms /     6 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    1958.89 ms /   289 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /     6 runs   (    0.52 ms per token,  1927.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3802.03 ms /   710 tokens (    5.35 ms per token,   186.74 tokens per second)\n",
            "llama_print_timings:        eval time =     198.43 ms /     5 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4213.70 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     6 runs   (    0.56 ms per token,  1772.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3978.72 ms /   740 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =     197.50 ms /     5 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    4388.33 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1541.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.82 ms /   429 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     233.58 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2667.24 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2917.98 ms /   549 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =     235.99 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3414.26 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1833.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2376.49 ms /   456 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =     234.20 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2749.86 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2070.14 ms /   394 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
            "llama_print_timings:        eval time =     233.03 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2433.00 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1784.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3034.78 ms /   573 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =     232.88 ms /     6 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3447.10 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.44 ms /     7 runs   (    0.63 ms per token,  1578.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     275.03 ms /     7 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =     312.92 ms /     7 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1529.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1870.08 ms /   355 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =     232.03 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2318.67 ms /   361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2039.72 ms /   392 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =     234.31 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2423.81 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.86 ms /     6 runs   (    0.48 ms per token,  2100.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5896.98 ms /  1070 tokens (    5.51 ms per token,   181.45 tokens per second)\n",
            "llama_print_timings:        eval time =     201.82 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    6403.72 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.49 ms /     7 runs   (    0.64 ms per token,  1557.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2466.28 ms /   466 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =     233.87 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2901.56 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.28 ms /    13 runs   (    0.56 ms per token,  1785.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3584.31 ms /   666 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =     472.85 ms /    12 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    4353.12 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any tax-related risks or benefits for the COCA COLA CO mentioned?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3346.88 ms /   629 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =     198.49 ms /     5 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3737.03 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.13 ms /     9 runs   (    0.68 ms per token,  1468.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3939.17 ms /   735 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
            "llama_print_timings:        eval time =     317.57 ms /     8 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4510.10 ms /   743 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2828.08 ms /   530 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =     233.12 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3324.19 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1623.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.00 ms /   453 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =     234.72 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2753.50 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1855.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4674.76 ms /   864 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =     282.25 ms /     7 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5217.88 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1883.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4870.47 ms /   893 tokens (    5.45 ms per token,   183.35 tokens per second)\n",
            "llama_print_timings:        eval time =     240.71 ms /     6 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    5492.21 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2725.71 ms /   517 tokens (    5.27 ms per token,   189.68 tokens per second)\n",
            "llama_print_timings:        eval time =     233.19 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3125.12 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1265.59 ms /   238 tokens (    5.32 ms per token,   188.06 tokens per second)\n",
            "llama_print_timings:        eval time =     233.26 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    1609.44 ms /   244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     6 runs   (    0.64 ms per token,  1574.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3935.00 ms /   731 tokens (    5.38 ms per token,   185.77 tokens per second)\n",
            "llama_print_timings:        eval time =     198.70 ms /     5 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    4387.89 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.53 ms per token,  1872.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3502.97 ms /   653 tokens (    5.36 ms per token,   186.41 tokens per second)\n",
            "llama_print_timings:        eval time =     195.34 ms /     5 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4025.81 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1824.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.06 ms /   413 tokens (    5.23 ms per token,   191.20 tokens per second)\n",
            "llama_print_timings:        eval time =     232.49 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2524.69 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1842.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1837.40 ms /   347 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =     233.16 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2185.03 ms /   353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2337.07 ms /   447 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =     231.47 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2717.00 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1539.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2293.33 ms /   436 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =     234.52 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2724.53 ms /   442 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1675.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5059.54 ms /   927 tokens (    5.46 ms per token,   183.22 tokens per second)\n",
            "llama_print_timings:        eval time =     241.63 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5651.33 ms /   933 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.53 ms per token,  1870.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5183.55 ms /   952 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =     202.31 ms /     5 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    5654.71 ms /   957 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.67 ms /     7 runs   (    0.67 ms per token,  1500.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2779.33 ms /   524 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =     234.90 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3278.30 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1771.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2298.63 ms /   440 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
            "llama_print_timings:        eval time =     232.12 ms /     6 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2687.83 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1856.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2637.68 ms /   504 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =     276.79 ms /     7 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3072.91 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1945.97 ms /   375 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
            "llama_print_timings:        eval time =     233.80 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2300.19 ms /   381 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1549.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3805.83 ms /   711 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =     237.70 ms /     6 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4319.60 ms /   717 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4180.09 ms /   776 tokens (    5.39 ms per token,   185.64 tokens per second)\n",
            "llama_print_timings:        eval time =     198.85 ms /     5 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    4659.43 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1818.31 ms /   352 tokens (    5.17 ms per token,   193.59 tokens per second)\n",
            "llama_print_timings:        eval time =     267.93 ms /     7 runs   (   38.28 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2206.45 ms /   359 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1775.80 ms /   344 tokens (    5.16 ms per token,   193.72 tokens per second)\n",
            "llama_print_timings:        eval time =     231.32 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2119.30 ms /   350 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     7 runs   (    0.68 ms per token,  1472.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.37 ms /   468 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
            "llama_print_timings:        eval time =     233.29 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2866.10 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1714.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5291.56 ms /   968 tokens (    5.47 ms per token,   182.93 tokens per second)\n",
            "llama_print_timings:        eval time =     284.23 ms /     7 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    5965.38 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1807.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2817.22 ms /   536 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
            "llama_print_timings:        eval time =     233.34 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    3218.81 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      90.66 ms /   148 runs   (    0.61 ms per token,  1632.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5335.29 ms /   975 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
            "llama_print_timings:        eval time =    5977.12 ms /   147 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =   12191.98 ms /  1122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1784.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.04 ms /   530 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     234.34 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3207.78 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1477.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3049.83 ms /   576 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =     274.82 ms /     7 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3595.92 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2821.01 ms /   533 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =     236.18 ms /     6 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3259.26 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1841.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     171.44 ms /    30 tokens (    5.71 ms per token,   174.99 tokens per second)\n",
            "llama_print_timings:        eval time =     232.50 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =     436.13 ms /    36 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     6 runs   (    0.58 ms per token,  1734.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3077.09 ms /   578 tokens (    5.32 ms per token,   187.84 tokens per second)\n",
            "llama_print_timings:        eval time =     196.72 ms /     5 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3451.01 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.59 ms /     7 runs   (    0.66 ms per token,  1523.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5329.82 ms /   973 tokens (    5.48 ms per token,   182.56 tokens per second)\n",
            "llama_print_timings:        eval time =     241.72 ms /     6 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    5937.49 ms /   979 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5334.63 ms /   975 tokens (    5.47 ms per token,   182.77 tokens per second)\n",
            "llama_print_timings:        eval time =     242.02 ms /     6 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    5892.56 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     6 runs   (    0.61 ms per token,  1637.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5374.00 ms /   983 tokens (    5.47 ms per token,   182.92 tokens per second)\n",
            "llama_print_timings:        eval time =     202.42 ms /     5 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    5898.65 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4919.40 ms /   903 tokens (    5.45 ms per token,   183.56 tokens per second)\n",
            "llama_print_timings:        eval time =     201.95 ms /     5 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    5482.02 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1841.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2854.34 ms /   538 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =     234.47 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3251.04 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3080.70 ms /   584 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =     275.15 ms /     7 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3537.24 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1511.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2391.15 ms /   451 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     233.91 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2875.40 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2857.88 ms /   540 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =     235.32 ms /     6 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3267.49 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      45.99 ms /    73 runs   (    0.63 ms per token,  1587.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5417.86 ms /   990 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2926.67 ms /    72 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8937.20 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      43.82 ms /    71 runs   (    0.62 ms per token,  1620.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     139.73 ms /    24 tokens (    5.82 ms per token,   171.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2885.03 ms /    71 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    3324.48 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4944.53 ms /   907 tokens (    5.45 ms per token,   183.44 tokens per second)\n",
            "llama_print_timings:        eval time =     240.25 ms /     6 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    5446.77 ms /   913 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      39.87 ms /    71 runs   (    0.56 ms per token,  1780.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5295.19 ms /   967 tokens (    5.48 ms per token,   182.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2836.18 ms /    70 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    8740.17 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      56.02 ms /    87 runs   (    0.64 ms per token,  1552.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5273.98 ms /   965 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3488.20 ms /    86 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    9406.48 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1796.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2823.27 ms /   536 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =     236.36 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3261.52 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      36.94 ms /    66 runs   (    0.56 ms per token,  1786.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.24 ms /   584 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2552.23 ms /    65 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6001.47 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1547.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2428.70 ms /   463 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
            "llama_print_timings:        eval time =     233.51 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2851.63 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2438.38 ms /   463 tokens (    5.27 ms per token,   189.88 tokens per second)\n",
            "llama_print_timings:        eval time =     230.92 ms /     6 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2881.62 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1889.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3300.53 ms /   618 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =     233.93 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3725.36 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1766.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.76 ms /   468 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
            "llama_print_timings:        eval time =     233.44 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2841.02 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1685.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2904.53 ms /   550 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =     234.99 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3351.78 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1949.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3677.38 ms /   687 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =     236.37 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    4190.36 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.49 ms /     6 runs   (    0.58 ms per token,  1717.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     132.92 ms /    24 tokens (    5.54 ms per token,   180.56 tokens per second)\n",
            "llama_print_timings:        eval time =     236.45 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =     400.62 ms /    30 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1673.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.95 ms /   469 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =     233.53 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2840.77 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.97 ms /     6 runs   (    0.50 ms per token,  2018.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3568.61 ms /   668 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =     199.70 ms /     5 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    3963.93 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1794.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2428.56 ms /   462 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =     233.53 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2893.16 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2772.08 ms /   524 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
            "llama_print_timings:        eval time =     234.23 ms /     6 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3205.72 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.48 ms /     6 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     206.85 ms /    34 tokens (    6.08 ms per token,   164.37 tokens per second)\n",
            "llama_print_timings:        eval time =     188.99 ms /     5 runs   (   37.80 ms per token,    26.46 tokens per second)\n",
            "llama_print_timings:       total time =     426.62 ms /    39 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1781.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2418.77 ms /   460 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =     235.21 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2795.60 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1802.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2642.69 ms /   504 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
            "llama_print_timings:        eval time =     236.04 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3041.14 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1614.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1990.33 ms /   384 tokens (    5.18 ms per token,   192.93 tokens per second)\n",
            "llama_print_timings:        eval time =     231.73 ms /     6 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2377.92 ms /   390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1793.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3450.81 ms /   648 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =     198.85 ms /     5 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    3912.28 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1792.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2113.48 ms /   404 tokens (    5.23 ms per token,   191.15 tokens per second)\n",
            "llama_print_timings:        eval time =     229.80 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2467.59 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1789.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3480.47 ms /   653 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =     195.54 ms /     5 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3864.87 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.85 ms /    60 runs   (    0.58 ms per token,  1721.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5242.97 ms /   958 tokens (    5.47 ms per token,   182.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2387.64 ms /    59 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    8201.91 ms /  1017 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1826.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2769.19 ms /   525 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =     232.63 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3165.49 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      74.28 ms /   124 runs   (    0.60 ms per token,  1669.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4816.34 ms /   887 tokens (    5.43 ms per token,   184.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4970.27 ms /   123 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   10553.29 ms /  1010 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.76 ms /     9 runs   (    0.53 ms per token,  1890.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4205.45 ms /   781 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =     318.25 ms /     8 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    4756.94 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1532.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2640.48 ms /   499 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
            "llama_print_timings:        eval time =     233.26 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3091.24 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1885.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2828.36 ms /   535 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =     233.68 ms /     6 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3287.45 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1896.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5375.57 ms /   984 tokens (    5.46 ms per token,   183.05 tokens per second)\n",
            "llama_print_timings:        eval time =     244.33 ms /     6 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    5902.89 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      32.15 ms /    58 runs   (    0.55 ms per token,  1804.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5241.26 ms /   956 tokens (    5.48 ms per token,   182.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2305.53 ms /    57 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8114.13 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.52 ms /     6 runs   (    0.59 ms per token,  1706.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1478.70 ms /   288 tokens (    5.13 ms per token,   194.77 tokens per second)\n",
            "llama_print_timings:        eval time =     192.87 ms /     5 runs   (   38.57 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    1765.82 ms /   293 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1699.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1902.35 ms /   368 tokens (    5.17 ms per token,   193.44 tokens per second)\n",
            "llama_print_timings:        eval time =     233.55 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2257.18 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     7 runs   (    0.69 ms per token,  1459.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3215.45 ms /   605 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =     236.13 ms /     6 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3648.24 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1689.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2390.30 ms /   455 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =     233.55 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2876.00 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.61 ms /   323 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
            "llama_print_timings:        eval time =     233.11 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2027.93 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1623.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1465.23 ms /   271 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =     235.17 ms /     6 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    1798.88 ms /   277 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1858.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3084.63 ms /   584 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =     233.43 ms /     6 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3488.69 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.59 ms /     7 runs   (    0.66 ms per token,  1525.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2819.98 ms /   536 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =     274.93 ms /     7 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3291.11 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1674.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2652.84 ms /   504 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
            "llama_print_timings:        eval time =     234.41 ms /     6 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3129.61 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2447.68 ms /   464 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =     234.96 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2830.24 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1902.84 ms /   366 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
            "llama_print_timings:        eval time =     234.93 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2261.51 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2912.19 ms /   552 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3309.50 ms /   558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     145.28 ms /   256 runs   (    0.57 ms per token,  1762.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5437.54 ms /   989 tokens (    5.50 ms per token,   181.88 tokens per second)\n",
            "llama_print_timings:        eval time =   10428.30 ms /   255 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =   17291.30 ms /  1244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1867.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4951.92 ms /   909 tokens (    5.45 ms per token,   183.57 tokens per second)\n",
            "llama_print_timings:        eval time =     241.31 ms /     6 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5451.97 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.07 ms /   437 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =     234.77 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2671.22 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1492.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3494.36 ms /   654 tokens (    5.34 ms per token,   187.16 tokens per second)\n",
            "llama_print_timings:        eval time =     238.34 ms /     6 runs   (   39.72 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4016.73 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3180.08 ms /   595 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
            "llama_print_timings:        eval time =     237.23 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3627.97 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1928.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5423.17 ms /   988 tokens (    5.49 ms per token,   182.18 tokens per second)\n",
            "llama_print_timings:        eval time =     243.84 ms /     6 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    5946.01 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1949.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5018.90 ms /   920 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
            "llama_print_timings:        eval time =     240.62 ms /     6 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    5651.49 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1835.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5427.02 ms /   991 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =     201.04 ms /     5 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5905.66 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     6 runs   (    0.64 ms per token,  1574.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5058.33 ms /   924 tokens (    5.47 ms per token,   182.67 tokens per second)\n",
            "llama_print_timings:        eval time =     201.97 ms /     5 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    5632.59 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1852.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3130.94 ms /   589 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
            "llama_print_timings:        eval time =     234.93 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3563.31 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      37.65 ms /    65 runs   (    0.58 ms per token,  1726.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5379.04 ms /   981 tokens (    5.48 ms per token,   182.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2599.83 ms /    64 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8528.15 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /     7 runs   (    1.36 ms per token,   736.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     187.04 ms /    31 tokens (    6.03 ms per token,   165.74 tokens per second)\n",
            "llama_print_timings:        eval time =     241.60 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =     489.27 ms /    37 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1779.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3052.27 ms /   576 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
            "llama_print_timings:        eval time =     234.81 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3497.24 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5375.66 ms /   982 tokens (    5.47 ms per token,   182.68 tokens per second)\n",
            "llama_print_timings:        eval time =     243.78 ms /     6 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    5911.56 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /     6 runs   (    0.52 ms per token,  1927.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5007.62 ms /   915 tokens (    5.47 ms per token,   182.72 tokens per second)\n",
            "llama_print_timings:        eval time =     202.07 ms /     5 runs   (   40.41 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    5583.08 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1949.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3083.95 ms /   584 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =     195.17 ms /     5 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3457.86 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1905.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3667.71 ms /   688 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
            "llama_print_timings:        eval time =     277.78 ms /     7 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4162.92 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     6 runs   (    0.62 ms per token,  1607.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3133.63 ms /   592 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =     196.45 ms /     5 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3586.13 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.09 ms /     6 runs   (    0.51 ms per token,  1942.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5382.10 ms /   984 tokens (    5.47 ms per token,   182.83 tokens per second)\n",
            "llama_print_timings:        eval time =     202.88 ms /     5 runs   (   40.58 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    5904.62 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     6 runs   (    0.66 ms per token,  1518.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5038.21 ms /   922 tokens (    5.46 ms per token,   183.00 tokens per second)\n",
            "llama_print_timings:        eval time =     200.71 ms /     5 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5528.21 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1612.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2305.41 ms /   436 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =     232.58 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2772.30 ms /   442 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      38.42 ms /    74 runs   (    0.52 ms per token,  1926.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3079.67 ms /   580 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2868.38 ms /    73 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6343.73 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.52 ms /     6 runs   (    0.59 ms per token,  1706.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3166.59 ms /   595 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
            "llama_print_timings:        eval time =     193.72 ms /     5 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3544.65 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1922.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5392.97 ms /   984 tokens (    5.48 ms per token,   182.46 tokens per second)\n",
            "llama_print_timings:        eval time =     202.91 ms /     5 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    5985.85 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.55 ms /    13 runs   (    0.50 ms per token,  1984.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3978.38 ms /   739 tokens (    5.38 ms per token,   185.75 tokens per second)\n",
            "llama_print_timings:        eval time =     474.82 ms /    12 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    4696.17 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the PayPal Holdings, Inc.'s total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1514.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3083.74 ms /   581 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =     237.65 ms /     6 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    3549.96 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3135.88 ms /   592 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =     196.89 ms /     5 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3590.35 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1815.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3037.55 ms /   576 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     233.88 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3448.34 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.53 ms per token,  1872.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     215.47 ms /    36 tokens (    5.99 ms per token,   167.07 tokens per second)\n",
            "llama_print_timings:        eval time =     193.16 ms /     5 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =     439.32 ms /    41 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3126.36 ms /   592 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =     237.26 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3537.80 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.78 ms /     7 runs   (    0.68 ms per token,  1465.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2167.55 ms /   412 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =     232.36 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2596.25 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1851.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3175.02 ms /   596 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
            "llama_print_timings:        eval time =     235.40 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3660.16 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1891.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1897.15 ms /   362 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     227.46 ms /     6 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
            "llama_print_timings:       total time =    2246.55 ms /   368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2593.07 ms /   493 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =     235.34 ms /     6 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2975.33 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1611.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2991.81 ms /   563 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =     234.18 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3436.11 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3181.06 ms /   597 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =     194.93 ms /     5 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3640.50 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1766.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3212.71 ms /   605 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
            "llama_print_timings:        eval time =     236.23 ms /     6 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3632.03 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1894.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3121.83 ms /   590 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =     197.01 ms /     5 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3490.68 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1647.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3173.01 ms /   598 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =     235.22 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3664.01 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1827.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3092.01 ms /   584 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =     236.11 ms /     6 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3547.45 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1783.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.82 ms /   472 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =     235.92 ms /     6 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2846.38 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1679.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1854.16 ms /   356 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =     233.16 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2202.07 ms /   362 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1820.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1264.97 ms /   244 tokens (    5.18 ms per token,   192.89 tokens per second)\n",
            "llama_print_timings:        eval time =     228.47 ms /     6 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =    1576.74 ms /   250 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1760.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3594.49 ms /   672 tokens (    5.35 ms per token,   186.95 tokens per second)\n",
            "llama_print_timings:        eval time =     237.65 ms /     6 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    4149.96 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1851.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.90 ms /   583 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =     195.12 ms /     5 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3450.52 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1785.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     171.53 ms /    28 tokens (    6.13 ms per token,   163.23 tokens per second)\n",
            "llama_print_timings:        eval time =     195.38 ms /     5 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =     395.51 ms /    33 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.09 ms /     6 runs   (    0.51 ms per token,  1943.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3615.64 ms /   678 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
            "llama_print_timings:        eval time =     196.02 ms /     5 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    4010.95 ms /   683 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     6 runs   (    0.64 ms per token,  1554.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3085.47 ms /   584 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
            "llama_print_timings:        eval time =     235.41 ms /     6 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3557.67 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.03 ms /     6 runs   (    0.50 ms per token,  1982.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5336.26 ms /   976 tokens (    5.47 ms per token,   182.90 tokens per second)\n",
            "llama_print_timings:        eval time =     242.65 ms /     6 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    5923.61 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1780.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3120.56 ms /   586 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
            "llama_print_timings:        eval time =     194.69 ms /     5 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3489.86 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1548.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2114.57 ms /   406 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =     231.89 ms /     6 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2488.34 ms /   412 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     151.91 ms /   256 runs   (    0.59 ms per token,  1685.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3993.32 ms /   741 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10204.41 ms /   255 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =   15541.03 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1909.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3165.33 ms /   594 tokens (    5.33 ms per token,   187.66 tokens per second)\n",
            "llama_print_timings:        eval time =     232.47 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3594.52 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2463.62 ms /   472 tokens (    5.22 ms per token,   191.59 tokens per second)\n",
            "llama_print_timings:        eval time =     274.09 ms /     7 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2883.87 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1885.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3075.97 ms /   581 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
            "llama_print_timings:        eval time =     232.48 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3487.35 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1621.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2082.92 ms /   400 tokens (    5.21 ms per token,   192.04 tokens per second)\n",
            "llama_print_timings:        eval time =     271.38 ms /     7 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2567.26 ms /   407 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1875.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3087.97 ms /   583 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =     197.00 ms /     5 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3499.00 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1910.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.23 ms /   464 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
            "llama_print_timings:        eval time =     234.20 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2793.44 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1878.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3209.27 ms /   603 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =     236.43 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3634.75 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.98 ms /     7 runs   (    0.71 ms per token,  1406.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1910.26 ms /   368 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
            "llama_print_timings:        eval time =     270.06 ms /     7 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2353.83 ms /   375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1823.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2916.64 ms /   552 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
            "llama_print_timings:        eval time =     272.74 ms /     7 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3435.90 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1857.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3166.50 ms /   596 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =     232.78 ms /     6 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3586.64 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.67 ms /   430 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =     230.39 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2608.23 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.04 ms /     7 runs   (    0.72 ms per token,  1390.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.12 ms /   432 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
            "llama_print_timings:        eval time =     271.66 ms /     7 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2675.24 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.79 ms /     7 runs   (    0.68 ms per token,  1460.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1868.88 ms /   360 tokens (    5.19 ms per token,   192.63 tokens per second)\n",
            "llama_print_timings:        eval time =     271.51 ms /     7 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2361.63 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1772.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2728.79 ms /   517 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =     235.41 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3140.91 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      56.33 ms /    99 runs   (    0.57 ms per token,  1757.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3078.31 ms /   583 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3853.59 ms /    98 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7415.32 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1835.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3182.39 ms /   594 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =     195.73 ms /     5 runs   (   39.15 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3673.76 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1853.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1861.56 ms /   360 tokens (    5.17 ms per token,   193.39 tokens per second)\n",
            "llama_print_timings:        eval time =     228.98 ms /     6 runs   (   38.16 ms per token,    26.20 tokens per second)\n",
            "llama_print_timings:       total time =    2204.67 ms /   366 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1753.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4622.22 ms /   856 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
            "llama_print_timings:        eval time =     200.56 ms /     5 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    5073.80 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     6 runs   (    0.66 ms per token,  1507.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3893.16 ms /   724 tokens (    5.38 ms per token,   185.97 tokens per second)\n",
            "llama_print_timings:        eval time =     198.69 ms /     5 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4386.34 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      39.80 ms /    67 runs   (    0.59 ms per token,  1683.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5561.27 ms /  1013 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2681.96 ms /    66 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    8775.39 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1514.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3664.43 ms /   684 tokens (    5.36 ms per token,   186.66 tokens per second)\n",
            "llama_print_timings:        eval time =     239.00 ms /     6 runs   (   39.83 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4184.48 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1813.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2906.15 ms /   546 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =     233.15 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3350.93 ms /   552 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1937.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4895.79 ms /   900 tokens (    5.44 ms per token,   183.83 tokens per second)\n",
            "llama_print_timings:        eval time =     200.28 ms /     5 runs   (   40.06 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    5358.61 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1482.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3618.03 ms /   674 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
            "llama_print_timings:        eval time =     236.89 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    4139.07 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.58 ms /     7 runs   (    1.08 ms per token,   923.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     217.68 ms /    34 tokens (    6.40 ms per token,   156.19 tokens per second)\n",
            "llama_print_timings:        eval time =     236.75 ms /     6 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =     514.23 ms /    40 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1850.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2867.46 ms /   539 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
            "llama_print_timings:        eval time =     233.96 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3299.80 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1901.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     173.06 ms /    32 tokens (    5.41 ms per token,   184.91 tokens per second)\n",
            "llama_print_timings:        eval time =     231.97 ms /     6 runs   (   38.66 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =     436.73 ms /    38 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1830.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4851.84 ms /   894 tokens (    5.43 ms per token,   184.26 tokens per second)\n",
            "llama_print_timings:        eval time =     241.39 ms /     6 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5357.03 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     6 runs   (    0.66 ms per token,  1522.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3900.36 ms /   728 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =     197.97 ms /     5 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4407.21 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1875.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5562.67 ms /  1010 tokens (    5.51 ms per token,   181.57 tokens per second)\n",
            "llama_print_timings:        eval time =     201.89 ms /     5 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    6091.00 ms /  1015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     6 runs   (    0.64 ms per token,  1553.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5323.77 ms /   970 tokens (    5.49 ms per token,   182.20 tokens per second)\n",
            "llama_print_timings:        eval time =     201.97 ms /     5 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    5867.09 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.60 ms per token,  1679.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5524.57 ms /  1006 tokens (    5.49 ms per token,   182.10 tokens per second)\n",
            "llama_print_timings:        eval time =     203.13 ms /     5 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6105.65 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     6 runs   (    0.68 ms per token,  1463.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5326.92 ms /   974 tokens (    5.47 ms per token,   182.84 tokens per second)\n",
            "llama_print_timings:        eval time =     203.38 ms /     5 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    5877.44 ms /   979 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1841.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2873.57 ms /   541 tokens (    5.31 ms per token,   188.27 tokens per second)\n",
            "llama_print_timings:        eval time =     236.69 ms /     6 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3407.79 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.11 ms /     9 runs   (    0.57 ms per token,  1762.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4713.44 ms /   866 tokens (    5.44 ms per token,   183.73 tokens per second)\n",
            "llama_print_timings:        eval time =     320.46 ms /     8 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    5336.52 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      37.21 ms /    60 runs   (    0.62 ms per token,  1612.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6002.79 ms /  1088 tokens (    5.52 ms per token,   181.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2455.40 ms /    60 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =    9101.11 ms /  1148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1844.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5039.21 ms /   924 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
            "llama_print_timings:        eval time =     201.40 ms /     5 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5538.08 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1607.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3484.88 ms /   652 tokens (    5.34 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =     236.84 ms /     6 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    4004.35 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3905.74 ms /   725 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
            "llama_print_timings:        eval time =     236.51 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    4499.89 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5948.10 ms /  1080 tokens (    5.51 ms per token,   181.57 tokens per second)\n",
            "llama_print_timings:        eval time =     245.44 ms /     6 runs   (   40.91 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    6569.94 ms /  1086 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      52.51 ms /    92 runs   (    0.57 ms per token,  1752.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4870.44 ms /   890 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3665.14 ms /    91 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    9239.40 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     6 runs   (    0.58 ms per token,  1710.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     228.05 ms /    39 tokens (    5.85 ms per token,   171.01 tokens per second)\n",
            "llama_print_timings:        eval time =     199.27 ms /     5 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =     459.16 ms /    44 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2858.96 ms /   543 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =     233.49 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3265.63 ms /   549 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     126.91 ms /    21 tokens (    6.04 ms per token,   165.48 tokens per second)\n",
            "llama_print_timings:        eval time =     234.23 ms /     6 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =     393.40 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      35.51 ms /    62 runs   (    0.57 ms per token,  1746.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4866.48 ms /   891 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2453.61 ms /    61 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7895.19 ms /   952 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1903.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2460.71 ms /   470 tokens (    5.24 ms per token,   191.00 tokens per second)\n",
            "llama_print_timings:        eval time =     233.99 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2843.36 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1694.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.12 ms /   472 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =     233.11 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2850.66 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3904.48 ms /   723 tokens (    5.40 ms per token,   185.17 tokens per second)\n",
            "llama_print_timings:        eval time =     195.67 ms /     5 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    4451.86 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1776.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3750.26 ms /   702 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =     196.61 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    4150.83 ms /   707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     6 runs   (    0.64 ms per token,  1559.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4855.45 ms /   896 tokens (    5.42 ms per token,   184.53 tokens per second)\n",
            "llama_print_timings:        eval time =     200.88 ms /     5 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    5343.70 ms /   901 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      43.73 ms /    68 runs   (    0.64 ms per token,  1554.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     224.41 ms /    35 tokens (    6.41 ms per token,   155.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.72 ms /    67 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    3288.84 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     142.51 ms /   256 runs   (    0.56 ms per token,  1796.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1774.48 ms /   344 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
            "llama_print_timings:        eval time =    9969.99 ms /   256 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12885.48 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.07 ms /     9 runs   (    0.56 ms per token,  1774.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4579.07 ms /   848 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
            "llama_print_timings:        eval time =     320.97 ms /     8 runs   (   40.12 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    5162.47 ms /   856 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.70 ms /     9 runs   (    0.63 ms per token,  1578.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4809.04 ms /   883 tokens (    5.45 ms per token,   183.61 tokens per second)\n",
            "llama_print_timings:        eval time =     321.88 ms /     8 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5432.29 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2432.76 ms /   462 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =     234.63 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2914.18 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1521.35 ms /   296 tokens (    5.14 ms per token,   194.56 tokens per second)\n",
            "llama_print_timings:        eval time =     269.44 ms /     7 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    1903.57 ms /   303 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      52.75 ms /    88 runs   (    0.60 ms per token,  1668.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5001.28 ms /   920 tokens (    5.44 ms per token,   183.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3519.03 ms /    87 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    9133.39 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.56 ms /    13 runs   (    0.50 ms per token,  1981.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5384.47 ms /   984 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
            "llama_print_timings:        eval time =     528.13 ms /    13 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6291.21 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the GENERAL MILLS INC?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     6 runs   (    0.62 ms per token,  1604.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5046.29 ms /   925 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =     201.66 ms /     5 runs   (   40.33 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    5532.55 ms /   930 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5534.01 ms /  1005 tokens (    5.51 ms per token,   181.60 tokens per second)\n",
            "llama_print_timings:        eval time =     201.89 ms /     5 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    6148.18 ms /  1010 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     154.59 ms /   256 runs   (    0.60 ms per token,  1655.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     934.42 ms /   183 tokens (    5.11 ms per token,   195.84 tokens per second)\n",
            "llama_print_timings:        eval time =    9798.94 ms /   255 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =   11827.86 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3847.66 ms /   715 tokens (    5.38 ms per token,   185.83 tokens per second)\n",
            "llama_print_timings:        eval time =     237.07 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    4306.92 ms /   721 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2815.68 ms /   532 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =     235.69 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3220.82 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      35.08 ms /    65 runs   (    0.54 ms per token,  1852.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4826.33 ms /   884 tokens (    5.46 ms per token,   183.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2577.60 ms /    64 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    7967.52 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1818.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4164.41 ms /   770 tokens (    5.41 ms per token,   184.90 tokens per second)\n",
            "llama_print_timings:        eval time =     197.18 ms /     5 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    4594.78 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1830.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5865.28 ms /  1059 tokens (    5.54 ms per token,   180.55 tokens per second)\n",
            "llama_print_timings:        eval time =     203.61 ms /     5 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    6502.92 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4816.34 ms /   886 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
            "llama_print_timings:        eval time =     201.36 ms /     5 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5285.13 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     6 runs   (    0.67 ms per token,  1501.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4934.32 ms /   901 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =     201.30 ms /     5 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    5519.44 ms /   906 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     9 runs   (    0.54 ms per token,  1866.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4772.07 ms /   879 tokens (    5.43 ms per token,   184.20 tokens per second)\n",
            "llama_print_timings:        eval time =     321.17 ms /     8 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5384.67 ms /   887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2774.19 ms /   527 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =     236.55 ms /     6 runs   (   39.42 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3178.56 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     7 runs   (    0.73 ms per token,  1373.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1645.60 ms /   314 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     233.38 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2011.77 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     7 runs   (    0.73 ms per token,  1371.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     884.62 ms /   165 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =     231.35 ms /     6 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    1244.83 ms /   171 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2173.53 ms /   416 tokens (    5.22 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =     269.44 ms /     7 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2665.44 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1763.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1098.63 ms /   204 tokens (    5.39 ms per token,   185.69 tokens per second)\n",
            "llama_print_timings:        eval time =     229.60 ms /     6 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    1417.04 ms /   210 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      43.95 ms /    68 runs   (    0.65 ms per token,  1547.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5565.73 ms /  1014 tokens (    5.49 ms per token,   182.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2731.82 ms /    67 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    8953.04 ms /  1081 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4876.06 ms /   895 tokens (    5.45 ms per token,   183.55 tokens per second)\n",
            "llama_print_timings:        eval time =     241.90 ms /     6 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5507.10 ms /   901 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1786.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3936.15 ms /   731 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =     197.42 ms /     5 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    4399.36 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     7 runs   (    0.72 ms per token,  1398.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1689.78 ms /   328 tokens (    5.15 ms per token,   194.11 tokens per second)\n",
            "llama_print_timings:        eval time =     234.68 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2063.76 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.08 ms /     7 runs   (    0.73 ms per token,  1376.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     924.29 ms /   176 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =     231.80 ms /     6 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    1290.59 ms /   182 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     7 runs   (    0.71 ms per token,  1398.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     929.47 ms /   176 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =     272.14 ms /     7 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    1344.68 ms /   183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3350.88 ms /   627 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =     234.93 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3829.36 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1770.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3422.60 ms /   640 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
            "llama_print_timings:        eval time =     235.96 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3920.38 ms /   646 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.95 ms /     7 runs   (    0.71 ms per token,  1413.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.79 ms /   469 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
            "llama_print_timings:        eval time =     234.19 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2916.20 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1685.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4776.85 ms /   874 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
            "llama_print_timings:        eval time =     201.61 ms /     5 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5424.69 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.04 ms /     6 runs   (    0.51 ms per token,  1975.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5986.38 ms /  1084 tokens (    5.52 ms per token,   181.08 tokens per second)\n",
            "llama_print_timings:        eval time =     204.40 ms /     5 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    6548.68 ms /  1089 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1917.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5837.12 ms /  1050 tokens (    5.56 ms per token,   179.88 tokens per second)\n",
            "llama_print_timings:        eval time =     203.37 ms /     5 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    6529.72 ms /  1055 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.36 ms /   562 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =     233.10 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3420.13 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     6 runs   (    0.60 ms per token,  1670.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3483.67 ms /   655 tokens (    5.32 ms per token,   188.02 tokens per second)\n",
            "llama_print_timings:        eval time =     199.33 ms /     5 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    3930.76 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3754.06 ms /   688 tokens (    5.46 ms per token,   183.27 tokens per second)\n",
            "llama_print_timings:        eval time =     239.15 ms /     6 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    4419.64 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.91 ms /   427 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =     229.88 ms /     6 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2643.35 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1750.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.94 ms /   434 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =     233.56 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2683.01 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1914.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2506.08 ms /   475 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =     235.93 ms /     6 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2918.53 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1891.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5773.07 ms /  1045 tokens (    5.52 ms per token,   181.01 tokens per second)\n",
            "llama_print_timings:        eval time =     202.97 ms /     5 runs   (   40.59 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    6431.39 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1698.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2951.64 ms /   560 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =     236.16 ms /     6 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3374.34 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1825.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3625.71 ms /   680 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =     196.69 ms /     5 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    4040.91 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3767.37 ms /   698 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =     195.98 ms /     5 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    4311.79 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1854.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4299.81 ms /   794 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =     238.09 ms /     6 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4794.81 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1840.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3709.90 ms /   691 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
            "llama_print_timings:        eval time =     195.92 ms /     5 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4129.59 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1813.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5631.64 ms /  1022 tokens (    5.51 ms per token,   181.47 tokens per second)\n",
            "llama_print_timings:        eval time =     244.33 ms /     6 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    6311.58 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1797.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5757.18 ms /  1046 tokens (    5.50 ms per token,   181.69 tokens per second)\n",
            "llama_print_timings:        eval time =     203.17 ms /     5 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6265.51 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3412.78 ms /   635 tokens (    5.37 ms per token,   186.07 tokens per second)\n",
            "llama_print_timings:        eval time =     196.48 ms /     5 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3936.54 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1811.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3802.11 ms /   712 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =     238.42 ms /     6 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4256.38 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     102.88 ms /   256 runs   (    0.40 ms per token,  2488.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5621.33 ms /  1024 tokens (    5.49 ms per token,   182.16 tokens per second)\n",
            "llama_print_timings:        eval time =   10519.06 ms /   256 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =   17420.65 ms /  1280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4319.55 ms /   798 tokens (    5.41 ms per token,   184.74 tokens per second)\n",
            "llama_print_timings:        eval time =     240.74 ms /     6 runs   (   40.12 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    4927.75 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3757.16 ms /   699 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
            "llama_print_timings:        eval time =     239.28 ms /     6 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    4223.29 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1571.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5193.04 ms /   950 tokens (    5.47 ms per token,   182.94 tokens per second)\n",
            "llama_print_timings:        eval time =     243.27 ms /     6 runs   (   40.54 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    5748.58 ms /   956 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5158.14 ms /   939 tokens (    5.49 ms per token,   182.04 tokens per second)\n",
            "llama_print_timings:        eval time =     241.25 ms /     6 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5800.05 ms /   945 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1880.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2955.22 ms /   559 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =     193.86 ms /     5 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3330.06 ms /   564 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     100.85 ms /   256 runs   (    0.39 ms per token,  2538.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5616.18 ms /  1021 tokens (    5.50 ms per token,   181.80 tokens per second)\n",
            "llama_print_timings:        eval time =   10478.21 ms /   255 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =   17345.07 ms /  1276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2564.54 ms /   483 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =     231.40 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    3055.89 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1650.79 ms /   312 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =     272.42 ms /     7 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2043.09 ms /   319 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.32 ms /   402 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     229.82 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2482.78 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2860.72 ms /   541 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =     234.79 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3261.83 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.29 ms /     7 runs   (    0.61 ms per token,  1630.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2425.11 ms /   464 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =     235.14 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2856.04 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1663.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2572.76 ms /   487 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
            "llama_print_timings:        eval time =     236.52 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3057.41 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2550.04 ms /   484 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =     233.38 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2941.18 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1902.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.43 ms /   517 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
            "llama_print_timings:        eval time =     237.32 ms /     6 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    3121.36 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1818.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.35 ms /   471 tokens (    5.23 ms per token,   191.05 tokens per second)\n",
            "llama_print_timings:        eval time =     234.32 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2847.36 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1547.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1956.93 ms /   376 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
            "llama_print_timings:        eval time =     272.74 ms /     7 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2457.17 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1697.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2470.14 ms /   466 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =     232.03 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2903.89 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1770.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2420.95 ms /   462 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =     233.29 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2799.28 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1836.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3665.97 ms /   686 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =     198.18 ms /     5 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    4071.67 ms /   691 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     6 runs   (    0.63 ms per token,  1595.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.83 ms /   548 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =     196.87 ms /     5 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3445.65 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1540.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2385.21 ms /   452 tokens (    5.28 ms per token,   189.50 tokens per second)\n",
            "llama_print_timings:        eval time =     232.46 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2820.24 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1699.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2774.27 ms /   523 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =     235.16 ms /     6 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3188.22 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.96 ms /     6 runs   (    0.49 ms per token,  2029.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3307.15 ms /   624 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
            "llama_print_timings:        eval time =     237.14 ms /     6 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3736.04 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     6 runs   (    0.67 ms per token,  1502.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2784.59 ms /   523 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =     195.60 ms /     5 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3235.53 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1839.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3134.57 ms /   590 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =     198.14 ms /     5 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    3561.87 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.00 ms /     6 runs   (    0.50 ms per token,  2003.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4574.99 ms /   843 tokens (    5.43 ms per token,   184.26 tokens per second)\n",
            "llama_print_timings:        eval time =     200.28 ms /     5 runs   (   40.06 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    5048.37 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.81 ms /    64 runs   (    0.54 ms per token,  1838.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5293.77 ms /   965 tokens (    5.49 ms per token,   182.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2553.70 ms /    63 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    8495.41 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1762.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3752.63 ms /   698 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
            "llama_print_timings:        eval time =     198.97 ms /     5 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4202.88 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     6 runs   (    0.71 ms per token,  1411.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3026.47 ms /   560 tokens (    5.40 ms per token,   185.03 tokens per second)\n",
            "llama_print_timings:        eval time =     199.17 ms /     5 runs   (   39.83 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    3456.50 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1860.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3681.91 ms /   688 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =     195.63 ms /     5 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    4210.80 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.95 ms /    13 runs   (    0.53 ms per token,  1869.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3844.05 ms /   716 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
            "llama_print_timings:        eval time =     473.41 ms /    12 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4573.69 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What employee benefits does the Walmart Inc. offer?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1776.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.96 ms /   492 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
            "llama_print_timings:        eval time =     235.17 ms /     6 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2991.61 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.55 ms per token,  1802.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3723.47 ms /   690 tokens (    5.40 ms per token,   185.31 tokens per second)\n",
            "llama_print_timings:        eval time =     195.28 ms /     5 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4258.97 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1986.21 ms /   382 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
            "llama_print_timings:        eval time =     230.65 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2350.47 ms /   388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1770.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     641.01 ms /   116 tokens (    5.53 ms per token,   180.96 tokens per second)\n",
            "llama_print_timings:        eval time =     231.22 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =     930.37 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2950.95 ms /   559 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =     233.88 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3367.41 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1757.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2550.95 ms /   486 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     234.75 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2956.16 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1573.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1955.70 ms /   376 tokens (    5.20 ms per token,   192.26 tokens per second)\n",
            "llama_print_timings:        eval time =     271.71 ms /     7 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2451.50 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1685.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.18 ms /   392 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =     273.14 ms /     7 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2534.41 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1855.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3125.59 ms /   592 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =     275.35 ms /     7 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3581.67 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1807.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2463.18 ms /   471 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
            "llama_print_timings:        eval time =     235.18 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2851.56 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5245.08 ms /   956 tokens (    5.49 ms per token,   182.27 tokens per second)\n",
            "llama_print_timings:        eval time =     243.47 ms /     6 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    5907.37 ms /   962 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1774.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3798.64 ms /   710 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =     197.78 ms /     5 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    4214.46 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1783.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.67 ms /   432 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =     268.90 ms /     7 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2667.59 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     6 runs   (    0.66 ms per token,  1525.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2950.03 ms /   557 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =     196.36 ms /     5 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3367.09 ms /   562 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "Total score for approach 2 and distance function cosine is 0.4055727554179567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(2, 'ip')"
      ],
      "metadata": {
        "id": "Y3m_VPxW3kL1",
        "outputId": "b785c86e-1b95-494d-c94c-76c4dbb8390c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.95 ms /     6 runs   (    0.49 ms per token,  2034.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5998.57 ms /  1083 tokens (    5.54 ms per token,   180.54 tokens per second)\n",
            "llama_print_timings:        eval time =     201.68 ms /     5 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    6582.03 ms /  1088 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1532.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5040.94 ms /   926 tokens (    5.44 ms per token,   183.70 tokens per second)\n",
            "llama_print_timings:        eval time =     242.85 ms /     6 runs   (   40.48 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    5580.38 ms /   932 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1911.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4405.02 ms /   814 tokens (    5.41 ms per token,   184.79 tokens per second)\n",
            "llama_print_timings:        eval time =     239.33 ms /     6 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    5011.03 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1803.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5088.15 ms /   930 tokens (    5.47 ms per token,   182.78 tokens per second)\n",
            "llama_print_timings:        eval time =     240.85 ms /     6 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5677.26 ms /   936 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1665.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2734.17 ms /   520 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =     235.66 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3211.74 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2738.03 ms /   516 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =     231.81 ms /     6 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    3224.45 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5037.64 ms /   923 tokens (    5.46 ms per token,   183.22 tokens per second)\n",
            "llama_print_timings:        eval time =     240.87 ms /     6 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5569.29 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     7 runs   (    0.65 ms per token,  1535.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4350.40 ms /   807 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
            "llama_print_timings:        eval time =     239.06 ms /     6 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4906.35 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      55.01 ms /    96 runs   (    0.57 ms per token,  1745.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5962.62 ms /  1078 tokens (    5.53 ms per token,   180.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3891.48 ms /    95 runs   (   40.96 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =   10562.25 ms /  1173 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5015.17 ms /   920 tokens (    5.45 ms per token,   183.44 tokens per second)\n",
            "llama_print_timings:        eval time =     282.99 ms /     7 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    5699.92 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1854.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6003.54 ms /  1087 tokens (    5.52 ms per token,   181.06 tokens per second)\n",
            "llama_print_timings:        eval time =     204.07 ms /     5 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    6522.54 ms /  1092 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4738.90 ms /   870 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
            "llama_print_timings:        eval time =     240.26 ms /     6 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    5353.00 ms /   876 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.61 ms /     6 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4084.58 ms /   759 tokens (    5.38 ms per token,   185.82 tokens per second)\n",
            "llama_print_timings:        eval time =     199.84 ms /     5 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    4523.96 ms /   764 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.11 ms /     9 runs   (    0.57 ms per token,  1760.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3987.96 ms /   743 tokens (    5.37 ms per token,   186.31 tokens per second)\n",
            "llama_print_timings:        eval time =     317.00 ms /     8 runs   (   39.63 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4554.01 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5350.93 ms /   976 tokens (    5.48 ms per token,   182.40 tokens per second)\n",
            "llama_print_timings:        eval time =     241.68 ms /     6 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    6053.64 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1876.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5234.74 ms /   958 tokens (    5.46 ms per token,   183.01 tokens per second)\n",
            "llama_print_timings:        eval time =     242.95 ms /     6 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    5804.73 ms /   964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      66.76 ms /   101 runs   (    0.66 ms per token,  1512.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1310.97 ms /   254 tokens (    5.16 ms per token,   193.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3847.93 ms /   100 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    5735.34 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1934.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5370.64 ms /   978 tokens (    5.49 ms per token,   182.10 tokens per second)\n",
            "llama_print_timings:        eval time =     201.59 ms /     5 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5892.85 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     6 runs   (    0.63 ms per token,  1581.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6005.99 ms /  1088 tokens (    5.52 ms per token,   181.15 tokens per second)\n",
            "llama_print_timings:        eval time =     245.79 ms /     6 runs   (   40.96 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    6729.62 ms /  1094 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.16 ms /     9 runs   (    0.57 ms per token,  1743.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4024.14 ms /   747 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
            "llama_print_timings:        eval time =     317.81 ms /     8 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4603.12 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1759.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2507.55 ms /   478 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =     234.84 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2912.42 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      63.45 ms /   107 runs   (    0.59 ms per token,  1686.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4126.83 ms /   768 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4228.89 ms /   106 runs   (   39.90 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    9041.64 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     148.06 ms /   256 runs   (    0.58 ms per token,  1729.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2895.72 ms /   546 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
            "llama_print_timings:        eval time =   10063.17 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   14106.57 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      51.59 ms /    79 runs   (    0.65 ms per token,  1531.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5995.01 ms /  1086 tokens (    5.52 ms per token,   181.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3197.80 ms /    78 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    9894.81 ms /  1164 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.35 ms /     7 runs   (    0.62 ms per token,  1608.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.04 ms /   525 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =     233.91 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3171.98 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2680.93 ms /   507 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =     237.50 ms /     6 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    3071.18 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1486.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2554.71 ms /   487 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =     236.36 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2956.93 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1507.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1547.71 ms /   283 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =     234.92 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    1952.26 ms /   289 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1910.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3811.00 ms /   710 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =     199.19 ms /     5 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4260.62 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3985.61 ms /   740 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
            "llama_print_timings:        eval time =     197.84 ms /     5 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    4399.55 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1508.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.28 ms /   429 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =     234.03 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2642.64 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2920.00 ms /   549 tokens (    5.32 ms per token,   188.01 tokens per second)\n",
            "llama_print_timings:        eval time =     236.64 ms /     6 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3437.31 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1773.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2378.19 ms /   456 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =     233.51 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2755.14 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.13 ms /   394 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =     233.29 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2427.41 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1892.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3036.26 ms /   573 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
            "llama_print_timings:        eval time =     233.65 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3448.83 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1817.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     271.45 ms /     7 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =     295.50 ms /     7 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /     7 runs   (    0.63 ms per token,  1582.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1870.11 ms /   355 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =     231.40 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2300.88 ms /   361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2040.53 ms /   392 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
            "llama_print_timings:        eval time =     233.67 ms /     6 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2443.88 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.81 ms /     6 runs   (    0.47 ms per token,  2134.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5891.88 ms /  1070 tokens (    5.51 ms per token,   181.61 tokens per second)\n",
            "llama_print_timings:        eval time =     203.51 ms /     5 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    6402.28 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1510.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.90 ms /   466 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =     233.25 ms /     6 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2861.64 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.05 ms /    13 runs   (    0.54 ms per token,  1842.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3581.73 ms /   666 tokens (    5.38 ms per token,   185.94 tokens per second)\n",
            "llama_print_timings:        eval time =     475.14 ms /    12 runs   (   39.60 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4368.09 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any tax-related risks or benefits for the COCA COLA CO mentioned?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3345.74 ms /   629 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
            "llama_print_timings:        eval time =     197.29 ms /     5 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3738.31 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     9 runs   (    0.52 ms per token,  1935.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3930.65 ms /   735 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
            "llama_print_timings:        eval time =     318.20 ms /     8 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    4471.87 ms /   743 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.81 ms /     7 runs   (    0.69 ms per token,  1455.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2828.27 ms /   530 tokens (    5.34 ms per token,   187.39 tokens per second)\n",
            "llama_print_timings:        eval time =     234.21 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3353.43 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1795.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.15 ms /   453 tokens (    5.23 ms per token,   191.05 tokens per second)\n",
            "llama_print_timings:        eval time =     231.01 ms /     6 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2743.25 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4663.28 ms /   864 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =     281.29 ms /     7 runs   (   40.18 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    5209.62 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1905.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4857.28 ms /   893 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
            "llama_print_timings:        eval time =     240.85 ms /     6 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5464.54 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1793.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2722.30 ms /   517 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =     235.52 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3124.75 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1704.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1261.58 ms /   238 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =     230.84 ms /     6 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    1581.60 ms /   244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       2.98 ms /     6 runs   (    0.50 ms per token,  2014.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3928.30 ms /   731 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
            "llama_print_timings:        eval time =     198.96 ms /     5 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4345.25 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1913.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3498.07 ms /   653 tokens (    5.36 ms per token,   186.67 tokens per second)\n",
            "llama_print_timings:        eval time =     198.97 ms /     5 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4007.32 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.86 ms /   413 tokens (    5.22 ms per token,   191.48 tokens per second)\n",
            "llama_print_timings:        eval time =     231.56 ms /     6 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2523.07 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1880.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1835.37 ms /   347 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =     230.70 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2181.86 ms /   353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.27 ms /   447 tokens (    5.21 ms per token,   191.91 tokens per second)\n",
            "llama_print_timings:        eval time =     233.58 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2698.16 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1487.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.92 ms /   436 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =     231.88 ms /     6 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2683.11 ms /   442 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1824.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5051.66 ms /   927 tokens (    5.45 ms per token,   183.50 tokens per second)\n",
            "llama_print_timings:        eval time =     240.19 ms /     6 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    5667.81 ms /   933 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1823.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5178.94 ms /   952 tokens (    5.44 ms per token,   183.82 tokens per second)\n",
            "llama_print_timings:        eval time =     201.38 ms /     5 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5641.65 ms /   957 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.38 ms /     7 runs   (    0.77 ms per token,  1301.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2781.58 ms /   524 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =     236.42 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3265.74 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2299.50 ms /   440 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =     230.45 ms /     6 runs   (   38.41 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2715.92 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2639.64 ms /   504 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
            "llama_print_timings:        eval time =     274.38 ms /     7 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3074.79 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1944.32 ms /   375 tokens (    5.18 ms per token,   192.87 tokens per second)\n",
            "llama_print_timings:        eval time =     233.23 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2300.80 ms /   381 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1547.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3804.70 ms /   711 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
            "llama_print_timings:        eval time =     239.53 ms /     6 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    4340.36 ms /   717 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1875.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4179.33 ms /   776 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
            "llama_print_timings:        eval time =     199.39 ms /     5 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    4713.56 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1817.66 ms /   352 tokens (    5.16 ms per token,   193.66 tokens per second)\n",
            "llama_print_timings:        eval time =     271.44 ms /     7 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2224.36 ms /   359 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1776.71 ms /   344 tokens (    5.16 ms per token,   193.62 tokens per second)\n",
            "llama_print_timings:        eval time =     231.55 ms /     6 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2127.29 ms /   350 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /     7 runs   (    0.63 ms per token,  1582.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.26 ms /   468 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =     233.42 ms /     6 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2862.17 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1696.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5300.55 ms /   968 tokens (    5.48 ms per token,   182.62 tokens per second)\n",
            "llama_print_timings:        eval time =     284.01 ms /     7 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    6025.29 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1796.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2818.33 ms /   536 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =     234.05 ms /     6 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3235.43 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      89.12 ms /   148 runs   (    0.60 ms per token,  1660.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5335.48 ms /   975 tokens (    5.47 ms per token,   182.74 tokens per second)\n",
            "llama_print_timings:        eval time =    5987.87 ms /   147 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =   12246.06 ms /  1122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2813.05 ms /   530 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =     233.98 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3235.01 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.68 ms /     7 runs   (    0.67 ms per token,  1494.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3046.06 ms /   576 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
            "llama_print_timings:        eval time =     276.08 ms /     7 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3622.60 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2824.20 ms /   533 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     235.50 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3286.67 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1875.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     171.46 ms /    30 tokens (    5.72 ms per token,   174.97 tokens per second)\n",
            "llama_print_timings:        eval time =     234.03 ms /     6 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =     439.74 ms /    36 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1840.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.12 ms /   578 tokens (    5.33 ms per token,   187.59 tokens per second)\n",
            "llama_print_timings:        eval time =     194.76 ms /     5 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3468.93 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.53 ms /     7 runs   (    0.65 ms per token,  1546.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5336.63 ms /   973 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
            "llama_print_timings:        eval time =     249.28 ms /     6 runs   (   41.55 ms per token,    24.07 tokens per second)\n",
            "llama_print_timings:       total time =    6005.35 ms /   979 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5342.78 ms /   975 tokens (    5.48 ms per token,   182.49 tokens per second)\n",
            "llama_print_timings:        eval time =     243.36 ms /     6 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    5943.23 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     6 runs   (    0.61 ms per token,  1651.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5383.31 ms /   983 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =     202.72 ms /     5 runs   (   40.54 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    5966.83 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1839.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4919.45 ms /   903 tokens (    5.45 ms per token,   183.56 tokens per second)\n",
            "llama_print_timings:        eval time =     201.05 ms /     5 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5520.18 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2859.34 ms /   538 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
            "llama_print_timings:        eval time =     236.55 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3296.57 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.76 ms /     7 runs   (    0.68 ms per token,  1470.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3087.77 ms /   584 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =     276.70 ms /     7 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3622.64 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1528.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2393.18 ms /   451 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =     233.92 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2897.39 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2864.69 ms /   540 tokens (    5.30 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =     236.04 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3321.31 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      48.71 ms /    73 runs   (    0.67 ms per token,  1498.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5426.62 ms /   990 tokens (    5.48 ms per token,   182.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2928.26 ms /    72 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    9047.33 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      41.99 ms /    71 runs   (    0.59 ms per token,  1690.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     140.46 ms /    24 tokens (    5.85 ms per token,   170.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2877.43 ms /    71 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    3365.94 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1809.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4949.14 ms /   907 tokens (    5.46 ms per token,   183.26 tokens per second)\n",
            "llama_print_timings:        eval time =     240.65 ms /     6 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    5545.59 ms /   913 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      40.69 ms /    71 runs   (    0.57 ms per token,  1744.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5297.71 ms /   967 tokens (    5.48 ms per token,   182.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2837.46 ms /    70 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    8845.83 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      58.02 ms /    87 runs   (    0.67 ms per token,  1499.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5277.41 ms /   965 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3495.01 ms /    86 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    9613.39 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1819.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2819.61 ms /   536 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =     235.21 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3260.00 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      37.03 ms /    66 runs   (    0.56 ms per token,  1782.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3083.58 ms /   584 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2558.68 ms /    65 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6070.43 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.02 ms /     7 runs   (    0.72 ms per token,  1395.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2438.99 ms /   463 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =     236.10 ms /     6 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2978.14 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1695.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2429.18 ms /   463 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =     230.92 ms /     6 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2870.74 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1857.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3302.47 ms /   618 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =     233.76 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3781.77 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2463.64 ms /   468 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
            "llama_print_timings:        eval time =     232.84 ms /     6 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2893.11 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1491.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2912.83 ms /   550 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =     235.53 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3457.30 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1878.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3673.09 ms /   687 tokens (    5.35 ms per token,   187.04 tokens per second)\n",
            "llama_print_timings:        eval time =     236.13 ms /     6 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    4220.66 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     6 runs   (    0.62 ms per token,  1601.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     132.85 ms /    24 tokens (    5.54 ms per token,   180.66 tokens per second)\n",
            "llama_print_timings:        eval time =     236.25 ms /     6 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =     410.23 ms /    30 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.71 ms /   469 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =     233.35 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2884.37 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1756.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3574.01 ms /   668 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
            "llama_print_timings:        eval time =     197.84 ms /     5 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    4077.29 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2437.85 ms /   462 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =     233.73 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2953.21 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1703.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2773.12 ms /   524 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =     233.85 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3208.02 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1794.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     205.05 ms /    34 tokens (    6.03 ms per token,   165.81 tokens per second)\n",
            "llama_print_timings:        eval time =     190.34 ms /     5 runs   (   38.07 ms per token,    26.27 tokens per second)\n",
            "llama_print_timings:       total time =     430.38 ms /    39 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1716.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2422.78 ms /   460 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =     234.36 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2854.08 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1482.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2639.73 ms /   504 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
            "llama_print_timings:        eval time =     234.11 ms /     6 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3064.64 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1531.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2010.07 ms /   384 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =     233.06 ms /     6 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2513.27 ms /   390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1766.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3446.01 ms /   648 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
            "llama_print_timings:        eval time =     196.84 ms /     5 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3897.34 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1705.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2116.10 ms /   404 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =     230.83 ms /     6 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2510.16 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     6 runs   (    0.62 ms per token,  1609.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3484.99 ms /   653 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =     196.51 ms /     5 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3922.72 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.57 ms /    60 runs   (    0.58 ms per token,  1735.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5250.10 ms /   958 tokens (    5.48 ms per token,   182.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2387.21 ms /    59 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8314.95 ms /  1017 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1891.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.78 ms /   525 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
            "llama_print_timings:        eval time =     233.92 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3200.80 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      72.42 ms /   124 runs   (    0.58 ms per token,  1712.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4833.60 ms /   887 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
            "llama_print_timings:        eval time =    4964.87 ms /   123 runs   (   40.36 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =   10693.29 ms /  1010 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.18 ms /     9 runs   (    0.69 ms per token,  1457.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4209.37 ms /   781 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
            "llama_print_timings:        eval time =     318.36 ms /     8 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4839.08 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1765.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2655.97 ms /   499 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =     232.26 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    3193.16 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2818.25 ms /   535 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =     233.56 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    3245.41 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1807.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5374.46 ms /   984 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
            "llama_print_timings:        eval time =     243.76 ms /     6 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    5971.50 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.14 ms /    58 runs   (    0.59 ms per token,  1698.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5250.46 ms /   956 tokens (    5.49 ms per token,   182.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2307.43 ms /    57 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    8257.15 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1701.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1479.87 ms /   288 tokens (    5.14 ms per token,   194.61 tokens per second)\n",
            "llama_print_timings:        eval time =     189.45 ms /     5 runs   (   37.89 ms per token,    26.39 tokens per second)\n",
            "llama_print_timings:       total time =    1785.66 ms /   293 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1904.31 ms /   368 tokens (    5.17 ms per token,   193.25 tokens per second)\n",
            "llama_print_timings:        eval time =     230.47 ms /     6 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2276.03 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1516.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3231.12 ms /   605 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =     235.85 ms /     6 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3824.77 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1909.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2386.23 ms /   455 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =     232.48 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2807.78 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1688.57 ms /   323 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
            "llama_print_timings:        eval time =     228.56 ms /     6 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    2047.85 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1550.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1465.15 ms /   271 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =     236.08 ms /     6 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    1821.39 ms /   277 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3086.03 ms /   584 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =     235.05 ms /     6 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3539.42 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1585.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2837.25 ms /   536 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =     274.67 ms /     7 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3452.30 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1646.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2642.22 ms /   504 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =     235.31 ms /     6 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3056.13 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1676.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2447.38 ms /   464 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =     233.69 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2854.04 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1902.05 ms /   366 tokens (    5.20 ms per token,   192.42 tokens per second)\n",
            "llama_print_timings:        eval time =     231.19 ms /     6 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2274.14 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.84 ms /     7 runs   (    0.69 ms per token,  1444.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2915.44 ms /   552 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =     235.24 ms /     6 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3419.93 ms /   558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     148.42 ms /   256 runs   (    0.58 ms per token,  1724.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5434.09 ms /   989 tokens (    5.49 ms per token,   182.00 tokens per second)\n",
            "llama_print_timings:        eval time =   10432.94 ms /   255 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =   17273.11 ms /  1244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4951.91 ms /   909 tokens (    5.45 ms per token,   183.57 tokens per second)\n",
            "llama_print_timings:        eval time =     240.63 ms /     6 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    5479.70 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     7 runs   (    0.63 ms per token,  1594.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2296.48 ms /   437 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =     232.83 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2732.55 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3503.76 ms /   654 tokens (    5.36 ms per token,   186.66 tokens per second)\n",
            "llama_print_timings:        eval time =     236.61 ms /     6 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    4044.68 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1707.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3170.83 ms /   595 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
            "llama_print_timings:        eval time =     234.40 ms /     6 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    3595.73 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1623.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5426.17 ms /   988 tokens (    5.49 ms per token,   182.08 tokens per second)\n",
            "llama_print_timings:        eval time =     243.60 ms /     6 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    6047.59 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.06 ms /     6 runs   (    0.51 ms per token,  1963.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5015.08 ms /   920 tokens (    5.45 ms per token,   183.45 tokens per second)\n",
            "llama_print_timings:        eval time =     241.69 ms /     6 runs   (   40.28 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    5614.44 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1778.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5428.74 ms /   991 tokens (    5.48 ms per token,   182.55 tokens per second)\n",
            "llama_print_timings:        eval time =     203.56 ms /     5 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    5953.64 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.15 ms /     6 runs   (    0.52 ms per token,  1907.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5064.64 ms /   924 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
            "llama_print_timings:        eval time =     201.78 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5680.33 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3128.75 ms /   589 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =     235.73 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3563.19 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      37.75 ms /    65 runs   (    0.58 ms per token,  1721.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5382.11 ms /   981 tokens (    5.49 ms per token,   182.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2606.06 ms /    64 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8626.47 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1910.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     185.33 ms /    31 tokens (    5.98 ms per token,   167.27 tokens per second)\n",
            "llama_print_timings:        eval time =     241.38 ms /     6 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =     457.79 ms /    37 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1920.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3042.10 ms /   576 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =     236.41 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3471.64 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1483.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5378.33 ms /   982 tokens (    5.48 ms per token,   182.58 tokens per second)\n",
            "llama_print_timings:        eval time =     245.01 ms /     6 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    5986.95 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5008.16 ms /   915 tokens (    5.47 ms per token,   182.70 tokens per second)\n",
            "llama_print_timings:        eval time =     201.49 ms /     5 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5571.15 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1918.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3087.08 ms /   584 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =     194.67 ms /     5 runs   (   38.93 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3480.29 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1590.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3676.52 ms /   688 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =     280.00 ms /     7 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    4248.82 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1858.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3143.68 ms /   592 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
            "llama_print_timings:        eval time =     195.23 ms /     5 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3590.87 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1935.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5382.89 ms /   984 tokens (    5.47 ms per token,   182.80 tokens per second)\n",
            "llama_print_timings:        eval time =     203.06 ms /     5 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    5897.71 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1809.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5057.40 ms /   922 tokens (    5.49 ms per token,   182.31 tokens per second)\n",
            "llama_print_timings:        eval time =     201.53 ms /     5 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5674.69 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2289.97 ms /   436 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     232.84 ms /     6 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2676.68 ms /   442 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      39.61 ms /    74 runs   (    0.54 ms per token,  1868.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.88 ms /   580 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
            "llama_print_timings:        eval time =    2874.76 ms /    73 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6380.26 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     6 runs   (    0.66 ms per token,  1505.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3185.11 ms /   595 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
            "llama_print_timings:        eval time =     196.29 ms /     5 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3687.82 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1807.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5379.61 ms /   984 tokens (    5.47 ms per token,   182.91 tokens per second)\n",
            "llama_print_timings:        eval time =     202.41 ms /     5 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    5901.16 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    13 runs   (    0.76 ms per token,  1309.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3982.69 ms /   739 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
            "llama_print_timings:        eval time =     477.84 ms /    12 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    4747.08 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the PayPal Holdings, Inc.'s total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1793.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3100.08 ms /   581 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =     237.09 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    3654.91 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1826.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3130.21 ms /   592 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =     197.64 ms /     5 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3519.51 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1819.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3039.66 ms /   576 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =     237.28 ms /     6 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3465.22 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1855.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     215.87 ms /    36 tokens (    6.00 ms per token,   166.77 tokens per second)\n",
            "llama_print_timings:        eval time =     195.92 ms /     5 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =     443.79 ms /    41 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     7 runs   (    0.63 ms per token,  1595.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3140.89 ms /   592 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =     236.33 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3665.09 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2168.86 ms /   412 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
            "llama_print_timings:        eval time =     230.90 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2599.18 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3175.09 ms /   596 tokens (    5.33 ms per token,   187.71 tokens per second)\n",
            "llama_print_timings:        eval time =     233.04 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3625.84 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1950.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1897.45 ms /   362 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =     230.04 ms /     6 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2256.53 ms /   368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1506.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2596.19 ms /   493 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =     237.14 ms /     6 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3014.86 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1622.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3007.43 ms /   563 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =     234.00 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3545.93 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1767.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3169.21 ms /   597 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =     196.15 ms /     5 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3559.88 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.37 ms /     7 runs   (    0.62 ms per token,  1603.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3215.70 ms /   605 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =     234.62 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3653.41 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     6 runs   (    0.63 ms per token,  1589.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3134.14 ms /   590 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =     196.02 ms /     5 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3585.45 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1679.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3182.76 ms /   598 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =     235.45 ms /     6 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3689.81 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.15 ms /     6 runs   (    0.52 ms per token,  1907.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3084.95 ms /   584 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =     235.72 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3510.38 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1759.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.82 ms /   472 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
            "llama_print_timings:        eval time =     235.04 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2855.79 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.60 ms /     7 runs   (    0.66 ms per token,  1521.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1859.99 ms /   356 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =     231.76 ms /     6 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2257.54 ms /   362 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.11 ms /     7 runs   (    0.73 ms per token,  1369.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1273.18 ms /   244 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =     229.27 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    1675.53 ms /   250 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /     6 runs   (    0.52 ms per token,  1931.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3580.10 ms /   672 tokens (    5.33 ms per token,   187.70 tokens per second)\n",
            "llama_print_timings:        eval time =     237.13 ms /     6 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    4051.86 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1914.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.03 ms /   583 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =     193.78 ms /     5 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3453.65 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1881.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     170.84 ms /    28 tokens (    6.10 ms per token,   163.90 tokens per second)\n",
            "llama_print_timings:        eval time =     194.50 ms /     5 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =     393.60 ms /    33 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.55 ms /     6 runs   (    0.59 ms per token,  1688.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3624.87 ms /   678 tokens (    5.35 ms per token,   187.04 tokens per second)\n",
            "llama_print_timings:        eval time =     199.27 ms /     5 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    4083.48 ms /   683 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3092.65 ms /   584 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =     233.63 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3566.61 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1909.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5324.49 ms /   976 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =     242.53 ms /     6 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    5854.55 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     6 runs   (    0.63 ms per token,  1596.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3125.00 ms /   586 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
            "llama_print_timings:        eval time =     196.71 ms /     5 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3551.55 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1790.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2129.81 ms /   406 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =     233.61 ms /     6 runs   (   38.93 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2568.83 ms /   412 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     154.84 ms /   256 runs   (    0.60 ms per token,  1653.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3980.01 ms /   741 tokens (    5.37 ms per token,   186.18 tokens per second)\n",
            "llama_print_timings:        eval time =   10217.90 ms /   255 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =   15455.22 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3164.03 ms /   594 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =     232.63 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3577.64 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1808.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2466.16 ms /   472 tokens (    5.22 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =     275.36 ms /     7 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2896.93 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1549.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3091.46 ms /   581 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =     238.94 ms /     6 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    3624.55 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1897.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2078.59 ms /   400 tokens (    5.20 ms per token,   192.44 tokens per second)\n",
            "llama_print_timings:        eval time =     271.81 ms /     7 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2489.06 ms /   407 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1876.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3079.18 ms /   583 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =     194.88 ms /     5 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3444.45 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.61 ms /     7 runs   (    0.52 ms per token,  1939.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2422.33 ms /   464 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =     234.12 ms /     6 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2806.55 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1624.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3217.89 ms /   603 tokens (    5.34 ms per token,   187.39 tokens per second)\n",
            "llama_print_timings:        eval time =     235.97 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3724.56 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1807.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1908.70 ms /   368 tokens (    5.19 ms per token,   192.80 tokens per second)\n",
            "llama_print_timings:        eval time =     271.07 ms /     7 runs   (   38.72 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2341.09 ms /   375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2904.44 ms /   552 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =     272.75 ms /     7 runs   (   38.96 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3357.05 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1797.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3169.67 ms /   596 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
            "llama_print_timings:        eval time =     233.49 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3616.26 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1542.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2248.42 ms /   430 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =     233.64 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2675.54 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2263.26 ms /   432 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =     273.12 ms /     7 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2781.99 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1861.23 ms /   360 tokens (    5.17 ms per token,   193.42 tokens per second)\n",
            "llama_print_timings:        eval time =     267.27 ms /     7 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    2254.89 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.92 ms /   517 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =     233.72 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3136.49 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      62.80 ms /    99 runs   (    0.63 ms per token,  1576.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3083.52 ms /   583 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3867.99 ms /    98 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7594.74 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1856.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3165.55 ms /   594 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
            "llama_print_timings:        eval time =     194.99 ms /     5 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3554.63 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1871.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1860.15 ms /   360 tokens (    5.17 ms per token,   193.53 tokens per second)\n",
            "llama_print_timings:        eval time =     233.81 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2223.46 ms /   366 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     6 runs   (    0.70 ms per token,  1423.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4627.33 ms /   856 tokens (    5.41 ms per token,   184.99 tokens per second)\n",
            "llama_print_timings:        eval time =     201.09 ms /     5 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5178.73 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3896.33 ms /   724 tokens (    5.38 ms per token,   185.82 tokens per second)\n",
            "llama_print_timings:        eval time =     198.28 ms /     5 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4393.95 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      42.62 ms /    67 runs   (    0.64 ms per token,  1572.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5564.69 ms /  1013 tokens (    5.49 ms per token,   182.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2686.89 ms /    66 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8860.60 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1652.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3671.81 ms /   684 tokens (    5.37 ms per token,   186.28 tokens per second)\n",
            "llama_print_timings:        eval time =     238.26 ms /     6 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4210.76 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2902.87 ms /   546 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =     233.82 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3317.38 ms /   552 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     6 runs   (    0.64 ms per token,  1563.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4900.83 ms /   900 tokens (    5.45 ms per token,   183.64 tokens per second)\n",
            "llama_print_timings:        eval time =     201.22 ms /     5 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5455.73 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.30 ms /     7 runs   (    0.61 ms per token,  1627.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3636.63 ms /   674 tokens (    5.40 ms per token,   185.34 tokens per second)\n",
            "llama_print_timings:        eval time =     236.55 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    4185.30 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1824.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     216.09 ms /    34 tokens (    6.36 ms per token,   157.34 tokens per second)\n",
            "llama_print_timings:        eval time =     234.62 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =     485.44 ms /    40 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1800.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2859.34 ms /   539 tokens (    5.30 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =     233.26 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3278.13 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1866.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     173.92 ms /    32 tokens (    5.44 ms per token,   183.99 tokens per second)\n",
            "llama_print_timings:        eval time =     233.34 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =     442.67 ms /    38 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1682.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4865.10 ms /   894 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
            "llama_print_timings:        eval time =     243.63 ms /     6 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    5487.81 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1876.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3903.70 ms /   728 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =     195.99 ms /     5 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    4393.64 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1844.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5556.14 ms /  1010 tokens (    5.50 ms per token,   181.78 tokens per second)\n",
            "llama_print_timings:        eval time =     202.05 ms /     5 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    6081.42 ms /  1015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1898.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5337.57 ms /   970 tokens (    5.50 ms per token,   181.73 tokens per second)\n",
            "llama_print_timings:        eval time =     200.86 ms /     5 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    5996.35 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1774.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5512.28 ms /  1006 tokens (    5.48 ms per token,   182.50 tokens per second)\n",
            "llama_print_timings:        eval time =     203.18 ms /     5 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6043.41 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1778.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5342.86 ms /   974 tokens (    5.49 ms per token,   182.30 tokens per second)\n",
            "llama_print_timings:        eval time =     201.64 ms /     5 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    6005.84 ms /   979 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1710.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2857.91 ms /   541 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =     236.14 ms /     6 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3281.81 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.16 ms /     9 runs   (    0.57 ms per token,  1744.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4709.78 ms /   866 tokens (    5.44 ms per token,   183.87 tokens per second)\n",
            "llama_print_timings:        eval time =     320.64 ms /     8 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    5324.67 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.41 ms /    60 runs   (    0.57 ms per token,  1743.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6013.55 ms /  1088 tokens (    5.53 ms per token,   180.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2453.83 ms /    60 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    9186.57 ms /  1148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     6 runs   (    0.64 ms per token,  1558.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5039.21 ms /   924 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
            "llama_print_timings:        eval time =     201.31 ms /     5 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    5598.13 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3490.06 ms /   652 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =     235.97 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    4035.83 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3888.47 ms /   725 tokens (    5.36 ms per token,   186.45 tokens per second)\n",
            "llama_print_timings:        eval time =     238.93 ms /     6 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    4377.92 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     6 runs   (    0.61 ms per token,  1636.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5959.13 ms /  1080 tokens (    5.52 ms per token,   181.23 tokens per second)\n",
            "llama_print_timings:        eval time =     246.19 ms /     6 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    6680.20 ms /  1086 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      53.43 ms /    92 runs   (    0.58 ms per token,  1721.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4848.23 ms /   890 tokens (    5.45 ms per token,   183.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3669.12 ms /    91 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    9121.66 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1781.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     228.18 ms /    39 tokens (    5.85 ms per token,   170.92 tokens per second)\n",
            "llama_print_timings:        eval time =     200.79 ms /     5 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =     464.23 ms /    44 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.48 ms /     7 runs   (    0.64 ms per token,  1563.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2879.93 ms /   543 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
            "llama_print_timings:        eval time =     235.55 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3431.51 ms /   549 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.51 ms /    21 tokens (    6.07 ms per token,   164.70 tokens per second)\n",
            "llama_print_timings:        eval time =     232.71 ms /     6 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =     394.54 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      36.41 ms /    62 runs   (    0.59 ms per token,  1702.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4851.79 ms /   891 tokens (    5.45 ms per token,   183.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2455.99 ms /    61 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    7788.13 ms /   952 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.37 ms /     7 runs   (    0.62 ms per token,  1603.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.46 ms /   470 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =     234.29 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2911.88 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1871.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2475.40 ms /   472 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =     235.57 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2940.79 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1861.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3885.54 ms /   723 tokens (    5.37 ms per token,   186.07 tokens per second)\n",
            "llama_print_timings:        eval time =     198.25 ms /     5 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4299.15 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3753.34 ms /   702 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =     198.79 ms /     5 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    4168.57 ms /   707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     6 runs   (    0.58 ms per token,  1733.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4868.91 ms /   896 tokens (    5.43 ms per token,   184.02 tokens per second)\n",
            "llama_print_timings:        eval time =     199.70 ms /     5 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5448.57 ms /   901 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      37.11 ms /    68 runs   (    0.55 ms per token,  1832.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     223.73 ms /    35 tokens (    6.39 ms per token,   156.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2700.08 ms /    67 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    3157.14 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     141.44 ms /   256 runs   (    0.55 ms per token,  1809.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1774.34 ms /   344 tokens (    5.16 ms per token,   193.88 tokens per second)\n",
            "llama_print_timings:        eval time =    9961.00 ms /   256 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =   12887.39 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     9 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4581.87 ms /   848 tokens (    5.40 ms per token,   185.08 tokens per second)\n",
            "llama_print_timings:        eval time =     321.15 ms /     8 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5168.13 ms /   856 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     9 runs   (    0.55 ms per token,  1834.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4828.76 ms /   883 tokens (    5.47 ms per token,   182.86 tokens per second)\n",
            "llama_print_timings:        eval time =     318.95 ms /     8 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    5588.16 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1696.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2421.33 ms /   462 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
            "llama_print_timings:        eval time =     231.96 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2832.96 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1794.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1521.73 ms /   296 tokens (    5.14 ms per token,   194.52 tokens per second)\n",
            "llama_print_timings:        eval time =     267.24 ms /     7 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    1902.06 ms /   303 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      55.20 ms /    88 runs   (    0.63 ms per token,  1594.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5008.88 ms /   920 tokens (    5.44 ms per token,   183.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3522.66 ms /    87 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    9329.65 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.67 ms /    13 runs   (    0.51 ms per token,  1949.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5374.67 ms /   984 tokens (    5.46 ms per token,   183.08 tokens per second)\n",
            "llama_print_timings:        eval time =     528.32 ms /    13 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6257.59 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the GENERAL MILLS INC?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1758.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5054.39 ms /   925 tokens (    5.46 ms per token,   183.01 tokens per second)\n",
            "llama_print_timings:        eval time =     201.34 ms /     5 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5683.81 ms /   930 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1813.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5513.49 ms /  1005 tokens (    5.49 ms per token,   182.28 tokens per second)\n",
            "llama_print_timings:        eval time =     202.95 ms /     5 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    6054.43 ms /  1010 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     159.34 ms /   256 runs   (    0.62 ms per token,  1606.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     936.74 ms /   183 tokens (    5.12 ms per token,   195.36 tokens per second)\n",
            "llama_print_timings:        eval time =    9798.26 ms /   255 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =   11919.25 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.70 ms /     7 runs   (    0.67 ms per token,  1490.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3845.20 ms /   715 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =     238.22 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4353.50 ms /   721 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1861.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2830.71 ms /   532 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =     231.98 ms /     6 runs   (   38.66 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    3362.77 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      35.17 ms /    65 runs   (    0.54 ms per token,  1848.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4808.56 ms /   884 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2574.03 ms /    64 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7885.91 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     6 runs   (    0.62 ms per token,  1600.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4173.11 ms /   770 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =     198.91 ms /     5 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    4785.87 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1863.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5846.48 ms /  1059 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
            "llama_print_timings:        eval time =     202.95 ms /     5 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    6402.24 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     6 runs   (    0.63 ms per token,  1577.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4816.85 ms /   886 tokens (    5.44 ms per token,   183.94 tokens per second)\n",
            "llama_print_timings:        eval time =     201.31 ms /     5 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    5407.31 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1795.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4927.65 ms /   901 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =     201.57 ms /     5 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5481.60 ms /   906 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     9 runs   (    0.57 ms per token,  1763.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4763.78 ms /   879 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
            "llama_print_timings:        eval time =     321.67 ms /     8 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5384.40 ms /   887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1536.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2793.55 ms /   527 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =     235.76 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3362.33 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1647.00 ms /   314 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =     229.75 ms /     6 runs   (   38.29 ms per token,    26.12 tokens per second)\n",
            "llama_print_timings:       total time =    2003.71 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1678.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     873.73 ms /   165 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =     233.43 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    1184.32 ms /   171 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1671.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2162.33 ms /   416 tokens (    5.20 ms per token,   192.39 tokens per second)\n",
            "llama_print_timings:        eval time =     270.19 ms /     7 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2583.05 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1687.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1097.05 ms /   204 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =     230.59 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    1412.66 ms /   210 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      39.78 ms /    68 runs   (    0.58 ms per token,  1709.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5578.68 ms /  1014 tokens (    5.50 ms per token,   181.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2723.51 ms /    67 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    9004.41 ms /  1081 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4860.21 ms /   895 tokens (    5.43 ms per token,   184.15 tokens per second)\n",
            "llama_print_timings:        eval time =     240.09 ms /     6 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5394.11 ms /   901 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     6 runs   (    0.68 ms per token,  1476.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3943.88 ms /   731 tokens (    5.40 ms per token,   185.35 tokens per second)\n",
            "llama_print_timings:        eval time =     199.14 ms /     5 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    4514.09 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1649.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1693.79 ms /   328 tokens (    5.16 ms per token,   193.65 tokens per second)\n",
            "llama_print_timings:        eval time =     232.17 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2070.63 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1683.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     919.30 ms /   176 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =     232.90 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    1231.79 ms /   182 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1790.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     919.25 ms /   176 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     265.61 ms /     7 runs   (   37.94 ms per token,    26.35 tokens per second)\n",
            "llama_print_timings:       total time =    1265.58 ms /   183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3346.48 ms /   627 tokens (    5.34 ms per token,   187.36 tokens per second)\n",
            "llama_print_timings:        eval time =     234.60 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3803.55 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     7 runs   (    0.65 ms per token,  1536.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3434.53 ms /   640 tokens (    5.37 ms per token,   186.34 tokens per second)\n",
            "llama_print_timings:        eval time =     237.54 ms /     6 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    3973.14 ms /   646 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2474.07 ms /   469 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =     235.51 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2935.85 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4761.73 ms /   874 tokens (    5.45 ms per token,   183.55 tokens per second)\n",
            "llama_print_timings:        eval time =     200.38 ms /     5 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    5248.61 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.01 ms /     6 runs   (    0.50 ms per token,  1990.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6002.37 ms /  1084 tokens (    5.54 ms per token,   180.60 tokens per second)\n",
            "llama_print_timings:        eval time =     203.37 ms /     5 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    6693.41 ms /  1089 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5829.96 ms /  1050 tokens (    5.55 ms per token,   180.10 tokens per second)\n",
            "llama_print_timings:        eval time =     203.74 ms /     5 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    6382.70 ms /  1055 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1570.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2991.47 ms /   562 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
            "llama_print_timings:        eval time =     235.46 ms /     6 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3453.89 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     6 runs   (    0.59 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3505.06 ms /   655 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
            "llama_print_timings:        eval time =     196.91 ms /     5 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    4037.01 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1913.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3726.66 ms /   688 tokens (    5.42 ms per token,   184.62 tokens per second)\n",
            "llama_print_timings:        eval time =     239.80 ms /     6 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    4207.13 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1757.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.27 ms /   427 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =     230.20 ms /     6 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2640.83 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.04 ms /     7 runs   (    0.72 ms per token,  1389.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2292.40 ms /   434 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =     234.22 ms /     6 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2727.89 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1915.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2524.81 ms /   475 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =     233.69 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3028.94 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.05 ms /     6 runs   (    0.51 ms per token,  1967.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5757.40 ms /  1045 tokens (    5.51 ms per token,   181.51 tokens per second)\n",
            "llama_print_timings:        eval time =     203.84 ms /     5 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    6318.89 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.79 ms /     7 runs   (    0.68 ms per token,  1459.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2956.04 ms /   560 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =     237.69 ms /     6 runs   (   39.61 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    3416.31 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.55 ms per token,  1804.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3647.62 ms /   680 tokens (    5.36 ms per token,   186.42 tokens per second)\n",
            "llama_print_timings:        eval time =     196.18 ms /     5 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    4175.39 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1822.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3753.16 ms /   698 tokens (    5.38 ms per token,   185.98 tokens per second)\n",
            "llama_print_timings:        eval time =     199.83 ms /     5 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    4194.67 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1512.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4304.44 ms /   794 tokens (    5.42 ms per token,   184.46 tokens per second)\n",
            "llama_print_timings:        eval time =     238.90 ms /     6 runs   (   39.82 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    4839.18 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     6 runs   (    0.62 ms per token,  1617.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3727.04 ms /   691 tokens (    5.39 ms per token,   185.40 tokens per second)\n",
            "llama_print_timings:        eval time =     197.92 ms /     5 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4267.78 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1857.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5612.84 ms /  1022 tokens (    5.49 ms per token,   182.08 tokens per second)\n",
            "llama_print_timings:        eval time =     244.49 ms /     6 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    6184.52 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1775.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5771.17 ms /  1046 tokens (    5.52 ms per token,   181.25 tokens per second)\n",
            "llama_print_timings:        eval time =     203.02 ms /     5 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    6396.33 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3390.98 ms /   635 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =     195.59 ms /     5 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3798.56 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     6 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3803.82 ms /   712 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
            "llama_print_timings:        eval time =     239.52 ms /     6 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    4265.23 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     104.96 ms /   256 runs   (    0.41 ms per token,  2438.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5638.28 ms /  1024 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
            "llama_print_timings:        eval time =   10512.85 ms /   256 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   17577.93 ms /  1280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4298.64 ms /   798 tokens (    5.39 ms per token,   185.64 tokens per second)\n",
            "llama_print_timings:        eval time =     239.82 ms /     6 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    4792.86 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3749.13 ms /   699 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
            "llama_print_timings:        eval time =     236.70 ms /     6 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4199.26 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5198.74 ms /   950 tokens (    5.47 ms per token,   182.74 tokens per second)\n",
            "llama_print_timings:        eval time =     241.89 ms /     6 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5859.95 ms /   956 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5131.40 ms /   939 tokens (    5.46 ms per token,   182.99 tokens per second)\n",
            "llama_print_timings:        eval time =     241.62 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5653.95 ms /   945 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.55 ms /     6 runs   (    0.93 ms per token,  1080.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2948.01 ms /   559 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
            "llama_print_timings:        eval time =     195.97 ms /     5 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3352.07 ms /   564 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     103.05 ms /   256 runs   (    0.40 ms per token,  2484.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5623.56 ms /  1021 tokens (    5.51 ms per token,   181.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10456.85 ms /   255 runs   (   41.01 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =   17453.91 ms /  1276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2547.43 ms /   483 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =     234.41 ms /     6 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2936.30 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1772.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1648.92 ms /   312 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =     274.54 ms /     7 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2038.35 ms /   319 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1678.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2111.73 ms /   402 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =     229.20 ms /     6 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    2480.48 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.12 ms /     7 runs   (    0.73 ms per token,  1367.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2868.84 ms /   541 tokens (    5.30 ms per token,   188.58 tokens per second)\n",
            "llama_print_timings:        eval time =     236.20 ms /     6 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3403.42 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2425.56 ms /   464 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =     232.29 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2820.12 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1805.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2552.15 ms /   487 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =     232.80 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2939.65 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2549.03 ms /   484 tokens (    5.27 ms per token,   189.88 tokens per second)\n",
            "llama_print_timings:        eval time =     235.27 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2948.60 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1543.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2732.41 ms /   517 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =     234.84 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3210.22 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1849.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2472.29 ms /   471 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
            "llama_print_timings:        eval time =     230.89 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2918.61 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1783.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1943.38 ms /   376 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
            "llama_print_timings:        eval time =     268.88 ms /     7 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2341.81 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1766.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2460.32 ms /   466 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =     235.00 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2853.66 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.36 ms /     7 runs   (    0.62 ms per token,  1605.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2422.90 ms /   462 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =     230.96 ms /     6 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2827.62 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3680.44 ms /   686 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =     196.84 ms /     5 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4228.18 ms /   691 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1763.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2976.88 ms /   548 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =     196.72 ms /     5 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3362.59 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.69 ms /   452 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =     234.27 ms /     6 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2753.03 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1792.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2765.74 ms /   523 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
            "llama_print_timings:        eval time =     234.31 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3168.50 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1821.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3328.64 ms /   624 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =     236.96 ms /     6 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3885.56 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1775.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2769.21 ms /   523 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =     196.51 ms /     5 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3131.47 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3123.13 ms /   590 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =     196.35 ms /     5 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3500.55 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1683.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4579.72 ms /   843 tokens (    5.43 ms per token,   184.07 tokens per second)\n",
            "llama_print_timings:        eval time =     199.97 ms /     5 runs   (   39.99 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    5121.93 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      35.55 ms /    64 runs   (    0.56 ms per token,  1800.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5281.09 ms /   965 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2549.74 ms /    63 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    8366.74 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     6 runs   (    0.70 ms per token,  1426.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3753.33 ms /   698 tokens (    5.38 ms per token,   185.97 tokens per second)\n",
            "llama_print_timings:        eval time =     198.09 ms /     5 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4238.24 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1758.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3032.86 ms /   560 tokens (    5.42 ms per token,   184.64 tokens per second)\n",
            "llama_print_timings:        eval time =     197.85 ms /     5 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    3467.41 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1809.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3661.24 ms /   688 tokens (    5.32 ms per token,   187.91 tokens per second)\n",
            "llama_print_timings:        eval time =     198.23 ms /     5 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4071.14 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    13 runs   (    0.66 ms per token,  1517.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3839.47 ms /   716 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =     475.51 ms /    12 runs   (   39.63 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4594.69 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What employee benefits does the Walmart Inc. offer?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1820.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2607.08 ms /   492 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
            "llama_print_timings:        eval time =     232.78 ms /     6 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3092.01 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1857.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3702.62 ms /   690 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =     195.94 ms /     5 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4117.58 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1986.23 ms /   382 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
            "llama_print_timings:        eval time =     231.01 ms /     6 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2346.32 ms /   388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1681.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     638.90 ms /   116 tokens (    5.51 ms per token,   181.56 tokens per second)\n",
            "llama_print_timings:        eval time =     236.50 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =     933.43 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.70 ms /     7 runs   (    0.67 ms per token,  1488.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2955.54 ms /   559 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
            "llama_print_timings:        eval time =     235.19 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3435.97 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1809.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2562.79 ms /   486 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     231.02 ms /     6 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    3020.05 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1943.29 ms /   376 tokens (    5.17 ms per token,   193.49 tokens per second)\n",
            "llama_print_timings:        eval time =     269.58 ms /     7 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2346.33 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1805.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2061.42 ms /   392 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =     271.50 ms /     7 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2471.03 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3125.30 ms /   592 tokens (    5.28 ms per token,   189.42 tokens per second)\n",
            "llama_print_timings:        eval time =     272.93 ms /     7 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3593.94 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.88 ms /     7 runs   (    0.70 ms per token,  1435.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2477.68 ms /   471 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =     233.43 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2975.02 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.33 ms /     7 runs   (    0.62 ms per token,  1614.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5226.65 ms /   956 tokens (    5.47 ms per token,   182.91 tokens per second)\n",
            "llama_print_timings:        eval time =     239.46 ms /     6 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5799.24 ms /   962 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.44 ms /     6 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3795.99 ms /   710 tokens (    5.35 ms per token,   187.04 tokens per second)\n",
            "llama_print_timings:        eval time =     196.81 ms /     5 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4215.82 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1570.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2252.74 ms /   432 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
            "llama_print_timings:        eval time =     271.65 ms /     7 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2753.04 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     6 runs   (    0.61 ms per token,  1651.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2950.45 ms /   557 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
            "llama_print_timings:        eval time =     196.54 ms /     5 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3360.55 ms /   562 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "Total score for approach 2 and distance function ip is 0.4055727554179567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(2, 'l2')"
      ],
      "metadata": {
        "id": "vDMuX3Ta3nC3",
        "outputId": "31450035-b047-4b70-ec89-7b8c238ed1a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1892.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5989.88 ms /  1083 tokens (    5.53 ms per token,   180.81 tokens per second)\n",
            "llama_print_timings:        eval time =     202.83 ms /     5 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    6509.29 ms /  1088 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1883.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5054.39 ms /   926 tokens (    5.46 ms per token,   183.21 tokens per second)\n",
            "llama_print_timings:        eval time =     241.87 ms /     6 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5690.79 ms /   932 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4388.87 ms /   814 tokens (    5.39 ms per token,   185.47 tokens per second)\n",
            "llama_print_timings:        eval time =     240.35 ms /     6 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    4876.60 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.28 ms /     7 runs   (    0.61 ms per token,  1636.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5089.81 ms /   930 tokens (    5.47 ms per token,   182.72 tokens per second)\n",
            "llama_print_timings:        eval time =     242.14 ms /     6 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5704.94 ms /   936 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1880.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2739.00 ms /   520 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =     232.00 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    3183.75 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2722.99 ms /   516 tokens (    5.28 ms per token,   189.50 tokens per second)\n",
            "llama_print_timings:        eval time =     232.68 ms /     6 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3121.43 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1515.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5037.88 ms /   923 tokens (    5.46 ms per token,   183.21 tokens per second)\n",
            "llama_print_timings:        eval time =     242.12 ms /     6 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5591.27 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1809.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4362.61 ms /   807 tokens (    5.41 ms per token,   184.98 tokens per second)\n",
            "llama_print_timings:        eval time =     239.01 ms /     6 runs   (   39.83 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4946.39 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      64.03 ms /    96 runs   (    0.67 ms per token,  1499.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5942.46 ms /  1078 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3894.04 ms /    95 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =   10616.08 ms /  1173 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.59 ms per token,  1680.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4997.43 ms /   920 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =     281.57 ms /     7 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5573.16 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     6 runs   (    0.63 ms per token,  1594.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6006.64 ms /  1087 tokens (    5.53 ms per token,   180.97 tokens per second)\n",
            "llama_print_timings:        eval time =     202.85 ms /     5 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    6649.51 ms /  1092 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1809.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4721.66 ms /   870 tokens (    5.43 ms per token,   184.26 tokens per second)\n",
            "llama_print_timings:        eval time =     241.61 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5267.16 ms /   876 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1823.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4073.05 ms /   759 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =     199.23 ms /     5 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4506.77 ms /   764 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.97 ms /     9 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3996.17 ms /   743 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
            "llama_print_timings:        eval time =     317.77 ms /     8 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4668.79 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1886.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5327.82 ms /   976 tokens (    5.46 ms per token,   183.19 tokens per second)\n",
            "llama_print_timings:        eval time =     241.64 ms /     6 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5868.71 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.33 ms /     7 runs   (    0.62 ms per token,  1615.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5233.58 ms /   958 tokens (    5.46 ms per token,   183.05 tokens per second)\n",
            "llama_print_timings:        eval time =     241.65 ms /     6 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5847.27 ms /   964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      58.93 ms /   101 runs   (    0.58 ms per token,  1713.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1316.72 ms /   254 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3831.62 ms /   100 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    5593.91 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.94 ms /     6 runs   (    0.82 ms per token,  1215.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5365.06 ms /   978 tokens (    5.49 ms per token,   182.29 tokens per second)\n",
            "llama_print_timings:        eval time =     204.21 ms /     5 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    5892.97 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1894.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6009.87 ms /  1088 tokens (    5.52 ms per token,   181.04 tokens per second)\n",
            "llama_print_timings:        eval time =     245.14 ms /     6 runs   (   40.86 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    6682.51 ms /  1094 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.15 ms /     9 runs   (    0.57 ms per token,  1748.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4024.36 ms /   747 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
            "llama_print_timings:        eval time =     315.82 ms /     8 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    4576.21 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1476.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2514.30 ms /   478 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
            "llama_print_timings:        eval time =     234.14 ms /     6 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2964.73 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      61.85 ms /   107 runs   (    0.58 ms per token,  1729.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4132.83 ms /   768 tokens (    5.38 ms per token,   185.83 tokens per second)\n",
            "llama_print_timings:        eval time =    4231.09 ms /   106 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    9001.96 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     148.51 ms /   256 runs   (    0.58 ms per token,  1723.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2904.51 ms /   546 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
            "llama_print_timings:        eval time =   10070.26 ms /   255 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   14152.79 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      44.72 ms /    79 runs   (    0.57 ms per token,  1766.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6006.27 ms /  1086 tokens (    5.53 ms per token,   180.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3192.24 ms /    78 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =    9880.09 ms /  1164 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1813.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.70 ms /   525 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
            "llama_print_timings:        eval time =     235.62 ms /     6 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3186.77 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.66 ms /     7 runs   (    0.67 ms per token,  1503.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2686.08 ms /   507 tokens (    5.30 ms per token,   188.75 tokens per second)\n",
            "llama_print_timings:        eval time =     235.74 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3132.78 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1760.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2566.70 ms /   487 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =     232.00 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    3033.14 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1844.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1533.31 ms /   283 tokens (    5.42 ms per token,   184.57 tokens per second)\n",
            "llama_print_timings:        eval time =     237.40 ms /     6 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    1873.32 ms /   289 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1921.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3801.22 ms /   710 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
            "llama_print_timings:        eval time =     200.22 ms /     5 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    4233.75 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     6 runs   (    0.64 ms per token,  1559.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3985.62 ms /   740 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
            "llama_print_timings:        eval time =     198.52 ms /     5 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4472.12 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1757.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2259.84 ms /   429 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =     229.56 ms /     6 runs   (   38.26 ms per token,    26.14 tokens per second)\n",
            "llama_print_timings:       total time =    2681.81 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2907.45 ms /   549 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =     232.16 ms /     6 runs   (   38.69 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3323.29 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2379.06 ms /   456 tokens (    5.22 ms per token,   191.67 tokens per second)\n",
            "llama_print_timings:        eval time =     234.66 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2767.18 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2071.99 ms /   394 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =     230.38 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2431.32 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1702.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3051.23 ms /   573 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
            "llama_print_timings:        eval time =     235.89 ms /     6 runs   (   39.32 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3597.58 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1886.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     269.83 ms /     7 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =     293.12 ms /     7 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1858.74 ms /   355 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =     232.29 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2219.48 ms /   361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1806.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2035.01 ms /   392 tokens (    5.19 ms per token,   192.63 tokens per second)\n",
            "llama_print_timings:        eval time =     233.86 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2405.32 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5901.88 ms /  1070 tokens (    5.52 ms per token,   181.30 tokens per second)\n",
            "llama_print_timings:        eval time =     204.49 ms /     5 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    6473.87 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1842.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2476.01 ms /   466 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =     231.86 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2918.68 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.12 ms /    13 runs   (    0.55 ms per token,  1826.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3572.97 ms /   666 tokens (    5.36 ms per token,   186.40 tokens per second)\n",
            "llama_print_timings:        eval time =     477.79 ms /    12 runs   (   39.82 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    4282.47 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any tax-related risks or benefits for the COCA COLA CO mentioned?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1825.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3350.15 ms /   629 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
            "llama_print_timings:        eval time =     196.61 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3737.50 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.90 ms /     9 runs   (    0.54 ms per token,  1837.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3955.57 ms /   735 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =     317.85 ms /     8 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4630.33 ms /   743 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1826.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2814.29 ms /   530 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
            "llama_print_timings:        eval time =     233.24 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3218.98 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2378.21 ms /   453 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =     233.94 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2756.23 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.37 ms /     7 runs   (    0.62 ms per token,  1603.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4688.07 ms /   864 tokens (    5.43 ms per token,   184.30 tokens per second)\n",
            "llama_print_timings:        eval time =     280.47 ms /     7 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    5324.05 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     7 runs   (    0.51 ms per token,  1958.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4864.83 ms /   893 tokens (    5.45 ms per token,   183.56 tokens per second)\n",
            "llama_print_timings:        eval time =     242.24 ms /     6 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    5410.66 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1574.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2729.43 ms /   517 tokens (    5.28 ms per token,   189.42 tokens per second)\n",
            "llama_print_timings:        eval time =     237.65 ms /     6 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    3140.27 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1623.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1264.42 ms /   238 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =     234.15 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    1597.38 ms /   244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1945.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3962.20 ms /   731 tokens (    5.42 ms per token,   184.49 tokens per second)\n",
            "llama_print_timings:        eval time =     197.22 ms /     5 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4542.33 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1852.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3489.24 ms /   653 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
            "llama_print_timings:        eval time =     196.34 ms /     5 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3885.83 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2162.69 ms /   413 tokens (    5.24 ms per token,   190.97 tokens per second)\n",
            "llama_print_timings:        eval time =     230.28 ms /     6 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2534.35 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1624.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1841.66 ms /   347 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =     234.99 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2200.14 ms /   353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     7 runs   (    0.66 ms per token,  1504.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2346.02 ms /   447 tokens (    5.25 ms per token,   190.54 tokens per second)\n",
            "llama_print_timings:        eval time =     233.81 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2813.17 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1774.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2297.14 ms /   436 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =     231.18 ms /     6 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2727.46 ms /   442 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1770.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5048.12 ms /   927 tokens (    5.45 ms per token,   183.63 tokens per second)\n",
            "llama_print_timings:        eval time =     240.85 ms /     6 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5570.42 ms /   933 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.37 ms /     6 runs   (    0.73 ms per token,  1373.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5196.93 ms /   952 tokens (    5.46 ms per token,   183.19 tokens per second)\n",
            "llama_print_timings:        eval time =     202.20 ms /     5 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    5806.38 ms /   957 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1786.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2772.54 ms /   524 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =     235.28 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3187.88 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2294.86 ms /   440 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =     231.13 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2677.77 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1866.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2640.34 ms /   504 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     272.63 ms /     7 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3071.54 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.78 ms /     7 runs   (    0.68 ms per token,  1463.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1950.18 ms /   375 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
            "llama_print_timings:        eval time =     231.82 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2354.92 ms /   381 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3816.05 ms /   711 tokens (    5.37 ms per token,   186.32 tokens per second)\n",
            "llama_print_timings:        eval time =     237.26 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    4372.41 ms /   717 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1855.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4165.78 ms /   776 tokens (    5.37 ms per token,   186.28 tokens per second)\n",
            "llama_print_timings:        eval time =     200.87 ms /     5 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    4605.05 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1687.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1819.75 ms /   352 tokens (    5.17 ms per token,   193.43 tokens per second)\n",
            "llama_print_timings:        eval time =     270.21 ms /     7 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2213.65 ms /   359 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.08 ms /     7 runs   (    0.73 ms per token,  1377.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1783.65 ms /   344 tokens (    5.19 ms per token,   192.86 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2196.01 ms /   350 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2475.14 ms /   468 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =     231.92 ms /     6 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2943.71 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5281.07 ms /   968 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =     283.30 ms /     7 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    5860.05 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1509.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2819.37 ms /   536 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
            "llama_print_timings:        eval time =     236.64 ms /     6 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3250.27 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      89.21 ms /   148 runs   (    0.60 ms per token,  1659.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5350.43 ms /   975 tokens (    5.49 ms per token,   182.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5976.12 ms /   147 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   12248.31 ms /  1122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.86 ms /     7 runs   (    0.69 ms per token,  1440.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2823.75 ms /   530 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =     236.44 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3344.87 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1766.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3043.48 ms /   576 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
            "llama_print_timings:        eval time =     275.99 ms /     7 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3531.41 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2816.88 ms /   533 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =     232.78 ms /     6 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3217.75 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     171.77 ms /    30 tokens (    5.73 ms per token,   174.65 tokens per second)\n",
            "llama_print_timings:        eval time =     234.34 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =     441.10 ms /    36 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     6 runs   (    0.67 ms per token,  1496.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3080.50 ms /   578 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
            "llama_print_timings:        eval time =     197.37 ms /     5 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    3480.28 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1693.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5338.95 ms /   973 tokens (    5.49 ms per token,   182.25 tokens per second)\n",
            "llama_print_timings:        eval time =     243.40 ms /     6 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    5997.29 ms /   979 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1787.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5326.27 ms /   975 tokens (    5.46 ms per token,   183.05 tokens per second)\n",
            "llama_print_timings:        eval time =     242.20 ms /     6 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    5878.39 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1793.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5389.21 ms /   983 tokens (    5.48 ms per token,   182.40 tokens per second)\n",
            "llama_print_timings:        eval time =     203.07 ms /     5 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    6001.71 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.55 ms per token,  1834.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4908.16 ms /   903 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
            "llama_print_timings:        eval time =     198.88 ms /     5 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    5389.63 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     7 runs   (    0.68 ms per token,  1472.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2855.47 ms /   538 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =     234.90 ms /     6 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3275.08 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1871.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3100.11 ms /   584 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =     276.04 ms /     7 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3709.41 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1677.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2374.76 ms /   451 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =     231.75 ms /     6 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2761.48 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1842.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2859.72 ms /   540 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =     235.28 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3278.42 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      43.25 ms /    73 runs   (    0.59 ms per token,  1687.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5430.93 ms /   990 tokens (    5.49 ms per token,   182.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2924.91 ms /    72 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    9017.19 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      39.80 ms /    71 runs   (    0.56 ms per token,  1784.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     138.74 ms /    24 tokens (    5.78 ms per token,   172.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2884.34 ms /    71 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    3269.12 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.67 ms /     7 runs   (    0.67 ms per token,  1497.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4952.58 ms /   907 tokens (    5.46 ms per token,   183.14 tokens per second)\n",
            "llama_print_timings:        eval time =     241.21 ms /     6 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5515.21 ms /   913 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      40.16 ms /    71 runs   (    0.57 ms per token,  1767.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5291.90 ms /   967 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2837.43 ms /    70 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    8710.32 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      52.84 ms /    87 runs   (    0.61 ms per token,  1646.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5283.97 ms /   965 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3490.57 ms /    86 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    9479.23 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1749.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2813.88 ms /   536 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =     236.59 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3223.87 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      46.00 ms /    66 runs   (    0.70 ms per token,  1434.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.46 ms /   584 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2568.90 ms /    65 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6145.01 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2429.41 ms /   463 tokens (    5.25 ms per token,   190.58 tokens per second)\n",
            "llama_print_timings:        eval time =     233.21 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2840.44 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2420.76 ms /   463 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
            "llama_print_timings:        eval time =     230.92 ms /     6 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2802.76 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1829.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3300.42 ms /   618 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =     237.59 ms /     6 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    3736.02 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.44 ms /     7 runs   (    0.63 ms per token,  1576.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2471.40 ms /   468 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =     234.16 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2926.04 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1928.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2913.79 ms /   550 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =     233.02 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3380.67 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1803.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3664.97 ms /   687 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =     237.96 ms /     6 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    4120.17 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     6 runs   (    0.59 ms per token,  1707.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     132.52 ms /    24 tokens (    5.52 ms per token,   181.10 tokens per second)\n",
            "llama_print_timings:        eval time =     235.98 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =     402.50 ms /    30 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /     7 runs   (    0.63 ms per token,  1583.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.07 ms /   469 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
            "llama_print_timings:        eval time =     235.68 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2857.21 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3585.53 ms /   668 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =     199.51 ms /     5 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    4113.58 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     7 runs   (    0.49 ms per token,  2024.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2419.30 ms /   462 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =     231.45 ms /     6 runs   (   38.57 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2797.96 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1681.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2769.78 ms /   524 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =     235.15 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3177.58 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1774.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     204.39 ms /    34 tokens (    6.01 ms per token,   166.35 tokens per second)\n",
            "llama_print_timings:        eval time =     189.55 ms /     5 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
            "llama_print_timings:       total time =     421.94 ms /    39 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2419.59 ms /   460 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =     230.64 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2804.86 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.79 ms /     7 runs   (    0.68 ms per token,  1459.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2654.13 ms /   504 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =     235.17 ms /     6 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3179.40 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1829.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1991.62 ms /   384 tokens (    5.19 ms per token,   192.81 tokens per second)\n",
            "llama_print_timings:        eval time =     229.27 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2362.39 ms /   390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1857.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3438.59 ms /   648 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =     198.49 ms /     5 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3835.93 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.30 ms /   404 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =     233.49 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2482.56 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     6 runs   (    0.73 ms per token,  1364.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3496.03 ms /   653 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
            "llama_print_timings:        eval time =     197.46 ms /     5 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    4007.78 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.03 ms /    60 runs   (    0.57 ms per token,  1762.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5240.68 ms /   958 tokens (    5.47 ms per token,   182.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2385.60 ms /    59 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8147.24 ms /  1017 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1564.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2772.57 ms /   525 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =     234.63 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3199.21 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      72.59 ms /   124 runs   (    0.59 ms per token,  1708.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4824.07 ms /   887 tokens (    5.44 ms per token,   183.87 tokens per second)\n",
            "llama_print_timings:        eval time =    4960.64 ms /   123 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =   10541.35 ms /  1010 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /     9 runs   (    0.97 ms per token,  1027.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4215.25 ms /   781 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =     318.71 ms /     8 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    4913.92 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2640.38 ms /   499 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =     233.44 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3046.77 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2815.03 ms /   535 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =     236.03 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3212.68 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     6 runs   (    0.63 ms per token,  1589.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5379.44 ms /   984 tokens (    5.47 ms per token,   182.92 tokens per second)\n",
            "llama_print_timings:        eval time =     242.56 ms /     6 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    5984.59 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      33.03 ms /    58 runs   (    0.57 ms per token,  1755.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5231.65 ms /   956 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2305.00 ms /    57 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8048.79 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1476.00 ms /   288 tokens (    5.13 ms per token,   195.12 tokens per second)\n",
            "llama_print_timings:        eval time =     190.36 ms /     5 runs   (   38.07 ms per token,    26.27 tokens per second)\n",
            "llama_print_timings:       total time =    1774.55 ms /   293 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.43 ms /     7 runs   (    0.63 ms per token,  1578.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1905.49 ms /   368 tokens (    5.18 ms per token,   193.13 tokens per second)\n",
            "llama_print_timings:        eval time =     231.25 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2306.50 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1803.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3223.37 ms /   605 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =     235.39 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3723.22 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1920.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2377.23 ms /   455 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =     235.16 ms /     6 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2767.21 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1710.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.96 ms /   323 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =     230.22 ms /     6 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2032.11 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1702.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1465.38 ms /   271 tokens (    5.41 ms per token,   184.93 tokens per second)\n",
            "llama_print_timings:        eval time =     235.72 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    1831.64 ms /   277 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     7 runs   (    0.70 ms per token,  1423.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3092.49 ms /   584 tokens (    5.30 ms per token,   188.84 tokens per second)\n",
            "llama_print_timings:        eval time =     236.98 ms /     6 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3623.66 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1648.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2825.65 ms /   536 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =     273.18 ms /     7 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3335.86 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1640.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2640.35 ms /   504 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     236.52 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3065.66 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1669.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2448.32 ms /   464 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =     234.01 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2867.30 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     7 runs   (    0.63 ms per token,  1593.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1903.56 ms /   366 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =     232.44 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2302.02 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /     7 runs   (    0.63 ms per token,  1581.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2923.65 ms /   552 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =     235.25 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3483.01 ms /   558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     149.97 ms /   256 runs   (    0.59 ms per token,  1707.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5418.47 ms /   989 tokens (    5.48 ms per token,   182.52 tokens per second)\n",
            "llama_print_timings:        eval time =   10420.60 ms /   255 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =   17313.44 ms /  1244 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     7 runs   (    0.70 ms per token,  1421.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4949.54 ms /   909 tokens (    5.45 ms per token,   183.65 tokens per second)\n",
            "llama_print_timings:        eval time =     241.45 ms /     6 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5548.19 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.59 ms /     7 runs   (    0.66 ms per token,  1525.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2304.84 ms /   437 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =     233.36 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2839.34 ms /   443 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1834.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3486.05 ms /   654 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =     235.82 ms /     6 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3949.50 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3167.57 ms /   595 tokens (    5.32 ms per token,   187.84 tokens per second)\n",
            "llama_print_timings:        eval time =     232.40 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3581.87 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      10.25 ms /     7 runs   (    1.46 ms per token,   683.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5429.08 ms /   988 tokens (    5.50 ms per token,   181.98 tokens per second)\n",
            "llama_print_timings:        eval time =     243.22 ms /     6 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    6100.32 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1893.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4997.01 ms /   920 tokens (    5.43 ms per token,   184.11 tokens per second)\n",
            "llama_print_timings:        eval time =     241.30 ms /     6 runs   (   40.22 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5503.95 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     6 runs   (    0.64 ms per token,  1552.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5420.09 ms /   991 tokens (    5.47 ms per token,   182.84 tokens per second)\n",
            "llama_print_timings:        eval time =     203.92 ms /     5 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    5973.80 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1916.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5048.79 ms /   924 tokens (    5.46 ms per token,   183.01 tokens per second)\n",
            "llama_print_timings:        eval time =     200.94 ms /     5 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    5599.39 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1853.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3126.81 ms /   589 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =     233.65 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3557.14 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.37 ms /    65 runs   (    0.53 ms per token,  1891.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5383.08 ms /   981 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2595.67 ms /    64 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    8573.66 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     185.85 ms /    31 tokens (    6.00 ms per token,   166.80 tokens per second)\n",
            "llama_print_timings:        eval time =     241.10 ms /     6 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =     462.38 ms /    37 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3037.28 ms /   576 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     237.24 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3450.10 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1663.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5378.83 ms /   982 tokens (    5.48 ms per token,   182.57 tokens per second)\n",
            "llama_print_timings:        eval time =     244.07 ms /     6 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    6018.31 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1911.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4993.54 ms /   915 tokens (    5.46 ms per token,   183.24 tokens per second)\n",
            "llama_print_timings:        eval time =     200.71 ms /     5 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5482.85 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1854.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.56 ms /   584 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =     196.61 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3455.74 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.08 ms /     7 runs   (    0.73 ms per token,  1377.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3679.76 ms /   688 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
            "llama_print_timings:        eval time =     278.73 ms /     7 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    4279.22 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3135.30 ms /   592 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =     193.38 ms /     5 runs   (   38.68 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    3526.39 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1893.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5377.96 ms /   984 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
            "llama_print_timings:        eval time =     202.63 ms /     5 runs   (   40.53 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    5891.07 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1761.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5054.24 ms /   922 tokens (    5.48 ms per token,   182.42 tokens per second)\n",
            "llama_print_timings:        eval time =     202.53 ms /     5 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    5688.91 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.05 ms /   436 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =     230.58 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2660.32 ms /   442 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      42.79 ms /    74 runs   (    0.58 ms per token,  1729.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3079.20 ms /   580 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2871.36 ms /    73 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6412.78 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     6 runs   (    0.60 ms per token,  1673.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3190.01 ms /   595 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =     196.03 ms /     5 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3725.55 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.48 ms /     6 runs   (    0.58 ms per token,  1722.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5373.34 ms /   984 tokens (    5.46 ms per token,   183.13 tokens per second)\n",
            "llama_print_timings:        eval time =     203.04 ms /     5 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    5891.07 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       8.25 ms /    13 runs   (    0.63 ms per token,  1575.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3983.89 ms /   739 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
            "llama_print_timings:        eval time =     478.71 ms /    12 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    4814.95 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the PayPal Holdings, Inc.'s total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3091.50 ms /   581 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =     235.11 ms /     6 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3596.40 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3129.67 ms /   592 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =     195.76 ms /     5 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3544.03 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1805.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3038.23 ms /   576 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =     235.89 ms /     6 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3482.14 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1777.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     214.76 ms /    36 tokens (    5.97 ms per token,   167.63 tokens per second)\n",
            "llama_print_timings:        eval time =     193.72 ms /     5 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =     442.88 ms /    41 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.68 ms /     7 runs   (    0.67 ms per token,  1496.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3139.97 ms /   592 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =     234.07 ms /     6 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3706.41 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.51 ms /   412 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =     233.53 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2534.14 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3167.66 ms /   596 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =     236.42 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3595.28 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1905.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.34 ms /   362 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =     230.23 ms /     6 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2247.92 ms /   368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.53 ms /     7 runs   (    0.65 ms per token,  1546.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2602.80 ms /   493 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =     235.41 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3061.68 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1856.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3004.84 ms /   563 tokens (    5.34 ms per token,   187.36 tokens per second)\n",
            "llama_print_timings:        eval time =     234.52 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3490.66 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     6 runs   (    0.56 ms per token,  1770.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3169.04 ms /   597 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     196.48 ms /     5 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3551.45 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3214.27 ms /   605 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =     235.34 ms /     6 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3641.17 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     6 runs   (    0.64 ms per token,  1573.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3135.60 ms /   590 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
            "llama_print_timings:        eval time =     196.93 ms /     5 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3612.61 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3178.69 ms /   598 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =     234.73 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3635.24 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     6 runs   (    0.60 ms per token,  1656.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3083.87 ms /   584 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =     234.46 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3510.11 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1683.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2467.39 ms /   472 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =     235.53 ms /     6 runs   (   39.25 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2867.31 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1448.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1867.05 ms /   356 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =     232.40 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2317.77 ms /   362 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.94 ms /     7 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1279.24 ms /   244 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =     230.50 ms /     6 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    1670.39 ms /   250 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1926.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3578.03 ms /   672 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =     238.75 ms /     6 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4048.40 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3086.77 ms /   583 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =     197.35 ms /     5 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3474.64 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     6 runs   (    0.64 ms per token,  1568.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     172.49 ms /    28 tokens (    6.16 ms per token,   162.33 tokens per second)\n",
            "llama_print_timings:        eval time =     196.00 ms /     5 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =     405.81 ms /    33 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     6 runs   (    0.64 ms per token,  1557.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3636.94 ms /   678 tokens (    5.36 ms per token,   186.42 tokens per second)\n",
            "llama_print_timings:        eval time =     201.34 ms /     5 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    4209.02 ms /   683 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1753.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3101.66 ms /   584 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =     234.57 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3613.11 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1750.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5334.30 ms /   976 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
            "llama_print_timings:        eval time =     244.04 ms /     6 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    5919.82 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     6 runs   (    0.70 ms per token,  1436.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3135.83 ms /   586 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
            "llama_print_timings:        eval time =     196.78 ms /     5 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3627.24 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2128.41 ms /   406 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =     231.88 ms /     6 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2581.84 ms /   412 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     153.37 ms /   256 runs   (    0.60 ms per token,  1669.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3983.47 ms /   741 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
            "llama_print_timings:        eval time =   10234.78 ms /   255 runs   (   40.14 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =   15481.09 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3165.97 ms /   594 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =     233.47 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3586.92 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1713.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.04 ms /   472 tokens (    5.22 ms per token,   191.48 tokens per second)\n",
            "llama_print_timings:        eval time =     271.66 ms /     7 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2893.16 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3096.99 ms /   581 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =     236.14 ms /     6 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3649.80 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1680.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2074.22 ms /   400 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
            "llama_print_timings:        eval time =     268.69 ms /     7 runs   (   38.38 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2478.04 ms /   407 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.54 ms per token,  1867.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3082.56 ms /   583 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =     196.81 ms /     5 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3462.28 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1952.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2421.05 ms /   464 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =     230.79 ms /     6 runs   (   38.47 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2804.05 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.49 ms /     7 runs   (    0.64 ms per token,  1560.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3228.05 ms /   603 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =     236.28 ms /     6 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3776.28 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1797.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1905.67 ms /   368 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
            "llama_print_timings:        eval time =     268.12 ms /     7 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2313.72 ms /   375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2906.10 ms /   552 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =     275.96 ms /     7 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3359.28 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3169.23 ms /   596 tokens (    5.32 ms per token,   188.06 tokens per second)\n",
            "llama_print_timings:        eval time =     232.80 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    3587.70 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     7 runs   (    0.69 ms per token,  1451.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.23 ms /   430 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
            "llama_print_timings:        eval time =     232.94 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2697.45 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.59 ms per token,  1680.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2256.55 ms /   432 tokens (    5.22 ms per token,   191.44 tokens per second)\n",
            "llama_print_timings:        eval time =     273.05 ms /     7 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2755.39 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1860.97 ms /   360 tokens (    5.17 ms per token,   193.45 tokens per second)\n",
            "llama_print_timings:        eval time =     271.35 ms /     7 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2260.72 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2725.43 ms /   517 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =     233.77 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3121.88 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      64.65 ms /    99 runs   (    0.65 ms per token,  1531.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.89 ms /   583 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3866.20 ms /    98 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    7602.75 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3163.77 ms /   594 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
            "llama_print_timings:        eval time =     198.72 ms /     5 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    3550.23 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1803.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1861.39 ms /   360 tokens (    5.17 ms per token,   193.40 tokens per second)\n",
            "llama_print_timings:        eval time =     229.79 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2232.93 ms /   366 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     6 runs   (    0.66 ms per token,  1514.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4630.65 ms /   856 tokens (    5.41 ms per token,   184.86 tokens per second)\n",
            "llama_print_timings:        eval time =     200.45 ms /     5 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    5199.75 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1864.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3895.19 ms /   724 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =     197.69 ms /     5 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    4385.21 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      46.43 ms /    67 runs   (    0.69 ms per token,  1443.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5560.89 ms /  1013 tokens (    5.49 ms per token,   182.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2691.85 ms /    66 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    8914.51 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3670.83 ms /   684 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
            "llama_print_timings:        eval time =     237.89 ms /     6 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4209.70 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2900.74 ms /   546 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =     235.48 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3353.50 ms /   552 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     6 runs   (    0.62 ms per token,  1602.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4907.86 ms /   900 tokens (    5.45 ms per token,   183.38 tokens per second)\n",
            "llama_print_timings:        eval time =     200.77 ms /     5 runs   (   40.15 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    5533.53 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3629.33 ms /   674 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =     237.70 ms /     6 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    4180.19 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1793.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     217.38 ms /    34 tokens (    6.39 ms per token,   156.40 tokens per second)\n",
            "llama_print_timings:        eval time =     234.33 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =     489.68 ms /    40 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1818.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2858.56 ms /   539 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =     236.38 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3291.05 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     174.03 ms /    32 tokens (    5.44 ms per token,   183.88 tokens per second)\n",
            "llama_print_timings:        eval time =     232.71 ms /     6 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =     447.56 ms /    38 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.44 ms /     7 runs   (    0.63 ms per token,  1577.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4866.24 ms /   894 tokens (    5.44 ms per token,   183.71 tokens per second)\n",
            "llama_print_timings:        eval time =     242.40 ms /     6 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    5551.60 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1775.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3895.47 ms /   728 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
            "llama_print_timings:        eval time =     198.15 ms /     5 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    4374.15 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     6 runs   (    0.61 ms per token,  1633.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5560.45 ms /  1010 tokens (    5.51 ms per token,   181.64 tokens per second)\n",
            "llama_print_timings:        eval time =     202.84 ms /     5 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    6110.39 ms /  1015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     6 runs   (    0.64 ms per token,  1556.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5346.89 ms /   970 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =     201.79 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    6028.42 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     6 runs   (    0.60 ms per token,  1656.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5524.09 ms /  1006 tokens (    5.49 ms per token,   182.11 tokens per second)\n",
            "llama_print_timings:        eval time =     202.56 ms /     5 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    6079.38 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.60 ms per token,  1678.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5348.55 ms /   974 tokens (    5.49 ms per token,   182.11 tokens per second)\n",
            "llama_print_timings:        eval time =     201.95 ms /     5 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    6031.09 ms /   979 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1774.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2860.63 ms /   541 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =     234.62 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3300.04 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.83 ms /     9 runs   (    0.65 ms per token,  1544.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4713.72 ms /   866 tokens (    5.44 ms per token,   183.72 tokens per second)\n",
            "llama_print_timings:        eval time =     321.35 ms /     8 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    5389.58 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      34.06 ms /    60 runs   (    0.57 ms per token,  1761.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6016.36 ms /  1088 tokens (    5.53 ms per token,   180.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2455.77 ms /    60 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =    9151.87 ms /  1148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.87 ms /     6 runs   (    0.98 ms per token,  1022.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5051.62 ms /   924 tokens (    5.47 ms per token,   182.91 tokens per second)\n",
            "llama_print_timings:        eval time =     201.02 ms /     5 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5614.98 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3491.30 ms /   652 tokens (    5.35 ms per token,   186.75 tokens per second)\n",
            "llama_print_timings:        eval time =     236.05 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3994.29 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1784.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3891.43 ms /   725 tokens (    5.37 ms per token,   186.31 tokens per second)\n",
            "llama_print_timings:        eval time =     236.19 ms /     6 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4350.63 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.56 ms per token,  1799.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5962.02 ms /  1080 tokens (    5.52 ms per token,   181.15 tokens per second)\n",
            "llama_print_timings:        eval time =     245.12 ms /     6 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    6662.85 ms /  1086 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      52.75 ms /    92 runs   (    0.57 ms per token,  1744.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4853.88 ms /   890 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3669.11 ms /    91 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    9081.50 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1876.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     228.69 ms /    39 tokens (    5.86 ms per token,   170.54 tokens per second)\n",
            "llama_print_timings:        eval time =     200.15 ms /     5 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =     460.65 ms /    44 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1613.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2874.89 ms /   543 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
            "llama_print_timings:        eval time =     236.21 ms /     6 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3417.18 ms /   549 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.73 ms /    21 tokens (    6.08 ms per token,   164.41 tokens per second)\n",
            "llama_print_timings:        eval time =     233.24 ms /     6 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =     393.74 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      35.59 ms /    62 runs   (    0.57 ms per token,  1742.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4860.57 ms /   891 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2457.04 ms /    61 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    7780.46 ms /   952 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     7 runs   (    0.62 ms per token,  1613.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2466.79 ms /   470 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =     234.61 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2908.41 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2483.53 ms /   472 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =     233.39 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2948.04 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1913.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3890.91 ms /   723 tokens (    5.38 ms per token,   185.82 tokens per second)\n",
            "llama_print_timings:        eval time =     199.34 ms /     5 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    4320.55 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1731.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3755.46 ms /   702 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =     197.30 ms /     5 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    4166.86 ms /   707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.59 ms per token,  1681.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4872.96 ms /   896 tokens (    5.44 ms per token,   183.87 tokens per second)\n",
            "llama_print_timings:        eval time =     201.71 ms /     5 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    5465.96 ms /   901 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      38.13 ms /    68 runs   (    0.56 ms per token,  1783.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     225.11 ms /    35 tokens (    6.43 ms per token,   155.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2698.88 ms /    67 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    3162.37 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     140.26 ms /   256 runs   (    0.55 ms per token,  1825.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1774.39 ms /   344 tokens (    5.16 ms per token,   193.87 tokens per second)\n",
            "llama_print_timings:        eval time =    9967.34 ms /   256 runs   (   38.93 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12862.35 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.02 ms /     9 runs   (    0.56 ms per token,  1793.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4580.52 ms /   848 tokens (    5.40 ms per token,   185.13 tokens per second)\n",
            "llama_print_timings:        eval time =     320.86 ms /     8 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    5162.61 ms /   856 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     9 runs   (    0.55 ms per token,  1828.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4825.91 ms /   883 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
            "llama_print_timings:        eval time =     321.85 ms /     8 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5561.67 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2421.09 ms /   462 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =     235.33 ms /     6 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2812.81 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1519.87 ms /   296 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
            "llama_print_timings:        eval time =     271.99 ms /     7 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    1896.25 ms /   303 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      51.89 ms /    88 runs   (    0.59 ms per token,  1695.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5011.24 ms /   920 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3523.18 ms /    87 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    9212.81 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       6.53 ms /    13 runs   (    0.50 ms per token,  1991.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5376.34 ms /   984 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
            "llama_print_timings:        eval time =     528.37 ms /    13 runs   (   40.64 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    6226.50 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the GENERAL MILLS INC?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5067.83 ms /   925 tokens (    5.48 ms per token,   182.52 tokens per second)\n",
            "llama_print_timings:        eval time =     202.06 ms /     5 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    5664.78 ms /   930 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5516.52 ms /  1005 tokens (    5.49 ms per token,   182.18 tokens per second)\n",
            "llama_print_timings:        eval time =     202.69 ms /     5 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    6026.53 ms /  1010 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     160.47 ms /   256 runs   (    0.63 ms per token,  1595.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     935.69 ms /   183 tokens (    5.11 ms per token,   195.58 tokens per second)\n",
            "llama_print_timings:        eval time =    9809.45 ms /   255 runs   (   38.47 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =   11853.34 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1532.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3844.68 ms /   715 tokens (    5.38 ms per token,   185.97 tokens per second)\n",
            "llama_print_timings:        eval time =     238.07 ms /     6 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4338.22 ms /   721 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2828.61 ms /   532 tokens (    5.32 ms per token,   188.08 tokens per second)\n",
            "llama_print_timings:        eval time =     233.85 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3344.89 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      36.69 ms /    65 runs   (    0.56 ms per token,  1771.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4810.66 ms /   884 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2576.09 ms /    64 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    7855.85 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     6 runs   (    0.61 ms per token,  1635.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4177.25 ms /   770 tokens (    5.43 ms per token,   184.33 tokens per second)\n",
            "llama_print_timings:        eval time =     198.99 ms /     5 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4752.90 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1762.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5853.25 ms /  1059 tokens (    5.53 ms per token,   180.93 tokens per second)\n",
            "llama_print_timings:        eval time =     203.22 ms /     5 runs   (   40.64 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    6369.86 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     6 runs   (    0.68 ms per token,  1466.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4819.70 ms /   886 tokens (    5.44 ms per token,   183.83 tokens per second)\n",
            "llama_print_timings:        eval time =     200.89 ms /     5 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    5375.89 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4923.04 ms /   901 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
            "llama_print_timings:        eval time =     200.63 ms /     5 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    5456.20 ms /   906 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.93 ms /     9 runs   (    0.55 ms per token,  1825.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4766.64 ms /   879 tokens (    5.42 ms per token,   184.41 tokens per second)\n",
            "llama_print_timings:        eval time =     321.62 ms /     8 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    5366.09 ms /   887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1532.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2787.73 ms /   527 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =     236.42 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3321.83 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1657.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1644.53 ms /   314 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
            "llama_print_timings:        eval time =     235.23 ms /     6 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2010.21 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     875.18 ms /   165 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =     229.91 ms /     6 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    1174.10 ms /   171 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2163.60 ms /   416 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =     270.37 ms /     7 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2575.36 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1640.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1096.60 ms /   204 tokens (    5.38 ms per token,   186.03 tokens per second)\n",
            "llama_print_timings:        eval time =     233.83 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    1415.29 ms /   210 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      39.87 ms /    68 runs   (    0.59 ms per token,  1705.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5577.23 ms /  1014 tokens (    5.50 ms per token,   181.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2727.41 ms /    67 runs   (   40.71 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    8931.97 ms /  1081 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4860.70 ms /   895 tokens (    5.43 ms per token,   184.13 tokens per second)\n",
            "llama_print_timings:        eval time =     241.97 ms /     6 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5382.44 ms /   901 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     6 runs   (    0.67 ms per token,  1482.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3943.52 ms /   731 tokens (    5.39 ms per token,   185.37 tokens per second)\n",
            "llama_print_timings:        eval time =     198.35 ms /     5 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    4461.11 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1756.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1697.94 ms /   328 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
            "llama_print_timings:        eval time =     231.23 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2079.71 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     919.19 ms /   176 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
            "llama_print_timings:        eval time =     233.17 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    1223.54 ms /   182 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     919.90 ms /   176 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
            "llama_print_timings:        eval time =     266.52 ms /     7 runs   (   38.07 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =    1261.57 ms /   183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1832.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3348.41 ms /   627 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =     237.98 ms /     6 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    3780.10 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     7 runs   (    0.71 ms per token,  1398.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3429.86 ms /   640 tokens (    5.36 ms per token,   186.60 tokens per second)\n",
            "llama_print_timings:        eval time =     239.15 ms /     6 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    3940.37 ms /   646 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.30 ms /     7 runs   (    0.61 ms per token,  1627.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2476.88 ms /   469 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
            "llama_print_timings:        eval time =     234.01 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2932.85 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1805.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4762.73 ms /   874 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
            "llama_print_timings:        eval time =     199.71 ms /     5 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5227.43 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1788.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6015.09 ms /  1084 tokens (    5.55 ms per token,   180.21 tokens per second)\n",
            "llama_print_timings:        eval time =     203.93 ms /     5 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    6668.04 ms /  1089 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.04 ms /     6 runs   (    0.51 ms per token,  1976.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5829.43 ms /  1050 tokens (    5.55 ms per token,   180.12 tokens per second)\n",
            "llama_print_timings:        eval time =     204.51 ms /     5 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    6343.99 ms /  1055 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1797.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2992.24 ms /   562 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =     233.70 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3403.82 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1828.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3501.90 ms /   655 tokens (    5.35 ms per token,   187.04 tokens per second)\n",
            "llama_print_timings:        eval time =     196.00 ms /     5 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    4031.02 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1714.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3730.81 ms /   688 tokens (    5.42 ms per token,   184.41 tokens per second)\n",
            "llama_print_timings:        eval time =     241.68 ms /     6 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    4191.34 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.52 ms /   427 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =     233.70 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2615.19 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1590.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.76 ms /   434 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =     233.34 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2680.93 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1661.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2527.55 ms /   475 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =     235.50 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3047.86 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1829.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5754.15 ms /  1045 tokens (    5.51 ms per token,   181.61 tokens per second)\n",
            "llama_print_timings:        eval time =     203.17 ms /     5 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6271.44 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1760.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2953.51 ms /   560 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =     232.50 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3366.84 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1752.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3641.84 ms /   680 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
            "llama_print_timings:        eval time =     198.45 ms /     5 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4170.26 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1758.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3751.08 ms /   698 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
            "llama_print_timings:        eval time =     198.38 ms /     5 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4170.99 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4297.25 ms /   794 tokens (    5.41 ms per token,   184.77 tokens per second)\n",
            "llama_print_timings:        eval time =     237.99 ms /     6 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    4791.50 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1890.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3721.47 ms /   691 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
            "llama_print_timings:        eval time =     199.04 ms /     5 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    4263.89 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1858.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5613.01 ms /  1022 tokens (    5.49 ms per token,   182.08 tokens per second)\n",
            "llama_print_timings:        eval time =     244.35 ms /     6 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    6182.16 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     6 runs   (    0.62 ms per token,  1620.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5766.09 ms /  1046 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =     202.55 ms /     5 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    6418.29 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1900.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3393.51 ms /   635 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =     197.98 ms /     5 runs   (   39.60 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    3797.08 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1805.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3800.82 ms /   712 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =     238.22 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4255.61 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     104.29 ms /   256 runs   (    0.41 ms per token,  2454.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5629.92 ms /  1024 tokens (    5.50 ms per token,   181.89 tokens per second)\n",
            "llama_print_timings:        eval time =   10505.36 ms /   256 runs   (   41.04 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =   17529.13 ms /  1280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1771.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4307.99 ms /   798 tokens (    5.40 ms per token,   185.24 tokens per second)\n",
            "llama_print_timings:        eval time =     237.10 ms /     6 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    4834.92 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3749.31 ms /   699 tokens (    5.36 ms per token,   186.43 tokens per second)\n",
            "llama_print_timings:        eval time =     238.36 ms /     6 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4207.52 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5195.46 ms /   950 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =     240.92 ms /     6 runs   (   40.15 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    5844.47 ms /   956 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1798.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5128.98 ms /   939 tokens (    5.46 ms per token,   183.08 tokens per second)\n",
            "llama_print_timings:        eval time =     241.66 ms /     6 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5657.08 ms /   945 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     6 runs   (    0.63 ms per token,  1593.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2949.25 ms /   559 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =     194.95 ms /     5 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3330.36 ms /   564 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =     108.25 ms /   256 runs   (    0.42 ms per token,  2364.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5626.81 ms /  1021 tokens (    5.51 ms per token,   181.45 tokens per second)\n",
            "llama_print_timings:        eval time =   10454.83 ms /   255 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =   17568.29 ms /  1276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1573.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2549.83 ms /   483 tokens (    5.28 ms per token,   189.42 tokens per second)\n",
            "llama_print_timings:        eval time =     235.16 ms /     6 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2957.14 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1646.25 ms /   312 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =     277.20 ms /     7 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    2036.02 ms /   319 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1703.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2113.01 ms /   402 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
            "llama_print_timings:        eval time =     230.26 ms /     6 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2477.36 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     7 runs   (    0.69 ms per token,  1451.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2866.59 ms /   541 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     234.68 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3354.08 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1817.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2432.88 ms /   464 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
            "llama_print_timings:        eval time =     231.48 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2874.66 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2550.59 ms /   487 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
            "llama_print_timings:        eval time =     235.99 ms /     6 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2946.06 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1689.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2547.16 ms /   484 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =     237.22 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2934.27 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.96 ms /     7 runs   (    0.71 ms per token,  1411.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.89 ms /   517 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =     236.11 ms /     6 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3164.11 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2487.35 ms /   471 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =     235.38 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2989.13 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1944.53 ms /   376 tokens (    5.17 ms per token,   193.36 tokens per second)\n",
            "llama_print_timings:        eval time =     269.18 ms /     7 runs   (   38.45 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2338.14 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1796.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.62 ms /   466 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =     231.64 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2840.44 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1796.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2418.15 ms /   462 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =     232.32 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2806.41 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     6 runs   (    0.69 ms per token,  1438.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3675.51 ms /   686 tokens (    5.36 ms per token,   186.64 tokens per second)\n",
            "llama_print_timings:        eval time =     198.56 ms /     5 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4190.32 ms /   691 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     6 runs   (    0.61 ms per token,  1640.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2981.28 ms /   548 tokens (    5.44 ms per token,   183.81 tokens per second)\n",
            "llama_print_timings:        eval time =     195.59 ms /     5 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3383.42 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1756.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2376.15 ms /   452 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =     233.38 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2770.88 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1677.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.13 ms /   523 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =     234.03 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3177.12 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1756.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3313.51 ms /   624 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
            "llama_print_timings:        eval time =     237.03 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    3834.13 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.52 ms /     6 runs   (    0.59 ms per token,  1705.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2776.77 ms /   523 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =     196.40 ms /     5 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3176.55 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3126.96 ms /   590 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
            "llama_print_timings:        eval time =     193.16 ms /     5 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    3505.07 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1759.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4579.24 ms /   843 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =     199.45 ms /     5 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    5081.33 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =      35.64 ms /    64 runs   (    0.56 ms per token,  1795.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5291.42 ms /   965 tokens (    5.48 ms per token,   182.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2555.34 ms /    63 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    8421.62 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     6 runs   (    0.71 ms per token,  1413.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3753.77 ms /   698 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =     198.39 ms /     5 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4188.08 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3042.03 ms /   560 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =     198.65 ms /     5 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    3532.23 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1841.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3664.38 ms /   688 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
            "llama_print_timings:        eval time =     196.85 ms /     5 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4074.08 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       7.12 ms /    13 runs   (    0.55 ms per token,  1825.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3841.71 ms /   716 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
            "llama_print_timings:        eval time =     473.57 ms /    12 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    4553.21 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What employee benefits does the Walmart Inc. offer?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.61 ms /     7 runs   (    0.66 ms per token,  1518.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2604.42 ms /   492 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =     234.61 ms /     6 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3108.06 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.59 ms per token,  1682.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3714.17 ms /   690 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
            "llama_print_timings:        eval time =     197.92 ms /     5 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4161.74 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1718.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1988.07 ms /   382 tokens (    5.20 ms per token,   192.15 tokens per second)\n",
            "llama_print_timings:        eval time =     229.51 ms /     6 runs   (   38.25 ms per token,    26.14 tokens per second)\n",
            "llama_print_timings:       total time =    2348.07 ms /   388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1772.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     640.90 ms /   116 tokens (    5.52 ms per token,   181.00 tokens per second)\n",
            "llama_print_timings:        eval time =     232.62 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =     931.45 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1786.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2951.27 ms /   559 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =     234.60 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3373.04 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.67 ms /     7 runs   (    0.67 ms per token,  1498.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2565.33 ms /   486 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =     234.55 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3083.53 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1772.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1947.84 ms /   376 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
            "llama_print_timings:        eval time =     269.21 ms /     7 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2355.34 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1863.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2063.67 ms /   392 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =     268.41 ms /     7 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2463.87 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1722.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3128.53 ms /   592 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     273.31 ms /     7 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3598.70 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.93 ms /     7 runs   (    0.70 ms per token,  1419.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2472.09 ms /   471 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =     234.50 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2917.20 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.28 ms /     7 runs   (    0.61 ms per token,  1633.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5243.37 ms /   956 tokens (    5.48 ms per token,   182.33 tokens per second)\n",
            "llama_print_timings:        eval time =     242.14 ms /     6 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5850.93 ms /   962 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1754.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3799.28 ms /   710 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
            "llama_print_timings:        eval time =     196.60 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    4221.42 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     7 runs   (    0.69 ms per token,  1458.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2251.36 ms /   432 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =     272.68 ms /     7 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2708.50 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     450.10 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1830.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2961.72 ms /   557 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
            "llama_print_timings:        eval time =     193.40 ms /     5 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    3424.25 ms /   562 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total score for approach 2 and distance function l2 is 0.4055727554179567\n"
          ]
        }
      ]
    }
  ]
}