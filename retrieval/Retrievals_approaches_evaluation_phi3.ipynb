{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZn0cvCexnUapf1MFMq1qu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winterForestStump/thesis/blob/main/retrieval/Retrievals_approaches_evaluation_phi3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqMqPVKIzJy0",
        "outputId": "99d27f2a-dfcd-45d9-aa34-82b9c00a5ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.76.tar.gz (49.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.76-cp310-cp310-linux_x86_64.whl size=80964247 sha256=786cfbd21c667c94c081d117736d108918f9780d3601bcf3b91e5617824680ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e5/04/a5fa9e60033548f205f0db5f6ab6f59cd27bd0da7f9c51cfe7\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.76\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download microsoft/Phi-3-mini-4k-instruct-gguf Phi-3-mini-4k-instruct-fp16.gguf --local-dir ./models --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBCZobiVzKeq",
        "outputId": "9bf626f5-7600-44a7-e3e2-9db9a446b736"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:132: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "Downloading 'Phi-3-mini-4k-instruct-fp16.gguf' to 'models/.huggingface/download/Phi-3-mini-4k-instruct-fp16.gguf.5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3.incomplete'\n",
            "Phi-3-mini-4k-instruct-fp16.gguf: 100% 7.64G/7.64G [00:53<00:00, 143MB/s]\n",
            "Download complete. Moving file to models/Phi-3-mini-4k-instruct-fp16.gguf\n",
            "models/Phi-3-mini-4k-instruct-fp16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCqrdCON0gMn",
        "outputId": "8b2a2671-a0ea-485d-90f6-500eed0cfef6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-community --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B4eLZEi3ZND",
        "outputId": "3bdbe33e-3d30-4385-e326-90ccd1aaf226"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from json import JSONDecodeError\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "vdNwMqueoQF5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP = 0\n",
        "N_CTX = 4096\n",
        "N_GPU_L = -1\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/models/Phi-3-mini-4k-instruct-fp16.gguf\",\n",
        "    temperature=TEMP,\n",
        "    n_ctx=N_CTX,\n",
        "    n_gpu_layers = N_GPU_L,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RRPjbl3zOj7",
        "outputId": "f8bf6240-5ef0-4891-fae3-8ead4bab18fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 195 tensors from /content/models/Phi-3-mini-4k-instruct-fp16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
            "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  130 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 323/32064 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = phi3\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32064\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 3072\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 96\n",
            "llm_load_print_meta: n_embd_head_k    = 96\n",
            "llm_load_print_meta: n_embd_head_v    = 96\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
            "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 8192\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 3B\n",
            "llm_load_print_meta: model ftype      = F16\n",
            "llm_load_print_meta: model params     = 3.82 B\n",
            "llm_load_print_meta: model size       = 7.12 GiB (16.00 BPW) \n",
            "llm_load_print_meta: general.name     = Phi3\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   187.88 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  7100.64 MiB\n",
            "....................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1536.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1536.00 MiB, K (f16):  768.00 MiB, V (f16):  768.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =    18.75 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.88 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1286\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'general.name': 'Phi3', 'tokenizer.ggml.pre': 'default', 'phi3.embedding_length': '3072', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.feed_forward_length': '8192', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.rope.dimension_count': '96', 'tokenizer.ggml.model': 'llama', 'general.file_type': '1'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
            "' + message['content'] + '<|end|>' + '\n",
            "' + '<|assistant|>' + '\n",
            "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
            "'}}{% endif %}{% endfor %}\n",
            "Using chat eos_token: <|endoftext|>\n",
            "Using chat bos_token: <s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader for approach 1\n",
        "\n",
        "prompt_1 = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    <|assistant|> You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question, grade it as relevant.\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. <|end|>\n",
        "    <|user|> Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: {question} <|end|>\n",
        "    <|assistant|>\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader_1 = prompt_1 | llm | JsonOutputParser()"
      ],
      "metadata": {
        "id": "B0cVnmRczRED"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader for approach 2\n",
        "\n",
        "prompt_2 = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    <|assistant|> You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question, grade it as relevant.\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. <|end|>\n",
        "    <|user|> Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: {question_name} <|end|>\n",
        "    <|assistant|>\n",
        "    \"\"\",\n",
        "    input_variables=[\"question_name\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader_2 = prompt_2 | llm | JsonOutputParser()"
      ],
      "metadata": {
        "id": "fjWWD4DP67nA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Thesis/retrievals/'\n",
        "\n",
        "dataframes = []\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.json'):\n",
        "        approach_name = file_name\n",
        "        dataframes.append(approach_name)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZJdMhlofa0M8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_results(approach_number:int, distance: str):\n",
        "  results_list = []\n",
        "\n",
        "  for i in range(len(dataframes)):\n",
        "\n",
        "    if approach_number == 1:\n",
        "      approach = pd.read_json(os.path.join(folder_path + dataframes[i]))\n",
        "      try:\n",
        "        for j in range(len(approach)):\n",
        "          question = approach['question'][j]\n",
        "          doc_txt = approach[distance][j]['page_content']\n",
        "          try:\n",
        "            answer = retrieval_grader_1.invoke({\"question\": question, \"document\": doc_txt})\n",
        "            results_list.append(pd.DataFrame({\"approach\": 1,\"distance\": distance, \"question\": question, \"answer\": [answer], \"document\": doc_txt}))\n",
        "          except JSONDecodeError as e:\n",
        "            print(f\"JSONDecodeError occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "          except OutputParserException as e:\n",
        "            print(f\"OutputParserException occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "      except KeyError as e:\n",
        "        print(f\"KeyError occurred: {e}. Skipping approach {approach_number} for dataframe {dataframes[i]}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    elif approach_number == 2:\n",
        "      approach = pd.read_json(os.path.join(folder_path + dataframes[i]))\n",
        "      try:\n",
        "        for j in range(len(approach)):\n",
        "          question = approach['question_name'][j]\n",
        "          doc_txt = approach[distance][j]['page_content']\n",
        "          try:\n",
        "            answer = retrieval_grader_2.invoke({\"question_name\": question, \"document\": doc_txt})\n",
        "            results_list.append(pd.DataFrame({\"approach\": 2,\"distance\": distance, \"question\": question, \"answer\": [answer], \"document\": doc_txt}))\n",
        "          except JSONDecodeError as e:\n",
        "            print(f\"JSONDecodeError occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "          except OutputParserException as e:\n",
        "            print(f\"OutputParserException occurred for question: {question}. Skipping...\")\n",
        "            continue\n",
        "      except KeyError as e:\n",
        "        print(f\"KeyError occurred: {e}. Skipping approach {approach_number} for dataframe {dataframes[i]}\")\n",
        "        continue\n",
        "\n",
        "  if results_list:\n",
        "    results = pd.concat(results_list, ignore_index=True)\n",
        "    score = 0\n",
        "    for i in range(len(results)):\n",
        "      if (results['answer'][i] is not None) and (results['answer'][i]['score'] == 'yes'):\n",
        "        score += 1\n",
        "    total_score = score/len(results)\n",
        "    print(f'Total score for approach {approach_number} and distance function {distance} is {total_score}')\n",
        "    results.to_json(f'/content/drive/MyDrive/Thesis/evaluation/eval_{approach_number}_{distance}.json')\n",
        "  else:\n",
        "    print(f\"No results to concatenate for approach {approach_number} and distance {distance}\")"
      ],
      "metadata": {
        "id": "ucfAHsBia0JX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(1, 'cosine')"
      ],
      "metadata": {
        "id": "EHHf1hr-3XM6",
        "outputId": "628678d3-58d9-47c2-ee12-7062753bde8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4585.43 ms /   786 tokens (    5.83 ms per token,   171.41 tokens per second)\n",
            "llama_print_timings:        eval time =     273.68 ms /     6 runs   (   45.61 ms per token,    21.92 tokens per second)\n",
            "llama_print_timings:       total time =    4966.56 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.14 ms /    68 runs   (    0.62 ms per token,  1613.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3136.35 ms /   608 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2611.39 ms /    68 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    5876.41 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      59.25 ms /    70 runs   (    0.85 ms per token,  1181.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4103.76 ms /   772 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2752.32 ms /    69 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7051.17 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3513.69 ms /   659 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =     230.69 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    3771.81 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     168.61 ms /   256 runs   (    0.66 ms per token,  1518.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2639.24 ms /   512 tokens (    5.15 ms per token,   193.99 tokens per second)\n",
            "llama_print_timings:        eval time =    9919.94 ms /   255 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =   13080.39 ms /   767 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2653.23 ms /   508 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     231.50 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2903.13 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.97 ms /    89 runs   (    0.56 ms per token,  1781.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2269.65 ms /   440 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3440.01 ms /    89 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    5840.81 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.55 ms /    64 runs   (    0.73 ms per token,  1374.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1749.18 ms /   336 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2454.19 ms /    63 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4333.61 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       2.97 ms /     6 runs   (    0.50 ms per token,  2017.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3466.86 ms /   650 tokens (    5.33 ms per token,   187.49 tokens per second)\n",
            "llama_print_timings:        eval time =     195.74 ms /     5 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3680.54 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.17 ms /    69 runs   (    0.60 ms per token,  1676.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2718.70 ms /   519 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2652.34 ms /    68 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    5481.90 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.16 ms /     7 runs   (    0.74 ms per token,  1357.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2364.14 ms /   447 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =     237.81 ms /     6 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    2623.92 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.03 ms /     7 runs   (    0.72 ms per token,  1390.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     649.81 ms /   115 tokens (    5.65 ms per token,   176.98 tokens per second)\n",
            "llama_print_timings:        eval time =     236.74 ms /     6 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =     906.77 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1676.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     736.79 ms /   131 tokens (    5.62 ms per token,   177.80 tokens per second)\n",
            "llama_print_timings:        eval time =     245.32 ms /     6 runs   (   40.89 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    1001.36 ms /   137 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     166.58 ms /   256 runs   (    0.65 ms per token,  1536.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2215.91 ms /   418 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
            "llama_print_timings:        eval time =   10069.04 ms /   255 runs   (   39.49 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   12789.58 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.31 ms /    94 runs   (    0.62 ms per token,  1611.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     880.83 ms /   168 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3647.96 ms /    94 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4681.70 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.06 ms /   104 runs   (    0.66 ms per token,  1505.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3497.87 ms /   647 tokens (    5.41 ms per token,   184.97 tokens per second)\n",
            "llama_print_timings:        eval time =    4176.60 ms /   103 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    7864.40 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     103.48 ms /   175 runs   (    0.59 ms per token,  1691.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2269.79 ms /   420 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
            "llama_print_timings:        eval time =    6950.39 ms /   174 runs   (   39.94 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    9502.35 ms /   594 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.81 ms /    69 runs   (    0.75 ms per token,  1331.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2514.60 ms /   472 tokens (    5.33 ms per token,   187.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2769.89 ms /    69 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5415.38 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.91 ms /    73 runs   (    0.60 ms per token,  1662.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3321.93 ms /   610 tokens (    5.45 ms per token,   183.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2882.47 ms /    72 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6319.11 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      73.38 ms /    98 runs   (    0.75 ms per token,  1335.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4073.86 ms /   747 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3946.58 ms /    97 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    8219.11 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     102.60 ms /   153 runs   (    0.67 ms per token,  1491.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5955.27 ms /  1072 tokens (    5.56 ms per token,   180.01 tokens per second)\n",
            "llama_print_timings:        eval time =    6330.28 ms /   153 runs   (   41.37 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   12612.15 ms /  1225 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.19 ms /    72 runs   (    0.60 ms per token,  1667.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2067.53 ms /   392 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2821.78 ms /    72 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5004.17 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.11 ms /    74 runs   (    0.61 ms per token,  1640.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2057.16 ms /   386 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2854.74 ms /    73 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5032.59 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.43 ms /    59 runs   (    0.74 ms per token,  1358.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1925.20 ms /   364 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2283.96 ms /    58 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    4323.91 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.33 ms /    76 runs   (    0.60 ms per token,  1676.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2320.82 ms /   437 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2939.62 ms /    75 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5376.33 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1718.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2527.56 ms /   475 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =     232.96 ms /     6 runs   (   38.83 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2780.06 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1650.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1463.32 ms /   271 tokens (    5.40 ms per token,   185.20 tokens per second)\n",
            "llama_print_timings:        eval time =     234.42 ms /     6 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    1713.54 ms /   277 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.08 ms /     7 runs   (    0.73 ms per token,  1377.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2550.50 ms /   475 tokens (    5.37 ms per token,   186.24 tokens per second)\n",
            "llama_print_timings:        eval time =     235.60 ms /     6 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2806.49 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.81 ms /   256 runs   (    0.61 ms per token,  1632.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2250.79 ms /   421 tokens (    5.35 ms per token,   187.05 tokens per second)\n",
            "llama_print_timings:        eval time =   10055.77 ms /   255 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   12733.81 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      84.84 ms /   140 runs   (    0.61 ms per token,  1650.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2936.70 ms /   541 tokens (    5.43 ms per token,   184.22 tokens per second)\n",
            "llama_print_timings:        eval time =    5529.49 ms /   139 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    8686.85 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.01 ms /    94 runs   (    0.68 ms per token,  1468.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2756.20 ms /   515 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3708.63 ms /    93 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    6631.74 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      71.74 ms /   122 runs   (    0.59 ms per token,  1700.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1496.49 ms /   271 tokens (    5.52 ms per token,   181.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4836.27 ms /   121 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    6508.35 ms /   392 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     6 runs   (    0.59 ms per token,  1708.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2141.71 ms /   405 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
            "llama_print_timings:        eval time =     197.32 ms /     5 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    2352.60 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.60 ms per token,  1680.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2061.08 ms /   392 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =     233.99 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2310.97 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.02 ms /     9 runs   (    0.78 ms per token,  1281.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     445.93 ms /    88 tokens (    5.07 ms per token,   197.34 tokens per second)\n",
            "llama_print_timings:        eval time =     352.83 ms /     9 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =     817.06 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.90 ms /     7 runs   (    0.70 ms per token,  1428.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2704.23 ms /   499 tokens (    5.42 ms per token,   184.53 tokens per second)\n",
            "llama_print_timings:        eval time =     243.11 ms /     6 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    2967.96 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1620.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2192.59 ms /   416 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =     232.86 ms /     6 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2440.30 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1787.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2443.66 ms /   458 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
            "llama_print_timings:        eval time =     236.13 ms /     6 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2695.29 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      95.99 ms /   143 runs   (    0.67 ms per token,  1489.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2713.96 ms /   511 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =    5678.59 ms /   142 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    8660.69 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.93 ms /    79 runs   (    0.62 ms per token,  1614.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3172.45 ms /   584 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3119.00 ms /    78 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    6421.85 ms /   662 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.43 ms /    64 runs   (    0.71 ms per token,  1408.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3428.54 ms /   637 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2534.97 ms /    63 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    6081.62 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.62 ms /    67 runs   (    0.58 ms per token,  1734.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2690.55 ms /   503 tokens (    5.35 ms per token,   186.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2607.14 ms /    66 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5397.24 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1966.77 ms /   371 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =     237.15 ms /     6 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2219.39 ms /   377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.61 ms /    69 runs   (    0.68 ms per token,  1480.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3292.72 ms /   616 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2766.43 ms /    69 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    6182.63 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.11 ms /    90 runs   (    0.57 ms per token,  1761.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4003.18 ms /   736 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3624.22 ms /    90 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    7764.65 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     6 runs   (    0.63 ms per token,  1592.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3294.74 ms /   616 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =     237.71 ms /     6 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    3550.04 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.59 ms /     6 runs   (    0.76 ms per token,  1307.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1676.71 ms /   315 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
            "llama_print_timings:        eval time =     199.66 ms /     5 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    1894.45 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     6 runs   (    0.72 ms per token,  1390.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     233.51 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =     247.88 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.44 ms /     9 runs   (    0.60 ms per token,  1654.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2569.00 ms /   474 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =     315.25 ms /     8 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2907.03 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      70.62 ms /   119 runs   (    0.59 ms per token,  1684.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2143.86 ms /   408 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
            "llama_print_timings:        eval time =    4628.51 ms /   118 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6954.76 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     163.85 ms /   256 runs   (    0.64 ms per token,  1562.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2268.66 ms /   428 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
            "llama_print_timings:        eval time =   10116.11 ms /   255 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =   12831.95 ms /   683 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1657.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2315.69 ms /   439 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =     236.28 ms /     6 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2567.73 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.72 ms /   256 runs   (    0.61 ms per token,  1633.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2875.98 ms /   533 tokens (    5.40 ms per token,   185.33 tokens per second)\n",
            "llama_print_timings:        eval time =   10177.11 ms /   255 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =   13482.76 ms /   788 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.91 ms /    68 runs   (    0.59 ms per token,  1704.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4904.92 ms /   884 tokens (    5.55 ms per token,   180.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2729.87 ms /    67 runs   (   40.74 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    7745.73 ms /   951 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     170.86 ms /   256 runs   (    0.67 ms per token,  1498.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2888.92 ms /   541 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =   10210.17 ms /   255 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =   13589.39 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2574.57 ms /   484 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =     239.44 ms /     6 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    2830.33 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     167.41 ms /   256 runs   (    0.65 ms per token,  1529.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2228.49 ms /   419 tokens (    5.32 ms per token,   188.02 tokens per second)\n",
            "llama_print_timings:        eval time =   10113.52 ms /   255 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =   12821.10 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      80.13 ms /   103 runs   (    0.78 ms per token,  1285.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3426.17 ms /   634 tokens (    5.40 ms per token,   185.05 tokens per second)\n",
            "llama_print_timings:        eval time =    4108.45 ms /   102 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    7750.63 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.24 ms /   256 runs   (    0.62 ms per token,  1607.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.39 ms /   416 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =   10126.84 ms /   256 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   12793.48 ms /   672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.80 ms /    69 runs   (    0.59 ms per token,  1691.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2231.41 ms /   410 tokens (    5.44 ms per token,   183.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2685.59 ms /    68 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5024.10 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.35 ms /    85 runs   (    0.60 ms per token,  1655.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2318.24 ms /   435 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3306.85 ms /    84 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5761.12 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.65 ms /    88 runs   (    0.79 ms per token,  1263.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2199.31 ms /   410 tokens (    5.36 ms per token,   186.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3440.11 ms /    87 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    5817.69 ms /   497 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.30 ms /    12 runs   (    0.61 ms per token,  1642.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2400.52 ms /   454 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =     433.60 ms /    11 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2857.80 ms /   465 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.66 ms /    65 runs   (    0.63 ms per token,  1598.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2776.16 ms /   516 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2541.68 ms /    64 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    5424.15 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.64 ms /    80 runs   (    0.60 ms per token,  1679.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3559.55 ms /   655 tokens (    5.43 ms per token,   184.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3162.33 ms /    79 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6848.59 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1696.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2321.57 ms /   438 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =     235.13 ms /     6 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2573.69 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.61 ms /    72 runs   (    0.70 ms per token,  1422.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2228.11 ms /   422 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2815.56 ms /    71 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    5175.81 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.22 ms /    60 runs   (    0.62 ms per token,  1612.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2082.83 ms /   390 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2295.39 ms /    59 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    4484.59 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.56 ms /    96 runs   (    0.60 ms per token,  1667.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3320.83 ms /   616 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3805.64 ms /    95 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    7283.12 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.76 ms /    91 runs   (    0.62 ms per token,  1603.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3671.35 ms /   672 tokens (    5.46 ms per token,   183.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3636.59 ms /    90 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    7472.35 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     7 runs   (    0.68 ms per token,  1475.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2622.03 ms /   486 tokens (    5.40 ms per token,   185.35 tokens per second)\n",
            "llama_print_timings:        eval time =     238.85 ms /     6 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    2883.09 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     157.88 ms /   256 runs   (    0.62 ms per token,  1621.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3170.22 ms /   592 tokens (    5.36 ms per token,   186.74 tokens per second)\n",
            "llama_print_timings:        eval time =   10301.31 ms /   255 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   13945.43 ms /   847 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.91 ms /    69 runs   (    0.74 ms per token,  1355.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4425.04 ms /   805 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2779.68 ms /    68 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    7355.77 ms /   873 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      66.03 ms /   109 runs   (    0.61 ms per token,  1650.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3209.42 ms /   598 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4302.06 ms /   108 runs   (   39.83 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    7678.78 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     7 runs   (    0.73 ms per token,  1371.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2183.60 ms /   412 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
            "llama_print_timings:        eval time =     238.06 ms /     6 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    2444.18 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.16 ms /     7 runs   (    0.74 ms per token,  1356.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1838.08 ms /   341 tokens (    5.39 ms per token,   185.52 tokens per second)\n",
            "llama_print_timings:        eval time =     239.01 ms /     6 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    2093.68 ms /   347 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.16 ms /   256 runs   (    0.61 ms per token,  1649.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.84 ms /   419 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
            "llama_print_timings:        eval time =   10080.09 ms /   255 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   12754.21 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1670.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2559.80 ms /   475 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =     237.00 ms /     6 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    2817.53 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     6 runs   (    0.61 ms per token,  1648.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2190.33 ms /   414 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =     196.61 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2401.72 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.36 ms /    69 runs   (    0.66 ms per token,  1521.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5431.18 ms /   983 tokens (    5.53 ms per token,   180.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2806.44 ms /    68 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =    8370.25 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1899.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3409.88 ms /   632 tokens (    5.40 ms per token,   185.34 tokens per second)\n",
            "llama_print_timings:        eval time =     279.07 ms /     7 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    3709.20 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.99 ms /    64 runs   (    0.58 ms per token,  1730.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2755.04 ms /   520 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2479.97 ms /    63 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5329.48 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      62.26 ms /    85 runs   (    0.73 ms per token,  1365.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2593.42 ms /   483 tokens (    5.37 ms per token,   186.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3364.79 ms /    84 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    6120.10 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     167.45 ms /   256 runs   (    0.65 ms per token,  1528.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.08 ms /   415 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =   10071.86 ms /   255 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   12744.02 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.34 ms /    68 runs   (    0.62 ms per token,  1605.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2080.82 ms /   391 tokens (    5.32 ms per token,   187.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2613.39 ms /    67 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4807.13 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.86 ms /    78 runs   (    0.59 ms per token,  1700.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2717.81 ms /   512 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3088.14 ms /    78 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    5926.34 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      76.36 ms /   110 runs   (    0.69 ms per token,  1440.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2880.38 ms /   531 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4368.61 ms /   109 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7457.65 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.12 ms /    12 runs   (    0.59 ms per token,  1684.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2763.87 ms /   515 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
            "llama_print_timings:        eval time =     440.95 ms /    11 runs   (   40.09 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    3229.72 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.20 ms /    12 runs   (    0.60 ms per token,  1665.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2558.13 ms /   479 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =     443.01 ms /    11 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    3026.51 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.19 ms /     7 runs   (    0.74 ms per token,  1349.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2341.19 ms /   440 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =     274.86 ms /     7 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2636.71 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.57 ms /     7 runs   (    0.65 ms per token,  1530.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2038.06 ms /   383 tokens (    5.32 ms per token,   187.92 tokens per second)\n",
            "llama_print_timings:        eval time =     237.36 ms /     6 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    2293.13 ms /   389 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      62.34 ms /   106 runs   (    0.59 ms per token,  1700.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2455.27 ms /   464 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
            "llama_print_timings:        eval time =    4166.05 ms /   106 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6781.55 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     104.80 ms /   150 runs   (    0.70 ms per token,  1431.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2763.59 ms /   520 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
            "llama_print_timings:        eval time =    6015.45 ms /   150 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    9068.68 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.80 ms /    95 runs   (    0.62 ms per token,  1615.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2599.08 ms /   484 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3731.64 ms /    94 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6483.48 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     174.41 ms /   256 runs   (    0.68 ms per token,  1467.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1802.79 ms /   344 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =   10105.38 ms /   256 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   12399.44 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     168.29 ms /   256 runs   (    0.66 ms per token,  1521.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2982.83 ms /   556 tokens (    5.36 ms per token,   186.40 tokens per second)\n",
            "llama_print_timings:        eval time =   10228.26 ms /   255 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   13693.71 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1714.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1539.72 ms /   293 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =     232.50 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    1788.48 ms /   299 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.82 ms /    67 runs   (    0.77 ms per token,  1293.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1633.13 ms /   308 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2604.72 ms /    66 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    4381.55 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     157.70 ms /   256 runs   (    0.62 ms per token,  1623.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1629.83 ms /   306 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
            "llama_print_timings:        eval time =    9981.09 ms /   255 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12070.93 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.41 ms /     9 runs   (    0.71 ms per token,  1404.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1174.23 ms /   221 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =     312.34 ms /     8 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    1506.59 ms /   229 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      76.58 ms /   112 runs   (    0.68 ms per token,  1462.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.55 ms /   436 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =    4383.03 ms /   111 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6917.43 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.06 ms /    64 runs   (    0.67 ms per token,  1486.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2395.14 ms /   447 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2487.52 ms /    63 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    4994.87 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     158.61 ms /   256 runs   (    0.62 ms per token,  1613.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2796.33 ms /   518 tokens (    5.40 ms per token,   185.24 tokens per second)\n",
            "llama_print_timings:        eval time =   10156.82 ms /   255 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =   13413.20 ms /   773 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    12 runs   (    0.77 ms per token,  1302.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1954.91 ms /   367 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =     435.81 ms /    11 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    2421.05 ms /   378 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.90 ms /    68 runs   (    0.60 ms per token,  1662.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1547.09 ms /   296 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2605.65 ms /    67 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4260.24 ms /   363 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     167.89 ms /   256 runs   (    0.66 ms per token,  1524.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1923.36 ms /   362 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =   10060.32 ms /   255 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   12468.61 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.88 ms /    77 runs   (    0.61 ms per token,  1642.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1916.65 ms /   362 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2971.44 ms /    76 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5004.31 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.73 ms /    70 runs   (    0.74 ms per token,  1353.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2222.53 ms /   419 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2733.07 ms /    69 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    5087.36 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.80 ms /    12 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2768.09 ms /   517 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =     433.88 ms /    11 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3229.35 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.80 ms /    12 runs   (    0.57 ms per token,  1764.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2551.20 ms /   480 tokens (    5.32 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =     472.71 ms /    12 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3047.15 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      92.53 ms /   129 runs   (    0.72 ms per token,  1394.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3514.19 ms /   650 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =    5158.88 ms /   128 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    8915.92 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.12 ms /    66 runs   (    0.61 ms per token,  1645.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1407.57 ms /   271 tokens (    5.19 ms per token,   192.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2543.12 ms /    65 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    4046.06 ms /   336 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     169.08 ms /   256 runs   (    0.66 ms per token,  1514.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1479.99 ms /   274 tokens (    5.40 ms per token,   185.14 tokens per second)\n",
            "llama_print_timings:        eval time =   10085.08 ms /   255 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   12016.49 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.17 ms /    68 runs   (    0.58 ms per token,  1735.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1791.62 ms /   344 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2620.65 ms /    67 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4505.34 ms /   411 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.94 ms /    11 runs   (    0.72 ms per token,  1385.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2973.72 ms /   555 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
            "llama_print_timings:        eval time =     399.22 ms /    10 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    3399.34 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.11 ms /     7 runs   (    0.73 ms per token,  1371.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1900.29 ms /   359 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =     238.85 ms /     6 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    2157.05 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.56 ms /    93 runs   (    0.59 ms per token,  1704.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2811.33 ms /   526 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3627.71 ms /    92 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6571.96 ms /   618 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.67 ms /    73 runs   (    0.69 ms per token,  1440.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2712.01 ms /   512 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2900.85 ms /    73 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    5743.18 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.95 ms /    72 runs   (    0.58 ms per token,  1716.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2791.93 ms /   517 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2802.07 ms /    71 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5702.64 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     164.88 ms /   256 runs   (    0.64 ms per token,  1552.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1575.81 ms /   300 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =   10024.13 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12065.50 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     102.36 ms /   166 runs   (    0.62 ms per token,  1621.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2712.19 ms /   512 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =    6549.97 ms /   165 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    9536.20 ms /   677 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.55 ms /   256 runs   (    0.61 ms per token,  1635.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1904.58 ms /   355 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9990.61 ms /   255 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   12313.65 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.25 ms /    91 runs   (    0.71 ms per token,  1416.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1366.48 ms /   255 tokens (    5.36 ms per token,   186.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3554.84 ms /    90 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5087.86 ms /   345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      86.22 ms /   136 runs   (    0.63 ms per token,  1577.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4953.30 ms /   898 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =    5543.78 ms /   135 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   10734.85 ms /  1033 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.21 ms /    71 runs   (    0.58 ms per token,  1723.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3147.10 ms /   584 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2780.76 ms /    70 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6041.32 ms /   654 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     164.57 ms /   256 runs   (    0.64 ms per token,  1555.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1619.33 ms /   307 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =   10032.64 ms /   255 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   12127.33 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     6 runs   (    0.64 ms per token,  1565.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1974.97 ms /   368 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
            "llama_print_timings:        eval time =     196.42 ms /     5 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2186.10 ms /   373 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      99.77 ms /   144 runs   (    0.69 ms per token,  1443.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2141.87 ms /   404 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5644.01 ms /   143 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    8049.40 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     180.97 ms /   256 runs   (    0.71 ms per token,  1414.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.65 ms /   423 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =   10137.75 ms /   255 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =   12881.60 ms /   678 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.13 ms /    70 runs   (    0.59 ms per token,  1702.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2976.92 ms /   551 tokens (    5.40 ms per token,   185.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2736.69 ms /    69 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    5823.78 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.22 ms /    62 runs   (    0.73 ms per token,  1371.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2931.07 ms /   547 tokens (    5.36 ms per token,   186.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2442.94 ms /    61 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    5489.33 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     6 runs   (    0.60 ms per token,  1671.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5449.62 ms /   982 tokens (    5.55 ms per token,   180.20 tokens per second)\n",
            "llama_print_timings:        eval time =     205.36 ms /     5 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    5681.34 ms /   987 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.21 ms /    82 runs   (    0.64 ms per token,  1570.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2796.44 ms /   522 tokens (    5.36 ms per token,   186.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3204.06 ms /    81 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6126.82 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.80 ms /    76 runs   (    0.56 ms per token,  1775.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3749.68 ms /   683 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3013.01 ms /    75 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    6882.49 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.38 ms /    83 runs   (    0.66 ms per token,  1526.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5388.32 ms /   975 tokens (    5.53 ms per token,   180.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3401.25 ms /    82 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =    8948.58 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.09 ms /    77 runs   (    0.57 ms per token,  1746.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2823.49 ms /   523 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3015.64 ms /    76 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    5948.94 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      23.15 ms /    40 runs   (    0.58 ms per token,  1728.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3709.59 ms /   687 tokens (    5.40 ms per token,   185.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.09 ms /    39 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    5342.51 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.89 ms /    73 runs   (    0.72 ms per token,  1380.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     133.75 ms /    24 tokens (    5.57 ms per token,   179.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2929.65 ms /    72 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    3200.65 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      61.38 ms /   108 runs   (    0.57 ms per token,  1759.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4403.10 ms /   802 tokens (    5.49 ms per token,   182.14 tokens per second)\n",
            "llama_print_timings:        eval time =    4343.43 ms /   107 runs   (   40.59 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    8909.48 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.29 ms /    75 runs   (    0.66 ms per token,  1521.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3492.99 ms /   645 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2978.62 ms /    74 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    6604.85 ms /   719 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      71.65 ms /   114 runs   (    0.63 ms per token,  1591.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5010.38 ms /   911 tokens (    5.50 ms per token,   181.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4634.75 ms /   113 runs   (   41.02 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    9837.53 ms /  1024 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.87 ms /    85 runs   (    0.61 ms per token,  1638.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3372.66 ms /   622 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3351.80 ms /    84 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    6852.36 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      78.88 ms /   109 runs   (    0.72 ms per token,  1381.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5003.29 ms /   912 tokens (    5.49 ms per token,   182.28 tokens per second)\n",
            "llama_print_timings:        eval time =    4491.03 ms /   109 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
            "llama_print_timings:       total time =    9712.29 ms /  1021 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.02 ms /    85 runs   (    0.59 ms per token,  1699.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3337.76 ms /   619 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3350.43 ms /    84 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    6814.17 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     160.68 ms /   256 runs   (    0.63 ms per token,  1593.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2574.73 ms /   482 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =   10169.09 ms /   255 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =   13188.96 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1716.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1879.84 ms /   360 tokens (    5.22 ms per token,   191.51 tokens per second)\n",
            "llama_print_timings:        eval time =     276.72 ms /     7 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2171.80 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.61 ms /    80 runs   (    0.71 ms per token,  1413.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2278.83 ms /   432 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3168.08 ms /    80 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    5587.62 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      61.87 ms /   104 runs   (    0.59 ms per token,  1680.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4021.46 ms /   742 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =    4150.94 ms /   103 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    8344.58 ms /   845 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.12 ms /    75 runs   (    0.67 ms per token,  1496.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3742.57 ms /   687 tokens (    5.45 ms per token,   183.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2986.55 ms /    74 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    6880.52 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.58 ms /    71 runs   (    0.61 ms per token,  1629.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1837.32 ms /   348 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2738.39 ms /    70 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    4687.29 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     172.69 ms /   256 runs   (    0.67 ms per token,  1482.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2188.65 ms /   413 tokens (    5.30 ms per token,   188.70 tokens per second)\n",
            "llama_print_timings:        eval time =   10124.76 ms /   255 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =   12799.40 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      59.24 ms /    84 runs   (    0.71 ms per token,  1417.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2946.78 ms /   552 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3355.43 ms /    84 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    6468.42 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.98 ms /    68 runs   (    0.60 ms per token,  1659.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2555.35 ms /   478 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2636.76 ms /    67 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5300.10 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    58 runs   (    0.63 ms per token,  1594.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1410.68 ms /   272 tokens (    5.19 ms per token,   192.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2229.65 ms /    57 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3733.45 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     170.06 ms /   256 runs   (    0.66 ms per token,  1505.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     123.93 ms /    21 tokens (    5.90 ms per token,   169.45 tokens per second)\n",
            "llama_print_timings:        eval time =   10006.45 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   10615.19 ms /   276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     143.68 ms /   193 runs   (    0.74 ms per token,  1343.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1371.82 ms /   264 tokens (    5.20 ms per token,   192.44 tokens per second)\n",
            "llama_print_timings:        eval time =    7568.43 ms /   192 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    9374.20 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      62.55 ms /   103 runs   (    0.61 ms per token,  1646.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1340.84 ms /   255 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3970.21 ms /   102 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5482.26 ms /   357 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     170.56 ms /   256 runs   (    0.67 ms per token,  1500.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2496.70 ms /   469 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10173.42 ms /   255 runs   (   39.90 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =   13197.22 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.19 ms /   237 runs   (    0.67 ms per token,  1488.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2583.84 ms /   482 tokens (    5.36 ms per token,   186.54 tokens per second)\n",
            "llama_print_timings:        eval time =    9417.51 ms /   236 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =   12467.46 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     176.35 ms /   256 runs   (    0.69 ms per token,  1451.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =      84.58 ms /    15 tokens (    5.64 ms per token,   177.34 tokens per second)\n",
            "llama_print_timings:        eval time =   10168.65 ms /   255 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =   10782.68 ms /   270 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      67.84 ms /   114 runs   (    0.60 ms per token,  1680.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2411.56 ms /   455 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4449.21 ms /   113 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    7054.66 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.53 ms /     9 runs   (    0.61 ms per token,  1628.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1668.50 ms /   320 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =     349.41 ms /     9 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2037.73 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.30 ms /     6 runs   (    0.88 ms per token,  1131.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2480.09 ms /   462 tokens (    5.37 ms per token,   186.28 tokens per second)\n",
            "llama_print_timings:        eval time =     197.59 ms /     5 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2700.18 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      74.03 ms /   109 runs   (    0.68 ms per token,  1472.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1260.19 ms /   234 tokens (    5.39 ms per token,   185.69 tokens per second)\n",
            "llama_print_timings:        eval time =    4201.68 ms /   108 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    5666.07 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     9 runs   (    0.56 ms per token,  1794.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.52 ms /   151 tokens (    5.15 ms per token,   194.21 tokens per second)\n",
            "llama_print_timings:        eval time =     322.09 ms /     8 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    1115.97 ms /   159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.03 ms /   515 tokens (    5.36 ms per token,   186.46 tokens per second)\n",
            "llama_print_timings:        eval time =     237.16 ms /     6 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3019.24 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     119.19 ms /   192 runs   (    0.62 ms per token,  1610.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2822.64 ms /   526 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =    7658.13 ms /   191 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =   10838.80 ms /   717 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1588.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.09 ms /   428 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =     237.20 ms /     6 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2529.81 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     171.20 ms /   256 runs   (    0.67 ms per token,  1495.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2144.55 ms /   407 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =   10135.64 ms /   255 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =   12768.96 ms /   662 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      99.31 ms /   140 runs   (    0.71 ms per token,  1409.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3896.03 ms /   715 tokens (    5.45 ms per token,   183.52 tokens per second)\n",
            "llama_print_timings:        eval time =    5654.64 ms /   139 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    9830.01 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     161.10 ms /   256 runs   (    0.63 ms per token,  1589.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2145.94 ms /   405 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =   10109.94 ms /   255 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =   12741.73 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      24.64 ms /    41 runs   (    0.60 ms per token,  1663.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.92 ms /   428 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.68 ms /    40 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3918.20 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      59.64 ms /    93 runs   (    0.64 ms per token,  1559.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1584.22 ms /   303 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3594.44 ms /    92 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5327.15 ms /   395 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      71.03 ms /   113 runs   (    0.63 ms per token,  1590.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2484.73 ms /   461 tokens (    5.39 ms per token,   185.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4424.97 ms /   112 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    7105.54 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.38 ms /    86 runs   (    0.59 ms per token,  1707.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2723.41 ms /   512 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3418.51 ms /    86 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    6286.72 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.45 ms /     7 runs   (    1.06 ms per token,   939.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2620.48 ms /   486 tokens (    5.39 ms per token,   185.46 tokens per second)\n",
            "llama_print_timings:        eval time =     241.68 ms /     6 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    2889.48 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1776.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2734.39 ms /   512 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =     241.80 ms /     6 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    2994.69 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.58 ms /   105 runs   (    0.61 ms per token,  1651.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3578.69 ms /   661 tokens (    5.41 ms per token,   184.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4178.64 ms /   104 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    7940.33 ms /   765 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      73.86 ms /    98 runs   (    0.75 ms per token,  1326.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1654.36 ms /   312 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3795.88 ms /    97 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5646.81 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      25.18 ms /    41 runs   (    0.61 ms per token,  1628.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2498.75 ms /   469 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.11 ms /    40 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    4153.91 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.97 ms /    65 runs   (    0.69 ms per token,  1445.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1975.91 ms /   376 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2558.74 ms /    65 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4652.56 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.53 ms /     7 runs   (    0.79 ms per token,  1266.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1913.66 ms /   359 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =     237.59 ms /     6 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    2171.79 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.49 ms /   105 runs   (    0.61 ms per token,  1628.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2920.00 ms /   544 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =    4130.40 ms /   104 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7231.69 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.68 ms /    55 runs   (    0.76 ms per token,  1319.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3755.37 ms /   692 tokens (    5.43 ms per token,   184.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2199.04 ms /    54 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    6074.72 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.11 ms /    85 runs   (    0.62 ms per token,  1600.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2337.12 ms /   436 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3293.54 ms /    84 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5764.24 ms /   520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      87.26 ms /   111 runs   (    0.79 ms per token,  1272.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2184.03 ms /   413 tokens (    5.29 ms per token,   189.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4368.28 ms /   110 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    6778.46 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.50 ms /     7 runs   (    0.79 ms per token,  1272.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1902.98 ms /   357 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =     236.21 ms /     6 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    2159.22 ms /   363 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.15 ms /    81 runs   (    0.61 ms per token,  1647.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4003.69 ms /   736 tokens (    5.44 ms per token,   183.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3231.21 ms /    80 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    7377.95 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      55.01 ms /    75 runs   (    0.73 ms per token,  1363.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.75 ms /   496 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2996.96 ms /    75 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    5794.02 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.87 ms /     9 runs   (    0.65 ms per token,  1533.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1471.56 ms /   277 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =     308.62 ms /     8 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    1799.66 ms /   285 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.06 ms /    12 runs   (    0.59 ms per token,  1699.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2533.83 ms /   474 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
            "llama_print_timings:        eval time =     429.65 ms /    11 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2988.34 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.68 ms /    80 runs   (    0.63 ms per token,  1578.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2275.03 ms /   431 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3106.93 ms /    79 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5517.74 ms /   510 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.29 ms /    81 runs   (    0.58 ms per token,  1713.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4260.36 ms /   774 tokens (    5.50 ms per token,   181.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3228.67 ms /    80 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7622.09 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.76 ms /    76 runs   (    0.71 ms per token,  1413.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4857.73 ms /   882 tokens (    5.51 ms per token,   181.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3084.13 ms /    75 runs   (   41.12 ms per token,    24.32 tokens per second)\n",
            "llama_print_timings:       total time =    8101.43 ms /   957 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.35 ms /    80 runs   (    0.58 ms per token,  1726.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4928.40 ms /   891 tokens (    5.53 ms per token,   180.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3227.14 ms /    79 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    8299.37 ms /   970 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.60 ms /    93 runs   (    0.69 ms per token,  1439.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3856.49 ms /   709 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3737.70 ms /    92 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    7781.10 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.47 ms /    72 runs   (    0.59 ms per token,  1695.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2363.34 ms /   448 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2778.12 ms /    71 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5249.72 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      59.86 ms /    91 runs   (    0.66 ms per token,  1520.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5066.15 ms /   916 tokens (    5.53 ms per token,   180.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3701.76 ms /    90 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =    8935.91 ms /  1006 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     157.11 ms /   256 runs   (    0.61 ms per token,  1629.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2756.75 ms /   519 tokens (    5.31 ms per token,   188.27 tokens per second)\n",
            "llama_print_timings:        eval time =   10190.93 ms /   255 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =   13398.32 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.37 ms /    81 runs   (    0.56 ms per token,  1785.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4670.74 ms /   852 tokens (    5.48 ms per token,   182.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3261.24 ms /    80 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    8055.95 ms /   932 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.03 ms /    72 runs   (    0.58 ms per token,  1712.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3471.99 ms /   634 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2847.10 ms /    71 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    6437.29 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      71.45 ms /   110 runs   (    0.65 ms per token,  1539.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4730.36 ms /   861 tokens (    5.49 ms per token,   182.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4465.17 ms /   109 runs   (   40.96 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    9410.67 ms /   970 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.70 ms /    86 runs   (    0.55 ms per token,  1803.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5087.12 ms /   916 tokens (    5.55 ms per token,   180.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3480.06 ms /    85 runs   (   40.94 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    8717.65 ms /  1001 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     6 runs   (    0.62 ms per token,  1609.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5475.23 ms /   983 tokens (    5.57 ms per token,   179.54 tokens per second)\n",
            "llama_print_timings:        eval time =     206.21 ms /     5 runs   (   41.24 ms per token,    24.25 tokens per second)\n",
            "llama_print_timings:       total time =    5709.30 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1885.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5565.27 ms /   998 tokens (    5.58 ms per token,   179.33 tokens per second)\n",
            "llama_print_timings:        eval time =     205.82 ms /     5 runs   (   41.16 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    5802.94 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.93 ms /    56 runs   (    0.66 ms per token,  1516.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4221.66 ms /   776 tokens (    5.44 ms per token,   183.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2234.78 ms /    55 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6576.10 ms /   831 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      92.65 ms /   149 runs   (    0.62 ms per token,  1608.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4345.53 ms /   791 tokens (    5.49 ms per token,   182.03 tokens per second)\n",
            "llama_print_timings:        eval time =    5999.77 ms /   148 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   10625.70 ms /   939 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.40 ms /    70 runs   (    0.59 ms per token,  1690.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6077.37 ms /  1079 tokens (    5.63 ms per token,   177.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2857.33 ms /    69 runs   (   41.41 ms per token,    24.15 tokens per second)\n",
            "llama_print_timings:       total time =    9071.02 ms /  1148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      30.17 ms /    52 runs   (    0.58 ms per token,  1723.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2104.39 ms /   398 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1984.98 ms /    51 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4176.16 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.16 ms /    56 runs   (    0.65 ms per token,  1548.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5432.34 ms /   975 tokens (    5.57 ms per token,   179.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2268.56 ms /    55 runs   (   41.25 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =    7814.23 ms /  1030 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      55.72 ms /    92 runs   (    0.61 ms per token,  1651.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4551.40 ms /   831 tokens (    5.48 ms per token,   182.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3704.81 ms /    91 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8430.74 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.51 ms /    72 runs   (    0.62 ms per token,  1617.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4368.13 ms /   791 tokens (    5.52 ms per token,   181.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2880.96 ms /    71 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    7379.89 ms /   862 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.75 ms /    10 runs   (    0.58 ms per token,  1738.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2629.42 ms /   495 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =     355.45 ms /     9 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3007.50 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.79 ms /    74 runs   (    0.86 ms per token,  1160.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2213.30 ms /   412 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2923.28 ms /    73 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    5303.84 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.16 ms /    75 runs   (    0.59 ms per token,  1698.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5436.60 ms /   971 tokens (    5.60 ms per token,   178.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3043.08 ms /    74 runs   (   41.12 ms per token,    24.32 tokens per second)\n",
            "llama_print_timings:       total time =    8611.78 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.63 ms /    12 runs   (    0.64 ms per token,  1571.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.65 ms /   503 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =     437.39 ms /    11 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    3140.77 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      93.50 ms /   144 runs   (    0.65 ms per token,  1540.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2434.81 ms /   450 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =    5684.07 ms /   143 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    8379.69 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     162.43 ms /   256 runs   (    0.63 ms per token,  1576.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1624.41 ms /   312 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10054.27 ms /   255 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   12168.16 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.38 ms /   514 tokens (    5.37 ms per token,   186.07 tokens per second)\n",
            "llama_print_timings:        eval time =     244.38 ms /     6 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    3023.55 ms /   520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     171.97 ms /   256 runs   (    0.67 ms per token,  1488.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2189.72 ms /   414 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =   10108.58 ms /   255 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =   12797.25 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.93 ms /    81 runs   (    0.63 ms per token,  1590.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2629.10 ms /   493 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3168.33 ms /    80 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    5942.92 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.01 ms /    72 runs   (    0.61 ms per token,  1635.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3305.08 ms /   608 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2834.89 ms /    71 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    6269.17 ms /   679 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.69 ms /   102 runs   (    0.63 ms per token,  1576.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3897.83 ms /   719 tokens (    5.42 ms per token,   184.46 tokens per second)\n",
            "llama_print_timings:        eval time =    4081.13 ms /   101 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    8171.16 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.25 ms /    97 runs   (    0.65 ms per token,  1533.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1732.78 ms /   325 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3755.93 ms /    96 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5667.37 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.17 ms /    67 runs   (    0.61 ms per token,  1627.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4637.20 ms /   846 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2689.22 ms /    66 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    7456.14 ms /   912 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.60 ms /     6 runs   (    0.77 ms per token,  1305.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2707.01 ms /   498 tokens (    5.44 ms per token,   183.97 tokens per second)\n",
            "llama_print_timings:        eval time =     203.66 ms /     5 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    2934.24 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.88 ms /    77 runs   (    0.61 ms per token,  1642.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1250.38 ms /   237 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2955.91 ms /    76 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4331.18 ms /   313 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1496.21 ms /   285 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =     194.86 ms /     5 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    1705.42 ms /   290 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     6 runs   (    0.66 ms per token,  1505.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5398.11 ms /   971 tokens (    5.56 ms per token,   179.88 tokens per second)\n",
            "llama_print_timings:        eval time =     206.53 ms /     5 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
            "llama_print_timings:       total time =    5630.32 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     6 runs   (    0.60 ms per token,  1657.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5330.21 ms /   960 tokens (    5.55 ms per token,   180.11 tokens per second)\n",
            "llama_print_timings:        eval time =     245.66 ms /     6 runs   (   40.94 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    5608.31 ms /   966 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.57 ms per token,  1741.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1883.33 ms /   359 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =     197.02 ms /     5 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2095.49 ms /   364 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.19 ms /    10 runs   (    0.62 ms per token,  1614.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1420.80 ms /   262 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
            "llama_print_timings:        eval time =     358.53 ms /     9 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    1799.94 ms /   271 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      60.33 ms /    82 runs   (    0.74 ms per token,  1359.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.57 ms /   560 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3250.33 ms /    81 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    6410.46 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.59 ms /    79 runs   (    0.59 ms per token,  1695.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2666.36 ms /   496 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3145.62 ms /    79 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    5950.57 ms /   575 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.17 ms /    11 runs   (    0.65 ms per token,  1535.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =      86.95 ms /    16 tokens (    5.43 ms per token,   184.01 tokens per second)\n",
            "llama_print_timings:        eval time =     393.35 ms /    10 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =     507.45 ms /    26 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.98 ms /    11 runs   (    0.63 ms per token,  1576.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2701.47 ms /   503 tokens (    5.37 ms per token,   186.19 tokens per second)\n",
            "llama_print_timings:        eval time =     394.73 ms /    10 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    3124.05 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.19 ms /    65 runs   (    0.59 ms per token,  1702.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4258.03 ms /   773 tokens (    5.51 ms per token,   181.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2589.40 ms /    64 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    6970.40 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.28 ms /    64 runs   (    0.57 ms per token,  1764.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4304.14 ms /   789 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2547.67 ms /    63 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    6963.58 ms /   852 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      67.02 ms /    87 runs   (    0.77 ms per token,  1298.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     136.06 ms /    24 tokens (    5.67 ms per token,   176.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3555.89 ms /    87 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    3884.40 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.45 ms /    87 runs   (    0.60 ms per token,  1658.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3307.45 ms /   611 tokens (    5.41 ms per token,   184.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3423.99 ms /    86 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6881.56 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.50 ms /   102 runs   (    0.68 ms per token,  1467.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4030.88 ms /   739 tokens (    5.45 ms per token,   183.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4100.39 ms /   101 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    8337.15 ms /   840 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     172.73 ms /   256 runs   (    0.67 ms per token,  1482.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2354.90 ms /   445 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =   10112.70 ms /   255 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =   12969.60 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.43 ms /     9 runs   (    0.60 ms per token,  1657.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2531.73 ms /   474 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =     319.77 ms /     8 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    2872.05 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.76 ms /   115 runs   (    0.56 ms per token,  1775.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2535.01 ms /   477 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    4501.27 ms /   114 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    7224.25 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      10.39 ms /    12 runs   (    0.87 ms per token,  1154.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2802.11 ms /   517 tokens (    5.42 ms per token,   184.50 tokens per second)\n",
            "llama_print_timings:        eval time =     444.72 ms /    11 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    3290.18 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.26 ms /    72 runs   (    0.70 ms per token,  1432.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4859.43 ms /   883 tokens (    5.50 ms per token,   181.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2923.58 ms /    71 runs   (   41.18 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    7935.36 ms /   954 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.32 ms /    78 runs   (    0.68 ms per token,  1462.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3935.03 ms /   715 tokens (    5.50 ms per token,   181.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3118.68 ms /    77 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    7204.28 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.74 ms /    87 runs   (    0.56 ms per token,  1784.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3895.11 ms /   719 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3470.41 ms /    86 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7510.09 ms /   805 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.27 ms /     7 runs   (    0.75 ms per token,  1329.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1680.50 ms /   315 tokens (    5.33 ms per token,   187.44 tokens per second)\n",
            "llama_print_timings:        eval time =     237.77 ms /     6 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    1936.15 ms /   321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      78.14 ms /   130 runs   (    0.60 ms per token,  1663.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3941.44 ms /   715 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =    5222.66 ms /   129 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    9395.42 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      75.09 ms /   109 runs   (    0.69 ms per token,  1451.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1670.34 ms /   320 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =    4298.65 ms /   109 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6174.37 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.96 ms /    85 runs   (    0.56 ms per token,  1772.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4520.20 ms /   821 tokens (    5.51 ms per token,   181.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3415.27 ms /    84 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8077.76 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     120.41 ms /   168 runs   (    0.72 ms per token,  1395.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2098.62 ms /   400 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =    6651.96 ms /   168 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    9072.91 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      98.30 ms /   168 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    6572.77 ms /   168 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6825.95 ms /   168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     120.51 ms /   196 runs   (    0.61 ms per token,  1626.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.99 ms /   374 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =    7657.40 ms /   195 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    9972.80 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     148.65 ms /   229 runs   (    0.65 ms per token,  1540.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     725.58 ms /   131 tokens (    5.54 ms per token,   180.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9045.44 ms /   228 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =   10188.63 ms /   359 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      24.31 ms /    44 runs   (    0.55 ms per token,  1809.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4205.86 ms /   773 tokens (    5.44 ms per token,   183.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1730.57 ms /    43 runs   (   40.25 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    6010.77 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      12.81 ms /    21 runs   (    0.61 ms per token,  1639.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3349.42 ms /   600 tokens (    5.58 ms per token,   179.14 tokens per second)\n",
            "llama_print_timings:        eval time =     855.83 ms /    21 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    4251.36 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.49 ms /    72 runs   (    0.58 ms per token,  1735.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2573.63 ms /   482 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2803.64 ms /    71 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5487.46 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.04 ms /    83 runs   (    0.65 ms per token,  1535.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2366.15 ms /   448 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3285.12 ms /    83 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    5801.28 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      72.83 ms /   125 runs   (    0.58 ms per token,  1716.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2570.50 ms /   479 tokens (    5.37 ms per token,   186.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4911.03 ms /   124 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7676.70 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.41 ms /    79 runs   (    0.65 ms per token,  1536.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2184.95 ms /   411 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3082.82 ms /    78 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    5401.87 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.12 ms /    98 runs   (    0.59 ms per token,  1686.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2525.92 ms /   469 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3825.53 ms /    97 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6506.96 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      86.28 ms /   127 runs   (    0.68 ms per token,  1472.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5975.23 ms /  1070 tokens (    5.58 ms per token,   179.07 tokens per second)\n",
            "llama_print_timings:        eval time =    5259.47 ms /   126 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
            "llama_print_timings:       total time =   11487.23 ms /  1196 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /     6 runs   (    0.52 ms per token,  1931.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5806.76 ms /  1040 tokens (    5.58 ms per token,   179.10 tokens per second)\n",
            "llama_print_timings:        eval time =     205.88 ms /     5 runs   (   41.18 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    6037.81 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      62.24 ms /    98 runs   (    0.64 ms per token,  1574.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3727.94 ms /   683 tokens (    5.46 ms per token,   183.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3917.39 ms /    97 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    7818.82 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.84 ms /    80 runs   (    0.57 ms per token,  1745.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3747.27 ms /   692 tokens (    5.42 ms per token,   184.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3175.27 ms /    79 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7048.43 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    11 runs   (    0.91 ms per token,  1096.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2335.36 ms /   440 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =     432.79 ms /    11 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2796.62 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.23 ms /    83 runs   (    0.58 ms per token,  1720.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2378.33 ms /   442 tokens (    5.38 ms per token,   185.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3201.76 ms /    82 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5708.82 ms /   524 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.87 ms /    66 runs   (    0.57 ms per token,  1742.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2665.52 ms /   501 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2550.69 ms /    65 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5312.84 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     152.48 ms /   256 runs   (    0.60 ms per token,  1678.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2645.04 ms /   490 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
            "llama_print_timings:        eval time =   10131.36 ms /   255 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =   13203.01 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     6 runs   (    0.71 ms per token,  1415.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2867.45 ms /   536 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =     240.16 ms /     6 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    3127.31 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.59 ms per token,  1681.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2690.25 ms /   498 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
            "llama_print_timings:        eval time =     198.86 ms /     5 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    2907.36 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     115.70 ms /   162 runs   (    0.71 ms per token,  1400.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3987.25 ms /   733 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
            "llama_print_timings:        eval time =    6550.11 ms /   161 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =   10877.29 ms /   894 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      77.36 ms /   139 runs   (    0.56 ms per token,  1796.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3947.55 ms /   723 tokens (    5.46 ms per token,   183.15 tokens per second)\n",
            "llama_print_timings:        eval time =    5568.02 ms /   138 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    9736.88 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.64 ms /    61 runs   (    0.75 ms per token,  1336.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2323.51 ms /   435 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2382.68 ms /    60 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4832.83 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      35.41 ms /    61 runs   (    0.58 ms per token,  1722.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.34 ms /   432 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2354.31 ms /    60 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    4740.35 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.64 ms /    81 runs   (    0.59 ms per token,  1700.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2231.48 ms /   421 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3123.28 ms /    80 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5489.12 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      33.57 ms /    54 runs   (    0.62 ms per token,  1608.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2614.55 ms /   485 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2103.87 ms /    53 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    4820.51 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      33.86 ms /    59 runs   (    0.57 ms per token,  1742.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3757.97 ms /   695 tokens (    5.41 ms per token,   184.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2333.87 ms /    58 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    6200.02 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.10 ms /    87 runs   (    0.73 ms per token,  1378.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2324.70 ms /   440 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3464.94 ms /    87 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    5975.10 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.40 ms /    86 runs   (    0.60 ms per token,  1673.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2367.06 ms /   442 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3350.54 ms /    85 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    5873.77 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.66 ms /   439 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =     235.66 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2579.97 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     136.82 ms /   214 runs   (    0.64 ms per token,  1564.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2150.82 ms /   405 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =    8438.31 ms /   213 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =   11003.49 ms /   618 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1702.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2494.27 ms /   470 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =     238.74 ms /     6 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    2751.17 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.77 ms /     7 runs   (    0.82 ms per token,  1212.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1758.65 ms /   336 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =     239.01 ms /     6 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    2019.44 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      99.85 ms /   170 runs   (    0.59 ms per token,  1702.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2273.09 ms /   424 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
            "llama_print_timings:        eval time =    6669.20 ms /   169 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    9245.40 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1543.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1711.07 ms /   323 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =     239.40 ms /     6 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    1967.24 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.54 ms /    76 runs   (    0.69 ms per token,  1446.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2192.51 ms /   411 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2977.78 ms /    75 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    5322.11 ms /   486 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     6 runs   (    0.63 ms per token,  1579.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1669.19 ms /   320 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
            "llama_print_timings:        eval time =     234.74 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    1918.86 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1650.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2014.62 ms /   384 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     273.78 ms /     7 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2305.27 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.26 ms /     7 runs   (    0.61 ms per token,  1642.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2408.55 ms /   455 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =     236.99 ms /     6 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    2663.42 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      99.77 ms /   146 runs   (    0.68 ms per token,  1463.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2038.44 ms /   381 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =    5760.25 ms /   145 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    8084.55 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      25.29 ms /    45 runs   (    0.56 ms per token,  1779.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2896.80 ms /   541 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1745.15 ms /    44 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    4715.11 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.93 ms /    99 runs   (    0.65 ms per token,  1548.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.56 ms /   558 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3937.65 ms /    98 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    7112.53 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.45 ms /    86 runs   (    0.63 ms per token,  1579.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.49 ms /    18 tokens (    7.08 ms per token,   141.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3394.84 ms /    85 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    3669.45 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     147.69 ms /   256 runs   (    0.58 ms per token,  1733.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3123.20 ms /   583 tokens (    5.36 ms per token,   186.67 tokens per second)\n",
            "llama_print_timings:        eval time =   10252.19 ms /   255 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =   13847.67 ms /   838 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      92.51 ms /   140 runs   (    0.66 ms per token,  1513.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3163.11 ms /   590 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
            "llama_print_timings:        eval time =    5572.34 ms /   139 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    9014.73 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      97.11 ms /   167 runs   (    0.58 ms per token,  1719.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2688.97 ms /   499 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =    6577.03 ms /   166 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    9544.20 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     145.49 ms /   235 runs   (    0.62 ms per token,  1615.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2827.21 ms /   528 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
            "llama_print_timings:        eval time =    9350.14 ms /   234 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =   12620.98 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      77.57 ms /   135 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7084.16 ms /  1242 tokens (    5.70 ms per token,   175.32 tokens per second)\n",
            "llama_print_timings:        eval time =    5626.39 ms /   134 runs   (   41.99 ms per token,    23.82 tokens per second)\n",
            "llama_print_timings:       total time =   12975.96 ms /  1376 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.66 ms /    69 runs   (    0.68 ms per token,  1478.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2716.56 ms /   512 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2725.10 ms /    68 runs   (   40.07 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    5576.59 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      61.14 ms /    86 runs   (    0.71 ms per token,  1406.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4312.45 ms /   790 tokens (    5.46 ms per token,   183.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3454.29 ms /    85 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    7943.06 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.24 ms /    79 runs   (    0.74 ms per token,  1356.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3561.91 ms /   655 tokens (    5.44 ms per token,   183.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3157.67 ms /    78 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    6885.96 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     153.73 ms /   256 runs   (    0.60 ms per token,  1665.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.22 ms /   432 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
            "llama_print_timings:        eval time =   10144.41 ms /   256 runs   (   39.63 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =   12921.93 ms /   688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1762.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2477.19 ms /   458 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =     194.21 ms /     5 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2690.63 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      35.00 ms /    61 runs   (    0.57 ms per token,  1742.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3754.62 ms /   691 tokens (    5.43 ms per token,   184.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2410.92 ms /    60 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    6275.65 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     150.16 ms /   243 runs   (    0.62 ms per token,  1618.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2602.92 ms /   486 tokens (    5.36 ms per token,   186.71 tokens per second)\n",
            "llama_print_timings:        eval time =    9676.13 ms /   242 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =   12745.10 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.63 ms /    12 runs   (    0.64 ms per token,  1573.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2057.29 ms /   388 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =     433.79 ms /    11 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    2516.14 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      74.38 ms /   128 runs   (    0.58 ms per token,  1720.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3169.56 ms /   583 tokens (    5.44 ms per token,   183.94 tokens per second)\n",
            "llama_print_timings:        eval time =    5078.11 ms /   127 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    8475.54 ms /   710 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      84.82 ms /   131 runs   (    0.65 ms per token,  1544.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1883.98 ms /   360 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =    5160.83 ms /   131 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    7296.49 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     154.47 ms /   256 runs   (    0.60 ms per token,  1657.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2011.10 ms /   372 tokens (    5.41 ms per token,   184.97 tokens per second)\n",
            "llama_print_timings:        eval time =   10086.26 ms /   255 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   12577.84 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     145.18 ms /   256 runs   (    0.57 ms per token,  1763.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1986.94 ms /   370 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    9994.78 ms /   255 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12438.11 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.17 ms /     7 runs   (    0.74 ms per token,  1352.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2350.67 ms /   439 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
            "llama_print_timings:        eval time =     239.19 ms /     6 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    2614.19 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.17 ms /     7 runs   (    0.74 ms per token,  1352.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     436.25 ms /    74 tokens (    5.90 ms per token,   169.63 tokens per second)\n",
            "llama_print_timings:        eval time =     237.80 ms /     6 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =     691.02 ms /    80 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.37 ms /    78 runs   (    0.58 ms per token,  1719.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.10 ms /   516 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3040.34 ms /    77 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    5940.35 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     157.48 ms /   256 runs   (    0.62 ms per token,  1625.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2319.82 ms /   439 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =   10132.56 ms /   255 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =   12958.04 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.99 ms /    72 runs   (    0.69 ms per token,  1440.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3621.67 ms /   666 tokens (    5.44 ms per token,   183.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2870.24 ms /    71 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    6641.84 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.15 ms /    91 runs   (    0.60 ms per token,  1680.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3437.21 ms /   626 tokens (    5.49 ms per token,   182.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3616.75 ms /    90 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7216.65 ms /   716 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      72.77 ms /   112 runs   (    0.65 ms per token,  1539.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2452.24 ms /   463 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4417.82 ms /   111 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    7086.66 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.30 ms /   256 runs   (    0.61 ms per token,  1637.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2255.91 ms /   423 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =   10102.84 ms /   255 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =   12854.11 ms /   678 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.77 ms /    65 runs   (    0.57 ms per token,  1767.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3675.66 ms /   675 tokens (    5.45 ms per token,   183.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2565.73 ms /    64 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    6352.45 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.25 ms /     9 runs   (    0.69 ms per token,  1440.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6597.84 ms /  1168 tokens (    5.65 ms per token,   177.03 tokens per second)\n",
            "llama_print_timings:        eval time =     378.47 ms /     9 runs   (   42.05 ms per token,    23.78 tokens per second)\n",
            "llama_print_timings:       total time =    7016.06 ms /  1177 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.82 ms /    91 runs   (    0.59 ms per token,  1690.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2149.99 ms /   405 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3523.01 ms /    90 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5819.92 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.71 ms /    90 runs   (    0.65 ms per token,  1533.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5510.70 ms /   989 tokens (    5.57 ms per token,   179.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3691.08 ms /    89 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =    9390.54 ms /  1078 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.40 ms /    77 runs   (    0.58 ms per token,  1734.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2716.55 ms /   507 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3014.26 ms /    76 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    5863.07 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.31 ms /    64 runs   (    0.69 ms per token,  1444.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2101.18 ms /   395 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2498.35 ms /    63 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    4728.29 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     149.84 ms /   227 runs   (    0.66 ms per token,  1514.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3231.99 ms /   595 tokens (    5.43 ms per token,   184.10 tokens per second)\n",
            "llama_print_timings:        eval time =    9108.87 ms /   226 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =   12822.33 ms /   821 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.82 ms /   105 runs   (    0.55 ms per token,  1815.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5286.85 ms /   950 tokens (    5.57 ms per token,   179.69 tokens per second)\n",
            "llama_print_timings:        eval time =    4269.80 ms /   104 runs   (   41.06 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    9747.05 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.28 ms /    74 runs   (    0.57 ms per token,  1750.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5478.56 ms /   980 tokens (    5.59 ms per token,   178.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3005.82 ms /    73 runs   (   41.18 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    8624.13 ms /  1053 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.07 ms /    96 runs   (    0.59 ms per token,  1682.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2713.23 ms /   507 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3753.90 ms /    95 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6630.75 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.57 ms /    68 runs   (    0.60 ms per token,  1675.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3702.13 ms /   679 tokens (    5.45 ms per token,   183.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2687.60 ms /    67 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    6519.96 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.64 ms /    75 runs   (    0.66 ms per token,  1510.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5483.24 ms /   989 tokens (    5.54 ms per token,   180.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3046.80 ms /    74 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    8680.65 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    12 runs   (    0.76 ms per token,  1315.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1646.70 ms /   311 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =     432.15 ms /    11 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    2114.33 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    12 runs   (    0.81 ms per token,  1228.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     465.90 ms /    12 runs   (   38.83 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =     495.02 ms /    12 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     160.04 ms /   256 runs   (    0.63 ms per token,  1599.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2760.12 ms /   514 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =   10185.52 ms /   255 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =   13466.21 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1701.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2498.07 ms /   466 tokens (    5.36 ms per token,   186.54 tokens per second)\n",
            "llama_print_timings:        eval time =     235.56 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2752.93 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.21 ms /    80 runs   (    0.59 ms per token,  1694.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4116.98 ms /   755 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3188.69 ms /    79 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7445.12 ms /   834 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      80.41 ms /   139 runs   (    0.58 ms per token,  1728.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4919.25 ms /   888 tokens (    5.54 ms per token,   180.52 tokens per second)\n",
            "llama_print_timings:        eval time =    5678.78 ms /   139 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =   10832.81 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     162.47 ms /   256 runs   (    0.63 ms per token,  1575.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3124.06 ms /   584 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
            "llama_print_timings:        eval time =   10240.41 ms /   255 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =   13843.23 ms /   839 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.97 ms /    60 runs   (    0.67 ms per token,  1501.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1659.12 ms /   315 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2318.16 ms /    59 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    4086.27 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.33 ms /    60 runs   (    0.77 ms per token,  1294.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2353.96 ms /    60 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2474.87 ms /    60 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.80 ms /   101 runs   (    0.57 ms per token,  1747.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5002.76 ms /   909 tokens (    5.50 ms per token,   181.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4082.18 ms /   100 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    9257.84 ms /  1009 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.98 ms /    67 runs   (    0.67 ms per token,  1489.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1900.78 ms /   358 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2591.25 ms /    66 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    4620.55 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.98 ms /    74 runs   (    0.61 ms per token,  1645.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1577.27 ms /   303 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2856.75 ms /    73 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    4551.13 ms /   376 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      68.76 ms /   105 runs   (    0.65 ms per token,  1527.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2754.00 ms /   519 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4142.26 ms /   104 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7090.78 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.47 ms /   105 runs   (    0.61 ms per token,  1628.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    4175.66 ms /   105 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    4355.92 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      60.16 ms /   104 runs   (    0.58 ms per token,  1728.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2180.34 ms /   410 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
            "llama_print_timings:        eval time =    4023.44 ms /   103 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    6366.37 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.14 ms /     7 runs   (    0.73 ms per token,  1361.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     465.94 ms /    82 tokens (    5.68 ms per token,   175.99 tokens per second)\n",
            "llama_print_timings:        eval time =     236.28 ms /     6 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =     717.64 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.59 ms /     7 runs   (    0.66 ms per token,  1525.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1730.41 ms /   326 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     242.04 ms /     6 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    1990.53 ms /   332 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.59 ms /   118 runs   (    0.59 ms per token,  1695.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1600.91 ms /   298 tokens (    5.37 ms per token,   186.14 tokens per second)\n",
            "llama_print_timings:        eval time =    4568.36 ms /   117 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    6357.80 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     163.79 ms /   256 runs   (    0.64 ms per token,  1562.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2400.71 ms /   453 tokens (    5.30 ms per token,   188.69 tokens per second)\n",
            "llama_print_timings:        eval time =   10130.81 ms /   255 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =   13014.58 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      66.58 ms /   106 runs   (    0.63 ms per token,  1592.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2794.64 ms /   522 tokens (    5.35 ms per token,   186.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4165.75 ms /   105 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    7147.18 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.03 ms /    67 runs   (    0.60 ms per token,  1673.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2342.68 ms /   438 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
            "llama_print_timings:        eval time =    2594.43 ms /    66 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5053.45 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.49 ms /    93 runs   (    0.58 ms per token,  1738.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2271.07 ms /   426 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3605.37 ms /    92 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6023.64 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     6 runs   (    0.70 ms per token,  1430.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2734.65 ms /   510 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
            "llama_print_timings:        eval time =     202.64 ms /     5 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    2956.22 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2645.39 ms /   496 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =     241.03 ms /     6 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    2908.03 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1750.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2013.37 ms /   384 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
            "llama_print_timings:        eval time =     274.50 ms /     7 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2303.57 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.15 ms /     7 runs   (    0.74 ms per token,  1359.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     427.54 ms /    78 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
            "llama_print_timings:        eval time =     238.22 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =     681.82 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    14 runs   (    0.70 ms per token,  1436.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1516.05 ms /   288 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =     505.00 ms /    13 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2052.27 ms /   301 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.81 ms /    69 runs   (    0.61 ms per token,  1650.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1985.83 ms /   376 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2715.53 ms /    69 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    4818.04 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      10.44 ms /    14 runs   (    0.75 ms per token,  1340.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1557.47 ms /   294 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =     509.45 ms /    13 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2099.71 ms /   307 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    14 runs   (    0.61 ms per token,  1628.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1262.47 ms /   239 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =     501.47 ms /    13 runs   (   38.57 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    1788.97 ms /   252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.66 ms /   105 runs   (    0.55 ms per token,  1820.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2142.74 ms /   405 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =    4076.81 ms /   104 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6381.42 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.13 ms /     7 runs   (    0.73 ms per token,  1364.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2418.51 ms /   455 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =     239.43 ms /     6 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    2680.68 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     6 runs   (    0.77 ms per token,  1293.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2222.06 ms /   416 tokens (    5.34 ms per token,   187.21 tokens per second)\n",
            "llama_print_timings:        eval time =     239.43 ms /     6 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    2481.70 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.42 ms /    97 runs   (    0.58 ms per token,  1719.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1795.67 ms /   332 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3773.67 ms /    96 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5716.01 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      30.43 ms /    49 runs   (    0.62 ms per token,  1610.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3296.45 ms /   613 tokens (    5.38 ms per token,   185.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1920.53 ms /    48 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5300.38 ms /   661 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.55 ms /    77 runs   (    0.60 ms per token,  1654.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2255.34 ms /   424 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3031.56 ms /    77 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5411.43 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      70.57 ms /   116 runs   (    0.61 ms per token,  1643.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4168.78 ms /   768 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
            "llama_print_timings:        eval time =    4724.72 ms /   116 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    9091.13 ms /   884 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      60.69 ms /   112 runs   (    0.54 ms per token,  1845.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3336.48 ms /   613 tokens (    5.44 ms per token,   183.73 tokens per second)\n",
            "llama_print_timings:        eval time =    4443.96 ms /   111 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7955.29 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     101.89 ms /   157 runs   (    0.65 ms per token,  1540.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3305.04 ms /   613 tokens (    5.39 ms per token,   185.47 tokens per second)\n",
            "llama_print_timings:        eval time =    6284.86 ms /   156 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    9884.11 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.00 ms /    78 runs   (    0.58 ms per token,  1733.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3357.71 ms /   624 tokens (    5.38 ms per token,   185.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3076.26 ms /    77 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    6562.14 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.09 ms /    52 runs   (    0.71 ms per token,  1401.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2064.50 ms /   392 tokens (    5.27 ms per token,   189.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2059.77 ms /    52 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    4230.12 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.71 ms /    65 runs   (    0.58 ms per token,  1723.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     477.45 ms /    85 tokens (    5.62 ms per token,   178.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2505.26 ms /    64 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3083.40 ms /   149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1669.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2228.25 ms /   419 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
            "llama_print_timings:        eval time =     233.86 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2479.41 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.98 ms /    65 runs   (    0.60 ms per token,  1667.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     906.01 ms /   175 tokens (    5.18 ms per token,   193.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2479.50 ms /    64 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3486.90 ms /   239 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.12 ms /   256 runs   (    0.62 ms per token,  1608.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.28 ms /   453 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10133.02 ms /   255 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =   13029.46 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      61.00 ms /    91 runs   (    0.67 ms per token,  1491.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3667.46 ms /   676 tokens (    5.43 ms per token,   184.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3631.24 ms /    90 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7466.98 ms /   766 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     162.01 ms /   256 runs   (    0.63 ms per token,  1580.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2188.78 ms /   415 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10089.10 ms /   255 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   12752.53 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     153.71 ms /   256 runs   (    0.60 ms per token,  1665.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1831.76 ms /   347 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =   10048.49 ms /   255 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   12305.62 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2531.71 ms /   474 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
            "llama_print_timings:        eval time =     236.53 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2785.75 ms /   480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.25 ms /    78 runs   (    0.55 ms per token,  1803.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2391.74 ms /   451 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3035.20 ms /    77 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    5529.32 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      71.71 ms /   111 runs   (    0.65 ms per token,  1547.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3990.22 ms /   732 tokens (    5.45 ms per token,   183.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4455.34 ms /   110 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    8628.42 ms /   842 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.19 ms /    68 runs   (    0.56 ms per token,  1780.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3621.26 ms /   663 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2686.32 ms /    67 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    6422.48 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     7 runs   (    0.73 ms per token,  1372.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1721.28 ms /   328 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =     276.49 ms /     7 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    2018.27 ms /   335 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2295.55 ms /   426 tokens (    5.39 ms per token,   185.58 tokens per second)\n",
            "llama_print_timings:        eval time =     233.52 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2547.01 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.62 ms /    94 runs   (    0.57 ms per token,  1753.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2706.48 ms /   506 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3674.87 ms /    93 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6527.35 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.76 ms /    12 runs   (    0.56 ms per token,  1774.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2491.86 ms /   470 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     430.52 ms /    11 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2946.09 ms /   481 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.70 ms /   104 runs   (    0.56 ms per token,  1771.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3687.64 ms /   680 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
            "llama_print_timings:        eval time =    4143.72 ms /   103 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7998.00 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     115.37 ms /   173 runs   (    0.67 ms per token,  1499.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5065.23 ms /   918 tokens (    5.52 ms per token,   181.24 tokens per second)\n",
            "llama_print_timings:        eval time =    7138.27 ms /   172 runs   (   41.50 ms per token,    24.10 tokens per second)\n",
            "llama_print_timings:       total time =   12557.79 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      59.88 ms /    90 runs   (    0.67 ms per token,  1503.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2406.41 ms /   453 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3517.73 ms /    89 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6080.97 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.97 ms /    65 runs   (    0.58 ms per token,  1711.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3880.59 ms /   711 tokens (    5.46 ms per token,   183.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2574.06 ms /    64 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    6565.46 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.64 ms /    85 runs   (    0.67 ms per token,  1500.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4438.89 ms /   810 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3426.00 ms /    84 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    8022.95 ms /   894 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.17 ms /    75 runs   (    0.56 ms per token,  1778.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5652.99 ms /  1016 tokens (    5.56 ms per token,   179.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3097.77 ms /    75 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
            "llama_print_timings:       total time =    8876.37 ms /  1091 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     151.57 ms /   256 runs   (    0.59 ms per token,  1689.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2408.46 ms /   453 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =   10165.07 ms /   255 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =   13042.48 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.38 ms /     7 runs   (    0.63 ms per token,  1598.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.83 ms /    24 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
            "llama_print_timings:        eval time =     237.09 ms /     6 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =     378.68 ms /    30 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      61.92 ms /    88 runs   (    0.70 ms per token,  1421.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3729.03 ms /   684 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3526.37 ms /    87 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    7437.50 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.09 ms /    71 runs   (    0.59 ms per token,  1687.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5014.51 ms /   911 tokens (    5.50 ms per token,   181.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2868.23 ms /    70 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    7995.65 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.83 ms /   105 runs   (    0.61 ms per token,  1644.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3986.80 ms /   728 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4207.88 ms /   104 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8371.68 ms /   832 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.50 ms /    94 runs   (    0.62 ms per token,  1606.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2980.78 ms /   555 tokens (    5.37 ms per token,   186.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3694.55 ms /    93 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6821.40 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.27 ms /    96 runs   (    0.53 ms per token,  1872.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5544.72 ms /   990 tokens (    5.60 ms per token,   178.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3916.21 ms /    95 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =    9614.14 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.22 ms /    70 runs   (    0.67 ms per token,  1482.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5115.51 ms /   925 tokens (    5.53 ms per token,   180.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2847.30 ms /    69 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =    8095.21 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.69 ms /    61 runs   (    0.60 ms per token,  1662.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5449.84 ms /   980 tokens (    5.56 ms per token,   179.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2471.89 ms /    60 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
            "llama_print_timings:       total time =    8026.99 ms /  1040 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     151.62 ms /   256 runs   (    0.59 ms per token,  1688.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2829.48 ms /   527 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =   10211.30 ms /   255 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =   13488.21 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.88 ms /    76 runs   (    0.58 ms per token,  1732.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6647.59 ms /  1173 tokens (    5.67 ms per token,   176.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3135.90 ms /    75 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
            "llama_print_timings:       total time =    9919.57 ms /  1248 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.64 ms /    65 runs   (    0.72 ms per token,  1393.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3898.96 ms /   718 tokens (    5.43 ms per token,   184.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2596.10 ms /    64 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    6625.75 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.04 ms /    75 runs   (    0.59 ms per token,  1703.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7380.39 ms /  1290 tokens (    5.72 ms per token,   174.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3120.73 ms /    74 runs   (   42.17 ms per token,    23.71 tokens per second)\n",
            "llama_print_timings:       total time =   10633.62 ms /  1364 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.13 ms /    63 runs   (    0.76 ms per token,  1308.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1971.82 ms /   372 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2462.31 ms /    62 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4560.46 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.42 ms /   100 runs   (    0.58 ms per token,  1711.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4271.69 ms /   780 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4015.24 ms /    99 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    8440.22 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.06 ms /    69 runs   (    0.73 ms per token,  1378.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2989.94 ms /   554 tokens (    5.40 ms per token,   185.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2735.77 ms /    68 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    5864.95 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.12 ms /    73 runs   (    0.60 ms per token,  1654.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1976.14 ms /   376 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2862.61 ms /    73 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    4945.66 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     163.83 ms /   256 runs   (    0.64 ms per token,  1562.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2101.25 ms /   400 tokens (    5.25 ms per token,   190.36 tokens per second)\n",
            "llama_print_timings:        eval time =   10155.60 ms /   256 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =   12740.29 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      31.34 ms /    52 runs   (    0.60 ms per token,  1659.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     950.70 ms /   184 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2021.10 ms /    52 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    3055.12 ms /   236 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1692.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2275.09 ms /   429 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =     234.20 ms /     6 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2527.34 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      78.66 ms /   113 runs   (    0.70 ms per token,  1436.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2124.09 ms /   398 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =    4413.20 ms /   112 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6743.05 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.31 ms /     7 runs   (    0.76 ms per token,  1319.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.13 ms /   364 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
            "llama_print_timings:        eval time =     240.32 ms /     6 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    2201.51 ms /   370 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     6 runs   (    0.63 ms per token,  1578.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2573.76 ms /   479 tokens (    5.37 ms per token,   186.11 tokens per second)\n",
            "llama_print_timings:        eval time =     197.24 ms /     5 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    2790.34 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.60 ms /    76 runs   (    0.69 ms per token,  1444.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3364.22 ms /   622 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3025.99 ms /    75 runs   (   40.35 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    6532.12 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     162.94 ms /   256 runs   (    0.64 ms per token,  1571.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2049.60 ms /   386 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =   10078.43 ms /   255 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   12607.64 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.13 ms /    70 runs   (    0.60 ms per token,  1661.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1256.25 ms /   236 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.74 ms /    69 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    4062.38 ms /   305 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2452.82 ms /   460 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =     233.76 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2704.09 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1638.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2278.56 ms /   430 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
            "llama_print_timings:        eval time =     232.76 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2528.75 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      73.42 ms /   101 runs   (    0.73 ms per token,  1375.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1628.86 ms /   310 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3952.67 ms /   100 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    5778.28 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     6 runs   (    0.61 ms per token,  1627.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.07 ms /   512 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =     201.55 ms /     5 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    2938.81 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.24 ms /    58 runs   (    0.64 ms per token,  1557.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5019.85 ms /   907 tokens (    5.53 ms per token,   180.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2342.09 ms /    57 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =    7478.60 ms /   964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.41 ms /     7 runs   (    0.77 ms per token,  1292.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1862.17 ms /   348 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
            "llama_print_timings:        eval time =     235.48 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2124.45 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     116.13 ms /   184 runs   (    0.63 ms per token,  1584.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5029.34 ms /   912 tokens (    5.51 ms per token,   181.34 tokens per second)\n",
            "llama_print_timings:        eval time =    7540.66 ms /   183 runs   (   41.21 ms per token,    24.27 tokens per second)\n",
            "llama_print_timings:       total time =   12926.67 ms /  1095 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1823.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2560.09 ms /   476 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
            "llama_print_timings:        eval time =     234.73 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2813.54 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.20 ms /    97 runs   (    0.60 ms per token,  1666.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5059.36 ms /   915 tokens (    5.53 ms per token,   180.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3940.52 ms /    96 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    9163.94 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     152.06 ms /   256 runs   (    0.59 ms per token,  1683.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1730.34 ms /   322 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
            "llama_print_timings:        eval time =    9985.72 ms /   255 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12134.27 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     160.61 ms /   256 runs   (    0.63 ms per token,  1593.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1801.85 ms /   341 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
            "llama_print_timings:        eval time =   10040.64 ms /   255 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   12308.52 ms /   596 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.83 ms /    63 runs   (    0.71 ms per token,  1405.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4021.81 ms /   735 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2519.69 ms /    62 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6674.31 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.87 ms /    70 runs   (    0.56 ms per token,  1800.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5296.88 ms /   956 tokens (    5.54 ms per token,   180.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2835.80 ms /    69 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =    8240.46 ms /  1025 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     154.23 ms /   256 runs   (    0.60 ms per token,  1659.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3099.10 ms /   572 tokens (    5.42 ms per token,   184.57 tokens per second)\n",
            "llama_print_timings:        eval time =   10241.31 ms /   255 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =   13773.84 ms /   827 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     7 runs   (    0.69 ms per token,  1451.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1901.76 ms /   360 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =     280.67 ms /     7 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    2202.14 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.75 ms /    66 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2660.59 ms /   490 tokens (    5.43 ms per token,   184.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2563.67 ms /    65 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    5342.06 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2058.97 ms /   389 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
            "llama_print_timings:        eval time =     196.61 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2273.58 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     161.37 ms /   256 runs   (    0.63 ms per token,  1586.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1668.08 ms /   320 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
            "llama_print_timings:        eval time =   10053.35 ms /   255 runs   (   39.42 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   12172.90 ms /   575 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      28.90 ms /    51 runs   (    0.57 ms per token,  1764.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2230.61 ms /   422 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1955.62 ms /    50 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4260.93 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      59.05 ms /    85 runs   (    0.69 ms per token,  1439.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2545.39 ms /   477 tokens (    5.34 ms per token,   187.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3348.50 ms /    84 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    6047.55 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.86 ms /    12 runs   (    0.57 ms per token,  1749.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2531.76 ms /   474 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =     430.46 ms /    11 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2984.64 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.42 ms /    75 runs   (    0.69 ms per token,  1458.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5347.78 ms /   968 tokens (    5.52 ms per token,   181.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3098.70 ms /    75 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
            "llama_print_timings:       total time =    8592.09 ms /  1043 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1711.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2387.71 ms /   442 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
            "llama_print_timings:        eval time =     233.10 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2639.27 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1620.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1709.75 ms /   323 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =     233.56 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    1959.59 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1590.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2314.86 ms /   434 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
            "llama_print_timings:        eval time =     233.11 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2563.95 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.92 ms /    96 runs   (    0.73 ms per token,  1373.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3110.23 ms /   579 tokens (    5.37 ms per token,   186.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3845.80 ms /    95 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    7147.22 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.02 ms /    95 runs   (    0.56 ms per token,  1791.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4280.53 ms /   776 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3852.24 ms /    95 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    8285.41 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.09 ms /   256 runs   (    0.61 ms per token,  1640.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2486.51 ms /   467 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =   10148.65 ms /   255 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =   13111.16 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     174.20 ms /   256 runs   (    0.68 ms per token,  1469.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     984.29 ms /   186 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9962.23 ms /   255 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   11418.69 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2314.99 ms /   434 tokens (    5.33 ms per token,   187.47 tokens per second)\n",
            "llama_print_timings:        eval time =     232.84 ms /     6 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2563.55 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     7 runs   (    0.63 ms per token,  1593.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1876.08 ms /   358 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =     232.92 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2125.31 ms /   364 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1565.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1919.36 ms /   363 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =     232.09 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2167.04 ms /   369 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.63 ms /    70 runs   (    0.59 ms per token,  1681.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2646.40 ms /   488 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2718.72 ms /    69 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    5474.07 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.97 ms /    69 runs   (    0.58 ms per token,  1726.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2709.04 ms /    69 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2808.09 ms /    69 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      96.90 ms /   147 runs   (    0.66 ms per token,  1517.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5381.27 ms /   970 tokens (    5.55 ms per token,   180.25 tokens per second)\n",
            "llama_print_timings:        eval time =    6030.31 ms /   146 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
            "llama_print_timings:       total time =   11671.13 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.79 ms /    90 runs   (    0.65 ms per token,  1530.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4531.41 ms /   827 tokens (    5.48 ms per token,   182.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3625.84 ms /    89 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    8306.42 ms /   916 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.97 ms /    70 runs   (    0.61 ms per token,  1629.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1815.06 ms /   344 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2738.03 ms /    70 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4663.34 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     6 runs   (    0.56 ms per token,  1770.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4260.23 ms /   779 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =     201.89 ms /     5 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    4482.44 ms /   784 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.08 ms /    83 runs   (    0.65 ms per token,  1534.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4567.70 ms /   832 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3402.26 ms /    83 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =    8129.37 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.19 ms /    97 runs   (    0.56 ms per token,  1789.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4494.28 ms /   820 tokens (    5.48 ms per token,   182.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3909.73 ms /    96 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    8551.40 ms /   916 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1699.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5774.24 ms /  1032 tokens (    5.60 ms per token,   178.72 tokens per second)\n",
            "llama_print_timings:        eval time =     249.15 ms /     6 runs   (   41.53 ms per token,    24.08 tokens per second)\n",
            "llama_print_timings:       total time =    6048.62 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      32.45 ms /    56 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5428.88 ms /   980 tokens (    5.54 ms per token,   180.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2262.77 ms /    55 runs   (   41.14 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =    7790.15 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.86 ms /    70 runs   (    0.60 ms per token,  1672.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3396.20 ms /   624 tokens (    5.44 ms per token,   183.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2762.45 ms /    69 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6282.87 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     100.84 ms /   149 runs   (    0.68 ms per token,  1477.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5778.32 ms /  1035 tokens (    5.58 ms per token,   179.12 tokens per second)\n",
            "llama_print_timings:        eval time =    6158.19 ms /   148 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
            "llama_print_timings:       total time =   12230.44 ms /  1183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.38 ms /   109 runs   (    0.58 ms per token,  1719.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3348.50 ms /   624 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4311.80 ms /   108 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    7827.15 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      65.75 ms /    94 runs   (    0.70 ms per token,  1429.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.01 ms /   365 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3668.56 ms /    93 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    5783.44 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     142.78 ms /   241 runs   (    0.59 ms per token,  1687.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4536.23 ms /   832 tokens (    5.45 ms per token,   183.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9869.14 ms /   241 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =   14846.38 ms /  1073 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     141.31 ms /   241 runs   (    0.59 ms per token,  1705.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    9880.72 ms /   241 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =   10301.55 ms /   241 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.59 ms /    72 runs   (    0.59 ms per token,  1690.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3363.39 ms /   623 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2832.75 ms /    71 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    6312.82 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.31 ms /    65 runs   (    0.59 ms per token,  1696.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2226.58 ms /   420 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2518.68 ms /    64 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    4845.94 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.10 ms /   256 runs   (    0.62 ms per token,  1609.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2517.64 ms /   471 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
            "llama_print_timings:        eval time =   10143.39 ms /   255 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =   13119.31 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.71 ms /   256 runs   (    0.61 ms per token,  1644.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   10173.48 ms /   256 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =   10603.06 ms /   256 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.66 ms /    62 runs   (    0.64 ms per token,  1563.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1367.10 ms /   264 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2429.25 ms /    62 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3889.85 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.73 ms /   107 runs   (    0.60 ms per token,  1678.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.73 ms /   420 tokens (    5.36 ms per token,   186.69 tokens per second)\n",
            "llama_print_timings:        eval time =    4159.07 ms /   106 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6578.19 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.80 ms /    73 runs   (    0.59 ms per token,  1705.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2228.11 ms /   423 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2812.99 ms /    72 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5150.27 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.63 ms /    12 runs   (    0.64 ms per token,  1573.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.88 ms /   416 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =     435.67 ms /    11 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    2662.24 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     7 runs   (    0.59 ms per token,  1682.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2345.62 ms /   439 tokens (    5.34 ms per token,   187.16 tokens per second)\n",
            "llama_print_timings:        eval time =     232.89 ms /     6 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2597.39 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2359.05 ms /   442 tokens (    5.34 ms per token,   187.36 tokens per second)\n",
            "llama_print_timings:        eval time =     232.71 ms /     6 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2607.94 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1962.34 ms /   376 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =     273.67 ms /     7 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2250.38 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.71 ms /    84 runs   (    0.69 ms per token,  1455.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3558.84 ms /   663 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3346.42 ms /    83 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    7056.16 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.11 ms /   120 runs   (    0.58 ms per token,  1736.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2682.42 ms /   495 tokens (    5.42 ms per token,   184.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4733.59 ms /   119 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7597.38 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.58 ms /    64 runs   (    0.71 ms per token,  1404.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4406.61 ms /   806 tokens (    5.47 ms per token,   182.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2575.45 ms /    63 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    7118.65 ms /   869 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.79 ms /    74 runs   (    0.55 ms per token,  1814.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2984.76 ms /   560 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2926.65 ms /    74 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6016.33 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.76 ms /    63 runs   (    0.65 ms per token,  1545.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2358.67 ms /   447 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2438.63 ms /    62 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    4907.93 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.67 ms /    96 runs   (    0.56 ms per token,  1788.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3556.80 ms /   652 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3800.85 ms /    95 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    7498.89 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.84 ms /    65 runs   (    0.60 ms per token,  1673.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1302.45 ms /   248 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2492.19 ms /    64 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3899.85 ms /   312 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      88.43 ms /   147 runs   (    0.60 ms per token,  1662.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3304.73 ms /   611 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =    5851.99 ms /   146 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    9404.25 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      82.92 ms /   147 runs   (    0.56 ms per token,  1772.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    5878.35 ms /   147 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    6110.25 ms /   147 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       8.20 ms /    11 runs   (    0.75 ms per token,  1340.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2524.01 ms /   468 tokens (    5.39 ms per token,   185.42 tokens per second)\n",
            "llama_print_timings:        eval time =     395.55 ms /    10 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    2951.86 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    11 runs   (    0.79 ms per token,  1266.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     436.19 ms /    11 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =     463.88 ms /    11 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     165.91 ms /   255 runs   (    0.65 ms per token,  1536.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2016.73 ms /   381 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =    9990.49 ms /   254 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   12473.08 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     162.12 ms /   255 runs   (    0.64 ms per token,  1572.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   10019.93 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   10445.78 ms /   255 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     164.67 ms /   256 runs   (    0.64 ms per token,  1554.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2194.33 ms /   410 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10097.09 ms /   255 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =   12756.83 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      66.25 ms /    90 runs   (    0.74 ms per token,  1358.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2318.42 ms /   438 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3536.39 ms /    89 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6032.48 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.18 ms /    72 runs   (    0.57 ms per token,  1748.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2842.63 ms /   530 tokens (    5.36 ms per token,   186.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2811.08 ms /    71 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    5757.54 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      67.88 ms /    96 runs   (    0.71 ms per token,  1414.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2982.46 ms /   558 tokens (    5.34 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3807.08 ms /    95 runs   (   40.07 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    6973.60 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.36 ms /     7 runs   (    0.62 ms per token,  1605.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2778.01 ms /   517 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
            "llama_print_timings:        eval time =     241.33 ms /     6 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    3037.96 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.28 ms /     7 runs   (    0.61 ms per token,  1634.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2849.85 ms /   535 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =     240.73 ms /     6 runs   (   40.12 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    3110.72 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      60.71 ms /    93 runs   (    0.65 ms per token,  1531.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1579.32 ms /   298 tokens (    5.30 ms per token,   188.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3600.64 ms /    92 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5336.05 ms /   390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.69 ms /    93 runs   (    0.75 ms per token,  1334.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3643.20 ms /    93 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3816.31 ms /    93 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.54 ms /    66 runs   (    0.58 ms per token,  1712.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1621.77 ms /   307 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2540.91 ms /    65 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    4258.66 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     164.12 ms /   256 runs   (    0.64 ms per token,  1559.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2376.41 ms /   445 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =   10155.36 ms /   255 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =   13002.87 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.29 ms /    12 runs   (    0.61 ms per token,  1646.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2410.70 ms /   455 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =     430.67 ms /    11 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2866.32 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1530.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1793.53 ms /   340 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =     233.72 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2044.30 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.65 ms /    93 runs   (    0.70 ms per token,  1438.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1810.54 ms /   344 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3660.01 ms /    93 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5640.17 ms /   437 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.58 ms /    88 runs   (    0.60 ms per token,  1673.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2142.55 ms /   406 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3399.88 ms /    87 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5678.09 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.32 ms /     9 runs   (    0.59 ms per token,  1693.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1413.02 ms /   272 tokens (    5.19 ms per token,   192.50 tokens per second)\n",
            "llama_print_timings:        eval time =     306.43 ms /     8 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    1736.00 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.99 ms /     7 runs   (    0.71 ms per token,  1401.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2695.06 ms /   502 tokens (    5.37 ms per token,   186.27 tokens per second)\n",
            "llama_print_timings:        eval time =     237.50 ms /     6 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    2954.77 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      68.75 ms /   112 runs   (    0.61 ms per token,  1629.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2228.92 ms /   415 tokens (    5.37 ms per token,   186.19 tokens per second)\n",
            "llama_print_timings:        eval time =    4353.64 ms /   111 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6777.33 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      70.55 ms /   107 runs   (    0.66 ms per token,  1516.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1898.24 ms /   357 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
            "llama_print_timings:        eval time =    4156.70 ms /   106 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6246.85 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     126.31 ms /   210 runs   (    0.60 ms per token,  1662.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2224.27 ms /   416 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    8298.21 ms /   210 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   10881.95 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     118.83 ms /   179 runs   (    0.66 ms per token,  1506.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2293.53 ms /   429 tokens (    5.35 ms per token,   187.05 tokens per second)\n",
            "llama_print_timings:        eval time =    7080.40 ms /   178 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    9718.31 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1696.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2057.17 ms /   387 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
            "llama_print_timings:        eval time =     233.00 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2307.08 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      67.56 ms /    96 runs   (    0.70 ms per token,  1420.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1708.66 ms /   326 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3740.62 ms /    95 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5630.10 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.41 ms /    95 runs   (    0.60 ms per token,  1654.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2304.69 ms /   427 tokens (    5.40 ms per token,   185.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3685.96 ms /    94 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6146.40 ms /   521 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Amcor plc_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Amcor plc_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1713.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2525.31 ms /   468 tokens (    5.40 ms per token,   185.32 tokens per second)\n",
            "llama_print_timings:        eval time =     233.54 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2776.95 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.33 ms /     6 runs   (    0.72 ms per token,  1386.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3515.64 ms /   644 tokens (    5.46 ms per token,   183.18 tokens per second)\n",
            "llama_print_timings:        eval time =     199.22 ms /     5 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    3737.64 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.05 ms /   104 runs   (    0.61 ms per token,  1649.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2127.47 ms /   397 tokens (    5.36 ms per token,   186.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4026.24 ms /   103 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6327.38 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     161.84 ms /   256 runs   (    0.63 ms per token,  1581.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3034.95 ms /   562 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
            "llama_print_timings:        eval time =   10263.69 ms /   255 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =   13787.69 ms /   817 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.30 ms /     7 runs   (    0.61 ms per token,  1626.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2055.26 ms /   387 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =     237.29 ms /     6 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2307.74 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      65.07 ms /    84 runs   (    0.77 ms per token,  1290.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1972.95 ms /   376 tokens (    5.25 ms per token,   190.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3340.25 ms /    84 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    5495.84 ms /   460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1789.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1988.60 ms /   374 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
            "llama_print_timings:        eval time =     233.19 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2237.35 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.70 ms /    96 runs   (    0.60 ms per token,  1663.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1885.88 ms /   359 tokens (    5.25 ms per token,   190.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3722.74 ms /    95 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5760.76 ms /   454 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     6 runs   (    0.66 ms per token,  1509.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5717.26 ms /  1023 tokens (    5.59 ms per token,   178.93 tokens per second)\n",
            "llama_print_timings:        eval time =     209.15 ms /     5 runs   (   41.83 ms per token,    23.91 tokens per second)\n",
            "llama_print_timings:       total time =    5952.65 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.41 ms /   256 runs   (    0.61 ms per token,  1647.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.59 ms /   450 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =   10118.87 ms /   255 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =   12968.74 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.28 ms /    72 runs   (    0.60 ms per token,  1663.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3358.70 ms /   622 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2835.10 ms /    71 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    6308.10 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.72 ms /    62 runs   (    0.75 ms per token,  1327.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5684.39 ms /  1024 tokens (    5.55 ms per token,   180.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.74 ms /    62 runs   (   41.59 ms per token,    24.04 tokens per second)\n",
            "llama_print_timings:       total time =    8390.31 ms /  1086 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.63 ms /    82 runs   (    0.67 ms per token,  1500.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8253.90 ms /  1439 tokens (    5.74 ms per token,   174.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3457.39 ms /    81 runs   (   42.68 ms per token,    23.43 tokens per second)\n",
            "llama_print_timings:       total time =   11892.89 ms /  1520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.14 ms /   256 runs   (    0.61 ms per token,  1650.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1721.70 ms /   322 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    9990.26 ms /   255 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   12156.06 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cash flow generated from operations and are there any notable trends or fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.47 ms /     9 runs   (    0.83 ms per token,  1204.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2725.93 ms /   499 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
            "llama_print_timings:        eval time =     319.19 ms /     8 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    3073.43 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      27.30 ms /    47 runs   (    0.58 ms per token,  1721.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3831.68 ms /   699 tokens (    5.48 ms per token,   182.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1840.68 ms /    46 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5743.17 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.64 ms /   256 runs   (    0.61 ms per token,  1644.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2004.86 ms /   384 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
            "llama_print_timings:        eval time =   10107.96 ms /   256 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   12558.71 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.10 ms /    90 runs   (    0.65 ms per token,  1549.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5761.69 ms /  1040 tokens (    5.54 ms per token,   180.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3733.22 ms /    90 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =    9660.09 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      71.20 ms /   123 runs   (    0.58 ms per token,  1727.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2519.12 ms /   472 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =    4846.88 ms /   123 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    7555.46 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.36 ms /    79 runs   (    0.68 ms per token,  1480.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5068.55 ms /   918 tokens (    5.52 ms per token,   181.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3220.16 ms /    78 runs   (   41.28 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =    8439.42 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.55 ms /    79 runs   (    0.56 ms per token,  1773.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3122.33 ms /   580 tokens (    5.38 ms per token,   185.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3112.13 ms /    78 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    6348.33 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.60 ms /   255 runs   (    0.61 ms per token,  1628.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2137.28 ms /   402 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =   10046.57 ms /   254 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   12606.69 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.60 ms /    70 runs   (    0.67 ms per token,  1502.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2446.77 ms /   462 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2725.73 ms /    69 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    5290.27 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.83 ms /    70 runs   (    0.57 ms per token,  1757.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2528.27 ms /   470 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2712.07 ms /    69 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5343.35 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      32.17 ms /    54 runs   (    0.60 ms per token,  1678.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2009.46 ms /   379 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2079.00 ms /    53 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    4168.17 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.81 ms /    12 runs   (    0.65 ms per token,  1537.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2442.07 ms /   458 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =     439.12 ms /    11 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    2906.73 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.02 ms /     7 runs   (    0.72 ms per token,  1395.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2520.44 ms /   466 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =     239.80 ms /     6 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    2780.05 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1899.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2277.38 ms /   430 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =     235.37 ms /     6 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2528.49 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1708.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2487.92 ms /   469 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =     237.08 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    2741.02 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.55 ms /    12 runs   (    0.55 ms per token,  1833.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2486.86 ms /   471 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =     432.89 ms /    11 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2940.83 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      89.97 ms /   132 runs   (    0.68 ms per token,  1467.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3486.86 ms /   648 tokens (    5.38 ms per token,   185.84 tokens per second)\n",
            "llama_print_timings:        eval time =    5310.30 ms /   132 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    9022.54 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.05 ms /    76 runs   (    0.65 ms per token,  1549.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5472.85 ms /   989 tokens (    5.53 ms per token,   180.71 tokens per second)\n",
            "llama_print_timings:        eval time =    3096.32 ms /    75 runs   (   41.28 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =    8703.45 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     102.69 ms /   179 runs   (    0.57 ms per token,  1743.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.53 ms /   402 tokens (    5.36 ms per token,   186.41 tokens per second)\n",
            "llama_print_timings:        eval time =    6956.95 ms /   178 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    9373.74 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      70.99 ms /   100 runs   (    0.71 ms per token,  1408.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2098.05 ms /   400 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3924.20 ms /    99 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    6230.27 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1587.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3027.27 ms /   566 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
            "llama_print_timings:        eval time =     237.54 ms /     6 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    3284.15 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.49 ms /    91 runs   (    0.59 ms per token,  1701.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     985.97 ms /   190 tokens (    5.19 ms per token,   192.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3507.63 ms /    90 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4629.66 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     111.73 ms /   154 runs   (    0.73 ms per token,  1378.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2313.32 ms /   434 tokens (    5.33 ms per token,   187.61 tokens per second)\n",
            "llama_print_timings:        eval time =    6045.99 ms /   153 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    8636.12 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.44 ms /     6 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1748.39 ms /   336 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =     193.85 ms /     5 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    1955.62 ms /   341 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.00 ms /    58 runs   (    0.67 ms per token,  1487.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5374.10 ms /   970 tokens (    5.54 ms per token,   180.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2359.33 ms /    57 runs   (   41.39 ms per token,    24.16 tokens per second)\n",
            "llama_print_timings:       total time =    7852.34 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      69.53 ms /   127 runs   (    0.55 ms per token,  1826.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4537.10 ms /   832 tokens (    5.45 ms per token,   183.38 tokens per second)\n",
            "llama_print_timings:        eval time =    5128.17 ms /   126 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    9856.89 ms /   958 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     144.93 ms /   256 runs   (    0.57 ms per token,  1766.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3089.28 ms /   570 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =   10200.65 ms /   255 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =   13698.55 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    12 runs   (    0.75 ms per token,  1327.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.61 ms /   463 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =     436.24 ms /    11 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    2930.53 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.81 ms /    73 runs   (    0.57 ms per token,  1745.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2252.88 ms /   420 tokens (    5.36 ms per token,   186.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2824.13 ms /    72 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5182.68 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      66.18 ms /   114 runs   (    0.58 ms per token,  1722.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1406.91 ms /   267 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =    4425.90 ms /   113 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5995.52 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      55.21 ms /    75 runs   (    0.74 ms per token,  1358.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.83 ms /   431 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2936.84 ms /    74 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    5368.50 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    14 runs   (    0.71 ms per token,  1403.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1006.51 ms /   186 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
            "llama_print_timings:        eval time =     502.35 ms /    13 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    1538.56 ms /   199 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.69 ms /    72 runs   (    0.57 ms per token,  1769.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3804.56 ms /   699 tokens (    5.44 ms per token,   183.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2852.31 ms /    71 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    6764.15 ms /   770 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.91 ms /    66 runs   (    0.59 ms per token,  1696.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3461.86 ms /   634 tokens (    5.46 ms per token,   183.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2603.57 ms /    65 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    6174.08 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1792.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2486.25 ms /   468 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =     237.72 ms /     6 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    2738.49 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     150.76 ms /   256 runs   (    0.59 ms per token,  1698.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2355.51 ms /   445 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =   10147.77 ms /   255 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =   12930.38 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.03 ms /   256 runs   (    0.61 ms per token,  1651.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1962.15 ms /   370 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =   10086.60 ms /   255 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   12479.71 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      31.54 ms /    55 runs   (    0.57 ms per token,  1743.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2265.85 ms /   428 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2129.95 ms /    54 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4470.25 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.27 ms /    64 runs   (    0.74 ms per token,  1353.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2357.28 ms /   446 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
            "llama_print_timings:        eval time =    2501.86 ms /    63 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    4977.49 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     150.25 ms /   256 runs   (    0.59 ms per token,  1703.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.77 ms /   431 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10102.95 ms /   255 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =   12811.37 ms /   686 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.23 ms /    99 runs   (    0.55 ms per token,  1825.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2345.70 ms /   440 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3856.32 ms /    98 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6337.64 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.61 ms /    11 runs   (    0.60 ms per token,  1663.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2930.75 ms /   548 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
            "llama_print_timings:        eval time =     394.39 ms /    10 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3347.61 ms /   558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      59.28 ms /    96 runs   (    0.62 ms per token,  1619.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4553.91 ms /   828 tokens (    5.50 ms per token,   181.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3879.36 ms /    95 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    8589.30 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.15 ms /   256 runs   (    0.62 ms per token,  1608.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3026.44 ms /   568 tokens (    5.33 ms per token,   187.68 tokens per second)\n",
            "llama_print_timings:        eval time =   10267.02 ms /   256 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   13730.31 ms /   824 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     160.10 ms /   256 runs   (    0.63 ms per token,  1598.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2676.17 ms /   504 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =   10183.45 ms /   255 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =   13303.15 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2495.25 ms /   468 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
            "llama_print_timings:        eval time =     238.04 ms /     6 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    2750.57 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.13 ms /    76 runs   (    0.62 ms per token,  1612.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3026.59 ms /   566 tokens (    5.35 ms per token,   187.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2997.20 ms /    75 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    6150.97 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     150.93 ms /   256 runs   (    0.59 ms per token,  1696.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.73 ms /   396 tokens (    5.50 ms per token,   181.84 tokens per second)\n",
            "llama_print_timings:        eval time =   10187.32 ms /   255 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =   12784.69 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.98 ms /     9 runs   (    0.78 ms per token,  1290.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1044.81 ms /   194 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
            "llama_print_timings:        eval time =     312.29 ms /     8 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    1376.91 ms /   202 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.24 ms /    97 runs   (    0.58 ms per token,  1724.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2064.95 ms /   386 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3762.12 ms /    96 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5968.92 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2404.84 ms /   456 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
            "llama_print_timings:        eval time =     237.27 ms /     6 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2657.75 ms /   462 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Square, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Square, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     130.94 ms /   228 runs   (    0.57 ms per token,  1741.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3051.96 ms /   568 tokens (    5.37 ms per token,   186.11 tokens per second)\n",
            "llama_print_timings:        eval time =    9138.22 ms /   228 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =   12556.41 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     153.31 ms /   256 runs   (    0.60 ms per token,  1669.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3078.87 ms /   570 tokens (    5.40 ms per token,   185.13 tokens per second)\n",
            "llama_print_timings:        eval time =   10230.05 ms /   255 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   13738.53 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      62.40 ms /    89 runs   (    0.70 ms per token,  1426.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3174.94 ms /   587 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3539.18 ms /    88 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    6879.22 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.52 ms /   256 runs   (    0.61 ms per token,  1646.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2705.93 ms /   499 tokens (    5.42 ms per token,   184.41 tokens per second)\n",
            "llama_print_timings:        eval time =   10206.24 ms /   255 runs   (   40.02 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =   13395.46 ms /   754 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      35.60 ms /    62 runs   (    0.57 ms per token,  1741.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3655.89 ms /   677 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2453.73 ms /    61 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    6203.06 ms /   738 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.32 ms /    73 runs   (    0.70 ms per token,  1422.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2183.60 ms /   413 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2857.95 ms /    72 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    5170.58 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      92.02 ms /   160 runs   (    0.58 ms per token,  1738.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.95 ms /   426 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
            "llama_print_timings:        eval time =    6251.03 ms /   159 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    8768.87 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      75.28 ms /   119 runs   (    0.63 ms per token,  1580.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2897.68 ms /   540 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4725.03 ms /   118 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    7822.12 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.49 ms /   256 runs   (    0.62 ms per token,  1605.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2801.90 ms /   526 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =   10191.87 ms /   255 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =   13438.45 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.30 ms /    70 runs   (    0.55 ms per token,  1827.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5377.82 ms /   976 tokens (    5.51 ms per token,   181.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2868.23 ms /    70 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    8346.52 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.02 ms /    85 runs   (    0.56 ms per token,  1770.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3824.50 ms /   701 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3373.10 ms /    84 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    7331.24 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.17 ms /    75 runs   (    0.56 ms per token,  1778.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3289.42 ms /   613 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2938.36 ms /    74 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    6330.17 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.08 ms /     7 runs   (    0.73 ms per token,  1378.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2739.65 ms /   512 tokens (    5.35 ms per token,   186.89 tokens per second)\n",
            "llama_print_timings:        eval time =     239.60 ms /     6 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    2999.13 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     141.57 ms /   242 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3034.34 ms /   568 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9703.28 ms /   242 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =   13129.08 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     140.38 ms /   256 runs   (    0.55 ms per token,  1823.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2164.07 ms /   408 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =   10123.25 ms /   256 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =   12689.75 ms /   664 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     139.81 ms /   256 runs   (    0.55 ms per token,  1831.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2868.36 ms /   535 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =   10188.22 ms /   255 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =   13451.96 ms /   790 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     141.86 ms /   256 runs   (    0.55 ms per token,  1804.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2204.90 ms /   412 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =   10061.05 ms /   255 runs   (   39.46 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   12645.22 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.28 ms /    86 runs   (    0.57 ms per token,  1745.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2787.74 ms /   520 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3364.90 ms /    85 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    6278.75 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1829.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2619.75 ms /   496 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =     239.86 ms /     6 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    2873.61 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.35 ms /    78 runs   (    0.65 ms per token,  1549.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2180.24 ms /   412 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3040.68 ms /    77 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5342.39 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.62 ms /    79 runs   (    0.58 ms per token,  1731.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2914.85 ms /   544 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3124.32 ms /    79 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    6152.16 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.81 ms /   256 runs   (    0.61 ms per token,  1643.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1920.38 ms /   366 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =   10068.76 ms /   255 runs   (   39.49 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   12423.77 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     154.37 ms /   256 runs   (    0.60 ms per token,  1658.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1576.70 ms /   300 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
            "llama_print_timings:        eval time =   10027.85 ms /   255 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   12019.01 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.34 ms /    54 runs   (    0.75 ms per token,  1338.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1799.52 ms /   344 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2129.61 ms /    54 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    4031.26 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.29 ms /    59 runs   (    0.68 ms per token,  1464.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5436.58 ms /   979 tokens (    5.55 ms per token,   180.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2396.76 ms /    58 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
            "llama_print_timings:       total time =    7953.46 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.17 ms /    70 runs   (    0.57 ms per token,  1742.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2497.72 ms /   470 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2701.75 ms /    69 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5300.64 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       8.11 ms /    14 runs   (    0.58 ms per token,  1725.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1157.67 ms /   221 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =     501.24 ms /    13 runs   (   38.56 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    1682.09 ms /   234 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      35.84 ms /    56 runs   (    0.64 ms per token,  1562.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2269.15 ms /   427 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2165.02 ms /    55 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4521.20 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.45 ms /    72 runs   (    0.63 ms per token,  1583.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1208.35 ms /   229 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2773.90 ms /    71 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4092.59 ms /   300 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     158.07 ms /   256 runs   (    0.62 ms per token,  1619.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2091.89 ms /   396 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =   10063.66 ms /   255 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   12584.67 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.59 ms /    68 runs   (    0.57 ms per token,  1762.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4292.43 ms /   787 tokens (    5.45 ms per token,   183.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.29 ms /    67 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7094.84 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     153.73 ms /   256 runs   (    0.60 ms per token,  1665.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3076.26 ms /   570 tokens (    5.40 ms per token,   185.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10209.77 ms /   255 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =   13687.23 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      80.64 ms /   116 runs   (    0.70 ms per token,  1438.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1491.13 ms /   288 tokens (    5.18 ms per token,   193.14 tokens per second)\n",
            "llama_print_timings:        eval time =    4559.19 ms /   116 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6251.79 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.48 ms /   256 runs   (    0.61 ms per token,  1635.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1535.54 ms /   295 tokens (    5.21 ms per token,   192.12 tokens per second)\n",
            "llama_print_timings:        eval time =   10032.38 ms /   255 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   11990.33 ms /   550 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     6 runs   (    0.63 ms per token,  1583.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2148.56 ms /   404 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
            "llama_print_timings:        eval time =     194.49 ms /     5 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2356.45 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.60 ms per token,  1679.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2045.14 ms /   388 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =     192.70 ms /     5 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2250.10 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1647.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2051.88 ms /   392 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =     236.33 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2304.43 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.48 ms /     9 runs   (    0.61 ms per token,  1641.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1111.95 ms /   216 tokens (    5.15 ms per token,   194.25 tokens per second)\n",
            "llama_print_timings:        eval time =     347.47 ms /     9 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    1473.71 ms /   225 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     6 runs   (    0.61 ms per token,  1634.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2097.58 ms /   398 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =     195.95 ms /     5 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2309.26 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.29 ms /     9 runs   (    0.70 ms per token,  1431.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     782.77 ms /   146 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =     315.48 ms /     8 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    1116.39 ms /   154 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.64 ms /     9 runs   (    0.74 ms per token,  1356.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1040.96 ms /   197 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
            "llama_print_timings:        eval time =     314.07 ms /     8 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    1377.65 ms /   205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2548.10 ms /   480 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =     279.83 ms /     7 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    2845.78 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2490.14 ms /   469 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =     237.55 ms /     6 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    2743.66 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2444.56 ms /   464 tokens (    5.27 ms per token,   189.81 tokens per second)\n",
            "llama_print_timings:        eval time =     234.82 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2700.79 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.10 ms /    65 runs   (    0.72 ms per token,  1379.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2662.62 ms /   498 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2554.49 ms /    64 runs   (   39.91 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    5331.85 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.64 ms /    68 runs   (    0.58 ms per token,  1715.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2905.18 ms /   542 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2651.82 ms /    67 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    5663.19 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.32 ms /    70 runs   (    0.58 ms per token,  1736.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1372.75 ms /   264 tokens (    5.20 ms per token,   192.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2745.57 ms /    70 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    4212.45 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      71.61 ms /   107 runs   (    0.67 ms per token,  1494.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2144.29 ms /   406 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4175.30 ms /   106 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6502.23 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.12 ms /    12 runs   (    0.59 ms per token,  1685.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2884.27 ms /   542 tokens (    5.32 ms per token,   187.92 tokens per second)\n",
            "llama_print_timings:        eval time =     437.50 ms /    11 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    3344.21 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1700.47 ms /   326 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
            "llama_print_timings:        eval time =     198.20 ms /     5 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    1910.19 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.32 ms /    72 runs   (    0.71 ms per token,  1403.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2525.81 ms /   477 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2823.81 ms /    71 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    5479.59 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.63 ms /    71 runs   (    0.56 ms per token,  1791.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2467.88 ms /   461 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2752.27 ms /    70 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5316.10 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.75 ms /    76 runs   (    0.55 ms per token,  1820.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2263.49 ms /   428 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2949.21 ms /    75 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5315.45 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.22 ms /    69 runs   (    0.67 ms per token,  1492.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1934.43 ms /   364 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2676.29 ms /    68 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    4728.81 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.73 ms /    91 runs   (    0.62 ms per token,  1603.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4479.90 ms /   821 tokens (    5.46 ms per token,   183.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3666.54 ms /    90 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    8280.55 ms /   911 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      79.75 ms /   142 runs   (    0.56 ms per token,  1780.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5527.77 ms /   992 tokens (    5.57 ms per token,   179.46 tokens per second)\n",
            "llama_print_timings:        eval time =    5831.02 ms /   141 runs   (   41.35 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =   11571.63 ms /  1133 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.63 ms /    97 runs   (    0.67 ms per token,  1500.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2941.89 ms /   551 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3855.93 ms /    96 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    6962.69 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.79 ms /    62 runs   (    0.67 ms per token,  1483.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2226.42 ms /   424 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2402.03 ms /    61 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    4732.09 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.28 ms /    67 runs   (    0.59 ms per token,  1705.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2167.42 ms /   407 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2598.96 ms /    66 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    4866.32 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.63 ms /    82 runs   (    0.59 ms per token,  1686.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2786.65 ms /   515 tokens (    5.41 ms per token,   184.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3202.96 ms /    81 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    6108.19 ms /   596 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.03 ms /    90 runs   (    0.59 ms per token,  1697.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4434.64 ms /   811 tokens (    5.47 ms per token,   182.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3618.61 ms /    89 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8188.68 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.41 ms /    93 runs   (    0.55 ms per token,  1809.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3918.22 ms /   699 tokens (    5.61 ms per token,   178.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3739.37 ms /    92 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    7791.15 ms /   791 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     154.82 ms /   256 runs   (    0.60 ms per token,  1653.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2701.75 ms /   506 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10157.48 ms /   255 runs   (   39.83 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =   13274.50 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      74.33 ms /   113 runs   (    0.66 ms per token,  1520.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3195.01 ms /   599 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
            "llama_print_timings:        eval time =    4485.67 ms /   112 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    7869.64 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      67.28 ms /   115 runs   (    0.59 ms per token,  1709.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1623.73 ms /   307 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =    4467.73 ms /   114 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6257.50 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      85.19 ms /   120 runs   (    0.71 ms per token,  1408.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2749.39 ms /   515 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
            "llama_print_timings:        eval time =    4734.37 ms /   119 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7704.16 ms /   634 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_3M CO_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_3M CO_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.21 ms /    71 runs   (    0.57 ms per token,  1765.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3409.05 ms /   631 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2789.63 ms /    70 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    6310.47 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      65.73 ms /    96 runs   (    0.68 ms per token,  1460.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2721.22 ms /   512 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3798.04 ms /    95 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    6704.24 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.37 ms /   101 runs   (    0.58 ms per token,  1730.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2007.33 ms /   382 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3912.85 ms /   100 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6070.49 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      67.50 ms /    93 runs   (    0.73 ms per token,  1377.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2184.55 ms /   410 tokens (    5.33 ms per token,   187.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3644.89 ms /    92 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    6006.77 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      31.57 ms /    59 runs   (    0.54 ms per token,  1868.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4077.67 ms /   752 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2382.59 ms /    59 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    6545.62 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      31.63 ms /    53 runs   (    0.60 ms per token,  1675.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2312.88 ms /   440 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2055.75 ms /    52 runs   (   39.53 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    4446.89 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.53 ms /     7 runs   (    0.79 ms per token,  1264.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2661.45 ms /   494 tokens (    5.39 ms per token,   185.61 tokens per second)\n",
            "llama_print_timings:        eval time =     243.49 ms /     6 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    2926.89 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.60 ms /     6 runs   (    0.60 ms per token,  1664.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2058.23 ms /   386 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =     197.59 ms /     5 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    2269.84 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.58 ms /    91 runs   (    0.53 ms per token,  1873.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2709.12 ms /   507 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3556.81 ms /    90 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6387.84 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.20 ms /     7 runs   (    0.74 ms per token,  1347.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.29 ms /   470 tokens (    5.32 ms per token,   188.05 tokens per second)\n",
            "llama_print_timings:        eval time =     238.14 ms /     6 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    2757.15 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.72 ms /    93 runs   (    0.58 ms per token,  1731.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5519.38 ms /   992 tokens (    5.56 ms per token,   179.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3819.46 ms /    93 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    9495.59 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.45 ms /    81 runs   (    0.59 ms per token,  1706.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5872.11 ms /  1050 tokens (    5.59 ms per token,   178.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3303.13 ms /    80 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =    9303.74 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      30.25 ms /    54 runs   (    0.56 ms per token,  1785.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4196.93 ms /   775 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2135.20 ms /    53 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    6409.11 ms /   828 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      55.77 ms /    97 runs   (    0.57 ms per token,  1739.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5086.92 ms /   918 tokens (    5.54 ms per token,   180.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3931.54 ms /    96 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    9171.48 ms /  1014 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     145.04 ms /   256 runs   (    0.57 ms per token,  1765.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2400.72 ms /   450 tokens (    5.33 ms per token,   187.44 tokens per second)\n",
            "llama_print_timings:        eval time =   10156.82 ms /   255 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =   12967.54 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     155.49 ms /   256 runs   (    0.61 ms per token,  1646.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1411.46 ms /   270 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10004.12 ms /   255 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   11842.25 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      68.88 ms /   107 runs   (    0.64 ms per token,  1553.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1960.06 ms /   370 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =    4177.15 ms /   106 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6316.17 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      11.29 ms /    14 runs   (    0.81 ms per token,  1239.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1840.00 ms /   338 tokens (    5.44 ms per token,   183.70 tokens per second)\n",
            "llama_print_timings:        eval time =     519.19 ms /    13 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    2395.04 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      28.87 ms /    53 runs   (    0.54 ms per token,  1835.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5940.02 ms /  1058 tokens (    5.61 ms per token,   178.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2148.17 ms /    52 runs   (   41.31 ms per token,    24.21 tokens per second)\n",
            "llama_print_timings:       total time =    8170.13 ms /  1110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     111.12 ms /   173 runs   (    0.64 ms per token,  1556.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3559.62 ms /   661 tokens (    5.39 ms per token,   185.69 tokens per second)\n",
            "llama_print_timings:        eval time =    6949.40 ms /   172 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   10799.62 ms /   833 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2396.14 ms /   455 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =     234.60 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2644.22 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.23 ms /     7 runs   (    0.60 ms per token,  1654.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2090.45 ms /   397 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =     236.27 ms /     6 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2340.79 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     150.99 ms /   256 runs   (    0.59 ms per token,  1695.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2182.97 ms /   416 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =   10072.65 ms /   255 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   12661.25 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.26 ms /   256 runs   (    0.62 ms per token,  1607.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2006.83 ms /   379 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10037.08 ms /   255 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   12462.56 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.83 ms /    71 runs   (    0.60 ms per token,  1657.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2092.59 ms /   397 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2754.98 ms /    70 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    4952.20 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.16 ms /    78 runs   (    0.55 ms per token,  1807.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5683.67 ms /  1019 tokens (    5.58 ms per token,   179.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3168.79 ms /    77 runs   (   41.15 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =    8973.54 ms /  1096 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.44 ms /    75 runs   (    0.63 ms per token,  1581.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2395.27 ms /   451 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2927.34 ms /    74 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    5442.63 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      64.34 ms /   112 runs   (    0.57 ms per token,  1740.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2076.13 ms /   392 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4393.56 ms /   112 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6624.56 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.75 ms /   256 runs   (    0.62 ms per token,  1602.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2047.32 ms /   389 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =   10070.66 ms /   255 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   12544.71 ms /   644 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1699.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2052.49 ms /   391 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =     194.15 ms /     5 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2260.49 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2397.98 ms /   453 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =     233.99 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2646.45 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      61.99 ms /    80 runs   (    0.77 ms per token,  1290.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     982.56 ms /   188 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3086.82 ms /    79 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4231.84 ms /   267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.82 ms /    79 runs   (    0.59 ms per token,  1687.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2918.66 ms /   544 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3093.43 ms /    78 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6132.64 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.21 ms /    77 runs   (    0.69 ms per token,  1447.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3203.71 ms /   595 tokens (    5.38 ms per token,   185.72 tokens per second)\n",
            "llama_print_timings:        eval time =    3050.27 ms /    76 runs   (   40.14 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    6390.84 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.52 ms /    69 runs   (    0.56 ms per token,  1791.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3424.74 ms /   632 tokens (    5.42 ms per token,   184.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2718.44 ms /    68 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    6246.38 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     6 runs   (    0.64 ms per token,  1554.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2144.41 ms /   408 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
            "llama_print_timings:        eval time =     233.29 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2392.36 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1693.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2054.54 ms /   392 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
            "llama_print_timings:        eval time =     196.03 ms /     5 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2263.92 ms /   397 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.59 ms /     7 runs   (    1.08 ms per token,   922.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1981.10 ms /   372 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
            "llama_print_timings:        eval time =     235.10 ms /     6 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2237.86 ms /   378 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      55.48 ms /    92 runs   (    0.60 ms per token,  1658.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2264.39 ms /   424 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3562.45 ms /    91 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5986.96 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1924.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2850.54 ms /   530 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
            "llama_print_timings:        eval time =     197.18 ms /     5 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3066.01 ms /   535 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     6 runs   (    0.69 ms per token,  1457.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3440.90 ms /   640 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
            "llama_print_timings:        eval time =     202.71 ms /     5 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    3667.33 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.90 ms /     7 runs   (    0.70 ms per token,  1429.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2222.47 ms /   412 tokens (    5.39 ms per token,   185.38 tokens per second)\n",
            "llama_print_timings:        eval time =     240.91 ms /     6 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    2486.20 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     153.24 ms /   256 runs   (    0.60 ms per token,  1670.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2119.95 ms /   399 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =   10054.91 ms /   255 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   12643.66 ms /   654 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.77 ms /    83 runs   (    0.59 ms per token,  1702.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1997.35 ms /   373 tokens (    5.35 ms per token,   186.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3200.86 ms /    82 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5333.80 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      67.10 ms /   122 runs   (    0.55 ms per token,  1818.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2057.50 ms /   392 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =    4732.18 ms /   121 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    6983.27 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.04 ms /    73 runs   (    0.64 ms per token,  1551.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2219.04 ms /   415 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2822.44 ms /    72 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5176.39 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.57 ms /    62 runs   (    0.59 ms per token,  1695.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3162.14 ms /   592 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2424.53 ms /    61 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    5692.28 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.20 ms /    69 runs   (    0.71 ms per token,  1402.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5845.94 ms /  1045 tokens (    5.59 ms per token,   178.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2826.20 ms /    68 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =    8814.52 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      60.25 ms /   103 runs   (    0.58 ms per token,  1709.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3181.03 ms /   591 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4063.70 ms /   102 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    7416.76 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.09 ms /    89 runs   (    0.59 ms per token,  1708.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3617.06 ms /   662 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3531.27 ms /    88 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    7299.10 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1693.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2272.66 ms /   430 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =     195.56 ms /     5 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2483.43 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.35 ms /    63 runs   (    0.70 ms per token,  1420.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3071.11 ms /   571 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2488.97 ms /    62 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5675.11 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1808.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1901.96 ms /   356 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
            "llama_print_timings:        eval time =     198.77 ms /     5 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    2116.08 ms /   361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.35 ms /    66 runs   (    0.55 ms per token,  1815.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2315.34 ms /   434 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2551.28 ms /    65 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    4964.14 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1863.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2626.35 ms /   496 tokens (    5.30 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =     238.48 ms /     6 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    2881.49 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       8.35 ms /    12 runs   (    0.70 ms per token,  1437.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2503.95 ms /   471 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
            "llama_print_timings:        eval time =     440.86 ms /    11 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    2973.01 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      62.73 ms /   114 runs   (    0.55 ms per token,  1817.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4341.06 ms /   791 tokens (    5.49 ms per token,   182.21 tokens per second)\n",
            "llama_print_timings:        eval time =    4588.23 ms /   113 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    9109.76 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      76.03 ms /   115 runs   (    0.66 ms per token,  1512.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4364.95 ms /   795 tokens (    5.49 ms per token,   182.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4652.91 ms /   114 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    9244.52 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.97 ms /    76 runs   (    0.57 ms per token,  1768.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1582.10 ms /   302 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2925.80 ms /    75 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4620.21 ms /   377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.87 ms /    12 runs   (    0.57 ms per token,  1748.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2450.41 ms /   458 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =     439.70 ms /    11 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    2914.77 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.15 ms /     7 runs   (    0.74 ms per token,  1360.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2749.16 ms /   510 tokens (    5.39 ms per token,   185.51 tokens per second)\n",
            "llama_print_timings:        eval time =     245.34 ms /     6 runs   (   40.89 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    3017.26 ms /   516 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.34 ms /    81 runs   (    0.57 ms per token,  1748.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5738.51 ms /  1026 tokens (    5.59 ms per token,   178.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3309.80 ms /    80 runs   (   41.37 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =    9177.39 ms /  1106 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      35.37 ms /    64 runs   (    0.55 ms per token,  1809.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5669.92 ms /  1012 tokens (    5.60 ms per token,   178.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2599.24 ms /    63 runs   (   41.26 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =    8380.29 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.39 ms /    77 runs   (    0.60 ms per token,  1659.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2231.76 ms /   423 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2983.22 ms /    76 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5333.27 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     112.24 ms /   180 runs   (    0.62 ms per token,  1603.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2151.76 ms /   405 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =    7065.10 ms /   179 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    9502.03 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.34 ms /    68 runs   (    0.59 ms per token,  1685.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2230.51 ms /   424 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2623.32 ms /    67 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4959.59 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     150.61 ms /   256 runs   (    0.59 ms per token,  1699.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2205.19 ms /   414 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =   10065.74 ms /   255 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   12674.32 ms /   669 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.17 ms /    98 runs   (    0.58 ms per token,  1714.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2607.90 ms /   486 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3826.57 ms /    97 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6590.66 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     7 runs   (    0.48 ms per token,  2071.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2937.67 ms /   549 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
            "llama_print_timings:        eval time =     239.67 ms /     6 runs   (   39.94 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    3196.63 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      58.75 ms /    84 runs   (    0.70 ms per token,  1429.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2623.31 ms /   493 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3302.80 ms /    83 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    6095.65 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.65 ms /    78 runs   (    0.57 ms per token,  1747.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4271.10 ms /   784 tokens (    5.45 ms per token,   183.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3155.95 ms /    78 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    7554.77 ms /   862 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     6 runs   (    0.73 ms per token,  1367.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3429.92 ms /   637 tokens (    5.38 ms per token,   185.72 tokens per second)\n",
            "llama_print_timings:        eval time =     201.76 ms /     5 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    3651.51 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.06 ms /    81 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4530.31 ms /   819 tokens (    5.53 ms per token,   180.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3245.33 ms /    80 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    7904.16 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.33 ms /    64 runs   (    0.58 ms per token,  1714.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2885.99 ms /   541 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2488.77 ms /    63 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    5473.35 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      31.06 ms /    56 runs   (    0.55 ms per token,  1802.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4346.08 ms /   786 tokens (    5.53 ms per token,   180.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2225.78 ms /    55 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    6664.81 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      63.82 ms /    91 runs   (    0.70 ms per token,  1425.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6205.73 ms /  1108 tokens (    5.60 ms per token,   178.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3776.30 ms /    90 runs   (   41.96 ms per token,    23.83 tokens per second)\n",
            "llama_print_timings:       total time =   10166.80 ms /  1198 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.06 ms /    79 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4416.49 ms /   794 tokens (    5.56 ms per token,   179.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3167.61 ms /    78 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    7732.33 ms /   872 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      52.49 ms /    80 runs   (    0.66 ms per token,  1524.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3627.05 ms /   671 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3193.21 ms /    79 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    6986.34 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.04 ms /    12 runs   (    0.59 ms per token,  1704.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2439.39 ms /   456 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =     435.24 ms /    11 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    2901.62 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      90.78 ms /   126 runs   (    0.72 ms per token,  1388.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7400.72 ms /  1298 tokens (    5.70 ms per token,   175.39 tokens per second)\n",
            "llama_print_timings:        eval time =    5314.14 ms /   125 runs   (   42.51 ms per token,    23.52 tokens per second)\n",
            "llama_print_timings:       total time =   13004.43 ms /  1423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.51 ms /    90 runs   (    0.57 ms per token,  1747.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2988.57 ms /   557 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3537.60 ms /    89 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    6678.22 ms /   646 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      89.71 ms /   137 runs   (    0.65 ms per token,  1527.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2992.61 ms /   560 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =    5464.75 ms /   136 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    8710.92 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     159.53 ms /   256 runs   (    0.62 ms per token,  1604.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3032.93 ms /   565 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10232.75 ms /   255 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =   13732.95 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1675.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2626.26 ms /   495 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =     235.46 ms /     6 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2878.29 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     104.89 ms /   159 runs   (    0.66 ms per token,  1515.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3163.03 ms /   591 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =    6354.95 ms /   158 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    9826.41 ms /   749 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.52 ms /    77 runs   (    0.59 ms per token,  1691.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2275.80 ms /   431 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2971.59 ms /    76 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5366.53 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      54.82 ms /    83 runs   (    0.66 ms per token,  1513.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2013.17 ms /   380 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3235.96 ms /    82 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5405.54 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.35 ms /    88 runs   (    0.57 ms per token,  1747.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2610.57 ms /   485 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3434.85 ms /    87 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6185.93 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.38 ms /    77 runs   (    0.62 ms per token,  1625.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3392.11 ms /   632 tokens (    5.37 ms per token,   186.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3058.02 ms /    76 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    6589.86 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.67 ms /    64 runs   (    0.62 ms per token,  1613.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2300.22 ms /   427 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2455.96 ms /    63 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4864.93 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      47.61 ms /    84 runs   (    0.57 ms per token,  1764.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1971.71 ms /   376 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3244.81 ms /    83 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5345.75 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.25 ms /     7 runs   (    0.75 ms per token,  1334.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.16 ms /   432 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =     277.86 ms /     7 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    2578.55 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     7 runs   (    0.70 ms per token,  1421.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2129.95 ms /   396 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
            "llama_print_timings:        eval time =     239.41 ms /     6 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    2393.44 ms /   402 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.23 ms /   461 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =     238.50 ms /     6 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    2717.41 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     156.66 ms /   256 runs   (    0.61 ms per token,  1634.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2405.10 ms /   456 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10132.50 ms /   255 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =   12996.18 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     157.45 ms /   256 runs   (    0.62 ms per token,  1625.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2054.32 ms /   386 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
            "llama_print_timings:        eval time =   10068.30 ms /   255 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   12607.01 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     151.40 ms /   256 runs   (    0.59 ms per token,  1690.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2538.44 ms /   475 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =   10149.99 ms /   255 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =   13142.47 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.73 ms /    68 runs   (    0.60 ms per token,  1669.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2276.22 ms /   432 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2669.21 ms /    68 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5052.59 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1624.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2186.06 ms /   412 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =     236.33 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2439.78 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1761.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1662.37 ms /   317 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     192.84 ms /     5 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    1868.17 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      48.49 ms /    71 runs   (    0.68 ms per token,  1464.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2203.39 ms /   414 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2767.24 ms /    70 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    5101.91 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.52 ms /    69 runs   (    0.57 ms per token,  1745.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2231.07 ms /   419 tokens (    5.32 ms per token,   187.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2669.49 ms /    68 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5010.08 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     6 runs   (    0.60 ms per token,  1673.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5008.93 ms /   898 tokens (    5.58 ms per token,   179.28 tokens per second)\n",
            "llama_print_timings:        eval time =     205.80 ms /     5 runs   (   41.16 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =    5240.48 ms /   903 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.69 ms /    12 runs   (    0.64 ms per token,  1559.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2397.24 ms /   445 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
            "llama_print_timings:        eval time =     429.18 ms /    11 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2854.92 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     161.45 ms /   256 runs   (    0.63 ms per token,  1585.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3564.08 ms /   659 tokens (    5.41 ms per token,   184.90 tokens per second)\n",
            "llama_print_timings:        eval time =   10309.90 ms /   255 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =   14348.60 ms /   914 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     143.37 ms /   256 runs   (    0.56 ms per token,  1785.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.25 ms /   555 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
            "llama_print_timings:        eval time =   10227.75 ms /   255 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   13661.87 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     149.17 ms /   256 runs   (    0.58 ms per token,  1716.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2802.41 ms /   528 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =   10237.20 ms /   256 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =   13498.15 ms /   784 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.03 ms /    12 runs   (    0.59 ms per token,  1706.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2229.47 ms /   420 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     431.47 ms /    11 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2684.85 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.59 ms /    12 runs   (    0.55 ms per token,  1821.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2054.70 ms /   387 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =     431.88 ms /    11 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2508.71 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      42.48 ms /    80 runs   (    0.53 ms per token,  1883.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7438.83 ms /  1300 tokens (    5.72 ms per token,   174.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3331.32 ms /    79 runs   (   42.17 ms per token,    23.71 tokens per second)\n",
            "llama_print_timings:       total time =   10911.69 ms /  1379 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.18 ms /    73 runs   (    0.56 ms per token,  1772.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2758.77 ms /   519 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2849.58 ms /    72 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    5726.35 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     100.77 ms /   164 runs   (    0.61 ms per token,  1627.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     133.38 ms /    24 tokens (    5.56 ms per token,   179.93 tokens per second)\n",
            "llama_print_timings:        eval time =    6564.46 ms /   164 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6990.22 ms /   188 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1718.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2273.54 ms /   426 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =     237.27 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2528.36 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       2.89 ms /     6 runs   (    0.48 ms per token,  2079.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2321.11 ms /   439 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =     196.43 ms /     5 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    2532.63 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.04 ms /    89 runs   (    0.63 ms per token,  1588.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2863.79 ms /   534 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3531.36 ms /    88 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    6560.45 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1707.79 ms /   328 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
            "llama_print_timings:        eval time =     197.74 ms /     5 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    1918.06 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      27.02 ms /    47 runs   (    0.57 ms per token,  1739.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2184.47 ms /   411 tokens (    5.32 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1798.85 ms /    46 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4057.04 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1707.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1786.55 ms /   339 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =     239.28 ms /     6 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    2040.06 ms /   345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.66 ms /    65 runs   (    0.64 ms per token,  1560.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2600.69 ms /   487 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2546.41 ms /    64 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    5261.63 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.58 ms /    68 runs   (    0.57 ms per token,  1762.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2936.52 ms /   550 tokens (    5.34 ms per token,   187.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2649.03 ms /    67 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    5684.71 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      49.15 ms /    68 runs   (    0.72 ms per token,  1383.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1923.32 ms /   368 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2687.97 ms /    68 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    4725.87 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     140.02 ms /   256 runs   (    0.55 ms per token,  1828.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1725.48 ms /   325 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =   10010.54 ms /   255 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   12123.10 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     152.70 ms /   256 runs   (    0.60 ms per token,  1676.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2206.55 ms /   416 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =   10073.48 ms /   255 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   12674.26 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      83.92 ms /   131 runs   (    0.64 ms per token,  1560.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.82 ms /   415 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =    5111.98 ms /   130 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7518.88 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      46.50 ms /    82 runs   (    0.57 ms per token,  1763.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2626.59 ms /   495 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3191.51 ms /    81 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    5932.71 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.42 ms /    77 runs   (    0.56 ms per token,  1773.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6153.11 ms /  1091 tokens (    5.64 ms per token,   177.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3152.66 ms /    76 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =    9427.76 ms /  1167 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.55 ms /    77 runs   (    0.57 ms per token,  1768.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2271.09 ms /   432 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3030.95 ms /    77 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5409.39 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.54 ms /     9 runs   (    0.73 ms per token,  1376.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1044.89 ms /   198 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =     307.49 ms /     8 runs   (   38.44 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    1373.04 ms /   206 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     163.39 ms /   256 runs   (    0.64 ms per token,  1566.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2204.23 ms /   413 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =   10093.97 ms /   255 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =   12732.63 ms /   668 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._l2_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1868.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2353.15 ms /   435 tokens (    5.41 ms per token,   184.86 tokens per second)\n",
            "llama_print_timings:        eval time =     233.37 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2600.27 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.28 ms /    12 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2881.73 ms /   544 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =     434.79 ms /    11 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3337.59 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      68.66 ms /   104 runs   (    0.66 ms per token,  1514.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5632.83 ms /  1011 tokens (    5.57 ms per token,   179.48 tokens per second)\n",
            "llama_print_timings:        eval time =    4259.70 ms /   103 runs   (   41.36 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =   10065.32 ms /  1114 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      30.92 ms /    53 runs   (    0.58 ms per token,  1714.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2138.80 ms /   408 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2080.78 ms /    53 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    4297.72 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.47 ms /    72 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2887.07 ms /   538 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2841.16 ms /    71 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5852.44 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.50 ms /    66 runs   (    0.57 ms per token,  1760.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.36 ms /   472 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2550.20 ms /    65 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5145.27 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.50 ms /    70 runs   (    0.58 ms per token,  1728.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3158.97 ms /   590 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2749.82 ms /    69 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    6010.50 ms /   659 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      41.26 ms /    73 runs   (    0.57 ms per token,  1769.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3378.87 ms /   620 tokens (    5.45 ms per token,   183.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2873.65 ms /    72 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    6363.00 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.06 ms /    68 runs   (    0.56 ms per token,  1786.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4022.88 ms /   739 tokens (    5.44 ms per token,   183.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2699.10 ms /    67 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    6818.91 ms /   806 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      50.42 ms /    69 runs   (    0.73 ms per token,  1368.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     137.10 ms /    24 tokens (    5.71 ms per token,   175.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2774.28 ms /    68 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    3042.85 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      62.04 ms /   113 runs   (    0.55 ms per token,  1821.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2819.51 ms /   528 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4486.77 ms /   113 runs   (   39.71 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7484.04 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      43.41 ms /    63 runs   (    0.69 ms per token,  1451.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2757.40 ms /   516 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2491.19 ms /    62 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    5365.43 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      37.76 ms /    65 runs   (    0.58 ms per token,  1721.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2382.56 ms /   442 tokens (    5.39 ms per token,   185.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2500.18 ms /    64 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4985.29 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      96.39 ms /   159 runs   (    0.61 ms per token,  1649.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2580.34 ms /   486 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =    6291.84 ms /   158 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    9149.26 ms /   644 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      66.18 ms /   117 runs   (    0.57 ms per token,  1767.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4884.88 ms /   883 tokens (    5.53 ms per token,   180.76 tokens per second)\n",
            "llama_print_timings:        eval time =    4742.14 ms /   116 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    9808.63 ms /   999 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      39.76 ms /    66 runs   (    0.60 ms per token,  1659.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4530.76 ms /   821 tokens (    5.52 ms per token,   181.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2640.18 ms /    65 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    7278.87 ms /   886 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      98.40 ms /   152 runs   (    0.65 ms per token,  1544.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3116.61 ms /   584 tokens (    5.34 ms per token,   187.38 tokens per second)\n",
            "llama_print_timings:        eval time =    6088.64 ms /   152 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    9479.87 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      65.51 ms /   117 runs   (    0.56 ms per token,  1785.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1945.93 ms /   367 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4541.05 ms /   116 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6653.67 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.58 ms /     7 runs   (    0.51 ms per token,  1955.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2624.38 ms /   494 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =     237.33 ms /     6 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    2878.13 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     154.76 ms /   256 runs   (    0.60 ms per token,  1654.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2670.43 ms /   503 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =   10167.34 ms /   255 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =   13270.09 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     158.67 ms /   256 runs   (    0.62 ms per token,  1613.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2006.23 ms /   378 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =   10075.59 ms /   255 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   12521.79 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      60.10 ms /    89 runs   (    0.68 ms per token,  1480.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2270.28 ms /   431 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3484.76 ms /    88 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    5916.46 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.23 ms /    67 runs   (    0.57 ms per token,  1752.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2600.93 ms /   487 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2602.37 ms /    66 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    5303.66 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.97 ms /    12 runs   (    0.58 ms per token,  1721.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1622.00 ms /   312 tokens (    5.20 ms per token,   192.35 tokens per second)\n",
            "llama_print_timings:        eval time =     430.52 ms /    11 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2072.79 ms /   323 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      73.26 ms /    95 runs   (    0.77 ms per token,  1296.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3793.38 ms /   702 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3835.10 ms /    94 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    7824.93 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      76.95 ms /   127 runs   (    0.61 ms per token,  1650.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1647.51 ms /   310 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4945.84 ms /   126 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6790.33 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      81.02 ms /   126 runs   (    0.64 ms per token,  1555.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1964.06 ms /   374 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4928.03 ms /   125 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7109.16 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     6 runs   (    0.62 ms per token,  1610.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1725.26 ms /   322 tokens (    5.36 ms per token,   186.64 tokens per second)\n",
            "llama_print_timings:        eval time =     195.18 ms /     5 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    1937.49 ms /   327 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     153.90 ms /   256 runs   (    0.60 ms per token,  1663.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1448.89 ms /   277 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
            "llama_print_timings:        eval time =   10002.17 ms /   255 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   11862.13 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      34.40 ms /    61 runs   (    0.56 ms per token,  1773.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3748.24 ms /   691 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2410.05 ms /    60 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    6248.48 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     157.49 ms /   256 runs   (    0.62 ms per token,  1625.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2093.42 ms /   397 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =   10088.71 ms /   255 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   12594.71 ms /   652 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.19 ms /     9 runs   (    0.58 ms per token,  1732.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1577.49 ms /   303 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
            "llama_print_timings:        eval time =     315.88 ms /     8 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    1909.73 ms /   311 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.81 ms /    14 runs   (    0.56 ms per token,  1792.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1536.37 ms /   292 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
            "llama_print_timings:        eval time =     511.89 ms /    13 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    2069.27 ms /   305 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     7 runs   (    0.72 ms per token,  1398.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2184.87 ms /   416 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     233.68 ms /     6 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2434.10 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     7 runs   (    0.70 ms per token,  1423.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2071.81 ms /   388 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
            "llama_print_timings:        eval time =     237.29 ms /     6 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2326.99 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1829.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2407.62 ms /   456 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =     236.13 ms /     6 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2658.76 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      96.72 ms /   168 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3245.16 ms /   604 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
            "llama_print_timings:        eval time =    6682.15 ms /   167 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =   10183.94 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     144.31 ms /   256 runs   (    0.56 ms per token,  1773.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3130.56 ms /   582 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
            "llama_print_timings:        eval time =   10206.89 ms /   255 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =   13749.80 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       6.68 ms /    12 runs   (    0.56 ms per token,  1797.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2546.97 ms /   480 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =     480.19 ms /    12 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    3048.91 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.32 ms /    72 runs   (    0.56 ms per token,  1785.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2443.70 ms /   464 tokens (    5.27 ms per token,   189.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2789.76 ms /    71 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5330.45 ms /   535 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      53.22 ms /    75 runs   (    0.71 ms per token,  1409.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2703.07 ms /   507 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2954.72 ms /    74 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    5793.65 ms /   581 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      40.55 ms /    78 runs   (    0.52 ms per token,  1923.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2142.08 ms /   406 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3032.76 ms /    77 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5278.50 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      56.95 ms /    90 runs   (    0.63 ms per token,  1580.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2885.59 ms /   543 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3554.45 ms /    89 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    6586.04 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     143.87 ms /   256 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2822.52 ms /   528 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10147.49 ms /   255 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =   13363.62 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    64 runs   (    0.57 ms per token,  1759.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2783.28 ms /   518 tokens (    5.37 ms per token,   186.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2476.40 ms /    63 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5353.43 ms /   581 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     147.18 ms /   256 runs   (    0.57 ms per token,  1739.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2885.71 ms /   542 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =   10192.89 ms /   255 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =   13499.57 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      44.77 ms /    80 runs   (    0.56 ms per token,  1786.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4065.61 ms /   749 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3183.84 ms /    79 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7364.88 ms /   828 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.11 ms /    64 runs   (    0.60 ms per token,  1679.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2785.23 ms /   517 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2502.13 ms /    63 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    5388.07 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      29.57 ms /    52 runs   (    0.57 ms per token,  1758.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2095.15 ms /   394 tokens (    5.32 ms per token,   188.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1996.75 ms /    51 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4165.69 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      22.72 ms /    41 runs   (    0.55 ms per token,  1804.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1492.98 ms /   288 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.46 ms /    40 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3118.87 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    12 runs   (    0.78 ms per token,  1286.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2383.44 ms /   448 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
            "llama_print_timings:        eval time =     438.16 ms /    11 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    2848.77 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     171.26 ms /   256 runs   (    0.67 ms per token,  1494.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1725.76 ms /   327 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
            "llama_print_timings:        eval time =   10051.04 ms /   255 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   12239.87 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      38.84 ms /    65 runs   (    0.60 ms per token,  1673.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4064.66 ms /   744 tokens (    5.46 ms per token,   183.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2619.27 ms /    65 runs   (   40.30 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    6791.71 ms /   809 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      55.33 ms /    83 runs   (    0.67 ms per token,  1500.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4763.72 ms /   868 tokens (    5.49 ms per token,   182.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3360.70 ms /    82 runs   (   40.98 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =    8271.56 ms /   950 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     148.90 ms /   256 runs   (    0.58 ms per token,  1719.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1645.08 ms /   312 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
            "llama_print_timings:        eval time =    9969.83 ms /   255 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12011.47 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.94 ms /    85 runs   (    0.68 ms per token,  1466.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1172.50 ms /   222 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3274.85 ms /    84 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4591.02 ms /   306 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      45.00 ms /    77 runs   (    0.58 ms per token,  1711.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3518.22 ms /   656 tokens (    5.36 ms per token,   186.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3081.10 ms /    77 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    6713.90 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      51.85 ms /    76 runs   (    0.68 ms per token,  1465.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3723.39 ms /   685 tokens (    5.44 ms per token,   183.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3030.46 ms /    75 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    6894.72 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       7.16 ms /    12 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2397.81 ms /   452 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =     433.83 ms /    11 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    2854.07 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      57.45 ms /    97 runs   (    0.59 ms per token,  1688.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1575.14 ms /   304 tokens (    5.18 ms per token,   193.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3788.20 ms /    97 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5500.01 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =      60.48 ms /    95 runs   (    0.64 ms per token,  1570.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2381.91 ms /   447 tokens (    5.33 ms per token,   187.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3707.81 ms /    94 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6233.15 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1790.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2574.88 ms /   488 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =     282.18 ms /     7 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    2871.58 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     515.52 ms\n",
            "llama_print_timings:      sample time =     110.38 ms /   161 runs   (    0.69 ms per token,  1458.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1706.06 ms /   327 tokens (    5.22 ms per token,   191.67 tokens per second)\n",
            "llama_print_timings:        eval time =    6292.60 ms /   160 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    8284.89 ms /   487 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_cosine_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_AES CORP_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_ip_2.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 1 for dataframe results_approach_AES CORP_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_l2_2.json\n",
            "Total score for approach 1 and distance function cosine is 0.5715990453460621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(1, 'ip')"
      ],
      "metadata": {
        "id": "fw_TIsTV3dTg",
        "outputId": "53a37013-7bc7-4999-f3f1-80ff6b552e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.12 ms /    88 runs   (    0.55 ms per token,  1828.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3729.57 ms /   663 tokens (    5.63 ms per token,   177.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3303.89 ms /    87 runs   (   37.98 ms per token,    26.33 tokens per second)\n",
            "llama_print_timings:       total time =    7217.84 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.36 ms /   102 runs   (    0.66 ms per token,  1514.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1435.49 ms /   276 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3835.24 ms /   101 runs   (   37.97 ms per token,    26.33 tokens per second)\n",
            "llama_print_timings:       total time =    5447.27 ms /   377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.49 ms /    70 runs   (    0.55 ms per token,  1818.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3990.66 ms /   772 tokens (    5.17 ms per token,   193.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2629.61 ms /    69 runs   (   38.11 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =    6734.50 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1899.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3383.75 ms /   659 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
            "llama_print_timings:        eval time =     226.34 ms /     6 runs   (   37.72 ms per token,    26.51 tokens per second)\n",
            "llama_print_timings:       total time =    3627.73 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.61 ms /   256 runs   (    0.54 ms per token,  1846.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2638.14 ms /   512 tokens (    5.15 ms per token,   194.08 tokens per second)\n",
            "llama_print_timings:        eval time =    9654.16 ms /   255 runs   (   37.86 ms per token,    26.41 tokens per second)\n",
            "llama_print_timings:       total time =   12670.34 ms /   767 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.76 ms /    80 runs   (    0.57 ms per token,  1748.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2916.04 ms /   568 tokens (    5.13 ms per token,   194.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3008.96 ms /    79 runs   (   38.09 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    6044.33 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.39 ms /    89 runs   (    0.51 ms per token,  1960.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2212.76 ms /   440 tokens (    5.03 ms per token,   198.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3336.68 ms /    89 runs   (   37.49 ms per token,    26.67 tokens per second)\n",
            "llama_print_timings:       total time =    5665.98 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.97 ms /    64 runs   (    0.67 ms per token,  1489.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1678.55 ms /   336 tokens (    5.00 ms per token,   200.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2371.58 ms /    63 runs   (   37.64 ms per token,    26.56 tokens per second)\n",
            "llama_print_timings:       total time =    4154.94 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     125.73 ms /   230 runs   (    0.55 ms per token,  1829.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2710.48 ms /   522 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =    8728.38 ms /   229 runs   (   38.12 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =   11796.38 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     6 runs   (    0.66 ms per token,  1504.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2920.49 ms /   540 tokens (    5.41 ms per token,   184.90 tokens per second)\n",
            "llama_print_timings:        eval time =     192.26 ms /     5 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    3132.30 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.64 ms /    91 runs   (    0.51 ms per token,  1951.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4033.88 ms /   770 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3472.03 ms /    90 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    7632.94 ms /   860 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.79 ms /    83 runs   (    0.73 ms per token,  1365.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2772.13 ms /   541 tokens (    5.12 ms per token,   195.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3164.14 ms /    82 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    6088.43 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.92 ms /   105 runs   (    0.55 ms per token,  1812.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =      85.30 ms /    16 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
            "llama_print_timings:        eval time =    4003.72 ms /   105 runs   (   38.13 ms per token,    26.23 tokens per second)\n",
            "llama_print_timings:       total time =    4231.50 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.92 ms /    71 runs   (    0.60 ms per token,  1654.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4000.08 ms /   765 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2717.81 ms /    70 runs   (   38.83 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    6829.03 ms /   835 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.92 ms /   256 runs   (    0.54 ms per token,  1842.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.44 ms /   418 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9710.93 ms /   255 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =   12257.70 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.48 ms /    94 runs   (    0.65 ms per token,  1528.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     837.45 ms /   168 tokens (    4.98 ms per token,   200.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3540.94 ms /    94 runs   (   37.67 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =    4526.06 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.81 ms /    14 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1483.03 ms /   292 tokens (    5.08 ms per token,   196.89 tokens per second)\n",
            "llama_print_timings:        eval time =     488.03 ms /    13 runs   (   37.54 ms per token,    26.64 tokens per second)\n",
            "llama_print_timings:       total time =    1992.10 ms /   305 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2540.43 ms /   495 tokens (    5.13 ms per token,   194.85 tokens per second)\n",
            "llama_print_timings:        eval time =     188.32 ms /     5 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =    2742.39 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.60 ms /    95 runs   (    0.65 ms per token,  1542.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3575.39 ms /   688 tokens (    5.20 ms per token,   192.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3668.89 ms /    94 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    7406.05 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.44 ms /    69 runs   (    0.54 ms per token,  1842.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2932.63 ms /   567 tokens (    5.17 ms per token,   193.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2613.49 ms /    68 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    5639.71 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.48 ms /    73 runs   (    0.62 ms per token,  1604.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3186.15 ms /   610 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2787.97 ms /    72 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    6087.07 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.01 ms /   104 runs   (    0.57 ms per token,  1762.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1720.95 ms /   331 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3910.06 ms /   103 runs   (   37.96 ms per token,    26.34 tokens per second)\n",
            "llama_print_timings:       total time =    5778.54 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.53 ms /   256 runs   (    0.59 ms per token,  1700.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1905.04 ms /   371 tokens (    5.13 ms per token,   194.75 tokens per second)\n",
            "llama_print_timings:        eval time =    9783.99 ms /   255 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =   12099.23 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.11 ms /    72 runs   (    0.53 ms per token,  1889.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1997.55 ms /   392 tokens (    5.10 ms per token,   196.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2743.62 ms /    72 runs   (   38.11 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =    4832.54 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.33 ms /    76 runs   (    0.61 ms per token,  1640.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1445.13 ms /   278 tokens (    5.20 ms per token,   192.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2895.10 ms /    75 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    4457.45 ms /   353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.34 ms /    76 runs   (    0.54 ms per token,  1838.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.33 ms /   440 tokens (    5.20 ms per token,   192.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2874.20 ms /    75 runs   (   38.32 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    5264.39 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.88 ms /   100 runs   (    0.55 ms per token,  1822.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1786.94 ms /   349 tokens (    5.12 ms per token,   195.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3772.18 ms /    99 runs   (   38.10 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =    5690.74 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.09 ms /     7 runs   (    0.73 ms per token,  1375.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2549.16 ms /   486 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =     231.88 ms /     6 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2799.48 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.96 ms /   122 runs   (    0.54 ms per token,  1849.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2238.59 ms /   430 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4651.24 ms /   121 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    7055.16 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1797.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2515.79 ms /   488 tokens (    5.16 ms per token,   193.98 tokens per second)\n",
            "llama_print_timings:        eval time =     231.99 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2762.68 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.25 ms /   256 runs   (    0.58 ms per token,  1715.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2180.63 ms /   421 tokens (    5.18 ms per token,   193.06 tokens per second)\n",
            "llama_print_timings:        eval time =    9908.95 ms /   255 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =   12483.03 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.03 ms /   256 runs   (    0.61 ms per token,  1640.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2694.60 ms /   519 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
            "llama_print_timings:        eval time =    9944.38 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   13052.56 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.49 ms /    94 runs   (    0.69 ms per token,  1457.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2696.60 ms /   515 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3628.90 ms /    93 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    6493.98 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.17 ms /   122 runs   (    0.55 ms per token,  1816.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1444.20 ms /   271 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4704.02 ms /   121 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    6314.74 ms /   392 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2569.77 ms /   496 tokens (    5.18 ms per token,   193.01 tokens per second)\n",
            "llama_print_timings:        eval time =     273.38 ms /     7 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2859.25 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.39 ms /     6 runs   (    0.73 ms per token,  1366.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2377.45 ms /   456 tokens (    5.21 ms per token,   191.80 tokens per second)\n",
            "llama_print_timings:        eval time =     193.92 ms /     5 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2590.18 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.15 ms /     9 runs   (    0.68 ms per token,  1463.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     441.07 ms /    88 tokens (    5.01 ms per token,   199.51 tokens per second)\n",
            "llama_print_timings:        eval time =     339.79 ms /     9 runs   (   37.75 ms per token,    26.49 tokens per second)\n",
            "llama_print_timings:       total time =     802.21 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1860.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.65 ms /   411 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =     230.04 ms /     6 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2404.39 ms /   417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.73 ms /    51 runs   (    0.56 ms per token,  1775.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5781.13 ms /  1062 tokens (    5.44 ms per token,   183.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2015.22 ms /    50 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7893.75 ms /  1112 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     6 runs   (    0.70 ms per token,  1421.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1697.33 ms /   328 tokens (    5.17 ms per token,   193.25 tokens per second)\n",
            "llama_print_timings:        eval time =     234.28 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    1948.10 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.82 ms /   256 runs   (    0.57 ms per token,  1767.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2694.57 ms /   511 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =    9959.19 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   13041.86 ms /   766 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.83 ms /   256 runs   (    0.54 ms per token,  1844.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2743.05 ms /   519 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =    9977.67 ms /   255 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   13095.97 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.41 ms /   256 runs   (    0.55 ms per token,  1810.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2041.85 ms /   386 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =    9910.05 ms /   255 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =   12329.63 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    14 runs   (    0.68 ms per token,  1467.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1477.15 ms /   283 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =     504.85 ms /    13 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2007.83 ms /   296 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1543.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1959.44 ms /   371 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =     233.59 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2213.07 ms /   377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.04 ms /    89 runs   (    0.57 ms per token,  1743.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2189.19 ms /   419 tokens (    5.22 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3407.61 ms /    88 runs   (   38.72 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    5716.87 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.45 ms /    90 runs   (    0.68 ms per token,  1464.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3913.91 ms /   736 tokens (    5.32 ms per token,   188.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3592.66 ms /    90 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    7670.26 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.78 ms /    69 runs   (    0.53 ms per token,  1876.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3245.52 ms /   616 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2709.00 ms /    69 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6047.53 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.53 ms per token,  1870.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     130.77 ms /    24 tokens (    5.45 ms per token,   183.53 tokens per second)\n",
            "llama_print_timings:        eval time =     234.02 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =     375.67 ms /    30 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1916.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1639.72 ms /   315 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
            "llama_print_timings:        eval time =     190.75 ms /     5 runs   (   38.15 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    1842.37 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.55 ms per token,  1834.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     228.48 ms /     6 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =     236.88 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.75 ms /     9 runs   (    0.64 ms per token,  1565.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2502.31 ms /   474 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =     315.24 ms /     8 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2837.69 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     6 runs   (    0.70 ms per token,  1432.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1703.53 ms /   324 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =     194.96 ms /     5 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    1918.38 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.08 ms /   439 tokens (    5.21 ms per token,   192.12 tokens per second)\n",
            "llama_print_timings:        eval time =     229.90 ms /     6 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2531.95 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.73 ms /   256 runs   (    0.60 ms per token,  1654.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2236.10 ms /   428 tokens (    5.22 ms per token,   191.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9982.79 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12637.62 ms /   683 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.66 ms /   256 runs   (    0.60 ms per token,  1676.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2804.14 ms /   533 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =   10044.29 ms /   255 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   13268.12 ms /   788 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.29 ms /   256 runs   (    0.59 ms per token,  1680.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1492.71 ms /   277 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =   10026.50 ms /   255 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   11948.91 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.10 ms /   256 runs   (    0.59 ms per token,  1694.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2854.36 ms /   541 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =   10032.70 ms /   255 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   13302.84 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.23 ms /    93 runs   (    0.55 ms per token,  1815.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2807.27 ms /   532 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3597.69 ms /    92 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    6531.63 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.63 ms /   126 runs   (    0.66 ms per token,  1524.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2191.65 ms /   420 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =    4870.65 ms /   125 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    7270.49 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1664.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2281.74 ms /   440 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
            "llama_print_timings:        eval time =     230.44 ms /     6 runs   (   38.41 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2527.14 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.55 ms /    69 runs   (    0.56 ms per token,  1789.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2495.38 ms /   475 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2653.22 ms /    68 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5240.22 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.95 ms /   256 runs   (    0.59 ms per token,  1684.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1829.63 ms /   352 tokens (    5.20 ms per token,   192.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9970.39 ms /   255 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12197.34 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.63 ms /   256 runs   (    0.60 ms per token,  1666.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1981.50 ms /   379 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =    9929.02 ms /   255 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12308.75 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     7 runs   (    0.51 ms per token,  1969.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1638.37 ms /   315 tokens (    5.20 ms per token,   192.26 tokens per second)\n",
            "llama_print_timings:        eval time =     231.23 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    1881.86 ms /   321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.19 ms /    12 runs   (    0.68 ms per token,  1464.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2367.87 ms /   454 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =     428.98 ms /    11 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2821.55 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.78 ms /     7 runs   (    0.68 ms per token,  1465.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2047.03 ms /   386 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =     231.49 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2300.50 ms /   392 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.11 ms /    65 runs   (    0.54 ms per token,  1851.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2767.39 ms /   516 tokens (    5.36 ms per token,   186.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2509.76 ms /    64 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5365.12 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.76 ms /    80 runs   (    0.68 ms per token,  1461.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3469.26 ms /   655 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3140.31 ms /    79 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    6751.40 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1847.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2277.84 ms /   438 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
            "llama_print_timings:        eval time =     229.24 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2521.35 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.53 ms /    60 runs   (    0.54 ms per token,  1844.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2021.81 ms /   390 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2280.89 ms /    59 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    4382.14 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.35 ms /    77 runs   (    0.68 ms per token,  1470.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1893.96 ms /   364 tokens (    5.20 ms per token,   192.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2939.73 ms /    76 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    4958.19 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.04 ms /    91 runs   (    0.54 ms per token,  1855.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3579.81 ms /   672 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
            "llama_print_timings:        eval time =    3575.82 ms /    91 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    7283.46 ms /   763 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.10 ms /    64 runs   (    0.58 ms per token,  1725.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.02 ms /   448 tokens (    5.19 ms per token,   192.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2453.14 ms /    63 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    4871.35 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1855.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2575.11 ms /   486 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     231.62 ms /     6 runs   (   38.60 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2825.11 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.43 ms /   256 runs   (    0.56 ms per token,  1797.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3118.33 ms /   592 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10091.11 ms /   255 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   13619.00 ms /   847 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.35 ms /    68 runs   (    0.53 ms per token,  1870.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3382.42 ms /   640 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2671.14 ms /    68 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6145.35 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      98.33 ms /   162 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2197.16 ms /   421 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =    6279.65 ms /   161 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    8735.14 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.81 ms /   114 runs   (    0.61 ms per token,  1632.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4240.08 ms /   792 tokens (    5.35 ms per token,   186.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4544.23 ms /   114 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    8958.58 ms /   906 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.01 ms /   256 runs   (    0.55 ms per token,  1815.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2223.36 ms /   419 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =    9960.99 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12558.28 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.30 ms /   256 runs   (    0.58 ms per token,  1737.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1580.88 ms /   299 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
            "llama_print_timings:        eval time =    9938.97 ms /   255 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =   11899.79 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.94 ms /     7 runs   (    0.71 ms per token,  1415.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2520.05 ms /   475 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =     237.21 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2775.98 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1933.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3365.79 ms /   632 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
            "llama_print_timings:        eval time =     273.31 ms /     7 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    3659.14 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.95 ms /    98 runs   (    0.57 ms per token,  1751.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5076.85 ms /   936 tokens (    5.42 ms per token,   184.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3957.42 ms /    98 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    9190.63 ms /  1034 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.84 ms /    64 runs   (    0.54 ms per token,  1836.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2756.76 ms /   520 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2469.80 ms /    63 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5313.82 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.01 ms /    64 runs   (    0.53 ms per token,  1881.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.99 ms /   568 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2480.81 ms /    63 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5551.63 ms /   631 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.16 ms /   256 runs   (    0.61 ms per token,  1649.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2165.59 ms /   415 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =    9959.20 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12524.14 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.45 ms /    68 runs   (    0.68 ms per token,  1463.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.85 ms /   391 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2599.37 ms /    67 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    4739.58 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.20 ms /    78 runs   (    0.55 ms per token,  1805.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2699.99 ms /   512 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3059.16 ms /    78 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5866.54 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.05 ms /    85 runs   (    0.55 ms per token,  1806.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.23 ms /   400 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3320.12 ms /    85 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5506.22 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.78 ms /    53 runs   (    0.62 ms per token,  1616.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2357.61 ms /   443 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2027.88 ms /    52 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4472.32 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.45 ms /   256 runs   (    0.60 ms per token,  1668.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3165.47 ms /   598 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =   10087.37 ms /   255 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   13671.57 ms /   853 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1811.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.31 ms /   440 tokens (    5.20 ms per token,   192.28 tokens per second)\n",
            "llama_print_timings:        eval time =     269.42 ms /     7 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2572.40 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1856.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.78 ms /   459 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =     231.84 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2658.93 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.98 ms /   127 runs   (    0.63 ms per token,  1587.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1954.64 ms /   375 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4924.37 ms /   126 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    7084.86 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.45 ms /   136 runs   (    0.55 ms per token,  1826.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2989.42 ms /   568 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    5340.77 ms /   136 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    8512.16 ms /   704 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.18 ms /   124 runs   (    0.61 ms per token,  1649.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2827.63 ms /   533 tokens (    5.31 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =    4827.38 ms /   123 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7840.20 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.38 ms /   256 runs   (    0.60 ms per token,  1669.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2938.84 ms /   556 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =   10060.55 ms /   255 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13416.08 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.16 ms /    59 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.55 ms /   440 tokens (    5.20 ms per token,   192.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2265.89 ms /    58 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4632.51 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.81 ms /     9 runs   (    0.53 ms per token,  1872.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1603.01 ms /   312 tokens (    5.14 ms per token,   194.63 tokens per second)\n",
            "llama_print_timings:        eval time =     306.82 ms /     8 runs   (   38.35 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    1925.21 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.64 ms /     9 runs   (    0.74 ms per token,  1355.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.05 ms /    45 tokens (    5.53 ms per token,   180.69 tokens per second)\n",
            "llama_print_timings:        eval time =     307.27 ms /     8 runs   (   38.41 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =     572.43 ms /    53 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.60 ms /   256 runs   (    0.55 ms per token,  1820.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1615.09 ms /   306 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =    9932.41 ms /   255 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   11918.88 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.53 ms /   112 runs   (    0.65 ms per token,  1544.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2305.77 ms /   436 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4322.88 ms /   111 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    6807.38 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.60 ms /    64 runs   (    0.56 ms per token,  1797.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.41 ms /   447 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2455.17 ms /    63 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4867.87 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.14 ms /    11 runs   (    0.56 ms per token,  1792.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.74 ms /   416 tokens (    5.19 ms per token,   192.70 tokens per second)\n",
            "llama_print_timings:        eval time =     385.65 ms /    10 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2564.05 ms /   426 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.64 ms /    11 runs   (    0.69 ms per token,  1439.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2314.26 ms /   436 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
            "llama_print_timings:        eval time =     390.34 ms /    10 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2730.31 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.40 ms /     9 runs   (    0.60 ms per token,  1665.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     815.75 ms /   154 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =     308.94 ms /     8 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    1139.60 ms /   162 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.13 ms /   256 runs   (    0.57 ms per token,  1751.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2632.94 ms /   501 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
            "llama_print_timings:        eval time =   10033.62 ms /   255 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   13090.01 ms /   756 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.64 ms /    77 runs   (    0.55 ms per token,  1805.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.01 ms /   362 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2945.27 ms /    76 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    4944.21 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.17 ms /    65 runs   (    0.56 ms per token,  1797.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1432.57 ms /   276 tokens (    5.19 ms per token,   192.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2463.49 ms /    64 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    3979.40 ms /   340 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.12 ms /    76 runs   (    0.61 ms per token,  1647.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2743.00 ms /   515 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2945.17 ms /    75 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5807.52 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.87 ms /    11 runs   (    0.53 ms per token,  1873.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.16 ms /   566 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =     387.77 ms /    10 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    3391.28 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.73 ms /   129 runs   (    0.65 ms per token,  1540.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3468.80 ms /   650 tokens (    5.34 ms per token,   187.38 tokens per second)\n",
            "llama_print_timings:        eval time =    5075.77 ms /   128 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    8763.47 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      21.40 ms /    38 runs   (    0.56 ms per token,  1775.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.75 ms /   432 tokens (    5.19 ms per token,   192.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.29 ms /    38 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3778.77 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.86 ms /    67 runs   (    0.58 ms per token,  1724.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3790.02 ms /   709 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2607.68 ms /    66 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6498.29 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.07 ms /    11 runs   (    0.55 ms per token,  1812.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2975.22 ms /   555 tokens (    5.36 ms per token,   186.54 tokens per second)\n",
            "llama_print_timings:        eval time =     392.49 ms /    10 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3391.39 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.56 ms /    61 runs   (    0.57 ms per token,  1765.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     727.31 ms /   144 tokens (    5.05 ms per token,   197.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2286.53 ms /    60 runs   (   38.11 ms per token,    26.24 tokens per second)\n",
            "llama_print_timings:       total time =    3091.59 ms /   204 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1855.28 ms /   359 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
            "llama_print_timings:        eval time =     230.61 ms /     6 runs   (   38.44 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2099.08 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.71 ms /   256 runs   (    0.61 ms per token,  1644.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.69 ms /   363 tokens (    5.23 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9945.38 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12247.84 ms /   618 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.36 ms /    72 runs   (    0.57 ms per token,  1740.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2721.32 ms /   517 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2786.98 ms /    71 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5611.27 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.66 ms /    66 runs   (    0.59 ms per token,  1707.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2222.11 ms /   420 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2529.43 ms /    65 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    4855.12 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.53 ms /   256 runs   (    0.59 ms per token,  1700.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1555.33 ms /   300 tokens (    5.18 ms per token,   192.89 tokens per second)\n",
            "llama_print_timings:        eval time =    9902.42 ms /   255 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =   11872.91 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.61 ms /   166 runs   (    0.53 ms per token,  1873.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.25 ms /   512 tokens (    5.23 ms per token,   191.38 tokens per second)\n",
            "llama_print_timings:        eval time =    6463.65 ms /   165 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    9361.16 ms /   677 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.84 ms /   256 runs   (    0.59 ms per token,  1697.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1877.48 ms /   355 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =    9941.40 ms /   255 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =   12213.42 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.07 ms /    91 runs   (    0.72 ms per token,  1398.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1327.29 ms /   255 tokens (    5.21 ms per token,   192.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3501.81 ms /    90 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    4991.89 ms /   345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.44 ms /   136 runs   (    0.55 ms per token,  1826.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4890.13 ms /   898 tokens (    5.45 ms per token,   183.64 tokens per second)\n",
            "llama_print_timings:        eval time =    5437.71 ms /   135 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =   10524.86 ms /  1033 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.44 ms /    55 runs   (    0.75 ms per token,  1327.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1280.66 ms /   243 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2083.43 ms /    54 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    3457.03 ms /   297 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1793.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2594.31 ms /   494 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =     195.81 ms /     5 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2805.02 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.82 ms /    77 runs   (    0.56 ms per token,  1798.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1938.73 ms /   370 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2945.49 ms /    76 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    4985.31 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      90.49 ms /   144 runs   (    0.63 ms per token,  1591.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2116.12 ms /   405 tokens (    5.22 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =    5564.33 ms /   143 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    7905.71 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1857.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.88 ms /   463 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
            "llama_print_timings:        eval time =     232.49 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2659.69 ms /   469 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.27 ms /    70 runs   (    0.65 ms per token,  1546.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2930.53 ms /   552 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2724.25 ms /    69 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    5772.98 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.43 ms /    67 runs   (    0.54 ms per token,  1839.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3693.46 ms /   692 tokens (    5.34 ms per token,   187.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2604.46 ms /    66 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6390.71 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     6 runs   (    0.64 ms per token,  1566.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5376.51 ms /   982 tokens (    5.48 ms per token,   182.65 tokens per second)\n",
            "llama_print_timings:        eval time =     202.92 ms /     5 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    5603.08 ms /   987 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.61 ms /     7 runs   (    0.52 ms per token,  1936.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2434.18 ms /   463 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =     231.54 ms /     6 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2681.31 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.37 ms /    64 runs   (    0.54 ms per token,  1862.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.57 ms /   376 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2486.45 ms /    64 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4508.81 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.36 ms /    69 runs   (    0.60 ms per token,  1668.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2376.63 ms /   453 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2669.53 ms /    68 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5150.24 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.33 ms /    76 runs   (    0.53 ms per token,  1884.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3679.03 ms /   683 tokens (    5.39 ms per token,   185.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2948.82 ms /    75 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6732.69 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      21.56 ms /    40 runs   (    0.54 ms per token,  1855.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3661.56 ms /   687 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.31 ms /    39 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5253.66 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.86 ms /    73 runs   (    0.68 ms per token,  1463.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     132.55 ms /    24 tokens (    5.52 ms per token,   181.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2879.36 ms /    72 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    3135.76 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.99 ms /    78 runs   (    0.54 ms per token,  1857.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2859.54 ms /   544 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3056.53 ms /    78 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6024.80 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1890.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.55 ms /   380 tokens (    5.22 ms per token,   191.67 tokens per second)\n",
            "llama_print_timings:        eval time =     233.49 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2229.10 ms /   386 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.84 ms /    68 runs   (    0.66 ms per token,  1516.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3458.61 ms /   648 tokens (    5.34 ms per token,   187.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2665.76 ms /    67 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    6242.81 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.05 ms /   256 runs   (    0.60 ms per token,  1661.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.65 ms /   498 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =   10045.69 ms /   255 runs   (   39.39 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   13102.16 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.98 ms /   113 runs   (    0.55 ms per token,  1823.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4387.94 ms /   816 tokens (    5.38 ms per token,   185.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4471.61 ms /   112 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    9020.28 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.79 ms /    11 runs   (    0.71 ms per token,  1412.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2258.37 ms /   426 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =     390.28 ms /    10 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2672.95 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.78 ms /   256 runs   (    0.53 ms per token,  1871.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2561.05 ms /   482 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
            "llama_print_timings:        eval time =   10027.76 ms /   255 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   12977.11 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1876.13 ms /   360 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =     271.96 ms /     7 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2167.96 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.73 ms /   256 runs   (    0.59 ms per token,  1698.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3122.11 ms /   590 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =   10081.86 ms /   255 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =   13626.60 ms /   845 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.13 ms /    75 runs   (    0.54 ms per token,  1868.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3657.00 ms /   687 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2918.07 ms /    74 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6676.96 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1985.00 ms /   384 tokens (    5.17 ms per token,   193.45 tokens per second)\n",
            "llama_print_timings:        eval time =     231.12 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2230.03 ms /   390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.66 ms /    71 runs   (    0.66 ms per token,  1521.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1828.24 ms /   348 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2720.04 ms /    70 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    4662.33 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.06 ms /    77 runs   (    0.56 ms per token,  1788.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.70 ms /   411 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2969.00 ms /    76 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5231.10 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.82 ms /    84 runs   (    0.65 ms per token,  1532.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2902.16 ms /   552 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3309.80 ms /    84 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6350.00 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.24 ms /    59 runs   (    0.56 ms per token,  1774.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2387.37 ms /   456 tokens (    5.24 ms per token,   191.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2262.35 ms /    58 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4732.14 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.80 ms /    66 runs   (    0.54 ms per token,  1843.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1389.02 ms /   266 tokens (    5.22 ms per token,   191.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2500.62 ms /    65 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    3975.18 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.82 ms /   117 runs   (    0.60 ms per token,  1675.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     121.42 ms /    21 tokens (    5.78 ms per token,   172.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4475.11 ms /   116 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    4774.20 ms /   137 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.95 ms /     9 runs   (    0.55 ms per token,  1817.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1407.98 ms /   272 tokens (    5.18 ms per token,   193.18 tokens per second)\n",
            "llama_print_timings:        eval time =     342.91 ms /     9 runs   (   38.10 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    1767.29 ms /   281 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.90 ms /   103 runs   (    0.56 ms per token,  1779.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1308.16 ms /   255 tokens (    5.13 ms per token,   194.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3926.55 ms /   102 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    5369.38 ms /   357 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.25 ms /   256 runs   (    0.60 ms per token,  1670.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.33 ms /   469 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
            "llama_print_timings:        eval time =    9980.90 ms /   255 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12851.89 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.82 ms /    77 runs   (    0.61 ms per token,  1644.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1851.34 ms /   354 tokens (    5.23 ms per token,   191.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2952.95 ms /    76 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4915.35 ms /   430 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.26 ms /   114 runs   (    0.55 ms per token,  1802.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2406.20 ms /   456 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =    4419.69 ms /   113 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    6985.84 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      92.68 ms /   153 runs   (    0.61 ms per token,  1650.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1471.82 ms /   283 tokens (    5.20 ms per token,   192.28 tokens per second)\n",
            "llama_print_timings:        eval time =    5877.20 ms /   152 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    7582.52 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1795.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2438.87 ms /   462 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =     192.70 ms /     5 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2646.26 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.97 ms /     9 runs   (    0.55 ms per token,  1810.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1346.89 ms /   260 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
            "llama_print_timings:        eval time =     306.34 ms /     8 runs   (   38.29 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    1667.96 ms /   268 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.92 ms /   109 runs   (    0.56 ms per token,  1789.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1221.37 ms /   234 tokens (    5.22 ms per token,   191.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4144.17 ms /   108 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    5507.70 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.67 ms /     9 runs   (    0.52 ms per token,  1925.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     765.33 ms /   151 tokens (    5.07 ms per token,   197.30 tokens per second)\n",
            "llama_print_timings:        eval time =     305.60 ms /     8 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    1084.27 ms /   159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1620.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2748.04 ms /   515 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =     240.41 ms /     6 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    3008.26 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.98 ms /     6 runs   (    0.50 ms per token,  2014.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3264.37 ms /   616 tokens (    5.30 ms per token,   188.70 tokens per second)\n",
            "llama_print_timings:        eval time =     194.53 ms /     5 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3476.11 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2238.31 ms /   428 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
            "llama_print_timings:        eval time =     230.05 ms /     6 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2482.27 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.94 ms /    74 runs   (    0.69 ms per token,  1452.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4888.98 ms /   903 tokens (    5.41 ms per token,   184.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2965.07 ms /    73 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    7992.95 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.87 ms /   123 runs   (    0.52 ms per token,  1925.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3610.38 ms /   675 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4805.97 ms /   122 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    8580.58 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.32 ms /   140 runs   (    0.58 ms per token,  1721.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3859.37 ms /   715 tokens (    5.40 ms per token,   185.26 tokens per second)\n",
            "llama_print_timings:        eval time =    5516.79 ms /   139 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    9587.07 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.14 ms /    93 runs   (    0.58 ms per token,  1717.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1561.45 ms /   303 tokens (    5.15 ms per token,   194.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3552.72 ms /    92 runs   (   38.62 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    5239.98 ms /   395 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.58 ms /    57 runs   (    0.64 ms per token,  1558.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2181.24 ms /   414 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2180.11 ms /    56 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4450.66 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.34 ms /   113 runs   (    0.55 ms per token,  1812.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2418.78 ms /   461 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4381.53 ms /   112 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6955.45 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.71 ms /    86 runs   (    0.62 ms per token,  1601.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2682.28 ms /   512 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3382.21 ms /    86 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6203.38 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1714.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.56 ms /    24 tokens (    5.40 ms per token,   185.24 tokens per second)\n",
            "llama_print_timings:        eval time =     232.99 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =     373.89 ms /    30 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.41 ms /   105 runs   (    0.53 ms per token,  1894.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3520.49 ms /   661 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
            "llama_print_timings:        eval time =    4088.30 ms /   104 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7749.20 ms /   765 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.02 ms /    98 runs   (    0.66 ms per token,  1507.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1610.05 ms /   312 tokens (    5.16 ms per token,   193.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3776.65 ms /    97 runs   (   38.93 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5541.98 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.56 ms /    65 runs   (    0.53 ms per token,  1880.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.50 ms /   376 tokens (    5.16 ms per token,   193.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2518.74 ms /    65 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    4543.28 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.65 ms /    76 runs   (    0.59 ms per token,  1702.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1771.59 ms /   340 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2914.05 ms /    75 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4794.80 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.93 ms /     7 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     168.93 ms /    32 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =     231.25 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =     413.85 ms /    38 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.59 ms /    95 runs   (    0.60 ms per token,  1678.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1577.73 ms /   301 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3639.77 ms /    94 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    5351.02 ms /   395 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.97 ms /   105 runs   (    0.55 ms per token,  1811.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2856.53 ms /   544 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    4087.28 ms /   104 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7086.93 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.27 ms /    68 runs   (    0.53 ms per token,  1874.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3738.36 ms /   693 tokens (    5.39 ms per token,   185.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2634.86 ms /    67 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6470.09 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.77 ms /    85 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.64 ms /   436 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3279.41 ms /    84 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5672.34 ms /   520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1486.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1819.10 ms /   347 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =     232.96 ms /     6 runs   (   38.83 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2067.86 ms /   353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.62 ms /     7 runs   (    0.80 ms per token,  1246.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1881.98 ms /   357 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =     232.63 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2139.78 ms /   363 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1659.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1867.45 ms /   360 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
            "llama_print_timings:        eval time =     269.59 ms /     7 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2153.32 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.28 ms /    81 runs   (    0.53 ms per token,  1871.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3927.22 ms /   736 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3157.96 ms /    80 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    7196.21 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.62 ms /    75 runs   (    0.62 ms per token,  1608.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2608.37 ms /   496 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2930.97 ms /    75 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5657.78 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.68 ms /    87 runs   (    0.57 ms per token,  1751.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.15 ms /   311 tokens (    5.15 ms per token,   194.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3323.21 ms /    86 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    5042.13 ms /   397 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.90 ms /   467 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     232.81 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2706.07 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    12 runs   (    0.72 ms per token,  1397.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2522.23 ms /   474 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =     429.31 ms /    11 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2978.15 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1829.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1869.88 ms /   354 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =     231.06 ms /     6 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2116.74 ms /   360 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.49 ms /    76 runs   (    0.57 ms per token,  1747.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4829.63 ms /   882 tokens (    5.48 ms per token,   182.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3009.63 ms /    75 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    7960.82 ms /   957 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.75 ms /   110 runs   (    0.62 ms per token,  1623.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2852.39 ms /   530 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4254.32 ms /   109 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    7295.07 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.77 ms /    93 runs   (    0.71 ms per token,  1414.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3802.20 ms /   709 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3669.37 ms /    92 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7663.56 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1820.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5453.73 ms /   990 tokens (    5.51 ms per token,   181.53 tokens per second)\n",
            "llama_print_timings:        eval time =     201.84 ms /     5 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    5682.43 ms /   995 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.86 ms /    72 runs   (    0.57 ms per token,  1762.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2336.59 ms /   448 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2775.31 ms /    71 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5214.93 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.33 ms /    68 runs   (    0.53 ms per token,  1871.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4892.25 ms /   892 tokens (    5.48 ms per token,   182.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2682.40 ms /    67 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7675.06 ms /   959 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.94 ms /    79 runs   (    0.61 ms per token,  1647.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4196.15 ms /   782 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3104.79 ms /    78 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7422.33 ms /   860 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.84 ms /    65 runs   (    0.63 ms per token,  1591.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4227.29 ms /   781 tokens (    5.41 ms per token,   184.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2550.73 ms /    64 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    6886.06 ms /   845 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.80 ms /    81 runs   (    0.63 ms per token,  1594.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4606.65 ms /   852 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3231.69 ms /    80 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    7977.41 ms /   932 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.66 ms /    70 runs   (    0.54 ms per token,  1858.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4756.56 ms /   877 tokens (    5.42 ms per token,   184.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2762.67 ms /    69 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7622.48 ms /   946 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.43 ms /   110 runs   (    0.59 ms per token,  1681.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4672.09 ms /   861 tokens (    5.43 ms per token,   184.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4390.18 ms /   109 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    9240.32 ms /   970 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.75 ms /   256 runs   (    0.60 ms per token,  1675.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2501.51 ms /   477 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =   10010.35 ms /   255 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   12927.61 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.79 ms /     6 runs   (    0.47 ms per token,  2148.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5354.26 ms /   983 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
            "llama_print_timings:        eval time =     201.59 ms /     5 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    5574.06 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.11 ms /     6 runs   (    0.52 ms per token,  1931.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5486.03 ms /   998 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
            "llama_print_timings:        eval time =     202.83 ms /     5 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    5711.21 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.71 ms /    56 runs   (    0.53 ms per token,  1885.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4155.76 ms /   776 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2178.43 ms /    55 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    6412.58 ms /   831 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2583.66 ms /   493 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =     196.18 ms /     5 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2793.63 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.23 ms /   118 runs   (    0.56 ms per token,  1781.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4199.39 ms /   773 tokens (    5.43 ms per token,   184.07 tokens per second)\n",
            "llama_print_timings:        eval time =    4642.50 ms /   117 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    9011.04 ms /   890 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.75 ms /    52 runs   (    0.55 ms per token,  1808.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2071.83 ms /   398 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1979.17 ms /    51 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4121.26 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.89 ms /    52 runs   (    0.69 ms per token,  1448.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1058.28 ms /   195 tokens (    5.43 ms per token,   184.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1993.26 ms /    51 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3138.22 ms /   246 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.35 ms /    70 runs   (    0.55 ms per token,  1825.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4619.67 ms /   856 tokens (    5.40 ms per token,   185.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2761.46 ms /    69 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    7483.05 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.34 ms /    97 runs   (    0.60 ms per token,  1662.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4803.28 ms /   883 tokens (    5.44 ms per token,   183.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3872.34 ms /    96 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    8830.13 ms /   979 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.06 ms /    92 runs   (    0.54 ms per token,  1837.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4470.90 ms /   831 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3629.30 ms /    91 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    8227.62 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.24 ms /   256 runs   (    0.57 ms per token,  1762.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2189.43 ms /   416 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    9984.00 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12548.84 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.16 ms /    10 runs   (    0.82 ms per token,  1225.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2613.79 ms /   495 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =     357.87 ms /     9 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    2995.22 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.14 ms /    78 runs   (    0.54 ms per token,  1850.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4255.62 ms /   791 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3057.84 ms /    77 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7424.46 ms /   868 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.25 ms /    75 runs   (    0.62 ms per token,  1621.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5331.54 ms /   971 tokens (    5.49 ms per token,   182.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3005.58 ms /    74 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8461.59 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.23 ms /   256 runs   (    0.59 ms per token,  1704.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1640.54 ms /   314 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    9918.98 ms /   255 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =   11979.46 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.86 ms /   144 runs   (    0.55 ms per token,  1826.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2375.01 ms /   450 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
            "llama_print_timings:        eval time =    5603.18 ms /   143 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    8170.61 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.48 ms /   256 runs   (    0.57 ms per token,  1747.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1598.89 ms /   312 tokens (    5.12 ms per token,   195.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9944.33 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   11933.74 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2716.10 ms /   514 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =     237.78 ms /     6 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    2969.09 ms /   520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.55 ms /   256 runs   (    0.58 ms per token,  1711.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2178.67 ms /   414 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =    9964.72 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12528.49 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.58 ms /    72 runs   (    0.61 ms per token,  1651.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3232.87 ms /   608 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2790.16 ms /    71 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6140.28 ms /   679 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.28 ms /   256 runs   (    0.57 ms per token,  1762.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.38 ms /   464 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =   10063.07 ms /   256 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12887.67 ms /   720 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.91 ms /   102 runs   (    0.54 ms per token,  1857.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3833.80 ms /   719 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3982.64 ms /   101 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7956.84 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.91 ms /    67 runs   (    0.54 ms per token,  1865.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4602.98 ms /   846 tokens (    5.44 ms per token,   183.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2631.06 ms /    66 runs   (   39.86 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7331.52 ms /   912 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1835.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3382.27 ms /   638 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =     194.50 ms /     5 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    3592.93 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.07 ms /     6 runs   (    0.51 ms per token,  1955.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.99 ms /   323 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =     191.61 ms /     5 runs   (   38.32 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    1889.76 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     6 runs   (    0.70 ms per token,  1424.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1473.71 ms /   285 tokens (    5.17 ms per token,   193.39 tokens per second)\n",
            "llama_print_timings:        eval time =     192.53 ms /     5 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    1682.28 ms /   290 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1935.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5355.88 ms /   971 tokens (    5.52 ms per token,   181.30 tokens per second)\n",
            "llama_print_timings:        eval time =     199.56 ms /     5 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5576.76 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1843.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5215.19 ms /   960 tokens (    5.43 ms per token,   184.08 tokens per second)\n",
            "llama_print_timings:        eval time =     240.91 ms /     6 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    5475.61 ms /   966 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.86 ms /    10 runs   (    0.69 ms per token,  1458.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2593.76 ms /   491 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =     354.70 ms /     9 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2970.29 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.42 ms /    12 runs   (    0.62 ms per token,  1617.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2185.03 ms /   416 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
            "llama_print_timings:        eval time =     467.47 ms /    12 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2678.27 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.70 ms /    79 runs   (    0.53 ms per token,  1894.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2938.06 ms /   555 tokens (    5.29 ms per token,   188.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3065.29 ms /    78 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6108.30 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1880.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3296.08 ms /   618 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =     196.22 ms /     5 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3508.42 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.09 ms /    11 runs   (    0.74 ms per token,  1359.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2976.03 ms /   556 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
            "llama_print_timings:        eval time =     397.18 ms /    10 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    3401.29 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.79 ms /    64 runs   (    0.51 ms per token,  1951.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4247.17 ms /   789 tokens (    5.38 ms per token,   185.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2504.68 ms /    63 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6840.49 ms /   852 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.48 ms /    65 runs   (    0.67 ms per token,  1494.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4160.60 ms /   773 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2569.95 ms /    64 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    6853.83 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.42 ms /    87 runs   (    0.55 ms per token,  1834.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4243.94 ms /   789 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3415.42 ms /    86 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7778.52 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.94 ms /    87 runs   (    0.70 ms per token,  1427.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3267.01 ms /   611 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3390.25 ms /    86 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6803.40 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.23 ms /   102 runs   (    0.53 ms per token,  1880.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3975.81 ms /   739 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =    4006.23 ms /   101 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    8122.69 ms /   840 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.41 ms /   256 runs   (    0.58 ms per token,  1736.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2348.84 ms /   445 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =    9966.37 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12698.02 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.90 ms /    47 runs   (    0.72 ms per token,  1386.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     891.24 ms /   170 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1779.73 ms /    46 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2755.81 ms /   216 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.84 ms /   115 runs   (    0.53 ms per token,  1890.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2525.30 ms /   477 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
            "llama_print_timings:        eval time =    4467.96 ms /   114 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7146.81 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.64 ms /    12 runs   (    0.55 ms per token,  1807.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.68 ms /   517 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =     429.23 ms /    11 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3173.11 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.78 ms /    72 runs   (    0.54 ms per token,  1856.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4838.09 ms /   883 tokens (    5.48 ms per token,   182.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2844.65 ms /    71 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    7786.02 ms /   954 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.28 ms /    78 runs   (    0.55 ms per token,  1802.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3831.65 ms /   715 tokens (    5.36 ms per token,   186.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3050.63 ms /    77 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    6989.89 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.55 ms /    98 runs   (    0.58 ms per token,  1733.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2980.43 ms /   558 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3801.01 ms /    97 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6923.58 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.26 ms /    78 runs   (    0.57 ms per token,  1762.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3211.51 ms /   607 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3026.19 ms /    77 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6346.66 ms /   684 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.28 ms /   130 runs   (    0.55 ms per token,  1823.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3872.04 ms /   715 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =    5108.59 ms /   129 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    9162.29 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.56 ms /    75 runs   (    0.58 ms per token,  1721.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2152.96 ms /   413 tokens (    5.21 ms per token,   191.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2880.06 ms /    74 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5135.58 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.69 ms /   119 runs   (    0.53 ms per token,  1898.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5715.71 ms /  1038 tokens (    5.51 ms per token,   181.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4797.53 ms /   118 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   10681.55 ms /  1156 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.47 ms /    97 runs   (    0.60 ms per token,  1659.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3488.14 ms /   652 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3798.30 ms /    96 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    7430.05 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.25 ms /   168 runs   (    0.57 ms per token,  1763.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.27 ms /   400 tokens (    5.18 ms per token,   193.02 tokens per second)\n",
            "llama_print_timings:        eval time =    6560.38 ms /   168 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    8861.63 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     104.45 ms /   168 runs   (    0.62 ms per token,  1608.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    6553.86 ms /   168 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    6795.02 ms /   168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     117.98 ms /   196 runs   (    0.60 ms per token,  1661.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1936.60 ms /   374 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
            "llama_print_timings:        eval time =    7602.37 ms /   195 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    9839.78 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.50 ms /   104 runs   (    0.55 ms per token,  1808.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.23 ms /   413 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4012.43 ms /   103 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    6300.32 ms /   516 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.11 ms /   115 runs   (    0.56 ms per token,  1793.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3262.73 ms /   608 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4511.00 ms /   115 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7927.77 ms /   723 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.37 ms /    78 runs   (    0.71 ms per token,  1408.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5723.57 ms /  1044 tokens (    5.48 ms per token,   182.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3153.72 ms /    77 runs   (   40.96 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    9016.14 ms /  1121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.44 ms /    72 runs   (    0.53 ms per token,  1873.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2545.18 ms /   482 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2771.84 ms /    71 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5406.21 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.42 ms /    83 runs   (    0.58 ms per token,  1714.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2333.25 ms /   448 tokens (    5.21 ms per token,   192.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3232.64 ms /    83 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5676.54 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.68 ms /    79 runs   (    0.54 ms per token,  1850.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3331.71 ms /   624 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3066.83 ms /    78 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6501.54 ms /   702 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.20 ms /   115 runs   (    0.58 ms per token,  1711.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3383.36 ms /   639 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =    4503.13 ms /   114 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    8053.91 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1889.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2258.15 ms /   428 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =     231.97 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2505.41 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.63 ms /    83 runs   (    0.54 ms per token,  1859.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2934.57 ms /   554 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3212.66 ms /    82 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6251.61 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.31 ms /    88 runs   (    0.65 ms per token,  1535.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2154.47 ms /   416 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3433.03 ms /    88 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5723.27 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.89 ms /    80 runs   (    0.54 ms per token,  1865.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3695.76 ms /   692 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3103.41 ms /    79 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6903.29 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.44 ms /    12 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2800.99 ms /   533 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =     433.89 ms /    11 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3255.04 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.88 ms /    92 runs   (    0.59 ms per token,  1707.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2266.09 ms /   431 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3547.58 ms /    91 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5937.86 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.88 ms /    11 runs   (    0.53 ms per token,  1871.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.57 ms /   428 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =     383.36 ms /    10 runs   (   38.34 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2645.03 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.74 ms /   256 runs   (    0.59 ms per token,  1698.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2584.43 ms /   490 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10011.56 ms /   255 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   12984.86 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.02 ms /    78 runs   (    0.56 ms per token,  1771.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.44 ms /   531 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3013.66 ms /    77 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5934.90 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     6 runs   (    0.66 ms per token,  1507.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2661.15 ms /   498 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
            "llama_print_timings:        eval time =     198.19 ms /     5 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    2876.81 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.99 ms /    78 runs   (    0.54 ms per token,  1857.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3336.50 ms /   628 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3040.30 ms /    77 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6479.41 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.23 ms /   139 runs   (    0.60 ms per token,  1670.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3890.98 ms /   723 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =    5508.92 ms /   138 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    9611.27 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.12 ms /   126 runs   (    0.60 ms per token,  1677.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6064.69 ms /  1101 tokens (    5.51 ms per token,   181.54 tokens per second)\n",
            "llama_print_timings:        eval time =    5137.40 ms /   125 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   11414.53 ms /  1226 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.58 ms /    61 runs   (    0.55 ms per token,  1816.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.66 ms /   435 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2336.60 ms /    60 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    4693.91 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.55 ms /    61 runs   (    0.57 ms per token,  1765.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.90 ms /   432 tokens (    5.19 ms per token,   192.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2345.38 ms /    60 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    4669.40 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.84 ms /    68 runs   (    0.66 ms per token,  1516.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1920.86 ms /   368 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2640.61 ms /    68 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    4671.53 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.00 ms /    81 runs   (    0.56 ms per token,  1800.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2196.19 ms /   421 tokens (    5.22 ms per token,   191.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3116.53 ms /    80 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5415.80 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.67 ms /    59 runs   (    0.71 ms per token,  1415.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3706.49 ms /   695 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2317.02 ms /    58 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    6125.67 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.63 ms /    68 runs   (    0.54 ms per token,  1856.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2971.35 ms /   552 tokens (    5.38 ms per token,   185.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2683.45 ms /    68 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5746.92 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.91 ms /    87 runs   (    0.60 ms per token,  1675.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.60 ms /   440 tokens (    5.18 ms per token,   192.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3396.80 ms /    87 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5799.39 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.86 ms /    85 runs   (    0.55 ms per token,  1813.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2217.47 ms /   418 tokens (    5.30 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3274.75 ms /    84 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5603.33 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1806.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2239.96 ms /   426 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =     230.98 ms /     6 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2484.97 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1903.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.07 ms /   470 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =     233.19 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2704.31 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    14 runs   (    0.65 ms per token,  1544.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     849.74 ms /   166 tokens (    5.12 ms per token,   195.35 tokens per second)\n",
            "llama_print_timings:        eval time =     499.30 ms /    13 runs   (   38.41 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    1371.08 ms /   179 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1589.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1750.92 ms /   336 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
            "llama_print_timings:        eval time =     235.04 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2004.25 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.43 ms /   256 runs   (    0.55 ms per token,  1810.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1949.86 ms /   375 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
            "llama_print_timings:        eval time =    9962.65 ms /   255 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12275.16 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1564.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1702.34 ms /   323 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =     234.34 ms /     6 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    1951.81 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.98 ms /   256 runs   (    0.57 ms per token,  1753.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.99 ms /   423 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =    9989.37 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12575.44 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.32 ms /   256 runs   (    0.54 ms per token,  1837.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1951.16 ms /   376 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
            "llama_print_timings:        eval time =    9997.36 ms /   256 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12314.73 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2877.80 ms /   542 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =     195.02 ms /     5 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3087.45 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1877.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.42 ms /   455 tokens (    5.21 ms per token,   191.87 tokens per second)\n",
            "llama_print_timings:        eval time =     231.17 ms /     6 runs   (   38.53 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2615.72 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.20 ms /   146 runs   (    0.60 ms per token,  1674.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2002.79 ms /   381 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5667.82 ms /   145 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    7883.00 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      24.65 ms /    45 runs   (    0.55 ms per token,  1825.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2872.53 ms /   541 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1727.04 ms /    44 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    4661.70 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.37 ms /    99 runs   (    0.51 ms per token,  1965.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2937.29 ms /   558 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3855.76 ms /    98 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6918.52 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.55 ms /    86 runs   (    0.68 ms per token,  1468.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     123.89 ms /    18 tokens (    6.88 ms per token,   145.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3346.28 ms /    85 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3609.45 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     115.95 ms /   206 runs   (    0.56 ms per token,  1776.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2761.40 ms /   525 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    8061.42 ms /   205 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   11113.42 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.27 ms /   140 runs   (    0.54 ms per token,  1835.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3141.06 ms /   590 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =    5459.44 ms /   139 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    8785.19 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.70 ms /    11 runs   (    0.52 ms per token,  1929.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2718.30 ms /   517 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =     393.06 ms /    10 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3132.49 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     100.45 ms /   167 runs   (    0.60 ms per token,  1662.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2652.27 ms /   499 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =    6493.70 ms /   166 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    9386.65 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.21 ms /   118 runs   (    0.64 ms per token,  1569.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3115.38 ms /   591 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4621.52 ms /   117 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7920.21 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.24 ms /   256 runs   (    0.57 ms per token,  1762.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.66 ms /   480 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
            "llama_print_timings:        eval time =   10028.23 ms /   255 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   12928.71 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.88 ms /    69 runs   (    0.52 ms per token,  1923.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.69 ms /   512 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2671.08 ms /    68 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5434.65 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.98 ms /    86 runs   (    0.72 ms per token,  1387.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4239.70 ms /   790 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3409.17 ms /    85 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    7795.36 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.32 ms /   107 runs   (    0.55 ms per token,  1834.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3694.82 ms /   691 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4169.20 ms /   106 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    8003.40 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     6 runs   (    0.70 ms per token,  1436.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2594.54 ms /   493 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =     194.70 ms /     5 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2805.09 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.41 ms /   165 runs   (    0.57 ms per token,  1747.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1877.24 ms /   360 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
            "llama_print_timings:        eval time =    6431.32 ms /   165 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    8533.16 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.67 ms /    65 runs   (    0.64 ms per token,  1559.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2939.75 ms /   560 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2519.48 ms /    64 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5558.67 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.84 ms /    12 runs   (    0.57 ms per token,  1753.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2049.33 ms /   388 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =     421.45 ms /    11 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2491.69 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     137.28 ms /   236 runs   (    0.58 ms per token,  1719.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1683.87 ms /   323 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
            "llama_print_timings:        eval time =    9124.91 ms /   235 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =   11154.17 ms /   558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.44 ms /    62 runs   (    0.59 ms per token,  1701.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1010.98 ms /   190 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2366.62 ms /    61 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3459.01 ms /   251 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.09 ms /   256 runs   (    0.56 ms per token,  1789.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1938.17 ms /   370 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =    9959.29 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12281.75 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.51 ms /    14 runs   (    0.54 ms per token,  1865.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1343.85 ms /   259 tokens (    5.19 ms per token,   192.73 tokens per second)\n",
            "llama_print_timings:        eval time =     496.73 ms /    13 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    1859.30 ms /   272 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.27 ms /    90 runs   (    0.54 ms per token,  1864.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1981.26 ms /   384 tokens (    5.16 ms per token,   193.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3486.15 ms /    90 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    5578.62 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     6 runs   (    0.65 ms per token,  1532.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2508.12 ms /   479 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
            "llama_print_timings:        eval time =     196.08 ms /     5 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2719.33 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.16 ms /    78 runs   (    0.53 ms per token,  1895.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2748.69 ms /   516 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3025.31 ms /    77 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5872.20 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.70 ms /   256 runs   (    0.57 ms per token,  1769.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2281.95 ms /   439 tokens (    5.20 ms per token,   192.38 tokens per second)\n",
            "llama_print_timings:        eval time =    9995.01 ms /   255 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12658.44 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.27 ms /   222 runs   (    0.61 ms per token,  1629.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1981.06 ms /   379 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =    8622.99 ms /   221 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   10940.25 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.17 ms /    91 runs   (    0.55 ms per token,  1813.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3472.47 ms /   655 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3530.17 ms /    90 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7123.87 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.79 ms /   256 runs   (    0.60 ms per token,  1653.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.63 ms /   423 tokens (    5.20 ms per token,   192.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9971.02 ms /   255 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12557.92 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.71 ms /   256 runs   (    0.58 ms per token,  1733.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2368.91 ms /   455 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =    9966.49 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12716.37 ms /   710 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.97 ms /     9 runs   (    0.55 ms per token,  1811.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6521.34 ms /  1168 tokens (    5.58 ms per token,   179.10 tokens per second)\n",
            "llama_print_timings:        eval time =     367.11 ms /     9 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    6915.87 ms /  1177 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.17 ms /    62 runs   (    0.50 ms per token,  1988.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5162.19 ms /   952 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2498.82 ms /    62 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7743.77 ms /  1014 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.67 ms /    75 runs   (    0.62 ms per token,  1606.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2430.18 ms /   459 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2897.07 ms /    74 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5441.67 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.88 ms /    71 runs   (    0.53 ms per token,  1874.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2546.12 ms /   487 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2738.62 ms /    70 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5374.55 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.86 ms /    64 runs   (    0.65 ms per token,  1528.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2068.66 ms /   395 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2453.35 ms /    63 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    4616.82 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.32 ms /    75 runs   (    0.54 ms per token,  1860.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2524.79 ms /   477 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2900.68 ms /    74 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5519.24 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     134.74 ms /   227 runs   (    0.59 ms per token,  1684.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3159.83 ms /   595 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =    8944.68 ms /   226 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   12458.01 ms /   821 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.11 ms /    70 runs   (    0.54 ms per token,  1836.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2673.43 ms /   509 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2701.84 ms /    69 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5463.37 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.60 ms /    94 runs   (    0.63 ms per token,  1577.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.35 ms /    20 tokens (    6.27 ms per token,   159.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3663.45 ms /    93 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3930.21 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.36 ms /   256 runs   (    0.58 ms per token,  1725.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2078.22 ms /   396 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9976.56 ms /   255 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12429.76 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.99 ms /    80 runs   (    0.54 ms per token,  1860.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6524.03 ms /  1173 tokens (    5.56 ms per token,   179.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3239.95 ms /    79 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    9881.74 ms /  1252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.01 ms /    75 runs   (    0.53 ms per token,  1874.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5429.72 ms /   989 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2989.91 ms /    74 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    8523.33 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.59 ms /    12 runs   (    0.55 ms per token,  1820.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1596.09 ms /   311 tokens (    5.13 ms per token,   194.85 tokens per second)\n",
            "llama_print_timings:        eval time =     422.14 ms /    11 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2035.88 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.51 ms /    96 runs   (    0.60 ms per token,  1669.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2802.13 ms /   534 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3748.95 ms /    95 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6690.79 ms /   629 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.87 ms /   256 runs   (    0.57 ms per token,  1767.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2729.78 ms /   514 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10023.29 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13136.15 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.17 ms /    70 runs   (    0.55 ms per token,  1833.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2348.37 ms /   448 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2695.31 ms /    69 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5133.43 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.00 ms /    96 runs   (    0.60 ms per token,  1655.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4647.73 ms /   861 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3822.22 ms /    95 runs   (   40.23 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    8618.77 ms /   956 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.05 ms /   107 runs   (    0.53 ms per token,  1875.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2733.61 ms /   515 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
            "llama_print_timings:        eval time =    4159.70 ms /   106 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7032.30 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.31 ms /   103 runs   (    0.60 ms per token,  1653.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1723.84 ms /   334 tokens (    5.16 ms per token,   193.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3963.51 ms /   102 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    5836.50 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.67 ms /    84 runs   (    0.53 ms per token,  1880.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3672.55 ms /   686 tokens (    5.35 ms per token,   186.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3258.31 ms /    83 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    7043.98 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.57 ms /    60 runs   (    0.54 ms per token,  1841.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1640.01 ms /   315 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2271.34 ms /    59 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    3987.46 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.01 ms /   120 runs   (    0.58 ms per token,  1738.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3186.39 ms /   595 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    4673.12 ms /   119 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    8036.62 ms /   714 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1829.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2503.96 ms /   477 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =     233.72 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2753.19 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.66 ms /    81 runs   (    0.59 ms per token,  1699.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     849.04 ms /   165 tokens (    5.15 ms per token,   194.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3064.15 ms /    80 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    4025.93 ms /   245 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.89 ms /    74 runs   (    0.66 ms per token,  1513.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1573.29 ms /   303 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2814.12 ms /    73 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    4498.43 ms /   376 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.37 ms /   102 runs   (    0.54 ms per token,  1842.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4146.38 ms /   771 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =    4011.59 ms /   101 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    8300.08 ms /   872 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    12 runs   (    0.73 ms per token,  1364.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2132.75 ms /   402 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =     428.11 ms /    11 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2588.71 ms /   413 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.87 ms /    12 runs   (    0.66 ms per token,  1524.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     514.35 ms /    94 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
            "llama_print_timings:        eval time =     430.45 ms /    11 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =     965.03 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.52 ms /   104 runs   (    0.56 ms per token,  1777.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.06 ms /    21 tokens (    5.96 ms per token,   167.92 tokens per second)\n",
            "llama_print_timings:        eval time =    4015.97 ms /   103 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4278.61 ms /   124 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     459.90 ms /    82 tokens (    5.61 ms per token,   178.30 tokens per second)\n",
            "llama_print_timings:        eval time =     232.10 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =     703.67 ms /    88 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1862.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1683.88 ms /   326 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
            "llama_print_timings:        eval time =     233.76 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    1930.58 ms /   332 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.14 ms /   445 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =     230.24 ms /     6 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2573.22 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.37 ms /   256 runs   (    0.58 ms per token,  1725.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2396.75 ms /   453 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =    9965.69 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12745.31 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.09 ms /   256 runs   (    0.56 ms per token,  1801.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2695.92 ms /   508 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =    9993.07 ms /   255 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   13064.53 ms /   763 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.39 ms /    69 runs   (    0.67 ms per token,  1487.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2303.78 ms /   440 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2665.33 ms /    68 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5089.16 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.82 ms /    93 runs   (    0.56 ms per token,  1794.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.97 ms /   426 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3590.78 ms /    92 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5959.13 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1915.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2678.85 ms /   510 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =     195.83 ms /     5 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2888.91 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     6 runs   (    0.66 ms per token,  1510.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2618.05 ms /   496 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =     234.31 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2872.53 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1759.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1998.13 ms /   384 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =     272.63 ms /     7 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2285.38 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1892.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     724.81 ms /   142 tokens (    5.10 ms per token,   195.91 tokens per second)\n",
            "llama_print_timings:        eval time =     189.86 ms /     5 runs   (   37.97 ms per token,    26.34 tokens per second)\n",
            "llama_print_timings:       total time =     924.34 ms /   147 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.90 ms /    14 runs   (    0.56 ms per token,  1773.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1476.64 ms /   288 tokens (    5.13 ms per token,   195.04 tokens per second)\n",
            "llama_print_timings:        eval time =     499.99 ms /    13 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    1998.85 ms /   301 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.15 ms /    69 runs   (    0.55 ms per token,  1808.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1475.73 ms /   288 tokens (    5.12 ms per token,   195.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2656.49 ms /    69 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    4221.95 ms /   357 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.69 ms /   256 runs   (    0.60 ms per token,  1654.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1607.39 ms /   312 tokens (    5.15 ms per token,   194.10 tokens per second)\n",
            "llama_print_timings:        eval time =    9933.68 ms /   255 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   11942.76 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.10 ms /   256 runs   (    0.59 ms per token,  1683.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    9949.01 ms /   256 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =   10350.69 ms /   256 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1867.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2374.35 ms /   455 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =     233.21 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2621.93 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1877.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2162.04 ms /   416 tokens (    5.20 ms per token,   192.41 tokens per second)\n",
            "llama_print_timings:        eval time =     232.69 ms /     6 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2407.44 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.45 ms /    97 runs   (    0.64 ms per token,  1553.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1765.04 ms /   332 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3761.44 ms /    96 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5684.33 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.36 ms /    77 runs   (    0.55 ms per token,  1817.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2202.43 ms /   424 tokens (    5.19 ms per token,   192.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3007.71 ms /    77 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5315.30 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.16 ms /    49 runs   (    0.66 ms per token,  1523.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3254.61 ms /   613 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1899.23 ms /    48 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    5240.88 ms /   661 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.97 ms /   116 runs   (    0.54 ms per token,  1842.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4119.94 ms /   768 tokens (    5.36 ms per token,   186.41 tokens per second)\n",
            "llama_print_timings:        eval time =    4603.17 ms /   116 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    8883.07 ms /   884 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.62 ms /   112 runs   (    0.61 ms per token,  1632.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3263.64 ms /   613 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =    4388.66 ms /   111 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    7834.65 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      93.26 ms /   157 runs   (    0.59 ms per token,  1683.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3253.15 ms /   613 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =    6164.44 ms /   156 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    9662.49 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.01 ms /    78 runs   (    0.55 ms per token,  1813.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3331.44 ms /   624 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3025.32 ms /    77 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6464.61 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.24 ms /    52 runs   (    0.54 ms per token,  1841.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.99 ms /   392 tokens (    5.18 ms per token,   193.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2019.51 ms /    52 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    4119.44 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.05 ms /    65 runs   (    0.68 ms per token,  1475.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     463.74 ms /    85 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2488.40 ms /    64 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3057.60 ms /   149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2217.40 ms /   419 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =     231.91 ms /     6 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2466.61 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.46 ms /    65 runs   (    0.56 ms per token,  1782.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     892.87 ms /   175 tokens (    5.10 ms per token,   196.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2441.38 ms /    64 runs   (   38.15 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    3416.52 ms /   239 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.39 ms /   256 runs   (    0.58 ms per token,  1725.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.76 ms /   453 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
            "llama_print_timings:        eval time =    9997.82 ms /   255 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12775.33 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.16 ms /    96 runs   (    0.65 ms per token,  1544.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5213.14 ms /   954 tokens (    5.46 ms per token,   183.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3867.38 ms /    95 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    9250.27 ms /  1049 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.22 ms /   256 runs   (    0.59 ms per token,  1692.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.43 ms /   415 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =    9995.06 ms /   255 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12558.36 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.08 ms /   256 runs   (    0.56 ms per token,  1789.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1820.69 ms /   347 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =    9932.35 ms /   255 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12136.22 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.19 ms /    78 runs   (    0.54 ms per token,  1848.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2396.58 ms /   451 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3002.39 ms /    77 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5504.18 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.57 ms /   256 runs   (    0.58 ms per token,  1711.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1600.11 ms /   312 tokens (    5.13 ms per token,   194.99 tokens per second)\n",
            "llama_print_timings:        eval time =    9951.06 ms /   256 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =   11956.22 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.35 ms /    69 runs   (    0.54 ms per token,  1847.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3341.17 ms /   631 tokens (    5.30 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2675.66 ms /    68 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6112.16 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.70 ms /   111 runs   (    0.57 ms per token,  1742.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3945.57 ms /   732 tokens (    5.39 ms per token,   185.52 tokens per second)\n",
            "llama_print_timings:        eval time =    4371.80 ms /   110 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    8480.84 ms /   842 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     7 runs   (    0.59 ms per token,  1693.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.73 ms /   424 tokens (    5.19 ms per token,   192.66 tokens per second)\n",
            "llama_print_timings:        eval time =     271.86 ms /     7 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2488.13 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1789.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1795.62 ms /   340 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
            "llama_print_timings:        eval time =     236.93 ms /     6 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    2046.32 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.45 ms /    12 runs   (    0.70 ms per token,  1420.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.75 ms /   470 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     433.55 ms /    11 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2925.80 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.35 ms /    94 runs   (    0.56 ms per token,  1795.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2713.35 ms /   506 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3641.29 ms /    93 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6486.68 ms /   599 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.84 ms /   104 runs   (    0.64 ms per token,  1556.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3637.07 ms /   680 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4106.71 ms /   103 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7925.30 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.88 ms /   173 runs   (    0.55 ms per token,  1804.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4983.43 ms /   918 tokens (    5.43 ms per token,   184.21 tokens per second)\n",
            "llama_print_timings:        eval time =    6965.48 ms /   172 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =   12224.87 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.60 ms /    72 runs   (    0.54 ms per token,  1865.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2219.66 ms /   422 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2767.57 ms /    71 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5083.10 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.19 ms /    59 runs   (    0.55 ms per token,  1832.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.66 ms /   532 tokens (    5.28 ms per token,   189.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2282.15 ms /    58 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5173.00 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.63 ms /   146 runs   (    0.65 ms per token,  1526.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2395.36 ms /   455 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =    5670.19 ms /   145 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    8299.33 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.66 ms /   256 runs   (    0.59 ms per token,  1687.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1901.69 ms /   365 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
            "llama_print_timings:        eval time =    9964.89 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12270.37 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.69 ms /   256 runs   (    0.54 ms per token,  1845.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.43 ms /   453 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =   10026.79 ms /   255 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   12795.67 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3613.15 ms /   675 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =     198.97 ms /     5 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    3828.06 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1835.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.61 ms /   462 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =     234.10 ms /     6 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2666.34 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.32 ms /    88 runs   (    0.54 ms per token,  1859.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3694.69 ms /   684 tokens (    5.40 ms per token,   185.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3442.31 ms /    87 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    7269.29 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.91 ms /     6 runs   (    0.49 ms per token,  2059.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =      87.64 ms /    16 tokens (    5.48 ms per token,   182.55 tokens per second)\n",
            "llama_print_timings:        eval time =     236.51 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =     333.83 ms /    22 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.46 ms /   105 runs   (    0.59 ms per token,  1708.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3891.22 ms /   728 tokens (    5.35 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4133.84 ms /   104 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    8186.10 ms /   832 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.28 ms /    94 runs   (    0.55 ms per token,  1832.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2965.79 ms /   555 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3650.85 ms /    93 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6747.55 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.48 ms /    96 runs   (    0.60 ms per token,  1670.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5411.72 ms /   990 tokens (    5.47 ms per token,   182.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3882.89 ms /    95 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    9459.95 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.38 ms /    70 runs   (    0.55 ms per token,  1824.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5031.04 ms /   925 tokens (    5.44 ms per token,   183.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2775.36 ms /    69 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7906.36 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.87 ms /   131 runs   (    0.59 ms per token,  1682.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2926.23 ms /   552 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
            "llama_print_timings:        eval time =    5115.25 ms /   130 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    8236.03 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.68 ms /    76 runs   (    0.65 ms per token,  1529.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6507.30 ms /  1173 tokens (    5.55 ms per token,   180.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3109.49 ms /    75 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =    9760.27 ms /  1248 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.26 ms /    59 runs   (    0.51 ms per token,  1949.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6405.22 ms /  1155 tokens (    5.55 ms per token,   180.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2377.81 ms /    58 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    8870.37 ms /  1213 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.17 ms /    12 runs   (    0.68 ms per token,  1468.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1866.11 ms /   357 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =     431.67 ms /    11 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2322.96 ms /   368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    65 runs   (    0.56 ms per token,  1786.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3865.46 ms /   718 tokens (    5.38 ms per token,   185.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2529.38 ms /    64 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6495.43 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.16 ms /    63 runs   (    0.56 ms per token,  1792.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1936.63 ms /   372 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2399.42 ms /    62 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    4419.38 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.01 ms /   100 runs   (    0.57 ms per token,  1754.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4238.99 ms /   780 tokens (    5.43 ms per token,   184.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3941.70 ms /    99 runs   (   39.82 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    8327.73 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.39 ms /    73 runs   (    0.57 ms per token,  1763.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1942.85 ms /   376 tokens (    5.17 ms per token,   193.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2838.26 ms /    73 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    4878.84 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.48 ms /    69 runs   (    0.63 ms per token,  1587.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2960.39 ms /   554 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2677.38 ms /    68 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5748.82 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.87 ms /    52 runs   (    0.56 ms per token,  1801.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     932.94 ms /   184 tokens (    5.07 ms per token,   197.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1985.23 ms /    52 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    2985.07 ms /   236 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.82 ms /   256 runs   (    0.59 ms per token,  1697.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2073.20 ms /   400 tokens (    5.18 ms per token,   192.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9997.39 ms /   256 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12482.56 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.76 ms /   113 runs   (    0.54 ms per token,  1859.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2073.95 ms /   398 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
            "llama_print_timings:        eval time =    4368.66 ms /   112 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    6589.94 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1591.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2268.81 ms /   429 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =     236.73 ms /     6 runs   (   39.46 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    2523.32 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1865.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1912.63 ms /   364 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
            "llama_print_timings:        eval time =     230.42 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2157.16 ms /   370 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1826.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1856.27 ms /   359 tokens (    5.17 ms per token,   193.40 tokens per second)\n",
            "llama_print_timings:        eval time =     230.62 ms /     6 runs   (   38.44 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2100.42 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     6 runs   (    0.63 ms per token,  1588.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2502.56 ms /   479 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =     194.64 ms /     5 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2712.43 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.72 ms /   137 runs   (    0.62 ms per token,  1617.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3651.84 ms /   682 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5414.05 ms /   136 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    9286.50 ms /   818 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.74 ms /   256 runs   (    0.60 ms per token,  1665.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2026.95 ms /   386 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
            "llama_print_timings:        eval time =    9969.35 ms /   255 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12412.63 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1902.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.48 ms /   460 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =     230.64 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2658.24 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1839.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2239.79 ms /   430 tokens (    5.21 ms per token,   191.98 tokens per second)\n",
            "llama_print_timings:        eval time =     230.66 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2484.57 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.91 ms /   101 runs   (    0.60 ms per token,  1658.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1598.98 ms /   310 tokens (    5.16 ms per token,   193.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3871.85 ms /   100 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    5621.32 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1937.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2701.47 ms /   512 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =     196.14 ms /     5 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2917.07 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1850.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2588.43 ms /   496 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
            "llama_print_timings:        eval time =     235.52 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2838.91 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     112.28 ms /   184 runs   (    0.61 ms per token,  1638.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4938.20 ms /   912 tokens (    5.41 ms per token,   184.68 tokens per second)\n",
            "llama_print_timings:        eval time =    7413.76 ms /   183 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =   12655.95 ms /  1095 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1917.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.53 ms /   476 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =     230.91 ms /     6 runs   (   38.48 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2746.34 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.48 ms /    97 runs   (    0.59 ms per token,  1687.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4990.43 ms /   915 tokens (    5.45 ms per token,   183.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3884.23 ms /    96 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    9036.00 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.60 ms /   256 runs   (    0.58 ms per token,  1711.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.48 ms /   375 tokens (    5.17 ms per token,   193.35 tokens per second)\n",
            "llama_print_timings:        eval time =    9959.58 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12317.17 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.67 ms /    12 runs   (    0.56 ms per token,  1798.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1856.67 ms /   358 tokens (    5.19 ms per token,   192.82 tokens per second)\n",
            "llama_print_timings:        eval time =     423.09 ms /    11 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2299.15 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.06 ms /    11 runs   (    0.55 ms per token,  1816.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2541.69 ms /   482 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     388.34 ms /    10 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2950.36 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.24 ms /   256 runs   (    0.59 ms per token,  1692.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.81 ms /   432 tokens (    5.19 ms per token,   192.70 tokens per second)\n",
            "llama_print_timings:        eval time =    9964.21 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12610.40 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1892.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1860.65 ms /   360 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
            "llama_print_timings:        eval time =     270.30 ms /     7 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2144.79 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.11 ms /   101 runs   (    0.60 ms per token,  1680.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4352.89 ms /   803 tokens (    5.42 ms per token,   184.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3998.41 ms /   100 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    8509.00 ms /   903 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1758.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.34 ms /   389 tokens (    5.22 ms per token,   191.69 tokens per second)\n",
            "llama_print_timings:        eval time =     191.14 ms /     5 runs   (   38.23 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    2232.96 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.75 ms /    51 runs   (    0.54 ms per token,  1837.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.58 ms /   422 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1948.92 ms /    50 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4219.03 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.72 ms /    55 runs   (    0.65 ms per token,  1539.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2610.95 ms /   490 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2119.74 ms /    54 runs   (   39.25 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    4821.02 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.88 ms /    85 runs   (    0.54 ms per token,  1852.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2501.62 ms /   477 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3286.30 ms /    84 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5903.08 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.93 ms /   256 runs   (    0.61 ms per token,  1652.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.05 ms /   375 tokens (    5.18 ms per token,   193.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9940.69 ms /   255 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =   12285.05 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1844.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.54 ms /   442 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =     234.53 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2578.53 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.16 ms /    72 runs   (    0.61 ms per token,  1630.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3638.05 ms /   680 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2848.92 ms /    72 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    6605.82 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1682.61 ms /   323 tokens (    5.21 ms per token,   191.96 tokens per second)\n",
            "llama_print_timings:        eval time =     232.21 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    1927.87 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1813.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2284.86 ms /   434 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =     230.79 ms /     6 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2530.22 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.88 ms /    66 runs   (    0.59 ms per token,  1697.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2118.25 ms /   408 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2546.95 ms /    65 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4759.46 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.01 ms /    73 runs   (    0.60 ms per token,  1658.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1832.12 ms /   349 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2799.02 ms /    72 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    4741.28 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.61 ms /    58 runs   (    0.58 ms per token,  1725.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6407.23 ms /  1154 tokens (    5.55 ms per token,   180.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2343.58 ms /    57 runs   (   41.12 ms per token,    24.32 tokens per second)\n",
            "llama_print_timings:       total time =    8847.81 ms /  1211 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.17 ms /    95 runs   (    0.52 ms per token,  1932.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4204.50 ms /   776 tokens (    5.42 ms per token,   184.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3776.69 ms /    95 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    8115.04 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.35 ms /   432 tokens (    5.20 ms per token,   192.23 tokens per second)\n",
            "llama_print_timings:        eval time =     270.37 ms /     7 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2532.96 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1811.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1900.49 ms /   366 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
            "llama_print_timings:        eval time =     230.78 ms /     6 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2145.11 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1450.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1633.14 ms /   309 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =     234.78 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    1884.83 ms /   315 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.80 ms /   256 runs   (    0.54 ms per token,  1844.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1804.83 ms /   344 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10000.58 ms /   256 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12180.94 ms /   600 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Amcor plc_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.80 ms /   117 runs   (    0.55 ms per token,  1805.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2091.28 ms /   397 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4522.39 ms /   116 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    6772.49 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.77 ms /   105 runs   (    0.69 ms per token,  1442.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2066.16 ms /   394 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =    4055.66 ms /   104 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    6307.23 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.00 ms /   109 runs   (    0.56 ms per token,  1786.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1979.93 ms /   379 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4193.78 ms /   108 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    6321.64 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.99 ms /    55 runs   (    0.62 ms per token,  1617.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5324.38 ms /   971 tokens (    5.48 ms per token,   182.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2195.91 ms /    54 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    7619.36 ms /  1025 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.89 ms /    70 runs   (    0.56 ms per token,  1799.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.80 ms /   344 tokens (    5.14 ms per token,   194.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.76 ms /    70 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    4567.37 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.07 ms /    83 runs   (    0.59 ms per token,  1691.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2673.13 ms /   509 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3207.06 ms /    82 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    6007.78 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     123.57 ms /   228 runs   (    0.54 ms per token,  1845.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5288.36 ms /   963 tokens (    5.49 ms per token,   182.10 tokens per second)\n",
            "llama_print_timings:        eval time =    9229.12 ms /   227 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   14881.79 ms /  1190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     126.46 ms /   218 runs   (    0.58 ms per token,  1723.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3615.47 ms /   678 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =    8602.98 ms /   217 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =   12569.80 ms /   895 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.48 ms /     6 runs   (    0.58 ms per token,  1721.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5657.63 ms /  1032 tokens (    5.48 ms per token,   182.41 tokens per second)\n",
            "llama_print_timings:        eval time =     243.68 ms /     6 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    5924.41 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.41 ms /    56 runs   (    0.65 ms per token,  1538.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5352.78 ms /   980 tokens (    5.46 ms per token,   183.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2243.40 ms /    55 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    7700.10 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.66 ms /    97 runs   (    0.52 ms per token,  1914.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5751.44 ms /  1042 tokens (    5.52 ms per token,   181.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3901.69 ms /    96 runs   (   40.64 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    9789.79 ms /  1138 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1687.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5112.90 ms /   934 tokens (    5.47 ms per token,   182.68 tokens per second)\n",
            "llama_print_timings:        eval time =     200.09 ms /     5 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    5335.14 ms /   939 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.36 ms /   149 runs   (    0.60 ms per token,  1667.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5681.78 ms /  1035 tokens (    5.49 ms per token,   182.16 tokens per second)\n",
            "llama_print_timings:        eval time =    6045.46 ms /   148 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =   11977.48 ms /  1183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.36 ms /   109 runs   (    0.62 ms per token,  1618.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3325.00 ms /   624 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4256.30 ms /   108 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7758.39 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2590.86 ms /   493 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
            "llama_print_timings:        eval time =     234.51 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2841.76 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1772.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     271.51 ms /     7 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =     282.27 ms /     7 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.47 ms /   110 runs   (    0.63 ms per token,  1583.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3345.93 ms /   623 tokens (    5.37 ms per token,   186.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4294.40 ms /   109 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    7821.62 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     137.34 ms /   241 runs   (    0.57 ms per token,  1754.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4489.99 ms /   832 tokens (    5.40 ms per token,   185.30 tokens per second)\n",
            "llama_print_timings:        eval time =    9717.74 ms /   241 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =   14621.76 ms /  1073 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.86 ms /    61 runs   (    0.57 ms per token,  1750.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1821.39 ms /   352 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2320.38 ms /    60 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    4228.55 ms /   412 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.39 ms /    89 runs   (    0.62 ms per token,  1606.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3334.69 ms /   624 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3515.24 ms /    89 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7005.85 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.01 ms /   256 runs   (    0.61 ms per token,  1630.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2469.86 ms /   471 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =   10020.23 ms /   255 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12941.68 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.81 ms /    83 runs   (    0.59 ms per token,  1700.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4251.29 ms /   792 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3305.56 ms /    83 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7688.64 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.66 ms /    62 runs   (    0.74 ms per token,  1357.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1354.36 ms /   264 tokens (    5.13 ms per token,   194.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2402.89 ms /    62 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3867.34 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.76 ms /    71 runs   (    0.56 ms per token,  1785.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1914.61 ms /   366 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2717.66 ms /    70 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    4733.72 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.84 ms /    99 runs   (    0.56 ms per token,  1772.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2070.55 ms /   396 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3819.62 ms /    98 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6028.96 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1552.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2313.16 ms /   439 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =     235.45 ms /     6 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2566.88 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.21 ms /    92 runs   (    0.56 ms per token,  1796.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1870.48 ms /   354 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3523.62 ms /    91 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    5520.92 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.96 ms /   115 runs   (    0.64 ms per token,  1554.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3125.52 ms /   580 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =    4527.06 ms /   114 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7852.71 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.98 ms /    84 runs   (    0.61 ms per token,  1647.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     131.41 ms /    21 tokens (    6.26 ms per token,   159.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3297.47 ms /    83 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    3567.39 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.26 ms /   105 runs   (    0.59 ms per token,  1686.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4521.60 ms /   838 tokens (    5.40 ms per token,   185.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4166.43 ms /   104 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    8858.07 ms /   942 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.20 ms /   122 runs   (    0.56 ms per token,  1788.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3511.43 ms /   650 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4774.74 ms /   121 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    8473.20 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.66 ms /    68 runs   (    0.70 ms per token,  1426.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4433.23 ms /   819 tokens (    5.41 ms per token,   184.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2716.75 ms /    67 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    7283.24 ms /   886 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1786.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2732.79 ms /   517 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =     194.76 ms /     5 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2943.41 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.39 ms /    11 runs   (    0.58 ms per token,  1721.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.90 ms /   458 tokens (    5.27 ms per token,   189.81 tokens per second)\n",
            "llama_print_timings:        eval time =     389.13 ms /    10 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2823.24 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.23 ms /    96 runs   (    0.61 ms per token,  1648.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3473.09 ms /   652 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3772.50 ms /    95 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7403.29 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.50 ms /    65 runs   (    0.56 ms per token,  1781.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1307.72 ms /   248 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2480.08 ms /    64 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3877.35 ms /   312 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.15 ms /    86 runs   (    0.55 ms per token,  1823.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3987.41 ms /   744 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3375.74 ms /    85 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7493.64 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.04 ms /   147 runs   (    0.54 ms per token,  1859.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3311.54 ms /   611 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =    5751.66 ms /   146 runs   (   39.39 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    9283.26 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.58 ms /   230 runs   (    0.63 ms per token,  1579.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.77 ms /   461 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =    9009.44 ms /   229 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   11829.97 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     6 runs   (    0.64 ms per token,  1554.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2558.03 ms /   483 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =     195.23 ms /     5 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2770.03 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     6 runs   (    0.62 ms per token,  1602.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4192.88 ms /   774 tokens (    5.42 ms per token,   184.60 tokens per second)\n",
            "llama_print_timings:        eval time =     199.07 ms /     5 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    4414.25 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.59 ms /    86 runs   (    0.58 ms per token,  1734.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3245.16 ms /   603 tokens (    5.38 ms per token,   185.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3347.47 ms /    85 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6725.07 ms /   688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.77 ms /    90 runs   (    0.56 ms per token,  1772.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.81 ms /   438 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3484.56 ms /    89 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5903.51 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.36 ms /    65 runs   (    0.65 ms per token,  1534.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1284.45 ms /   247 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2479.20 ms /    64 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3868.93 ms /   311 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.03 ms /    72 runs   (    0.54 ms per token,  1844.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2809.64 ms /   530 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2778.33 ms /    71 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5689.07 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.67 ms /    92 runs   (    0.66 ms per token,  1516.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3477.34 ms /   651 tokens (    5.34 ms per token,   187.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3631.91 ms /    91 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    7274.06 ms /   742 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1912.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2684.30 ms /   511 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =     237.30 ms /     6 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    2937.76 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1787.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.30 ms /   517 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     234.76 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2977.47 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     165.40 ms /   256 runs   (    0.65 ms per token,  1547.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1569.51 ms /   301 tokens (    5.21 ms per token,   191.78 tokens per second)\n",
            "llama_print_timings:        eval time =    9938.84 ms /   255 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =   11962.32 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.50 ms /   102 runs   (    0.59 ms per token,  1685.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.13 ms /   472 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3993.51 ms /   102 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6614.16 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.33 ms /    66 runs   (    0.72 ms per token,  1394.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1628.50 ms /   307 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2527.72 ms /    65 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4278.88 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.75 ms /    86 runs   (    0.54 ms per token,  1839.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3441.12 ms /   648 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3392.22 ms /    86 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6960.72 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.44 ms /     7 runs   (    0.63 ms per token,  1576.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1774.18 ms /   340 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =     234.52 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2023.61 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.42 ms /    12 runs   (    0.70 ms per token,  1426.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2409.33 ms /   455 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =     435.71 ms /    11 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    2873.98 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.41 ms /    93 runs   (    0.55 ms per token,  1809.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1782.11 ms /   344 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3604.18 ms /    93 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    5512.36 ms /   437 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.89 ms /    88 runs   (    0.64 ms per token,  1574.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2117.87 ms /   406 tokens (    5.22 ms per token,   191.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3395.95 ms /    87 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5651.02 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.90 ms /    95 runs   (    0.62 ms per token,  1613.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2538.30 ms /   479 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
            "llama_print_timings:        eval time =    3685.15 ms /    94 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6377.17 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.23 ms /     7 runs   (    0.60 ms per token,  1654.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2421.71 ms /   464 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =     234.60 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2672.79 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.14 ms /   112 runs   (    0.64 ms per token,  1552.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2165.95 ms /   415 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4339.86 ms /   111 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6691.63 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1820.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2387.99 ms /   456 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =     270.36 ms /     7 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2674.40 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.78 ms /   210 runs   (    0.65 ms per token,  1546.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.00 ms /   416 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =    8243.42 ms /   210 runs   (   39.25 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   10772.64 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     101.37 ms /   179 runs   (    0.57 ms per token,  1765.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.50 ms /   429 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
            "llama_print_timings:        eval time =    6944.61 ms /   178 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    9499.33 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.47 ms /     7 runs   (    0.78 ms per token,  1279.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.49 ms /   387 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     237.02 ms /     6 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    2285.26 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.86 ms /   256 runs   (    0.61 ms per token,  1632.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1376.50 ms /   264 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =    9889.96 ms /   255 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =   11700.02 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.98 ms /    90 runs   (    0.73 ms per token,  1363.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1903.04 ms /   368 tokens (    5.17 ms per token,   193.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3490.64 ms /    90 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    5558.82 ms /   458 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Amcor plc_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Square, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1924.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2504.15 ms /   468 tokens (    5.35 ms per token,   186.89 tokens per second)\n",
            "llama_print_timings:        eval time =     231.93 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2751.17 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.44 ms /     6 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3431.56 ms /   644 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =     195.70 ms /     5 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3644.09 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.23 ms /   131 runs   (    0.57 ms per token,  1764.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8242.52 ms /  1446 tokens (    5.70 ms per token,   175.43 tokens per second)\n",
            "llama_print_timings:        eval time =    5457.02 ms /   130 runs   (   41.98 ms per token,    23.82 tokens per second)\n",
            "llama_print_timings:       total time =   13943.46 ms /  1576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.07 ms /    70 runs   (    0.76 ms per token,  1318.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2039.23 ms /   387 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2695.37 ms /    69 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4871.00 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.27 ms /    54 runs   (    0.54 ms per token,  1844.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3389.44 ms /   640 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2076.74 ms /    53 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5544.33 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.11 ms /    59 runs   (    0.58 ms per token,  1729.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.53 ms /   415 tokens (    5.20 ms per token,   192.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2256.44 ms /    58 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    4502.78 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.85 ms /     7 runs   (    1.12 ms per token,   891.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1977.93 ms /   374 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =     237.69 ms /     6 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    2240.89 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2447.93 ms /   461 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
            "llama_print_timings:        eval time =     231.27 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2696.44 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.04 ms /    62 runs   (    0.66 ms per token,  1510.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8141.38 ms /  1437 tokens (    5.67 ms per token,   176.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2572.12 ms /    61 runs   (   42.17 ms per token,    23.72 tokens per second)\n",
            "llama_print_timings:       total time =   10846.66 ms /  1498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.19 ms /   256 runs   (    0.53 ms per token,  1879.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2048.19 ms /   390 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9948.92 ms /   255 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12383.95 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.17 ms /    72 runs   (    0.57 ms per token,  1749.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3347.57 ms /   622 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2787.72 ms /    71 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6242.55 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.89 ms /    94 runs   (    0.57 ms per token,  1744.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =      86.75 ms /    16 tokens (    5.42 ms per token,   184.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3698.21 ms /    94 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3922.33 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.61 ms /    65 runs   (    0.69 ms per token,  1457.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2509.17 ms /   476 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2518.24 ms /    64 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5151.55 ms /   540 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.51 ms /    64 runs   (    0.57 ms per token,  1753.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2182.24 ms /   416 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2498.34 ms /    64 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4770.27 ms /   480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.25 ms /    88 runs   (    0.57 ms per token,  1751.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2340.97 ms /   448 tokens (    5.23 ms per token,   191.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3442.31 ms /    88 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5905.76 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.89 ms /   256 runs   (    0.59 ms per token,  1685.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2006.40 ms /   384 tokens (    5.23 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9990.37 ms /   256 runs   (   39.02 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12437.03 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.35 ms /    75 runs   (    0.82 ms per token,  1222.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2422.47 ms /   458 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2901.73 ms /    74 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5468.77 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.44 ms /    99 runs   (    0.53 ms per token,  1887.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5843.02 ms /  1058 tokens (    5.52 ms per token,   181.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3986.18 ms /    98 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    9973.56 ms /  1156 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.08 ms /    75 runs   (    0.56 ms per token,  1782.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4890.19 ms /   896 tokens (    5.46 ms per token,   183.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2977.50 ms /    74 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7985.83 ms /   970 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.10 ms /    94 runs   (    0.58 ms per token,  1737.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.61 ms /   414 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3625.81 ms /    93 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5919.35 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1538.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2498.39 ms /   470 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
            "llama_print_timings:        eval time =     235.80 ms /     6 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2754.47 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.40 ms /    70 runs   (    0.58 ms per token,  1732.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2431.43 ms /   462 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2702.59 ms /    69 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5235.43 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     159.66 ms /   256 runs   (    0.62 ms per token,  1603.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1989.09 ms /   383 tokens (    5.19 ms per token,   192.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9964.57 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12400.29 ms /   638 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.27 ms /    70 runs   (    0.56 ms per token,  1782.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.85 ms /   470 tokens (    5.24 ms per token,   190.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2698.06 ms /    69 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5258.95 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      11.09 ms /    14 runs   (    0.79 ms per token,  1262.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     975.19 ms /   192 tokens (    5.08 ms per token,   196.88 tokens per second)\n",
            "llama_print_timings:        eval time =     539.92 ms /    14 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    1542.44 ms /   206 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.72 ms /    65 runs   (    0.63 ms per token,  1596.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2489.35 ms /   468 tokens (    5.32 ms per token,   188.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2502.02 ms /    64 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5101.29 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1807.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     126.25 ms /    21 tokens (    6.01 ms per token,   166.34 tokens per second)\n",
            "llama_print_timings:        eval time =     232.52 ms /     6 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =     370.36 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1781.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.35 ms /   430 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2498.04 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.27 ms /    12 runs   (    0.52 ms per token,  1915.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.16 ms /   471 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =     427.14 ms /    11 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2910.32 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.96 ms /   136 runs   (    0.64 ms per token,  1563.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1516.43 ms /   290 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
            "llama_print_timings:        eval time =    5218.08 ms /   135 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    6966.31 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.50 ms /   132 runs   (    0.58 ms per token,  1725.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3440.83 ms /   648 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =    5195.89 ms /   132 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    8832.30 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.61 ms /    75 runs   (    0.63 ms per token,  1575.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2452.70 ms /   464 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2949.89 ms /    75 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5541.86 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.23 ms /   100 runs   (    0.55 ms per token,  1810.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2078.38 ms /   400 tokens (    5.20 ms per token,   192.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3869.65 ms /    99 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6087.06 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.06 ms /   139 runs   (    0.60 ms per token,  1653.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2948.23 ms /   557 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
            "llama_print_timings:        eval time =    5428.03 ms /   138 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    8598.12 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.24 ms /    91 runs   (    0.54 ms per token,  1848.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     972.62 ms /   190 tokens (    5.12 ms per token,   195.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3438.83 ms /    90 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    4529.79 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.54 ms /   458 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
            "llama_print_timings:        eval time =     231.40 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2661.48 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      91.49 ms /   154 runs   (    0.59 ms per token,  1683.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2315.71 ms /   434 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
            "llama_print_timings:        eval time =    5983.17 ms /   153 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    8531.13 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1765.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1729.84 ms /   336 tokens (    5.15 ms per token,   194.24 tokens per second)\n",
            "llama_print_timings:        eval time =     196.65 ms /     5 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    1939.65 ms /   341 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.66 ms /   127 runs   (    0.55 ms per token,  1823.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4496.50 ms /   832 tokens (    5.40 ms per token,   185.03 tokens per second)\n",
            "llama_print_timings:        eval time =    5056.46 ms /   126 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    9750.00 ms /   958 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.26 ms /    89 runs   (    0.54 ms per token,  1844.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2414.35 ms /   458 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3451.76 ms /    88 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5984.43 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.72 ms /     7 runs   (    0.67 ms per token,  1483.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2314.70 ms /   440 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
            "llama_print_timings:        eval time =     280.00 ms /     7 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    2613.41 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.22 ms /    12 runs   (    0.60 ms per token,  1662.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2431.61 ms /   463 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =     426.86 ms /    11 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2884.38 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.23 ms /    72 runs   (    0.56 ms per token,  1789.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1266.36 ms /   246 tokens (    5.15 ms per token,   194.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2721.33 ms /    71 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    4083.69 ms /   317 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.01 ms /   103 runs   (    0.61 ms per token,  1634.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2332.59 ms /   447 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4000.33 ms /   102 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6498.67 ms /   549 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.89 ms /    14 runs   (    0.56 ms per token,  1774.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     986.53 ms /   186 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =     494.84 ms /    13 runs   (   38.06 ms per token,    26.27 tokens per second)\n",
            "llama_print_timings:       total time =    1503.85 ms /   199 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.76 ms /    58 runs   (    0.53 ms per token,  1885.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     849.30 ms /   164 tokens (    5.18 ms per token,   193.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2171.58 ms /    57 runs   (   38.10 ms per token,    26.25 tokens per second)\n",
            "llama_print_timings:       total time =    3095.72 ms /   221 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.56 ms /    77 runs   (    0.53 ms per token,  1898.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2980.87 ms /   562 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2976.66 ms /    76 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6062.46 ms /   638 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.60 ms /     7 runs   (    0.66 ms per token,  1522.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2486.46 ms /   468 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =     236.60 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    2741.78 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     137.17 ms /   256 runs   (    0.54 ms per token,  1866.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2827.30 ms /   536 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =   10034.55 ms /   255 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   13259.30 ms /   791 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.43 ms /    55 runs   (    0.55 ms per token,  1807.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2263.22 ms /   429 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2106.61 ms /    54 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4453.49 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.67 ms /    64 runs   (    0.54 ms per token,  1846.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.40 ms /   446 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2467.10 ms /    63 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4882.68 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.61 ms /    87 runs   (    0.71 ms per token,  1412.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2418.57 ms /   459 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3376.25 ms /    86 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5947.62 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.75 ms /    12 runs   (    0.56 ms per token,  1776.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2414.08 ms /   464 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =     468.24 ms /    12 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    2903.35 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.76 ms /    12 runs   (    0.56 ms per token,  1775.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.99 ms /   459 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
            "llama_print_timings:        eval time =     430.65 ms /    11 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2865.80 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.55 ms /    96 runs   (    0.63 ms per token,  1585.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4484.65 ms /   828 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3821.76 ms /    95 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8469.70 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.80 ms /    72 runs   (    0.55 ms per token,  1809.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3433.90 ms /   645 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2783.13 ms /    71 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6319.38 ms /   716 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.02 ms /   256 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2640.60 ms /   504 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.30 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13046.27 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.46 ms /   117 runs   (    0.65 ms per token,  1530.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2636.31 ms /   502 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4565.55 ms /   116 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    7399.36 ms /   618 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.74 ms /   468 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =     233.20 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2707.98 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.44 ms /    71 runs   (    0.54 ms per token,  1846.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.47 ms /   389 tokens (    5.21 ms per token,   191.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2712.07 ms /    70 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    4835.52 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.29 ms /    76 runs   (    0.58 ms per token,  1715.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3009.41 ms /   566 tokens (    5.32 ms per token,   188.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2944.47 ms /    75 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6069.85 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.77 ms /     9 runs   (    0.53 ms per token,  1887.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1013.39 ms /   194 tokens (    5.22 ms per token,   191.44 tokens per second)\n",
            "llama_print_timings:        eval time =     302.05 ms /     8 runs   (   37.76 ms per token,    26.49 tokens per second)\n",
            "llama_print_timings:       total time =    1328.89 ms /   202 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.52 ms /   439 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
            "llama_print_timings:        eval time =     230.65 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2532.46 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.56 ms /    96 runs   (    0.60 ms per token,  1667.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.64 ms /   384 tokens (    5.16 ms per token,   193.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3699.94 ms /    95 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5827.72 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     109.17 ms /   202 runs   (    0.54 ms per token,  1850.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2182.27 ms /   412 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
            "llama_print_timings:        eval time =    7860.00 ms /   201 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   10330.11 ms /   613 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Square, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_3M CO_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.86 ms /   256 runs   (    0.60 ms per token,  1663.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3053.86 ms /   570 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =   10055.54 ms /   255 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13544.26 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     134.00 ms /   224 runs   (    0.60 ms per token,  1671.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2715.14 ms /   515 tokens (    5.27 ms per token,   189.68 tokens per second)\n",
            "llama_print_timings:        eval time =    8766.23 ms /   223 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   11849.35 ms /   738 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.57 ms /    79 runs   (    0.55 ms per token,  1813.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2907.57 ms /   546 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3057.92 ms /    78 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6078.63 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.75 ms /    72 runs   (    0.57 ms per token,  1766.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2192.07 ms /   419 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2765.57 ms /    71 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5062.52 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.52 ms /    64 runs   (    0.57 ms per token,  1752.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2796.53 ms /   525 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2475.05 ms /    63 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5369.36 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.04 ms /    57 runs   (    0.54 ms per token,  1836.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.80 ms /   397 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2166.28 ms /    56 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    4312.34 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      99.05 ms /   160 runs   (    0.62 ms per token,  1615.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2237.94 ms /   426 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    6207.99 ms /   159 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    8704.46 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1837.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2555.80 ms /   487 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =     193.23 ms /     5 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2764.62 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.05 ms /   256 runs   (    0.60 ms per token,  1661.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2765.15 ms /   526 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =   10049.73 ms /   255 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13239.82 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.62 ms /    70 runs   (    0.71 ms per token,  1410.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5314.71 ms /   976 tokens (    5.45 ms per token,   183.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2851.25 ms /    70 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    8304.92 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.66 ms /    85 runs   (    0.55 ms per token,  1821.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3758.28 ms /   701 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3310.85 ms /    84 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7195.68 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.91 ms /   104 runs   (    0.60 ms per token,  1653.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4857.17 ms /   890 tokens (    5.46 ms per token,   183.23 tokens per second)\n",
            "llama_print_timings:        eval time =    4165.40 ms /   103 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    9197.74 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.83 ms /   105 runs   (    0.56 ms per token,  1784.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2807.96 ms /   532 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =    4082.08 ms /   104 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7037.95 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     6 runs   (    0.67 ms per token,  1491.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3058.69 ms /   576 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
            "llama_print_timings:        eval time =     236.50 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3314.41 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.28 ms /   256 runs   (    0.53 ms per token,  1878.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2129.26 ms /   408 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
            "llama_print_timings:        eval time =   10021.64 ms /   256 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12540.91 ms /   664 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.87 ms /   256 runs   (    0.56 ms per token,  1779.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2927.43 ms /   552 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10038.87 ms /   255 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   13374.81 ms /   807 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.56 ms /    73 runs   (    0.54 ms per token,  1845.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2613.02 ms /   492 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2813.39 ms /    72 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5533.89 ms /   564 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.03 ms /   416 tokens (    5.19 ms per token,   192.77 tokens per second)\n",
            "llama_print_timings:        eval time =     231.58 ms /     6 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2404.16 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.10 ms /    86 runs   (    0.65 ms per token,  1533.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.98 ms /   520 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3337.63 ms /    85 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6204.62 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.04 ms /     6 runs   (    0.51 ms per token,  1971.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2611.41 ms /   496 tokens (    5.26 ms per token,   189.94 tokens per second)\n",
            "llama_print_timings:        eval time =     234.01 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2864.16 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.07 ms /    63 runs   (    0.54 ms per token,  1849.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4890.23 ms /   899 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2485.50 ms /    62 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    7469.45 ms /   961 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.83 ms /    78 runs   (    0.66 ms per token,  1504.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2172.92 ms /   412 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2995.81 ms /    77 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    5296.53 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.81 ms /   256 runs   (    0.59 ms per token,  1697.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1557.25 ms /   300 tokens (    5.19 ms per token,   192.65 tokens per second)\n",
            "llama_print_timings:        eval time =    9914.61 ms /   255 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =   11896.95 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.82 ms /    93 runs   (    0.55 ms per token,  1830.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2825.35 ms /   536 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =    3610.70 ms /    92 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6566.30 ms /   628 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.14 ms /    54 runs   (    0.52 ms per token,  1919.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1772.80 ms /   344 tokens (    5.15 ms per token,   194.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2086.80 ms /    54 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    3931.41 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.70 ms /    70 runs   (    0.60 ms per token,  1678.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2489.82 ms /   470 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.36 ms /    69 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5305.99 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.83 ms /   128 runs   (    0.55 ms per token,  1807.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.35 ms /   311 tokens (    5.15 ms per token,   194.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4913.03 ms /   127 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    6689.18 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.09 ms /    56 runs   (    0.68 ms per token,  1470.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2252.36 ms /   427 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2137.91 ms /    55 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    4490.12 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.41 ms /    95 runs   (    0.54 ms per token,  1848.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.25 ms /   468 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3673.92 ms /    94 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    6271.25 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.56 ms /    72 runs   (    0.54 ms per token,  1867.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1186.04 ms /   229 tokens (    5.18 ms per token,   193.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2715.11 ms /    71 runs   (   38.24 ms per token,    26.15 tokens per second)\n",
            "llama_print_timings:       total time =    3993.77 ms /   300 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.86 ms /   256 runs   (    0.55 ms per token,  1804.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2363.19 ms /   443 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =    9952.08 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12703.86 ms /   698 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.68 ms /    68 runs   (    0.54 ms per token,  1853.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4283.83 ms /   787 tokens (    5.44 ms per token,   183.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2661.28 ms /    67 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7045.39 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.16 ms /    82 runs   (    0.59 ms per token,  1702.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2067.07 ms /   397 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3160.09 ms /    81 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5345.61 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.99 ms /   116 runs   (    0.65 ms per token,  1546.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1475.43 ms /   288 tokens (    5.12 ms per token,   195.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4501.26 ms /   116 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    6166.75 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.29 ms /   256 runs   (    0.59 ms per token,  1681.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.49 ms /   344 tokens (    5.14 ms per token,   194.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9990.19 ms /   256 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12188.72 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1786.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.97 ms /   388 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =     190.61 ms /     5 runs   (   38.12 ms per token,    26.23 tokens per second)\n",
            "llama_print_timings:       total time =    2234.16 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     6 runs   (    0.60 ms per token,  1655.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2111.42 ms /   404 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =     192.71 ms /     5 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2317.37 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1589.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2028.88 ms /   392 tokens (    5.18 ms per token,   193.21 tokens per second)\n",
            "llama_print_timings:        eval time =     229.96 ms /     6 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2274.00 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.26 ms /     9 runs   (    0.58 ms per token,  1710.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1105.12 ms /   216 tokens (    5.12 ms per token,   195.45 tokens per second)\n",
            "llama_print_timings:        eval time =     341.23 ms /     9 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
            "llama_print_timings:       total time =    1462.44 ms /   225 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     6 runs   (    0.66 ms per token,  1518.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2082.95 ms /   398 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
            "llama_print_timings:        eval time =     192.07 ms /     5 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2295.60 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.25 ms /    10 runs   (    0.53 ms per token,  1904.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2803.22 ms /   528 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =     394.85 ms /    10 runs   (   39.49 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    3219.32 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.89 ms /     9 runs   (    0.54 ms per token,  1839.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1016.70 ms /   197 tokens (    5.16 ms per token,   193.76 tokens per second)\n",
            "llama_print_timings:        eval time =     302.54 ms /     8 runs   (   37.82 ms per token,    26.44 tokens per second)\n",
            "llama_print_timings:       total time =    1334.76 ms /   205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.54 ms /    55 runs   (    0.56 ms per token,  1800.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2070.27 ms /   399 tokens (    5.19 ms per token,   192.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2095.40 ms /    54 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4240.81 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1873.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.43 ms /   469 tokens (    5.25 ms per token,   190.54 tokens per second)\n",
            "llama_print_timings:        eval time =     232.46 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2708.56 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.34 ms /    11 runs   (    0.67 ms per token,  1498.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2121.35 ms /   405 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =     386.61 ms /    10 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2532.07 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.42 ms /   108 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1533.50 ms /   290 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4125.02 ms /   107 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    5812.34 ms /   397 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.10 ms /    68 runs   (    0.55 ms per token,  1832.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2850.39 ms /   542 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2628.31 ms /    67 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5574.07 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.44 ms /    70 runs   (    0.72 ms per token,  1387.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1363.35 ms /   264 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2719.46 ms /    70 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4215.24 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.06 ms /   140 runs   (    0.55 ms per token,  1816.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4433.62 ms /   823 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
            "llama_print_timings:        eval time =    5552.85 ms /   139 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =   10191.16 ms /   962 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.49 ms /    12 runs   (    0.71 ms per token,  1412.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2890.35 ms /   542 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
            "llama_print_timings:        eval time =     431.45 ms /    11 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3351.07 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1815.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1694.37 ms /   326 tokens (    5.20 ms per token,   192.40 tokens per second)\n",
            "llama_print_timings:        eval time =     193.99 ms /     5 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    1901.31 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1753.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1770.02 ms /   341 tokens (    5.19 ms per token,   192.65 tokens per second)\n",
            "llama_print_timings:        eval time =     196.22 ms /     5 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    1978.14 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.16 ms /    51 runs   (    0.53 ms per token,  1877.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.90 ms /   375 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1935.26 ms /    50 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3945.81 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.97 ms /   256 runs   (    0.61 ms per token,  1641.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1555.68 ms /   302 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9921.09 ms /   255 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =   11890.34 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1781.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.03 ms /   448 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =     268.10 ms /     7 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2612.67 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.19 ms /    12 runs   (    0.68 ms per token,  1465.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1906.56 ms /   367 tokens (    5.19 ms per token,   192.49 tokens per second)\n",
            "llama_print_timings:        eval time =     430.50 ms /    11 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2363.16 ms /   378 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.46 ms /   142 runs   (    0.54 ms per token,  1857.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5428.75 ms /   992 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    5714.28 ms /   141 runs   (   40.53 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =   11348.62 ms /  1133 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.67 ms /    83 runs   (    0.61 ms per token,  1638.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2350.06 ms /   448 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3195.41 ms /    82 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    5676.55 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.02 ms /   256 runs   (    0.61 ms per token,  1630.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2283.16 ms /   438 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
            "llama_print_timings:        eval time =    9993.88 ms /   255 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   12709.32 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.42 ms /   256 runs   (    0.61 ms per token,  1647.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1634.19 ms /   307 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =   10008.36 ms /   255 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12070.50 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.78 ms /    67 runs   (    0.55 ms per token,  1821.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2118.77 ms /   407 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2555.06 ms /    66 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    4762.71 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2108.23 ms /   403 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =     232.60 ms /     6 runs   (   38.77 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2355.31 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.08 ms /    90 runs   (    0.60 ms per token,  1664.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4393.47 ms /   811 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3564.55 ms /    89 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    8103.62 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.64 ms /    68 runs   (    0.54 ms per token,  1856.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2500.33 ms /   480 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
            "llama_print_timings:        eval time =    2621.53 ms /    67 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5212.09 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1854.52 ms /   355 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
            "llama_print_timings:        eval time =     232.33 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2100.21 ms /   361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.11 ms /   113 runs   (    0.59 ms per token,  1709.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3188.54 ms /   599 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4405.70 ms /   112 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7760.39 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1858.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2409.70 ms /   458 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =     232.05 ms /     6 runs   (   38.68 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2656.59 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.86 ms /   151 runs   (    0.63 ms per token,  1591.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2199.08 ms /   424 tokens (    5.19 ms per token,   192.81 tokens per second)\n",
            "llama_print_timings:        eval time =    5857.14 ms /   150 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    8315.53 ms /   574 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_3M CO_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.80 ms /    71 runs   (    0.52 ms per token,  1929.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3373.92 ms /   631 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2760.67 ms /    70 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6228.76 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.77 ms /    81 runs   (    0.55 ms per token,  1809.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3409.00 ms /   640 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3201.32 ms /    81 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6729.58 ms /   721 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.08 ms /   101 runs   (    0.56 ms per token,  1800.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1980.18 ms /   382 tokens (    5.18 ms per token,   192.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3879.54 ms /   100 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    5993.97 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.84 ms /    72 runs   (    0.55 ms per token,  1807.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5626.58 ms /  1021 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2881.07 ms /    71 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    8618.57 ms /  1092 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1890.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.48 ms /   383 tokens (    5.18 ms per token,   193.19 tokens per second)\n",
            "llama_print_timings:        eval time =     232.85 ms /     6 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2228.68 ms /   389 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.64 ms /    53 runs   (    0.56 ms per token,  1788.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.67 ms /   440 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2028.86 ms /    52 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4390.72 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     6 runs   (    0.68 ms per token,  1467.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2048.65 ms /   386 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =     192.94 ms /     5 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2257.34 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.61 ms /    77 runs   (    0.57 ms per token,  1765.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2083.24 ms /   395 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2949.69 ms /    76 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    5137.95 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2456.88 ms /   470 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =     233.58 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2705.04 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1886.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2588.78 ms /   496 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =     232.28 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2835.78 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.96 ms /    81 runs   (    0.53 ms per token,  1885.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5826.59 ms /  1050 tokens (    5.55 ms per token,   180.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3248.67 ms /    80 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    9191.22 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      96.75 ms /   145 runs   (    0.67 ms per token,  1498.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3386.59 ms /   635 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =    5709.87 ms /   144 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    9338.55 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.10 ms /    97 runs   (    0.56 ms per token,  1792.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4982.40 ms /   917 tokens (    5.43 ms per token,   184.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3864.59 ms /    96 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8990.02 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.77 ms /   104 runs   (    0.54 ms per token,  1864.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4977.72 ms /   909 tokens (    5.48 ms per token,   182.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4146.19 ms /   103 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    9270.76 ms /  1012 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.86 ms /   256 runs   (    0.57 ms per token,  1767.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2856.37 ms /   544 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
            "llama_print_timings:        eval time =   10080.61 ms /   256 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   13338.26 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.82 ms /    50 runs   (    0.62 ms per token,  1622.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6246.99 ms /  1127 tokens (    5.54 ms per token,   180.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2011.38 ms /    49 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    8345.48 ms /  1176 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.92 ms /   107 runs   (    0.56 ms per token,  1785.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1940.89 ms /   370 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4122.08 ms /   106 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    6206.66 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.91 ms /    14 runs   (    0.57 ms per token,  1769.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1767.28 ms /   338 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =     504.74 ms /    13 runs   (   38.83 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2293.83 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.58 ms /    53 runs   (    0.52 ms per token,  1921.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5893.57 ms /  1058 tokens (    5.57 ms per token,   179.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2114.38 ms /    52 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    8091.46 ms /  1110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.58 ms /   163 runs   (    0.59 ms per token,  1705.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3613.75 ms /   680 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    6490.98 ms /   163 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =   10366.82 ms /   843 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.72 ms /   256 runs   (    0.59 ms per token,  1687.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4335.72 ms /   807 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
            "llama_print_timings:        eval time =   10269.42 ms /   255 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =   15026.29 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.80 ms /   256 runs   (    0.60 ms per token,  1664.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1812.27 ms /   352 tokens (    5.15 ms per token,   194.23 tokens per second)\n",
            "llama_print_timings:        eval time =    9951.98 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12173.44 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.14 ms /   256 runs   (    0.57 ms per token,  1751.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.77 ms /   416 tokens (    5.19 ms per token,   192.79 tokens per second)\n",
            "llama_print_timings:        eval time =   10001.34 ms /   255 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12569.79 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.62 ms /   108 runs   (    0.59 ms per token,  1697.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5548.44 ms /  1014 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
            "llama_print_timings:        eval time =    4346.46 ms /   107 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =   10068.37 ms /  1121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.33 ms /    78 runs   (    0.63 ms per token,  1581.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     187.83 ms /    27 tokens (    6.96 ms per token,   143.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3144.93 ms /    77 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    3460.25 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.33 ms /    82 runs   (    0.54 ms per token,  1849.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.85 ms /   462 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3163.68 ms /    81 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5686.05 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.43 ms /    12 runs   (    0.54 ms per token,  1866.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.34 ms /   422 tokens (    5.21 ms per token,   191.96 tokens per second)\n",
            "llama_print_timings:        eval time =     424.90 ms /    11 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2643.42 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.37 ms /    83 runs   (    0.59 ms per token,  1681.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2620.16 ms /   495 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3206.84 ms /    82 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5951.41 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.58 ms /   256 runs   (    0.60 ms per token,  1677.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2023.96 ms /   389 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =    9975.68 ms /   255 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12417.14 ms /   644 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.57 ms /   391 tokens (    5.19 ms per token,   192.84 tokens per second)\n",
            "llama_print_timings:        eval time =     193.56 ms /     5 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2234.21 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1870.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.50 ms /   453 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =     233.81 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2617.94 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1730.31 ms /   336 tokens (    5.15 ms per token,   194.19 tokens per second)\n",
            "llama_print_timings:        eval time =     233.89 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    1978.37 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.81 ms /    77 runs   (    0.69 ms per token,  1458.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3177.85 ms /   595 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3000.13 ms /    76 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6306.26 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1850.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1812.63 ms /   352 tokens (    5.15 ms per token,   194.19 tokens per second)\n",
            "llama_print_timings:        eval time =     232.47 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2057.42 ms /   358 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.00 ms /    69 runs   (    0.54 ms per token,  1864.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3341.44 ms /   632 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2671.58 ms /    68 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6108.68 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.53 ms /    62 runs   (    0.62 ms per token,  1609.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2747.90 ms /   516 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2399.92 ms /    61 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5251.26 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1816.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3248.28 ms /   612 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =     193.64 ms /     5 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3457.34 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.33 ms /     9 runs   (    0.59 ms per token,  1687.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1387.71 ms /   266 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =     307.93 ms /     8 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    1711.51 ms /   274 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1904.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.21 ms /   392 tokens (    5.18 ms per token,   193.18 tokens per second)\n",
            "llama_print_timings:        eval time =     231.29 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2274.17 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     6 runs   (    0.69 ms per token,  1454.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2075.08 ms /   395 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =     192.66 ms /     5 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2284.02 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.51 ms /    62 runs   (    0.52 ms per token,  1907.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2487.14 ms /   471 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2382.97 ms /    61 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4953.25 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.96 ms /   256 runs   (    0.59 ms per token,  1695.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2110.53 ms /   403 tokens (    5.24 ms per token,   190.95 tokens per second)\n",
            "llama_print_timings:        eval time =    9978.58 ms /   255 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12508.24 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1768.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.47 ms /   428 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =     229.85 ms /     6 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2487.51 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.73 ms /    83 runs   (    0.56 ms per token,  1776.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1935.19 ms /   373 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3177.45 ms /    82 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    5224.47 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.94 ms /    80 runs   (    0.56 ms per token,  1780.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3145.40 ms /   591 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3110.58 ms /    79 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6373.57 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.61 ms /    73 runs   (    0.54 ms per token,  1842.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.85 ms /   415 tokens (    5.19 ms per token,   192.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2809.06 ms /    72 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5059.47 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.52 ms /    62 runs   (    0.67 ms per token,  1493.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3129.81 ms /   592 tokens (    5.29 ms per token,   189.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2424.24 ms /    61 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    5663.01 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.47 ms /    69 runs   (    0.53 ms per token,  1892.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5739.01 ms /  1045 tokens (    5.49 ms per token,   182.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2763.80 ms /    68 runs   (   40.64 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8608.36 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.13 ms /    89 runs   (    0.61 ms per token,  1644.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3540.97 ms /   662 tokens (    5.35 ms per token,   186.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3484.90 ms /    88 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7166.33 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.93 ms /    74 runs   (    0.55 ms per token,  1807.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3299.73 ms /   622 tokens (    5.31 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2864.19 ms /    73 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6265.23 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     6 runs   (    0.71 ms per token,  1404.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.61 ms /   430 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =     193.85 ms /     5 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2459.06 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.95 ms /     9 runs   (    0.55 ms per token,  1817.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2537.64 ms /   477 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
            "llama_print_timings:        eval time =     313.84 ms /     8 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2871.77 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1883.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1856.15 ms /   356 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =     193.79 ms /     5 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2062.77 ms /   361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1913.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2592.03 ms /   496 tokens (    5.23 ms per token,   191.36 tokens per second)\n",
            "llama_print_timings:        eval time =     236.78 ms /     6 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    2843.43 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.77 ms /    12 runs   (    0.56 ms per token,  1772.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2463.19 ms /   471 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
            "llama_print_timings:        eval time =     430.28 ms /    11 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2915.30 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.67 ms /   115 runs   (    0.54 ms per token,  1834.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4322.56 ms /   795 tokens (    5.44 ms per token,   183.92 tokens per second)\n",
            "llama_print_timings:        eval time =    4555.95 ms /   114 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    9046.51 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.82 ms /    64 runs   (    0.54 ms per token,  1837.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2633.04 ms /   498 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2471.75 ms /    63 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5191.01 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.49 ms /    76 runs   (    0.66 ms per token,  1505.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1563.99 ms /   302 tokens (    5.18 ms per token,   193.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2921.03 ms /    75 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    4609.21 ms /   377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.40 ms /    12 runs   (    0.53 ms per token,  1874.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.84 ms /   467 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =     426.67 ms /    11 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2907.20 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.86 ms /    12 runs   (    0.57 ms per token,  1748.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.02 ms /   458 tokens (    5.27 ms per token,   189.65 tokens per second)\n",
            "llama_print_timings:        eval time =     429.03 ms /    11 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2865.63 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.16 ms /    64 runs   (    0.66 ms per token,  1517.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5569.58 ms /  1012 tokens (    5.50 ms per token,   181.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2576.49 ms /    63 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    8265.92 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.18 ms /    81 runs   (    0.53 ms per token,  1876.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5641.74 ms /  1026 tokens (    5.50 ms per token,   181.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3250.75 ms /    80 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    9013.17 ms /  1106 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.51 ms /    77 runs   (    0.63 ms per token,  1587.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2228.14 ms /   423 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2970.10 ms /    76 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5318.86 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.46 ms /   256 runs   (    0.60 ms per token,  1679.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1857.48 ms /   357 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =    9971.96 ms /   255 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12250.24 ms /   612 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.36 ms /    68 runs   (    0.56 ms per token,  1772.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.76 ms /   432 tokens (    5.20 ms per token,   192.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2613.61 ms /    67 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4954.21 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.81 ms /   468 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =     233.25 ms /     6 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2705.08 ms /   474 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.80 ms /    98 runs   (    0.54 ms per token,  1856.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2619.93 ms /   486 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3804.98 ms /    97 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6559.80 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.74 ms /    84 runs   (    0.53 ms per token,  1877.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2583.40 ms /   493 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3259.29 ms /    83 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5953.82 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.62 ms /   256 runs   (    0.55 ms per token,  1833.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2619.01 ms /   490 tokens (    5.34 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =   10000.19 ms /   255 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13003.27 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.42 ms /   129 runs   (    0.51 ms per token,  1971.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5346.74 ms /   976 tokens (    5.48 ms per token,   182.54 tokens per second)\n",
            "llama_print_timings:        eval time =    5176.97 ms /   128 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =   10703.02 ms /  1104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.13 ms /    78 runs   (    0.67 ms per token,  1496.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4205.68 ms /   781 tokens (    5.38 ms per token,   185.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3079.12 ms /    77 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    7424.01 ms /   858 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.11 ms /    81 runs   (    0.54 ms per token,  1836.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4419.15 ms /   819 tokens (    5.40 ms per token,   185.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3191.19 ms /    80 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7726.67 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.42 ms /    68 runs   (    0.70 ms per token,  1434.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2561.95 ms /   483 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2629.77 ms /    67 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5310.41 ms /   550 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.09 ms /     6 runs   (    0.51 ms per token,  1943.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5308.47 ms /   976 tokens (    5.44 ms per token,   183.86 tokens per second)\n",
            "llama_print_timings:        eval time =     243.34 ms /     6 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    5571.47 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.10 ms /    91 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6134.49 ms /  1108 tokens (    5.54 ms per token,   180.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3687.51 ms /    90 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    9963.87 ms /  1198 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.37 ms /   562 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =     232.80 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    3233.23 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3466.40 ms /   650 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =     194.64 ms /     5 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    3677.09 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.28 ms /   126 runs   (    0.55 ms per token,  1818.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7328.48 ms /  1298 tokens (    5.65 ms per token,   177.12 tokens per second)\n",
            "llama_print_timings:        eval time =    5183.53 ms /   125 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =   12708.50 ms /  1423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.59 ms /    85 runs   (    0.64 ms per token,  1556.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2912.13 ms /   546 tokens (    5.33 ms per token,   187.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3303.57 ms /    84 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6351.84 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.84 ms /    90 runs   (    0.55 ms per token,  1805.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2943.78 ms /   559 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3490.00 ms /    89 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6560.32 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.67 ms /   161 runs   (    0.54 ms per token,  1836.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6202.27 ms /  1116 tokens (    5.56 ms per token,   179.93 tokens per second)\n",
            "llama_print_timings:        eval time =    6553.44 ms /   160 runs   (   40.96 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =   12994.76 ms /  1276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.77 ms /   131 runs   (    0.63 ms per token,  1582.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2859.54 ms /   538 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =    5103.12 ms /   130 runs   (   39.25 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    8166.93 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.46 ms /   234 runs   (    0.62 ms per token,  1608.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2713.66 ms /   514 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9163.67 ms /   233 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   12262.56 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1858.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2590.87 ms /   495 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =     235.99 ms /     6 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2844.70 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.44 ms /   111 runs   (    0.64 ms per token,  1553.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3298.28 ms /   623 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
            "llama_print_timings:        eval time =    4345.18 ms /   110 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7828.87 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.21 ms /    77 runs   (    0.56 ms per token,  1781.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2259.06 ms /   431 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2965.06 ms /    76 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5332.74 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.63 ms /    83 runs   (    0.55 ms per token,  1819.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.93 ms /   380 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3181.08 ms /    82 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    5272.47 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.20 ms /    88 runs   (    0.60 ms per token,  1654.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2568.78 ms /   485 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3398.05 ms /    87 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    6099.07 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.12 ms /    77 runs   (    0.53 ms per token,  1872.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3343.47 ms /   632 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2986.06 ms /    76 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6435.95 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.12 ms /    64 runs   (    0.77 ms per token,  1302.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2252.86 ms /   427 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2454.11 ms /    63 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4829.54 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.77 ms /   256 runs   (    0.59 ms per token,  1697.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2064.30 ms /   394 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =    9968.67 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12441.08 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1823.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.91 ms /   432 tokens (    5.22 ms per token,   191.67 tokens per second)\n",
            "llama_print_timings:        eval time =     270.84 ms /     7 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2539.84 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1854.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.60 ms /   397 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
            "llama_print_timings:        eval time =     229.24 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2313.15 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1873.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2411.21 ms /   459 tokens (    5.25 ms per token,   190.36 tokens per second)\n",
            "llama_print_timings:        eval time =     234.60 ms /     6 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2660.02 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1890.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2805.90 ms /   530 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
            "llama_print_timings:        eval time =     234.81 ms /     6 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3056.00 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.54 ms /   256 runs   (    0.56 ms per token,  1796.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2045.34 ms /   386 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
            "llama_print_timings:        eval time =    9963.69 ms /   255 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12390.58 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.24 ms /    86 runs   (    0.65 ms per token,  1529.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1995.16 ms /   384 tokens (    5.20 ms per token,   192.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3309.80 ms /    85 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5442.85 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.75 ms /   256 runs   (    0.57 ms per token,  1756.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.01 ms /   475 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =   10035.94 ms /   255 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   12949.90 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.72 ms /     6 runs   (    0.45 ms per token,  2203.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3838.05 ms /   719 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =     200.14 ms /     5 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    4054.48 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1787.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1642.71 ms /   317 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
            "llama_print_timings:        eval time =     194.47 ms /     5 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    1851.34 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.86 ms /    69 runs   (    0.61 ms per token,  1648.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.39 ms /   419 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2653.22 ms /    68 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4960.11 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2142.50 ms /   408 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
            "llama_print_timings:        eval time =     231.77 ms /     6 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2390.57 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.87 ms /     6 runs   (    0.48 ms per token,  2094.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4886.32 ms /   898 tokens (    5.44 ms per token,   183.78 tokens per second)\n",
            "llama_print_timings:        eval time =     198.84 ms /     5 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    5103.86 ms /   903 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.92 ms /     6 runs   (    0.49 ms per token,  2054.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3474.09 ms /   654 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =     198.37 ms /     5 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    3688.82 ms /   659 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.20 ms /   256 runs   (    0.57 ms per token,  1763.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3552.05 ms /   659 tokens (    5.39 ms per token,   185.53 tokens per second)\n",
            "llama_print_timings:        eval time =   10118.27 ms /   255 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =   14058.75 ms /   914 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.09 ms /    71 runs   (    0.54 ms per token,  1863.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3835.09 ms /   712 tokens (    5.39 ms per token,   185.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2805.37 ms /    71 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6740.91 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.59 ms /   256 runs   (    0.55 ms per token,  1808.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2636.18 ms /   504 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
            "llama_print_timings:        eval time =   10052.37 ms /   255 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13094.09 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.06 ms /    56 runs   (    0.54 ms per token,  1862.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3974.01 ms /   739 tokens (    5.38 ms per token,   185.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2175.26 ms /    55 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6230.72 ms /   794 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    12 runs   (    0.75 ms per token,  1340.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2215.77 ms /   420 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     431.63 ms /    11 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2674.54 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.96 ms /    84 runs   (    0.56 ms per token,  1788.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1927.51 ms /   368 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3261.82 ms /    84 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    5305.32 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.24 ms /    80 runs   (    0.62 ms per token,  1624.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7293.89 ms /  1300 tokens (    5.61 ms per token,   178.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3301.07 ms /    79 runs   (   41.79 ms per token,    23.93 tokens per second)\n",
            "llama_print_timings:       total time =   10740.81 ms /  1379 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1844.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.20 ms /   426 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =     232.18 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2486.80 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.11 ms /   129 runs   (    0.63 ms per token,  1590.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3788.01 ms /   708 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =    5099.22 ms /   128 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    9100.17 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.00 ms /     6 runs   (    0.50 ms per token,  1997.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2301.24 ms /   439 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     192.71 ms /     5 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2508.47 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.73 ms /    89 runs   (    0.53 ms per token,  1904.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2816.58 ms /   534 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3458.66 ms /    88 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6394.82 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.31 ms /   256 runs   (    0.59 ms per token,  1703.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1938.42 ms /   372 tokens (    5.21 ms per token,   191.91 tokens per second)\n",
            "llama_print_timings:        eval time =    9943.77 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12283.59 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.10 ms /    56 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     974.07 ms /   188 tokens (    5.18 ms per token,   193.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2098.55 ms /    55 runs   (   38.16 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    3145.37 ms /   243 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.03 ms /     7 runs   (    0.72 ms per token,  1392.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1788.94 ms /   339 tokens (    5.28 ms per token,   189.50 tokens per second)\n",
            "llama_print_timings:        eval time =     236.05 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2041.80 ms /   345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.73 ms /    65 runs   (    0.55 ms per token,  1819.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2563.52 ms /   487 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =    2495.55 ms /    64 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5151.29 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.47 ms /    69 runs   (    0.56 ms per token,  1793.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.99 ms /   398 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2641.75 ms /    68 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4804.28 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.25 ms /    68 runs   (    0.69 ms per token,  1439.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1906.63 ms /   368 tokens (    5.18 ms per token,   193.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2655.71 ms /    68 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    4680.83 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.49 ms /    92 runs   (    0.56 ms per token,  1786.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.45 ms /   437 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3556.47 ms /    91 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5969.26 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     159.61 ms /   256 runs   (    0.62 ms per token,  1603.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.36 ms /   416 tokens (    5.19 ms per token,   192.74 tokens per second)\n",
            "llama_print_timings:        eval time =    9965.37 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12555.04 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.66 ms /   131 runs   (    0.63 ms per token,  1584.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.77 ms /   415 tokens (    5.20 ms per token,   192.42 tokens per second)\n",
            "llama_print_timings:        eval time =    5071.71 ms /   130 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    7437.36 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.14 ms /    77 runs   (    0.55 ms per token,  1827.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6038.59 ms /  1091 tokens (    5.53 ms per token,   180.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3098.52 ms /    76 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    9254.73 ms /  1167 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.60 ms /    83 runs   (    0.54 ms per token,  1861.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5024.60 ms /   914 tokens (    5.50 ms per token,   181.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3298.63 ms /    82 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8444.42 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.95 ms /   256 runs   (    0.60 ms per token,  1673.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2109.99 ms /   404 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
            "llama_print_timings:        eval time =    9986.01 ms /   255 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12517.22 ms /   659 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.99 ms /     9 runs   (    0.55 ms per token,  1803.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1019.29 ms /   198 tokens (    5.15 ms per token,   194.25 tokens per second)\n",
            "llama_print_timings:        eval time =     301.30 ms /     8 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
            "llama_print_timings:       total time =    1334.17 ms /   206 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.60 ms /   256 runs   (    0.60 ms per token,  1677.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2153.31 ms /   413 tokens (    5.21 ms per token,   191.80 tokens per second)\n",
            "llama_print_timings:        eval time =    9987.38 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12564.58 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.92 ms /    12 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2411.46 ms /   460 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
            "llama_print_timings:        eval time =     429.60 ms /    11 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2863.50 ms /   471 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._l2_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_AES CORP_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_cosine_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     7 runs   (    0.49 ms per token,  2039.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2282.72 ms /   435 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =     226.14 ms /     6 runs   (   37.69 ms per token,    26.53 tokens per second)\n",
            "llama_print_timings:       total time =    2523.53 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.37 ms /    80 runs   (    0.52 ms per token,  1933.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3232.25 ms /   624 tokens (    5.18 ms per token,   193.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3090.04 ms /    80 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    6427.29 ms /   704 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.14 ms /   104 runs   (    0.55 ms per token,  1820.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5479.19 ms /  1011 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
            "llama_print_timings:        eval time =    4089.19 ms /   103 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    9718.48 ms /  1114 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.88 ms /    82 runs   (    0.57 ms per token,  1749.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2124.19 ms /   414 tokens (    5.13 ms per token,   194.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3105.14 ms /    81 runs   (   38.34 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    5344.63 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.50 ms /    53 runs   (    0.63 ms per token,  1582.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2114.81 ms /   408 tokens (    5.18 ms per token,   192.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2031.92 ms /    53 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    4232.90 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.24 ms /    66 runs   (    0.55 ms per token,  1821.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2425.77 ms /   472 tokens (    5.14 ms per token,   194.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2498.36 ms /    65 runs   (   38.44 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    5013.19 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.89 ms /   165 runs   (    0.50 ms per token,  2015.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5975.46 ms /  1094 tokens (    5.46 ms per token,   183.08 tokens per second)\n",
            "llama_print_timings:        eval time =    6626.73 ms /   164 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   12841.38 ms /  1258 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.23 ms /    73 runs   (    0.65 ms per token,  1545.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3259.97 ms /   620 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2820.35 ms /    72 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6204.71 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.99 ms /   150 runs   (    0.55 ms per token,  1829.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4541.55 ms /   847 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
            "llama_print_timings:        eval time =    5888.43 ms /   149 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   10643.06 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.79 ms /    69 runs   (    0.56 ms per token,  1778.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4016.17 ms /   748 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2674.55 ms /    68 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6790.71 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.83 ms /   104 runs   (    0.53 ms per token,  1896.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3049.48 ms /   581 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =    4037.26 ms /   103 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7223.80 ms /   684 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.19 ms /   113 runs   (    0.58 ms per token,  1733.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2777.08 ms /   528 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4418.77 ms /   113 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    7361.25 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.20 ms /   256 runs   (    0.58 ms per token,  1727.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2918.46 ms /   555 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
            "llama_print_timings:        eval time =    9988.51 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   13315.86 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    65 runs   (    0.56 ms per token,  1786.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2312.54 ms /   442 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2479.27 ms /    64 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    4879.03 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.45 ms /   256 runs   (    0.58 ms per token,  1712.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2022.90 ms /   389 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
            "llama_print_timings:        eval time =    9935.39 ms /   255 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12356.50 ms /   644 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.55 ms /   117 runs   (    0.58 ms per token,  1732.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4795.02 ms /   883 tokens (    5.43 ms per token,   184.15 tokens per second)\n",
            "llama_print_timings:        eval time =    4639.44 ms /   116 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    9613.41 ms /   999 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.53 ms /    11 runs   (    0.59 ms per token,  1685.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2578.16 ms /   491 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
            "llama_print_timings:        eval time =     391.66 ms /    10 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2990.25 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1879.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     170.47 ms /    30 tokens (    5.68 ms per token,   175.98 tokens per second)\n",
            "llama_print_timings:        eval time =     230.11 ms /     6 runs   (   38.35 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =     411.71 ms /    36 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.30 ms /   106 runs   (    0.63 ms per token,  1598.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3918.16 ms /   731 tokens (    5.36 ms per token,   186.57 tokens per second)\n",
            "llama_print_timings:        eval time =    4167.15 ms /   105 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    8255.73 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1876.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2581.99 ms /   494 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =     233.96 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2830.50 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.25 ms /   256 runs   (    0.58 ms per token,  1738.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1973.41 ms /   378 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9914.18 ms /   255 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =   12288.04 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.69 ms /    67 runs   (    0.55 ms per token,  1826.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2534.68 ms /   487 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.19 ms /    66 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5201.32 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.51 ms /    12 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1608.22 ms /   312 tokens (    5.15 ms per token,   194.00 tokens per second)\n",
            "llama_print_timings:        eval time =     430.31 ms /    11 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2062.86 ms /   323 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.55 ms /    12 runs   (    0.63 ms per token,  1588.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2169.12 ms /   412 tokens (    5.26 ms per token,   189.94 tokens per second)\n",
            "llama_print_timings:        eval time =     425.01 ms /    11 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2621.76 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.19 ms /   127 runs   (    0.54 ms per token,  1835.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1596.71 ms /   310 tokens (    5.15 ms per token,   194.15 tokens per second)\n",
            "llama_print_timings:        eval time =    4846.46 ms /   126 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    6608.73 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1773.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2407.30 ms /   464 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =     230.86 ms /     6 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2652.46 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.20 ms /   126 runs   (    0.59 ms per token,  1698.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1954.68 ms /   374 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4845.86 ms /   125 runs   (   38.77 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    6976.56 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.18 ms /   256 runs   (    0.58 ms per token,  1727.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1425.95 ms /   277 tokens (    5.15 ms per token,   194.26 tokens per second)\n",
            "llama_print_timings:        eval time =    9847.06 ms /   255 runs   (   38.62 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =   11656.37 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.21 ms /    81 runs   (    0.55 ms per token,  1832.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1940.35 ms /   376 tokens (    5.16 ms per token,   193.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3137.44 ms /    81 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    5178.31 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.45 ms /    12 runs   (    0.54 ms per token,  1861.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2025.14 ms /   390 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
            "llama_print_timings:        eval time =     426.42 ms /    11 runs   (   38.77 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2470.46 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.82 ms /   256 runs   (    0.56 ms per token,  1792.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1568.19 ms /   300 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =    9953.09 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   11884.42 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.04 ms /     9 runs   (    0.56 ms per token,  1786.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1559.64 ms /   303 tokens (    5.15 ms per token,   194.27 tokens per second)\n",
            "llama_print_timings:        eval time =     310.00 ms /     8 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    1884.89 ms /   311 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    14 runs   (    0.72 ms per token,  1392.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1531.58 ms /   292 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =     508.13 ms /    13 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2066.12 ms /   305 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1811.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2179.15 ms /   416 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =     233.95 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2427.68 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.85 ms /   113 runs   (    0.54 ms per token,  1857.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.56 ms /   418 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4387.05 ms /   112 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6728.39 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.23 ms /    11 runs   (    0.66 ms per token,  1520.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.91 ms /   456 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =     432.16 ms /    11 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    2829.23 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.20 ms /   168 runs   (    0.51 ms per token,  1949.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3242.29 ms /   604 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
            "llama_print_timings:        eval time =    6554.53 ms /   167 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   10012.88 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.74 ms /    12 runs   (    0.56 ms per token,  1780.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2196.29 ms /   419 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =     424.98 ms /    11 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2640.92 ms /   430 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.01 ms /     9 runs   (    0.67 ms per token,  1498.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1063.72 ms /   202 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
            "llama_print_timings:        eval time =     305.52 ms /     8 runs   (   38.19 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    1387.61 ms /   210 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.26 ms /    12 runs   (    0.52 ms per token,  1916.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2528.97 ms /   480 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =     468.14 ms /    12 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    3022.30 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.70 ms /    67 runs   (    0.53 ms per token,  1876.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3737.20 ms /   703 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2596.99 ms /    66 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6421.22 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.94 ms /    75 runs   (    0.67 ms per token,  1501.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2670.41 ms /   507 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2903.88 ms /    74 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5694.27 ms /   581 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.40 ms /    90 runs   (    0.55 ms per token,  1821.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2854.61 ms /   541 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3484.05 ms /    89 runs   (   39.15 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6459.26 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.98 ms /   256 runs   (    0.58 ms per token,  1729.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2755.27 ms /   523 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
            "llama_print_timings:        eval time =    9998.97 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13134.58 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.45 ms /    64 runs   (    0.60 ms per token,  1664.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2715.49 ms /   518 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2470.82 ms /    63 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5277.43 ms /   581 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.18 ms /    67 runs   (    0.55 ms per token,  1802.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2132.73 ms /   405 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2561.46 ms /    66 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4782.99 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.02 ms /    80 runs   (    0.54 ms per token,  1859.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4010.23 ms /   750 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3135.91 ms /    79 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7253.33 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.61 ms /    52 runs   (    0.67 ms per token,  1502.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2084.66 ms /   394 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1983.35 ms /    51 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4156.29 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      21.06 ms /    41 runs   (    0.51 ms per token,  1946.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1472.92 ms /   288 tokens (    5.11 ms per token,   195.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.05 ms /    40 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    3060.06 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.67 ms /   256 runs   (    0.60 ms per token,  1655.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1682.89 ms /   327 tokens (    5.15 ms per token,   194.31 tokens per second)\n",
            "llama_print_timings:        eval time =    9901.26 ms /   255 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =   11985.48 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.74 ms /   341 tokens (    5.19 ms per token,   192.68 tokens per second)\n",
            "llama_print_timings:        eval time =     235.62 ms /     6 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2019.36 ms /   347 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.95 ms /    65 runs   (    0.58 ms per token,  1712.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3968.41 ms /   744 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.36 ms /    65 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6641.25 ms /   809 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.67 ms /    83 runs   (    0.53 ms per token,  1900.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4728.19 ms /   868 tokens (    5.45 ms per token,   183.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3282.15 ms /    82 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    8121.55 ms /   950 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.25 ms /   256 runs   (    0.59 ms per token,  1703.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1601.02 ms /   312 tokens (    5.13 ms per token,   194.88 tokens per second)\n",
            "llama_print_timings:        eval time =    9889.80 ms /   255 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =   11880.30 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.65 ms /    76 runs   (    0.57 ms per token,  1741.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3654.03 ms /   685 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2958.46 ms /    75 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6719.72 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.30 ms /   256 runs   (    0.54 ms per token,  1851.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2437.02 ms /   458 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =    9988.92 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12777.97 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    12 runs   (    0.76 ms per token,  1318.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2402.25 ms /   452 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
            "llama_print_timings:        eval time =     430.71 ms /    11 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2859.92 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.49 ms /   121 runs   (    0.52 ms per token,  1905.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3888.90 ms /   728 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4743.56 ms /   120 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    8787.35 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.00 ms /    97 runs   (    0.68 ms per token,  1469.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1555.84 ms /   304 tokens (    5.12 ms per token,   195.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3765.27 ms /    97 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    5475.04 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.82 ms /   161 runs   (    0.56 ms per token,  1792.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1681.80 ms /   327 tokens (    5.14 ms per token,   194.43 tokens per second)\n",
            "llama_print_timings:        eval time =    6199.14 ms /   160 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    8089.61 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     7 runs   (    0.65 ms per token,  1534.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2381.69 ms /   456 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     233.31 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2632.82 ms /   462 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_ip_2.json\n",
            "KeyError occurred: 'ip'. Skipping approach 1 for dataframe results_approach_AES CORP_l2_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_l2_2.json\n",
            "Total score for approach 1 and distance function ip is 0.5670588235294117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(1, 'l2')"
      ],
      "metadata": {
        "id": "Oae2_wwp3gmq",
        "outputId": "48d0b1f5-f893-42a4-9aff-8dde7c795804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     7 runs   (    0.47 ms per token,  2146.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3474.01 ms /   655 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =     235.53 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3725.16 ms /   661 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.98 ms /    68 runs   (    0.54 ms per token,  1839.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3204.68 ms /   608 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2676.93 ms /    68 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5970.10 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.40 ms /    70 runs   (    0.53 ms per token,  1871.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4183.28 ms /   772 tokens (    5.42 ms per token,   184.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2736.46 ms /    69 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    7016.10 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     7 runs   (    0.50 ms per token,  1994.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3511.02 ms /   659 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =     236.57 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3764.24 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.92 ms /    80 runs   (    0.66 ms per token,  1511.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.72 ms /   568 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3113.01 ms /    79 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6232.03 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1903.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2627.62 ms /   504 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
            "llama_print_timings:        eval time =     235.89 ms /     6 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2877.48 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.95 ms /    64 runs   (    0.55 ms per token,  1831.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1726.46 ms /   336 tokens (    5.14 ms per token,   194.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2436.36 ms /    63 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    4242.56 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.67 ms /   256 runs   (    0.59 ms per token,  1687.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.58 ms /   428 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =    9949.45 ms /   255 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12572.20 ms /   683 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.56 ms per token,  1800.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3469.81 ms /   650 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =     197.36 ms /     5 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3683.01 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.27 ms /    69 runs   (    0.55 ms per token,  1802.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2751.58 ms /   519 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2662.62 ms /    68 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5513.86 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.61 ms /    91 runs   (    0.51 ms per token,  1952.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4145.55 ms /   770 tokens (    5.38 ms per token,   185.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3573.20 ms /    90 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7836.51 ms /   860 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1586.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2312.23 ms /   440 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =     235.02 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2565.70 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     643.11 ms /   115 tokens (    5.59 ms per token,   178.82 tokens per second)\n",
            "llama_print_timings:        eval time =     232.22 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =     887.33 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.39 ms /   256 runs   (    0.57 ms per token,  1748.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2194.96 ms /   418 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    9982.30 ms /   255 runs   (   39.15 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12570.17 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.80 ms /   256 runs   (    0.55 ms per token,  1831.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1399.19 ms /   270 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9885.77 ms /   255 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =   11644.52 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.50 ms /   104 runs   (    0.54 ms per token,  1840.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3459.82 ms /   647 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
            "llama_print_timings:        eval time =    4050.18 ms /   103 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7644.38 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.68 ms /   231 runs   (    0.59 ms per token,  1702.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2281.02 ms /   437 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =    8979.66 ms /   230 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   11603.33 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.29 ms /    95 runs   (    0.57 ms per token,  1749.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3651.47 ms /   688 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3722.35 ms /    94 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7508.15 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.69 ms /    67 runs   (    0.53 ms per token,  1877.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2786.14 ms /   527 tokens (    5.29 ms per token,   189.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2589.15 ms /    66 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5462.91 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.57 ms /    73 runs   (    0.54 ms per token,  1844.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3247.06 ms /   610 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2832.92 ms /    72 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6173.30 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.00 ms /    98 runs   (    0.54 ms per token,  1849.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4050.62 ms /   747 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3835.38 ms /    97 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    8015.68 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.49 ms /   153 runs   (    0.62 ms per token,  1602.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5873.79 ms /  1072 tokens (    5.48 ms per token,   182.51 tokens per second)\n",
            "llama_print_timings:        eval time =    6271.15 ms /   153 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =   12384.01 ms /  1225 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.52 ms /    72 runs   (    0.53 ms per token,  1869.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.38 ms /   392 tokens (    5.17 ms per token,   193.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2793.81 ms /    72 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4910.76 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.97 ms /    64 runs   (    0.70 ms per token,  1423.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2112.16 ms /   403 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2458.81 ms /    63 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4675.92 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.52 ms /    59 runs   (    0.55 ms per token,  1814.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1900.30 ms /   364 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2246.10 ms /    58 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    4221.82 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.79 ms /    76 runs   (    0.54 ms per token,  1863.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2277.12 ms /   437 tokens (    5.21 ms per token,   191.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2925.87 ms /    75 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5298.08 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.86 ms /     7 runs   (    0.69 ms per token,  1441.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2516.46 ms /   475 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =     236.41 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2769.42 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1466.58 ms /   271 tokens (    5.41 ms per token,   184.78 tokens per second)\n",
            "llama_print_timings:        eval time =     229.61 ms /     6 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    1711.43 ms /   277 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.52 ms /     7 runs   (    0.50 ms per token,  1989.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2498.83 ms /   475 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
            "llama_print_timings:        eval time =     231.37 ms /     6 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2743.92 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.55 ms /   256 runs   (    0.60 ms per token,  1656.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2194.10 ms /   421 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =    9979.80 ms /   255 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12571.52 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.94 ms /   140 runs   (    0.56 ms per token,  1796.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2843.72 ms /   541 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    5469.72 ms /   139 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    8501.38 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.25 ms /    94 runs   (    0.52 ms per token,  1908.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2747.05 ms /   515 tokens (    5.33 ms per token,   187.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3651.48 ms /    93 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6518.41 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.39 ms /   122 runs   (    0.54 ms per token,  1837.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1450.35 ms /   271 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4742.91 ms /   121 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6355.61 ms /   392 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     6 runs   (    0.66 ms per token,  1524.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2139.24 ms /   405 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =     195.13 ms /     5 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2355.26 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1684.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2036.98 ms /   392 tokens (    5.20 ms per token,   192.44 tokens per second)\n",
            "llama_print_timings:        eval time =     232.64 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2282.63 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     9 runs   (    0.55 ms per token,  1833.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     439.56 ms /    88 tokens (    4.99 ms per token,   200.20 tokens per second)\n",
            "llama_print_timings:        eval time =     340.19 ms /     9 runs   (   37.80 ms per token,    26.46 tokens per second)\n",
            "llama_print_timings:       total time =     791.85 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1934.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2627.80 ms /   499 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =     233.47 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2875.50 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1539.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2154.45 ms /   416 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
            "llama_print_timings:        eval time =     232.05 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2401.04 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1478.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2410.03 ms /   458 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     235.41 ms /     6 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2662.89 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.37 ms /     7 runs   (    0.91 ms per token,  1098.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2173.30 ms /   414 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
            "llama_print_timings:        eval time =     231.14 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2426.79 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.12 ms /   256 runs   (    0.56 ms per token,  1776.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.80 ms /   430 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9998.12 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12627.52 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.23 ms /    64 runs   (    0.52 ms per token,  1926.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3395.89 ms /   637 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2473.77 ms /    63 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5952.85 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.30 ms /    84 runs   (    0.57 ms per token,  1739.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3027.05 ms /   575 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3271.95 ms /    83 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6417.20 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.90 ms /    67 runs   (    0.52 ms per token,  1919.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2661.01 ms /   503 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2592.78 ms /    66 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5341.42 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.55 ms /    69 runs   (    0.53 ms per token,  1887.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3247.20 ms /   616 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2716.58 ms /    69 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6051.68 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.15 ms /    90 runs   (    0.54 ms per token,  1869.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3956.51 ms /   736 tokens (    5.38 ms per token,   186.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3569.59 ms /    90 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    7646.60 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1894.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3247.02 ms /   616 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =     233.70 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    3495.25 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1639.05 ms /   315 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =     193.17 ms /     5 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    1844.24 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1808.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     228.80 ms /     6 runs   (   38.13 ms per token,    26.22 tokens per second)\n",
            "llama_print_timings:       total time =     238.87 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.99 ms /     9 runs   (    0.67 ms per token,  1503.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2510.57 ms /   474 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =     313.46 ms /     8 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2843.46 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.26 ms /    72 runs   (    0.55 ms per token,  1833.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2132.98 ms /   402 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2764.33 ms /    71 runs   (   38.93 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    4990.93 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.90 ms /   256 runs   (    0.59 ms per token,  1685.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2238.41 ms /   428 tokens (    5.23 ms per token,   191.21 tokens per second)\n",
            "llama_print_timings:        eval time =    9968.98 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12609.85 ms /   683 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1685.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2283.99 ms /   439 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =     230.13 ms /     6 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    2528.79 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.18 ms /   256 runs   (    0.59 ms per token,  1682.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2806.02 ms /   533 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =   10025.29 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13219.38 ms /   788 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.17 ms /    68 runs   (    0.69 ms per token,  1441.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4788.08 ms /   884 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2712.95 ms /    67 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    7620.88 ms /   951 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.86 ms /   256 runs   (    0.58 ms per token,  1719.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2857.89 ms /   541 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =   10057.41 ms /   255 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13306.24 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1876.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2554.84 ms /   484 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =     232.97 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2803.51 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.30 ms /   256 runs   (    0.58 ms per token,  1714.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2199.36 ms /   419 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
            "llama_print_timings:        eval time =    9998.77 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12595.87 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.97 ms /   126 runs   (    0.54 ms per token,  1853.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.69 ms /   420 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4879.26 ms /   125 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    7237.55 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.58 ms /   256 runs   (    0.57 ms per token,  1746.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2164.36 ms /   416 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =   10012.06 ms /   256 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12544.69 ms /   672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.56 ms /    69 runs   (    0.69 ms per token,  1450.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2179.34 ms /   410 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2659.43 ms /    68 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4955.19 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.64 ms /    85 runs   (    0.54 ms per token,  1862.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.26 ms /   435 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3274.86 ms /    84 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5667.85 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.19 ms /    88 runs   (    0.59 ms per token,  1686.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.15 ms /   410 tokens (    5.26 ms per token,   190.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3388.43 ms /    87 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5666.07 ms /   497 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.56 ms /    12 runs   (    0.55 ms per token,  1828.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2393.49 ms /   454 tokens (    5.27 ms per token,   189.68 tokens per second)\n",
            "llama_print_timings:        eval time =     428.12 ms /    11 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2843.42 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.43 ms /    65 runs   (    0.55 ms per token,  1834.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.10 ms /   516 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2516.46 ms /    64 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5322.10 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.39 ms /    80 runs   (    0.68 ms per token,  1470.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3472.69 ms /   655 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3136.77 ms /    79 runs   (   39.71 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6741.85 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.79 ms /   438 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =     233.46 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2535.90 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.88 ms /    72 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.66 ms /   422 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2764.62 ms /    71 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5053.64 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.16 ms /    77 runs   (    0.63 ms per token,  1598.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1895.12 ms /   363 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2962.07 ms /    76 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4973.90 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.65 ms /    96 runs   (    0.53 ms per token,  1895.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3273.63 ms /   616 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3728.17 ms /    95 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7129.96 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.33 ms /    91 runs   (    0.64 ms per token,  1560.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3561.95 ms /   672 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3583.06 ms /    90 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7297.83 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.15 ms /     7 runs   (    0.59 ms per token,  1685.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2551.52 ms /   486 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =     234.22 ms /     6 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2801.74 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.07 ms /   256 runs   (    0.55 ms per token,  1827.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3122.37 ms /   592 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10089.35 ms /   255 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   13609.42 ms /   847 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.17 ms /    69 runs   (    0.54 ms per token,  1856.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4335.37 ms /   805 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2707.05 ms /    68 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7138.20 ms /   873 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.05 ms /   109 runs   (    0.58 ms per token,  1728.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3200.96 ms /   598 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4237.54 ms /   108 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7595.14 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.58 ms /     7 runs   (    0.51 ms per token,  1954.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.61 ms /   416 tokens (    5.19 ms per token,   192.72 tokens per second)\n",
            "llama_print_timings:        eval time =     271.21 ms /     7 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2443.94 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     7 runs   (    0.50 ms per token,  1980.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1751.13 ms /   336 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =     230.97 ms /     6 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    1994.91 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.22 ms /   256 runs   (    0.58 ms per token,  1715.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2204.46 ms /   419 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =    9974.84 ms /   255 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12575.09 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     7 runs   (    0.72 ms per token,  1398.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2502.00 ms /   475 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =     232.27 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2752.04 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.88 ms /     6 runs   (    0.81 ms per token,  1228.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.03 ms /   414 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     196.64 ms /     5 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2409.41 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.00 ms /    69 runs   (    0.55 ms per token,  1815.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5364.97 ms /   983 tokens (    5.46 ms per token,   183.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2749.85 ms /    68 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8217.28 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1567.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3357.01 ms /   632 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =     277.86 ms /     7 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3656.98 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.61 ms /    85 runs   (    0.55 ms per token,  1823.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2747.44 ms /   520 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3326.22 ms /    85 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6190.05 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.03 ms /    64 runs   (    0.55 ms per token,  1826.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2559.43 ms /   482 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2463.52 ms /    63 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5110.08 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.50 ms /   256 runs   (    0.59 ms per token,  1689.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.42 ms /   415 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =    9950.26 ms /   255 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12526.49 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.51 ms /    68 runs   (    0.74 ms per token,  1346.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2039.04 ms /   391 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2602.72 ms /    67 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4769.30 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.22 ms /    78 runs   (    0.55 ms per token,  1804.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2687.18 ms /   512 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3054.14 ms /    78 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5851.20 ms /   590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.76 ms /   110 runs   (    0.68 ms per token,  1471.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2806.85 ms /   531 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =    4285.52 ms /   109 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7273.12 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.40 ms /    12 runs   (    0.62 ms per token,  1621.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2730.49 ms /   516 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
            "llama_print_timings:        eval time =     433.47 ms /    11 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3194.12 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.75 ms /    12 runs   (    0.56 ms per token,  1777.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2523.72 ms /   478 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =     428.06 ms /    11 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2974.49 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1855.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.60 ms /   440 tokens (    5.20 ms per token,   192.43 tokens per second)\n",
            "llama_print_timings:        eval time =     270.41 ms /     7 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2570.85 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.77 ms /     7 runs   (    0.68 ms per token,  1467.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1988.69 ms /   383 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =     231.41 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2236.29 ms /   389 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.76 ms /   106 runs   (    0.56 ms per token,  1773.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2453.94 ms /   464 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =    4144.55 ms /   106 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6752.37 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.54 ms /   150 runs   (    0.64 ms per token,  1570.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2720.23 ms /   520 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =    5912.30 ms /   150 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    8877.46 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.18 ms /    95 runs   (    0.57 ms per token,  1753.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2580.01 ms /   484 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3690.11 ms /    94 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6403.96 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.39 ms /   256 runs   (    0.60 ms per token,  1679.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1771.46 ms /   344 tokens (    5.15 ms per token,   194.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9963.60 ms /   256 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =   12144.50 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.17 ms /   256 runs   (    0.60 ms per token,  1671.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2941.98 ms /   556 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =   10062.50 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13419.70 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.78 ms /    67 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1599.95 ms /   308 tokens (    5.19 ms per token,   192.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2548.47 ms /    66 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    4238.28 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.52 ms /     7 runs   (    0.65 ms per token,  1549.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1518.00 ms /   293 tokens (    5.18 ms per token,   193.02 tokens per second)\n",
            "llama_print_timings:        eval time =     232.32 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    1765.29 ms /   299 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.57 ms /   256 runs   (    0.56 ms per token,  1783.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1616.14 ms /   306 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =    9914.59 ms /   255 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =   11908.72 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.43 ms /     9 runs   (    0.60 ms per token,  1656.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1142.09 ms /   221 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
            "llama_print_timings:        eval time =     304.67 ms /     8 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
            "llama_print_timings:       total time =    1462.50 ms /   229 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.12 ms /   112 runs   (    0.58 ms per token,  1719.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2313.17 ms /   436 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4330.41 ms /   111 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    6812.70 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.54 ms /    64 runs   (    0.56 ms per token,  1800.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.96 ms /   447 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2462.31 ms /    63 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4882.10 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.77 ms /     6 runs   (    1.30 ms per token,   771.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1947.39 ms /   376 tokens (    5.18 ms per token,   193.08 tokens per second)\n",
            "llama_print_timings:        eval time =     193.34 ms /     5 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2158.67 ms /   381 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.29 ms /   256 runs   (    0.55 ms per token,  1811.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2761.46 ms /   518 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
            "llama_print_timings:        eval time =   10023.52 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13163.01 ms /   773 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.15 ms /    68 runs   (    0.68 ms per token,  1473.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1536.73 ms /   296 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2594.02 ms /    67 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    4242.94 ms /   363 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.76 ms /   256 runs   (    0.58 ms per token,  1720.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1899.95 ms /   362 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =    9973.91 ms /   255 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12295.50 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.23 ms /    77 runs   (    0.56 ms per token,  1781.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1895.41 ms /   362 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2948.91 ms /    76 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4951.30 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.81 ms /    70 runs   (    0.54 ms per token,  1851.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.42 ms /   419 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2697.83 ms /    69 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    4988.90 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.45 ms /    12 runs   (    0.70 ms per token,  1419.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2764.51 ms /   517 tokens (    5.35 ms per token,   187.01 tokens per second)\n",
            "llama_print_timings:        eval time =     437.43 ms /    11 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    3232.56 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.23 ms /    12 runs   (    0.52 ms per token,  1926.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2528.11 ms /   480 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =     471.80 ms /    12 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3021.84 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.43 ms /   129 runs   (    0.61 ms per token,  1644.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3474.56 ms /   650 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
            "llama_print_timings:        eval time =    5066.43 ms /   128 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    8750.25 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.90 ms /    66 runs   (    0.59 ms per token,  1696.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1411.92 ms /   271 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2510.48 ms /    65 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    4017.65 ms /   336 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.74 ms /   256 runs   (    0.59 ms per token,  1687.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1463.31 ms /   274 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =   10006.11 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   11887.40 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.68 ms /    68 runs   (    0.55 ms per token,  1804.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1771.43 ms /   344 tokens (    5.15 ms per token,   194.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2600.47 ms /    67 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    4462.55 ms /   411 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.13 ms /    11 runs   (    0.56 ms per token,  1794.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2944.36 ms /   555 tokens (    5.31 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =     391.25 ms /    10 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    3356.56 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.05 ms /     7 runs   (    0.72 ms per token,  1385.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1864.61 ms /   359 tokens (    5.19 ms per token,   192.53 tokens per second)\n",
            "llama_print_timings:        eval time =     237.85 ms /     6 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    2119.30 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.30 ms /    69 runs   (    0.56 ms per token,  1801.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2811.47 ms /   527 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2669.03 ms /    68 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5578.91 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.96 ms /    73 runs   (    0.56 ms per token,  1782.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2680.08 ms /   512 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2855.08 ms /    73 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5634.68 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.81 ms /    72 runs   (    0.64 ms per token,  1571.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2743.70 ms /   517 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2788.69 ms /    71 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5649.76 ms /   588 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.14 ms /   256 runs   (    0.59 ms per token,  1693.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1556.99 ms /   300 tokens (    5.19 ms per token,   192.68 tokens per second)\n",
            "llama_print_timings:        eval time =    9930.86 ms /   255 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   11898.72 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.50 ms /   166 runs   (    0.54 ms per token,  1854.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2685.66 ms /   512 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
            "llama_print_timings:        eval time =    6476.78 ms /   165 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    9390.23 ms /   677 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.64 ms /   256 runs   (    0.59 ms per token,  1699.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1865.00 ms /   355 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    9934.80 ms /   255 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12194.22 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.25 ms /    91 runs   (    0.72 ms per token,  1394.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1331.68 ms /   255 tokens (    5.22 ms per token,   191.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3502.41 ms /    90 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    4988.85 ms /   345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.45 ms /   136 runs   (    0.54 ms per token,  1851.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4906.47 ms /   898 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
            "llama_print_timings:        eval time =    5439.42 ms /   135 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =   10541.53 ms /  1033 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.81 ms /    71 runs   (    0.57 ms per token,  1739.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3118.28 ms /   584 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2743.35 ms /    70 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5969.20 ms /   654 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.44 ms /     6 runs   (    0.57 ms per token,  1745.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.32 ms /   495 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =     194.48 ms /     5 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2800.97 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.43 ms /   256 runs   (    0.60 ms per token,  1679.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     952.22 ms /   180 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
            "llama_print_timings:        eval time =    9905.45 ms /   255 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =   11274.68 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.10 ms /   144 runs   (    0.58 ms per token,  1732.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2113.82 ms /   404 tokens (    5.23 ms per token,   191.12 tokens per second)\n",
            "llama_print_timings:        eval time =    5581.34 ms /   143 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    7902.71 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1625.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2447.13 ms /   463 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
            "llama_print_timings:        eval time =     232.69 ms /     6 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2698.57 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.18 ms /    70 runs   (    0.52 ms per token,  1934.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2899.42 ms /   552 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2702.33 ms /    69 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5694.28 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.05 ms /    62 runs   (    0.63 ms per token,  1587.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2896.76 ms /   547 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2397.02 ms /    61 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5392.35 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.96 ms /     6 runs   (    0.49 ms per token,  2027.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5384.22 ms /   982 tokens (    5.48 ms per token,   182.38 tokens per second)\n",
            "llama_print_timings:        eval time =     201.80 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5606.55 ms /   987 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.19 ms /    82 runs   (    0.54 ms per token,  1855.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2765.91 ms /   522 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3168.19 ms /    81 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    6044.38 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.13 ms /    76 runs   (    0.54 ms per token,  1847.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3696.01 ms /   683 tokens (    5.41 ms per token,   184.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2958.04 ms /    75 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6764.46 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.10 ms /    83 runs   (    0.57 ms per token,  1762.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5316.08 ms /   975 tokens (    5.45 ms per token,   183.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3331.43 ms /    82 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    8785.24 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.97 ms /    77 runs   (    0.53 ms per token,  1879.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2783.33 ms /   523 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2987.31 ms /    76 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5873.95 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      20.81 ms /    40 runs   (    0.52 ms per token,  1922.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3655.74 ms /   687 tokens (    5.32 ms per token,   187.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.67 ms /    39 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    5253.27 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.41 ms /    73 runs   (    0.66 ms per token,  1507.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     131.78 ms /    24 tokens (    5.49 ms per token,   182.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2873.08 ms /    72 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    3129.39 ms /    96 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.32 ms /   108 runs   (    0.52 ms per token,  1917.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4347.18 ms /   802 tokens (    5.42 ms per token,   184.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4261.73 ms /   107 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    8757.20 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.62 ms /    75 runs   (    0.65 ms per token,  1542.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3452.54 ms /   645 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2935.18 ms /    74 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6513.92 ms /   719 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.40 ms /   114 runs   (    0.56 ms per token,  1770.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4936.07 ms /   911 tokens (    5.42 ms per token,   184.56 tokens per second)\n",
            "llama_print_timings:        eval time =    4558.83 ms /   113 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    9665.33 ms /  1024 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.87 ms /    85 runs   (    0.56 ms per token,  1775.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3330.89 ms /   622 tokens (    5.36 ms per token,   186.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3299.45 ms /    84 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6751.09 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.72 ms /   109 runs   (    0.66 ms per token,  1519.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4938.51 ms /   912 tokens (    5.42 ms per token,   184.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4419.97 ms /   109 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    9554.25 ms /  1021 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.38 ms /    85 runs   (    0.55 ms per token,  1832.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3291.26 ms /   619 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3303.19 ms /    84 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6710.53 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.87 ms /   256 runs   (    0.57 ms per token,  1767.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2539.71 ms /   482 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =    9989.86 ms /   255 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12934.47 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1891.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1855.13 ms /   360 tokens (    5.15 ms per token,   194.06 tokens per second)\n",
            "llama_print_timings:        eval time =     274.27 ms /     7 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2143.17 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.29 ms /    80 runs   (    0.68 ms per token,  1473.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2254.59 ms /   432 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3126.51 ms /    80 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5516.85 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.66 ms /    75 runs   (    0.53 ms per token,  1891.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3651.86 ms /   687 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2905.89 ms /    74 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6659.42 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1924.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1981.58 ms /   384 tokens (    5.16 ms per token,   193.78 tokens per second)\n",
            "llama_print_timings:        eval time =     233.28 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2227.75 ms /   390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.77 ms /    71 runs   (    0.66 ms per token,  1518.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1829.94 ms /   348 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2727.54 ms /    70 runs   (   38.96 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4673.08 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.20 ms /   256 runs   (    0.60 ms per token,  1671.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.18 ms /   413 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =   10006.39 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12585.67 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.76 ms /    84 runs   (    0.54 ms per token,  1835.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2902.43 ms /   552 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3296.86 ms /    84 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6314.72 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.99 ms /    68 runs   (    0.65 ms per token,  1545.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.04 ms /   478 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2620.58 ms /    67 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5233.94 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.04 ms /    58 runs   (    0.57 ms per token,  1755.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1409.91 ms /   272 tokens (    5.18 ms per token,   192.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2192.65 ms /    57 runs   (   38.47 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    3682.20 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.55 ms /   256 runs   (    0.56 ms per token,  1771.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     121.07 ms /    21 tokens (    5.77 ms per token,   173.46 tokens per second)\n",
            "llama_print_timings:        eval time =    9890.28 ms /   255 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =   10412.77 ms /   276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     103.27 ms /   193 runs   (    0.54 ms per token,  1868.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1365.55 ms /   264 tokens (    5.17 ms per token,   193.33 tokens per second)\n",
            "llama_print_timings:        eval time =    7415.43 ms /   192 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    9042.38 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.28 ms /   103 runs   (    0.68 ms per token,  1465.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1306.16 ms /   255 tokens (    5.12 ms per token,   195.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3955.89 ms /   102 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    5436.81 ms /   357 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     173.74 ms /   256 runs   (    0.68 ms per token,  1473.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2455.07 ms /   469 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
            "llama_print_timings:        eval time =   10011.75 ms /   255 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   12944.01 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.38 ms /   237 runs   (    0.61 ms per token,  1630.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2544.95 ms /   482 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9255.87 ms /   236 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12204.47 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.61 ms /   256 runs   (    0.60 ms per token,  1677.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =      84.85 ms /    15 tokens (    5.66 ms per token,   176.79 tokens per second)\n",
            "llama_print_timings:        eval time =    9982.65 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   10469.78 ms /   270 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.24 ms /   114 runs   (    0.73 ms per token,  1369.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2393.28 ms /   455 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4442.78 ms /   113 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7048.43 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.29 ms /     9 runs   (    0.59 ms per token,  1701.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1647.10 ms /   320 tokens (    5.15 ms per token,   194.28 tokens per second)\n",
            "llama_print_timings:        eval time =     349.38 ms /     9 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2013.34 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1825.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2425.82 ms /   462 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
            "llama_print_timings:        eval time =     194.24 ms /     5 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2634.23 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.14 ms /   109 runs   (    0.63 ms per token,  1576.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1222.99 ms /   234 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4156.73 ms /   108 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    5555.92 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.05 ms /     9 runs   (    0.67 ms per token,  1486.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     779.47 ms /   151 tokens (    5.16 ms per token,   193.72 tokens per second)\n",
            "llama_print_timings:        eval time =     311.34 ms /     8 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    1111.20 ms /   159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2765.46 ms /   515 tokens (    5.37 ms per token,   186.23 tokens per second)\n",
            "llama_print_timings:        eval time =     237.48 ms /     6 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    3021.25 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     104.82 ms /   192 runs   (    0.55 ms per token,  1831.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2780.49 ms /   526 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =    7512.24 ms /   191 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   10593.04 ms /   717 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2260.21 ms /   428 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =     232.33 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2508.93 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.46 ms /   256 runs   (    0.61 ms per token,  1636.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2112.96 ms /   407 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
            "llama_print_timings:        eval time =   10002.02 ms /   255 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   12563.42 ms /   662 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.38 ms /   140 runs   (    0.58 ms per token,  1720.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3835.89 ms /   715 tokens (    5.36 ms per token,   186.40 tokens per second)\n",
            "llama_print_timings:        eval time =    5517.57 ms /   139 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    9566.43 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.17 ms /   256 runs   (    0.57 ms per token,  1751.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2139.53 ms /   405 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
            "llama_print_timings:        eval time =    9960.89 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12500.11 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.68 ms /    41 runs   (    0.68 ms per token,  1481.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.11 ms /   428 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.97 ms /    40 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3883.49 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.17 ms /    93 runs   (    0.57 ms per token,  1749.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1575.43 ms /   303 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3553.75 ms /    92 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    5266.64 ms /   395 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.26 ms /    86 runs   (    0.54 ms per token,  1858.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2678.69 ms /   512 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3371.80 ms /    86 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6173.13 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.95 ms /   113 runs   (    0.59 ms per token,  1687.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2445.10 ms /   461 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    4391.89 ms /   112 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7012.08 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1874.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2544.79 ms /   486 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
            "llama_print_timings:        eval time =     232.89 ms /     6 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2796.87 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.91 ms /     6 runs   (    0.48 ms per token,  2062.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2678.52 ms /   512 tokens (    5.23 ms per token,   191.15 tokens per second)\n",
            "llama_print_timings:        eval time =     234.47 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2926.65 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.36 ms /   105 runs   (    0.59 ms per token,  1683.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3568.37 ms /   661 tokens (    5.40 ms per token,   185.24 tokens per second)\n",
            "llama_print_timings:        eval time =    4104.09 ms /   104 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7841.30 ms /   765 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1692.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3346.95 ms /   632 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =     236.95 ms /     6 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3601.57 ms /   638 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      25.36 ms /    41 runs   (    0.62 ms per token,  1616.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.02 ms /   469 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.32 ms /    40 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4096.21 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.20 ms /    76 runs   (    0.59 ms per token,  1681.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1790.54 ms /   340 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2914.00 ms /    75 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4820.25 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     166.02 ms /    32 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =     230.11 ms /     6 runs   (   38.35 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =     405.52 ms /    38 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.45 ms /   105 runs   (    0.54 ms per token,  1860.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2854.16 ms /   544 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4080.49 ms /   104 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7077.82 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.44 ms /    55 runs   (    0.54 ms per token,  1868.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3749.15 ms /   692 tokens (    5.42 ms per token,   184.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2133.88 ms /    54 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    5966.66 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.27 ms /    85 runs   (    0.59 ms per token,  1690.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2289.60 ms /   436 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3281.49 ms /    84 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5697.05 ms /   520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.73 ms /   111 runs   (    0.68 ms per token,  1465.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2162.92 ms /   413 tokens (    5.24 ms per token,   190.95 tokens per second)\n",
            "llama_print_timings:        eval time =    4298.09 ms /   110 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    6652.63 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.21 ms /     7 runs   (    0.74 ms per token,  1344.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1854.64 ms /   357 tokens (    5.20 ms per token,   192.49 tokens per second)\n",
            "llama_print_timings:        eval time =     229.85 ms /     6 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2101.68 ms /   363 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.91 ms /    81 runs   (    0.57 ms per token,  1764.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3932.50 ms /   736 tokens (    5.34 ms per token,   187.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3164.03 ms /    80 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    7219.46 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.60 ms /    75 runs   (    0.61 ms per token,  1644.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2624.39 ms /   496 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2944.59 ms /    75 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5691.48 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     9 runs   (    0.56 ms per token,  1800.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1434.16 ms /   277 tokens (    5.18 ms per token,   193.14 tokens per second)\n",
            "llama_print_timings:        eval time =     305.81 ms /     8 runs   (   38.23 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    1759.24 ms /   285 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.30 ms /    12 runs   (    0.61 ms per token,  1644.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2511.39 ms /   474 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =     427.64 ms /    11 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2962.35 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.05 ms /    80 runs   (    0.69 ms per token,  1453.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2253.47 ms /   431 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3084.68 ms /    79 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5478.14 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.89 ms /    81 runs   (    0.54 ms per token,  1845.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4175.59 ms /   774 tokens (    5.39 ms per token,   185.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3182.31 ms /    80 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7478.21 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.24 ms /    76 runs   (    0.74 ms per token,  1351.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4816.34 ms /   882 tokens (    5.46 ms per token,   183.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3039.80 ms /    75 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    8006.91 ms /   957 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.17 ms /    80 runs   (    0.54 ms per token,  1853.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4838.52 ms /   891 tokens (    5.43 ms per token,   184.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3175.53 ms /    79 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    8130.03 ms /   970 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.73 ms /    93 runs   (    0.57 ms per token,  1763.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3821.72 ms /   709 tokens (    5.39 ms per token,   185.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3633.81 ms /    92 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7590.08 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.16 ms /    72 runs   (    0.57 ms per token,  1749.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.58 ms /   448 tokens (    5.20 ms per token,   192.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2773.18 ms /    71 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5205.63 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.09 ms /    91 runs   (    0.56 ms per token,  1781.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5041.03 ms /   916 tokens (    5.50 ms per token,   181.71 tokens per second)\n",
            "llama_print_timings:        eval time =    3629.72 ms /    90 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    8812.52 ms /  1006 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.88 ms /   256 runs   (    0.59 ms per token,  1707.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.57 ms /   519 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =   10057.90 ms /   255 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13205.24 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.92 ms /    81 runs   (    0.60 ms per token,  1655.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4629.90 ms /   852 tokens (    5.43 ms per token,   184.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3227.92 ms /    80 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7997.34 ms /   932 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.51 ms /    72 runs   (    0.53 ms per token,  1869.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3412.39 ms /   634 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2793.33 ms /    71 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6310.43 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.33 ms /   110 runs   (    0.65 ms per token,  1542.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4670.66 ms /   861 tokens (    5.42 ms per token,   184.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4416.41 ms /   109 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    9286.38 ms /   970 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.98 ms /    86 runs   (    0.52 ms per token,  1911.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4990.02 ms /   916 tokens (    5.45 ms per token,   183.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3421.44 ms /    85 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8540.35 ms /  1001 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.94 ms /     6 runs   (    0.49 ms per token,  2038.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5397.86 ms /   983 tokens (    5.49 ms per token,   182.11 tokens per second)\n",
            "llama_print_timings:        eval time =     199.06 ms /     5 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    5619.27 ms /   988 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1894.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5466.93 ms /   998 tokens (    5.48 ms per token,   182.55 tokens per second)\n",
            "llama_print_timings:        eval time =     202.07 ms /     5 runs   (   40.41 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    5691.02 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.25 ms /    56 runs   (    0.68 ms per token,  1464.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4172.17 ms /   776 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2219.28 ms /    55 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    6508.26 ms /   831 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.86 ms /   149 runs   (    0.56 ms per token,  1798.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4269.51 ms /   791 tokens (    5.40 ms per token,   185.27 tokens per second)\n",
            "llama_print_timings:        eval time =    5904.86 ms /   148 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =   10391.86 ms /   939 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.58 ms /    70 runs   (    0.57 ms per token,  1768.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5982.39 ms /  1079 tokens (    5.54 ms per token,   180.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2819.34 ms /    69 runs   (   40.86 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    8918.92 ms /  1148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.04 ms /    52 runs   (    0.56 ms per token,  1790.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2071.99 ms /   398 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1993.78 ms /    51 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    4138.13 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.80 ms /    56 runs   (    0.60 ms per token,  1657.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5376.54 ms /   975 tokens (    5.51 ms per token,   181.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2229.36 ms /    55 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    7704.26 ms /  1030 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.97 ms /    92 runs   (    0.62 ms per token,  1615.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4479.61 ms /   831 tokens (    5.39 ms per token,   185.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3664.05 ms /    91 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8308.14 ms /   922 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.04 ms /    72 runs   (    0.57 ms per token,  1754.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4307.05 ms /   791 tokens (    5.45 ms per token,   183.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2822.60 ms /    71 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7238.50 ms /   862 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.98 ms /    10 runs   (    0.60 ms per token,  1671.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2593.69 ms /   495 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =     354.51 ms /     9 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2968.32 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.23 ms /    74 runs   (    0.68 ms per token,  1473.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.27 ms /   412 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2845.81 ms /    73 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5130.17 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.45 ms /    75 runs   (    0.55 ms per token,  1809.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5320.91 ms /   971 tokens (    5.48 ms per token,   182.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2993.37 ms /    74 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8428.56 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    12 runs   (    0.74 ms per token,  1343.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2644.40 ms /   503 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =     436.00 ms /    11 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    3106.61 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.27 ms /   144 runs   (    0.61 ms per token,  1650.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2399.05 ms /   450 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
            "llama_print_timings:        eval time =    5588.04 ms /   143 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    8209.71 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.40 ms /   256 runs   (    0.58 ms per token,  1725.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1600.02 ms /   312 tokens (    5.13 ms per token,   195.00 tokens per second)\n",
            "llama_print_timings:        eval time =    9920.33 ms /   255 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =   11934.58 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.14 ms /     7 runs   (    0.59 ms per token,  1690.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2720.35 ms /   514 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =     235.89 ms /     6 runs   (   39.32 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2973.18 ms /   520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.66 ms /   256 runs   (    0.60 ms per token,  1655.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2161.15 ms /   414 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9956.38 ms /   255 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12541.17 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.06 ms /    81 runs   (    0.77 ms per token,  1305.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2590.67 ms /   493 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3173.53 ms /    80 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    5931.02 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.46 ms /    72 runs   (    0.55 ms per token,  1824.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3263.14 ms /   608 tokens (    5.37 ms per token,   186.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2791.54 ms /    71 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6163.60 ms /   679 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.81 ms /   102 runs   (    0.64 ms per token,  1573.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3848.61 ms /   719 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4023.57 ms /   101 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    8044.90 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.63 ms /    97 runs   (    0.59 ms per token,  1683.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1700.72 ms /   325 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3739.88 ms /    96 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5588.55 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.44 ms /    67 runs   (    0.63 ms per token,  1578.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4572.01 ms /   846 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2656.66 ms /    66 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    7345.22 ms /   912 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.01 ms /     6 runs   (    0.50 ms per token,  1994.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2651.65 ms /   498 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =     196.62 ms /     5 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2863.00 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1782.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.47 ms /   323 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =     194.93 ms /     5 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    1893.20 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.72 ms /    87 runs   (    0.57 ms per token,  1749.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2116.65 ms /   408 tokens (    5.19 ms per token,   192.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3359.55 ms /    86 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5601.78 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     6 runs   (    0.61 ms per token,  1626.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5364.88 ms /   971 tokens (    5.53 ms per token,   180.99 tokens per second)\n",
            "llama_print_timings:        eval time =     201.37 ms /     5 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5590.39 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5238.06 ms /   960 tokens (    5.46 ms per token,   183.27 tokens per second)\n",
            "llama_print_timings:        eval time =     242.03 ms /     6 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    5506.12 ms /   966 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     6 runs   (    0.61 ms per token,  1633.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1858.65 ms /   359 tokens (    5.18 ms per token,   193.15 tokens per second)\n",
            "llama_print_timings:        eval time =     193.94 ms /     5 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2066.08 ms /   364 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.38 ms /    10 runs   (    0.74 ms per token,  1355.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1411.96 ms /   262 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =     354.63 ms /     9 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    1792.67 ms /   271 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.78 ms /    82 runs   (    0.55 ms per token,  1831.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2993.63 ms /   560 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3194.76 ms /    81 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6309.55 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.96 ms /    79 runs   (    0.53 ms per token,  1882.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2618.68 ms /   496 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3098.45 ms /    79 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5823.41 ms /   575 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.12 ms /    11 runs   (    0.56 ms per token,  1795.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =      86.46 ms /    16 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
            "llama_print_timings:        eval time =     391.28 ms /    10 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =     494.98 ms /    26 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.25 ms /    11 runs   (    0.66 ms per token,  1516.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2686.08 ms /   503 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =     394.31 ms /    10 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3105.50 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.42 ms /    65 runs   (    0.54 ms per token,  1834.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4171.72 ms /   773 tokens (    5.40 ms per token,   185.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2541.75 ms /    64 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    6814.55 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.36 ms /    64 runs   (    0.82 ms per token,  1222.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4268.91 ms /   789 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2545.15 ms /    63 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    6943.49 ms /   852 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.98 ms /    87 runs   (    0.59 ms per token,  1706.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     134.88 ms /    24 tokens (    5.62 ms per token,   177.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3484.18 ms /    87 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    3745.10 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.31 ms /    87 runs   (    0.56 ms per token,  1801.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3262.41 ms /   611 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3369.09 ms /    86 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6754.06 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.59 ms /   102 runs   (    0.53 ms per token,  1903.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4022.06 ms /   739 tokens (    5.44 ms per token,   183.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4002.92 ms /   101 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    8166.98 ms /   840 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     162.48 ms /   256 runs   (    0.63 ms per token,  1575.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2332.53 ms /   445 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =    9995.00 ms /   255 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12768.49 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.21 ms /     9 runs   (    0.58 ms per token,  1725.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2504.91 ms /   474 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     309.93 ms /     8 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2834.37 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.13 ms /   115 runs   (    0.68 ms per token,  1471.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2510.56 ms /   477 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    4493.72 ms /   114 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7216.93 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.63 ms /    12 runs   (    0.55 ms per token,  1809.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.02 ms /   517 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =     431.73 ms /    11 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3177.69 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.05 ms /    72 runs   (    0.58 ms per token,  1712.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4790.65 ms /   883 tokens (    5.43 ms per token,   184.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2853.64 ms /    71 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7762.52 ms /   954 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.44 ms /    78 runs   (    0.56 ms per token,  1795.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3870.20 ms /   715 tokens (    5.41 ms per token,   184.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3038.98 ms /    77 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7024.64 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.19 ms /    87 runs   (    0.58 ms per token,  1733.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3840.29 ms /   719 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3423.09 ms /    86 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7400.78 ms /   805 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1662.36 ms /   315 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =     232.73 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    1914.36 ms /   321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.16 ms /   130 runs   (    0.56 ms per token,  1776.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3832.98 ms /   715 tokens (    5.36 ms per token,   186.54 tokens per second)\n",
            "llama_print_timings:        eval time =    5106.90 ms /   129 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    9124.17 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.77 ms /   109 runs   (    0.63 ms per token,  1585.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1659.33 ms /   320 tokens (    5.19 ms per token,   192.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4237.75 ms /   109 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    6068.94 ms /   429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.89 ms /    85 runs   (    0.54 ms per token,  1852.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4425.59 ms /   821 tokens (    5.39 ms per token,   185.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3347.92 ms /    84 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7897.10 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      98.59 ms /   168 runs   (    0.59 ms per token,  1703.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2098.93 ms /   400 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =    6561.46 ms /   168 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    8911.42 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     107.95 ms /   168 runs   (    0.64 ms per token,  1556.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    6573.47 ms /   168 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6843.88 ms /   168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     132.11 ms /   229 runs   (    0.58 ms per token,  1733.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2300.15 ms /   438 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =    8918.49 ms /   228 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   11573.71 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     116.12 ms /   196 runs   (    0.59 ms per token,  1687.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     377.91 ms /    67 tokens (    5.64 ms per token,   177.29 tokens per second)\n",
            "llama_print_timings:        eval time =    7601.11 ms /   195 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    8282.79 ms /   262 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.30 ms /    44 runs   (    0.64 ms per token,  1554.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4153.89 ms /   773 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1725.33 ms /    43 runs   (   40.12 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    5958.23 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      10.62 ms /    21 runs   (    0.51 ms per token,  1978.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3288.37 ms /   600 tokens (    5.48 ms per token,   182.46 tokens per second)\n",
            "llama_print_timings:        eval time =     835.60 ms /    21 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    4159.57 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.50 ms /    72 runs   (    0.55 ms per token,  1822.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2540.39 ms /   482 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2769.28 ms /    71 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    5411.14 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.89 ms /    83 runs   (    0.69 ms per token,  1458.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.06 ms /   448 tokens (    5.20 ms per token,   192.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3253.37 ms /    83 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5742.06 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.83 ms /   125 runs   (    0.54 ms per token,  1842.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2504.62 ms /   479 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =    4849.17 ms /   124 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    7524.40 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1589.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2238.63 ms /   428 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
            "llama_print_timings:        eval time =     230.66 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2485.10 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.31 ms /    79 runs   (    0.61 ms per token,  1635.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2178.77 ms /   411 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3044.17 ms /    78 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5347.90 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.00 ms /   127 runs   (    0.61 ms per token,  1628.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5883.41 ms /  1070 tokens (    5.50 ms per token,   181.87 tokens per second)\n",
            "llama_print_timings:        eval time =    5182.11 ms /   126 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =   11292.75 ms /  1196 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.96 ms /     6 runs   (    0.49 ms per token,  2029.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5727.73 ms /  1040 tokens (    5.51 ms per token,   181.57 tokens per second)\n",
            "llama_print_timings:        eval time =     204.76 ms /     5 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    5954.12 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.78 ms /    98 runs   (    0.66 ms per token,  1512.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3659.34 ms /   683 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3867.48 ms /    97 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7700.53 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.02 ms /    80 runs   (    0.55 ms per token,  1817.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3703.98 ms /   692 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3112.53 ms /    79 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6930.69 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.43 ms /    11 runs   (    0.58 ms per token,  1710.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.52 ms /   440 tokens (    5.20 ms per token,   192.26 tokens per second)\n",
            "llama_print_timings:        eval time =     428.55 ms /    11 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2738.38 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.60 ms /    83 runs   (    0.62 ms per token,  1608.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2356.78 ms /   442 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3200.14 ms /    82 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5687.72 ms /   524 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.08 ms /    66 runs   (    0.55 ms per token,  1829.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2633.91 ms /   501 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2546.15 ms /    65 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5271.42 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.83 ms /   256 runs   (    0.60 ms per token,  1664.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2589.10 ms /   490 tokens (    5.28 ms per token,   189.26 tokens per second)\n",
            "llama_print_timings:        eval time =   10016.93 ms /   255 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   13017.98 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2811.37 ms /   536 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =     238.01 ms /     6 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    3064.61 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.88 ms /    95 runs   (    0.57 ms per token,  1763.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3096.94 ms /   576 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =    3719.24 ms /    95 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6955.48 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      97.76 ms /   162 runs   (    0.60 ms per token,  1657.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3928.71 ms /   733 tokens (    5.36 ms per token,   186.58 tokens per second)\n",
            "llama_print_timings:        eval time =    6436.61 ms /   161 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =   10638.77 ms /   894 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.91 ms /   139 runs   (    0.54 ms per token,  1855.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3882.40 ms /   723 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    5469.44 ms /   138 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    9548.23 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.35 ms /    61 runs   (    0.61 ms per token,  1633.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2360.38 ms /   445 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2337.30 ms /    60 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4793.92 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.88 ms /    61 runs   (    0.56 ms per token,  1800.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.62 ms /   446 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2344.35 ms /    60 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4758.11 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.37 ms /    68 runs   (    0.70 ms per token,  1435.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1901.60 ms /   368 tokens (    5.17 ms per token,   193.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2646.03 ms /    68 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    4659.22 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.06 ms /   256 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2428.50 ms /   456 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.67 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12816.22 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.45 ms /    54 runs   (    0.58 ms per token,  1716.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2580.30 ms /   485 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2080.34 ms /    53 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    4741.42 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.88 ms /    51 runs   (    0.55 ms per token,  1829.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3698.26 ms /   691 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1976.75 ms /    50 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    5747.48 ms /   741 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.25 ms /    87 runs   (    0.70 ms per token,  1420.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.20 ms /   440 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3410.74 ms /    87 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5859.98 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.74 ms /    86 runs   (    0.54 ms per token,  1839.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.40 ms /   442 tokens (    5.27 ms per token,   189.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3319.53 ms /    85 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5765.23 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1766.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2289.39 ms /   439 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =     233.50 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2537.73 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     128.57 ms /   214 runs   (    0.60 ms per token,  1664.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2120.09 ms /   405 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
            "llama_print_timings:        eval time =    8324.05 ms /   213 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   10777.15 ms /   618 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1773.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.66 ms /   470 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
            "llama_print_timings:        eval time =     233.76 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2706.12 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     7 runs   (    0.71 ms per token,  1400.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1736.73 ms /   336 tokens (    5.17 ms per token,   193.47 tokens per second)\n",
            "llama_print_timings:        eval time =     234.85 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    1987.37 ms /   342 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.32 ms /   170 runs   (    0.55 ms per token,  1802.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2232.83 ms /   424 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =    6605.78 ms /   169 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    9080.54 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1943.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1681.53 ms /   323 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
            "llama_print_timings:        eval time =     233.91 ms /     6 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    1928.52 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      93.39 ms /   156 runs   (    0.60 ms per token,  1670.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1895.37 ms /   362 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =    6033.81 ms /   155 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    8171.25 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1820.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1639.96 ms /   318 tokens (    5.16 ms per token,   193.91 tokens per second)\n",
            "llama_print_timings:        eval time =     193.73 ms /     5 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    1845.72 ms /   323 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1986.23 ms /   384 tokens (    5.17 ms per token,   193.33 tokens per second)\n",
            "llama_print_timings:        eval time =     272.98 ms /     7 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2273.46 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      92.48 ms /   146 runs   (    0.63 ms per token,  1578.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.26 ms /   444 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5658.20 ms /   145 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    8222.61 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2055.22 ms /   392 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =     233.90 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2303.22 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      24.20 ms /    45 runs   (    0.54 ms per token,  1859.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2856.43 ms /   541 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1729.86 ms /    44 runs   (   39.32 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    4648.04 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.96 ms /    99 runs   (    0.59 ms per token,  1708.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2966.47 ms /   558 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3849.03 ms /    98 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6963.61 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.45 ms /    86 runs   (    0.52 ms per token,  1934.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     124.61 ms /    18 tokens (    6.92 ms per token,   144.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3327.22 ms /    85 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3558.87 ms /   103 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.69 ms /   256 runs   (    0.57 ms per token,  1745.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3077.53 ms /   583 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =   10080.54 ms /   255 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   13556.76 ms /   838 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      90.23 ms /   140 runs   (    0.64 ms per token,  1551.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3122.37 ms /   590 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =    5484.75 ms /   139 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    8843.22 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.35 ms /   167 runs   (    0.57 ms per token,  1751.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2628.29 ms /   499 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =    6513.54 ms /   166 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    9382.42 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     130.03 ms /   235 runs   (    0.55 ms per token,  1807.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2794.96 ms /   528 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =    9183.95 ms /   234 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12320.03 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.26 ms /    94 runs   (    0.53 ms per token,  1870.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5592.50 ms /  1013 tokens (    5.52 ms per token,   181.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3773.32 ms /    93 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    9502.92 ms /  1106 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.83 ms /   112 runs   (    0.66 ms per token,  1517.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2677.86 ms /   512 tokens (    5.23 ms per token,   191.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4369.35 ms /   111 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    7238.96 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.52 ms /    86 runs   (    0.55 ms per token,  1809.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4251.40 ms /   790 tokens (    5.38 ms per token,   185.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3380.90 ms /    85 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7751.12 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.95 ms /    74 runs   (    0.59 ms per token,  1683.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3675.62 ms /   688 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2948.14 ms /    74 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    6743.86 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.72 ms /   256 runs   (    0.59 ms per token,  1687.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.07 ms /   432 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
            "llama_print_timings:        eval time =   10056.91 ms /   256 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   12723.04 ms /   688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1795.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.28 ms /   434 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
            "llama_print_timings:        eval time =     193.43 ms /     5 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2494.95 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.70 ms /   165 runs   (    0.57 ms per token,  1742.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1855.04 ms /   360 tokens (    5.15 ms per token,   194.07 tokens per second)\n",
            "llama_print_timings:        eval time =    6425.18 ms /   165 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    8520.60 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.61 ms /   256 runs   (    0.58 ms per token,  1734.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.99 ms /   448 tokens (    5.29 ms per token,   189.03 tokens per second)\n",
            "llama_print_timings:        eval time =    9996.39 ms /   255 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12755.99 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    12 runs   (    0.71 ms per token,  1404.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2058.65 ms /   388 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =     427.38 ms /    11 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2514.05 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.80 ms /    65 runs   (    0.57 ms per token,  1766.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2953.78 ms /   560 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2502.99 ms /    64 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5547.07 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.71 ms /   131 runs   (    0.64 ms per token,  1564.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1855.09 ms /   360 tokens (    5.15 ms per token,   194.06 tokens per second)\n",
            "llama_print_timings:        eval time =    5094.88 ms /   131 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    7155.35 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.99 ms /   256 runs   (    0.57 ms per token,  1753.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1971.23 ms /   372 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
            "llama_print_timings:        eval time =    9987.08 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12348.55 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     137.11 ms /   256 runs   (    0.54 ms per token,  1867.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1973.92 ms /   370 tokens (    5.33 ms per token,   187.44 tokens per second)\n",
            "llama_print_timings:        eval time =    9955.37 ms /   255 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12292.65 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.90 ms /     7 runs   (    0.70 ms per token,  1430.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2316.25 ms /   439 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =     233.60 ms /     6 runs   (   38.93 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2570.51 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.94 ms /     7 runs   (    0.71 ms per token,  1416.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     430.49 ms /    74 tokens (    5.82 ms per token,   171.90 tokens per second)\n",
            "llama_print_timings:        eval time =     231.81 ms /     6 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =     676.52 ms /    80 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.51 ms /    78 runs   (    0.54 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2722.83 ms /   516 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3023.09 ms /    77 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5852.63 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.89 ms /   256 runs   (    0.58 ms per token,  1719.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.95 ms /   439 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =    9967.25 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12661.71 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.00 ms /    72 runs   (    0.61 ms per token,  1636.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3559.80 ms /   666 tokens (    5.35 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2819.39 ms /    71 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    6491.43 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.42 ms /    91 runs   (    0.57 ms per token,  1769.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3374.18 ms /   626 tokens (    5.39 ms per token,   185.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3529.26 ms /    90 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7037.85 ms /   716 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.50 ms /   112 runs   (    0.60 ms per token,  1659.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.13 ms /   463 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
            "llama_print_timings:        eval time =    4357.82 ms /   111 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6947.33 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.27 ms /   256 runs   (    0.58 ms per token,  1726.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2220.62 ms /   423 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
            "llama_print_timings:        eval time =    9972.40 ms /   255 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12590.73 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.23 ms /    65 runs   (    0.54 ms per token,  1844.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3634.12 ms /   675 tokens (    5.38 ms per token,   185.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2518.26 ms /    64 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6244.68 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.70 ms /     9 runs   (    0.63 ms per token,  1577.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6466.03 ms /  1168 tokens (    5.54 ms per token,   180.64 tokens per second)\n",
            "llama_print_timings:        eval time =     372.37 ms /     9 runs   (   41.37 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =    6868.78 ms /  1177 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.97 ms /    90 runs   (    0.54 ms per token,  1837.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5443.85 ms /   989 tokens (    5.50 ms per token,   181.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3601.12 ms /    89 runs   (   40.46 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    9178.90 ms /  1078 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.18 ms /    75 runs   (    0.66 ms per token,  1525.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.55 ms /   459 tokens (    5.26 ms per token,   189.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2901.88 ms /    74 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5441.28 ms /   533 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.68 ms /    77 runs   (    0.54 ms per token,  1847.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2689.09 ms /   507 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2980.96 ms /    76 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5773.62 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.61 ms /    64 runs   (    0.56 ms per token,  1797.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2067.65 ms /   395 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2443.84 ms /    63 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    4596.93 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     128.91 ms /   227 runs   (    0.57 ms per token,  1760.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3190.69 ms /   595 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =    8904.14 ms /   226 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   12436.37 ms /   821 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.37 ms /   105 runs   (    0.53 ms per token,  1896.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5212.08 ms /   950 tokens (    5.49 ms per token,   182.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4198.88 ms /   104 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    9562.78 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.10 ms /    74 runs   (    0.69 ms per token,  1448.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5352.57 ms /   980 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2974.41 ms /    73 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    8461.08 ms /  1053 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.15 ms /    96 runs   (    0.56 ms per token,  1772.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2685.16 ms /   507 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3730.64 ms /    95 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6552.58 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.51 ms /    68 runs   (    0.68 ms per token,  1462.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3609.18 ms /   679 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2662.12 ms /    67 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6396.21 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.90 ms /    75 runs   (    0.53 ms per token,  1879.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5417.74 ms /   989 tokens (    5.48 ms per token,   182.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2993.48 ms /    74 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8519.86 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.84 ms /    12 runs   (    0.57 ms per token,  1755.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1599.41 ms /   311 tokens (    5.14 ms per token,   194.45 tokens per second)\n",
            "llama_print_timings:        eval time =     426.32 ms /    11 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2044.33 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.07 ms /    12 runs   (    0.59 ms per token,  1697.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     456.05 ms /    12 runs   (   38.00 ms per token,    26.31 tokens per second)\n",
            "llama_print_timings:       total time =     473.23 ms /    12 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.21 ms /   256 runs   (    0.56 ms per token,  1775.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2749.50 ms /   514 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.42 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13131.27 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.53 ms /     7 runs   (    0.65 ms per token,  1543.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2481.71 ms /   466 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
            "llama_print_timings:        eval time =     233.65 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2734.19 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.21 ms /    80 runs   (    0.57 ms per token,  1769.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4074.38 ms /   755 tokens (    5.40 ms per token,   185.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3138.33 ms /    79 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    7328.74 ms /   834 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.36 ms /   139 runs   (    0.61 ms per token,  1647.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4807.48 ms /   888 tokens (    5.41 ms per token,   184.71 tokens per second)\n",
            "llama_print_timings:        eval time =    5617.11 ms /   139 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   10643.27 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.39 ms /   256 runs   (    0.58 ms per token,  1713.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3076.56 ms /   584 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
            "llama_print_timings:        eval time =   10098.47 ms /   255 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =   13591.21 ms /   839 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.56 ms /    60 runs   (    0.58 ms per token,  1736.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1638.87 ms /   315 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2276.60 ms /    59 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    3999.06 ms /   374 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.74 ms /    60 runs   (    0.58 ms per token,  1726.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2312.01 ms /    60 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2393.56 ms /    60 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.38 ms /   101 runs   (    0.55 ms per token,  1823.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4964.27 ms /   909 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4023.32 ms /   100 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    9133.04 ms /  1009 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.77 ms /    67 runs   (    0.58 ms per token,  1728.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1854.14 ms /   358 tokens (    5.18 ms per token,   193.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2559.28 ms /    66 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    4508.00 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      26.48 ms /    51 runs   (    0.52 ms per token,  1926.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3914.32 ms /   727 tokens (    5.38 ms per token,   185.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1967.84 ms /    50 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5960.09 ms /   777 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.00 ms /   105 runs   (    0.56 ms per token,  1779.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.38 ms /   519 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4084.58 ms /   104 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6950.61 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.99 ms /   105 runs   (    0.67 ms per token,  1500.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    4126.61 ms /   105 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    4297.91 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2074.96 ms /   400 tokens (    5.19 ms per token,   192.77 tokens per second)\n",
            "llama_print_timings:        eval time =     232.18 ms /     6 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2322.48 ms /   406 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.93 ms /   104 runs   (    0.55 ms per token,  1826.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     506.61 ms /    92 tokens (    5.51 ms per token,   181.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4022.22 ms /   103 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    4666.19 ms /   195 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.19 ms /   326 tokens (    5.17 ms per token,   193.45 tokens per second)\n",
            "llama_print_timings:        eval time =     233.36 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    1932.73 ms /   332 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.55 ms /   118 runs   (    0.61 ms per token,  1649.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1578.67 ms /   298 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =    4540.00 ms /   117 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    6294.44 ms /   415 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.04 ms /   256 runs   (    0.61 ms per token,  1640.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.76 ms /   453 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =   10022.89 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12815.81 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.22 ms /   106 runs   (    0.56 ms per token,  1789.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2760.73 ms /   522 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =    4117.39 ms /   105 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7023.39 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.38 ms /    67 runs   (    0.68 ms per token,  1476.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2305.21 ms /   438 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2576.60 ms /    66 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4993.22 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.98 ms /    93 runs   (    0.60 ms per token,  1661.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.02 ms /   426 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3581.94 ms /    92 runs   (   38.93 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5963.36 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1898.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2589.15 ms /   496 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
            "llama_print_timings:        eval time =     235.66 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2839.14 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     6 runs   (    0.69 ms per token,  1459.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2707.20 ms /   510 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     199.55 ms /     5 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    2925.78 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1996.38 ms /   384 tokens (    5.20 ms per token,   192.35 tokens per second)\n",
            "llama_print_timings:        eval time =     271.54 ms /     7 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2282.86 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1840.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     418.30 ms /    78 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
            "llama_print_timings:        eval time =     233.73 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =     662.83 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.46 ms /    14 runs   (    0.53 ms per token,  1877.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1481.26 ms /   288 tokens (    5.14 ms per token,   194.43 tokens per second)\n",
            "llama_print_timings:        eval time =     499.19 ms /    13 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2002.55 ms /   301 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.86 ms /    69 runs   (    0.52 ms per token,  1924.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1942.52 ms /   376 tokens (    5.17 ms per token,   193.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2673.79 ms /    69 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    4705.80 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.90 ms /   256 runs   (    0.59 ms per token,  1685.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1611.16 ms /   312 tokens (    5.16 ms per token,   193.65 tokens per second)\n",
            "llama_print_timings:        eval time =    9922.62 ms /   255 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =   11930.90 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1917.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.89 ms /   376 tokens (    5.16 ms per token,   193.63 tokens per second)\n",
            "llama_print_timings:        eval time =     231.43 ms /     6 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2185.96 ms /   382 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.89 ms /   105 runs   (    0.57 ms per token,  1753.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2137.16 ms /   405 tokens (    5.28 ms per token,   189.50 tokens per second)\n",
            "llama_print_timings:        eval time =    4052.29 ms /   104 runs   (   38.96 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6340.20 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1888.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2374.15 ms /   455 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =     233.34 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2622.01 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1747.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.37 ms /   416 tokens (    5.19 ms per token,   192.56 tokens per second)\n",
            "llama_print_timings:        eval time =     232.10 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2406.75 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.69 ms /    97 runs   (    0.71 ms per token,  1412.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1755.53 ms /   332 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3756.94 ms /    96 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5680.43 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      25.95 ms /    49 runs   (    0.53 ms per token,  1888.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3249.14 ms /   613 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1895.06 ms /    48 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    5216.41 ms /   661 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.39 ms /   116 runs   (    0.68 ms per token,  1479.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4109.16 ms /   768 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
            "llama_print_timings:        eval time =    4652.89 ms /   116 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    8965.99 ms /   884 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.92 ms /   112 runs   (    0.53 ms per token,  1900.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3252.76 ms /   613 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =    4352.05 ms /   111 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7757.25 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      91.74 ms /   157 runs   (    0.58 ms per token,  1711.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3275.74 ms /   613 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =    6148.90 ms /   156 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    9663.55 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.01 ms /    78 runs   (    0.62 ms per token,  1624.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3308.14 ms /   624 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3044.84 ms /    77 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    6477.02 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.64 ms /    56 runs   (    0.62 ms per token,  1616.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     775.44 ms /   147 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2112.21 ms /    55 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2975.28 ms /   202 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.48 ms /    69 runs   (    0.54 ms per token,  1840.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.89 ms /   510 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2666.07 ms /    68 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5435.62 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.14 ms /   419 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     229.30 ms /     6 runs   (   38.22 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2438.29 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.64 ms /    65 runs   (    0.72 ms per token,  1393.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     892.27 ms /   175 tokens (    5.10 ms per token,   196.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2469.52 ms /    64 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    3471.54 ms /   239 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.08 ms /   256 runs   (    0.56 ms per token,  1776.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2387.54 ms /   453 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =   10002.94 ms /   255 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   12785.59 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.27 ms /    91 runs   (    0.56 ms per token,  1774.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3634.38 ms /   676 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3535.47 ms /    90 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7301.40 ms /   766 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.48 ms /   256 runs   (    0.61 ms per token,  1646.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.08 ms /   415 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =    9944.23 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12523.00 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.34 ms /   256 runs   (    0.61 ms per token,  1627.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1812.40 ms /   347 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =    9928.79 ms /   255 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12165.02 ms /   602 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1668.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2497.10 ms /   474 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
            "llama_print_timings:        eval time =     232.51 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2744.61 ms /   480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.48 ms /    78 runs   (    0.66 ms per token,  1515.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2374.06 ms /   451 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3013.89 ms /    77 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5517.28 ms /   528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.52 ms /   111 runs   (    0.56 ms per token,  1775.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3952.64 ms /   732 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
            "llama_print_timings:        eval time =    4366.83 ms /   110 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    8483.45 ms /   842 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.38 ms /    68 runs   (    0.68 ms per token,  1466.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3523.21 ms /   663 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2667.70 ms /    67 runs   (   39.82 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6312.67 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1835.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1698.65 ms /   328 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
            "llama_print_timings:        eval time =     272.43 ms /     7 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    1985.05 ms /   335 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1715.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2203.42 ms /   424 tokens (    5.20 ms per token,   192.43 tokens per second)\n",
            "llama_print_timings:        eval time =     271.34 ms /     7 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2491.24 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.76 ms /    12 runs   (    0.56 ms per token,  1774.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.28 ms /   470 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     428.45 ms /    11 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2912.46 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.03 ms /    94 runs   (    0.66 ms per token,  1515.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2670.60 ms /   506 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3671.49 ms /    93 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6507.55 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_PEPSICO INC_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.63 ms /   104 runs   (    0.53 ms per token,  1903.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3620.43 ms /   680 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4061.49 ms /   103 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7822.62 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      91.33 ms /   173 runs   (    0.53 ms per token,  1894.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5015.27 ms /   918 tokens (    5.46 ms per token,   183.04 tokens per second)\n",
            "llama_print_timings:        eval time =    6949.48 ms /   172 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   12216.96 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.07 ms /    90 runs   (    0.66 ms per token,  1523.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2381.23 ms /   453 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3489.92 ms /    89 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6034.30 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.89 ms /    65 runs   (    0.57 ms per token,  1761.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3804.90 ms /   711 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2523.14 ms /    64 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6426.32 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.67 ms /    85 runs   (    0.68 ms per token,  1473.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4378.45 ms /   810 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3392.34 ms /    84 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    7932.95 ms /   894 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.48 ms /    75 runs   (    0.54 ms per token,  1852.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5553.13 ms /  1016 tokens (    5.47 ms per token,   182.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3041.18 ms /    75 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    8705.89 ms /  1091 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.10 ms /   256 runs   (    0.57 ms per token,  1764.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2388.43 ms /   453 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
            "llama_print_timings:        eval time =    9953.69 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12745.31 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1790.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.47 ms /    24 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
            "llama_print_timings:        eval time =     230.70 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =     370.11 ms /    30 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.12 ms /    88 runs   (    0.59 ms per token,  1688.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3679.03 ms /   684 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3443.58 ms /    87 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    7262.13 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.79 ms /    71 runs   (    0.57 ms per token,  1740.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4943.34 ms /   911 tokens (    5.43 ms per token,   184.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2814.07 ms /    70 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7864.05 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.18 ms /   105 runs   (    0.55 ms per token,  1804.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3932.14 ms /   728 tokens (    5.40 ms per token,   185.14 tokens per second)\n",
            "llama_print_timings:        eval time =    4117.50 ms /   104 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    8200.31 ms /   832 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.93 ms /    94 runs   (    0.62 ms per token,  1622.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2946.75 ms /   555 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3657.57 ms /    93 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6752.07 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.97 ms /    96 runs   (    0.54 ms per token,  1847.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5435.20 ms /   990 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3847.71 ms /    95 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    9430.66 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.94 ms /    70 runs   (    0.60 ms per token,  1668.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5059.59 ms /   925 tokens (    5.47 ms per token,   182.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2784.97 ms /    69 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7957.63 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.27 ms /    61 runs   (    0.56 ms per token,  1780.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5375.12 ms /   980 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2424.65 ms /    60 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    7892.46 ms /  1040 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.68 ms /   256 runs   (    0.55 ms per token,  1832.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2800.51 ms /   527 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.24 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13183.44 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.53 ms /    76 runs   (    0.53 ms per token,  1874.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6547.04 ms /  1173 tokens (    5.58 ms per token,   179.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3080.69 ms /    75 runs   (   41.08 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    9743.71 ms /  1248 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.96 ms /    68 runs   (    0.69 ms per token,  1448.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3933.45 ms /   736 tokens (    5.34 ms per token,   187.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2725.73 ms /    68 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    6795.12 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.41 ms /    63 runs   (    0.56 ms per token,  1779.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1952.50 ms /   372 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2398.36 ms /    62 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    4441.60 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.27 ms /   100 runs   (    0.62 ms per token,  1605.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4196.41 ms /   780 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3957.74 ms /    99 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    8319.04 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.54 ms /    69 runs   (    0.56 ms per token,  1790.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2960.87 ms /   554 tokens (    5.34 ms per token,   187.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2674.10 ms /    68 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5729.66 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.16 ms /    73 runs   (    0.56 ms per token,  1773.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.85 ms /   376 tokens (    5.16 ms per token,   193.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2831.42 ms /    73 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    4871.25 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.65 ms /   256 runs   (    0.57 ms per token,  1757.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2088.11 ms /   400 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9992.60 ms /   256 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12466.31 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.56 ms /    52 runs   (    0.65 ms per token,  1549.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     934.56 ms /   184 tokens (    5.08 ms per token,   196.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1993.86 ms /    52 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    3010.92 ms /   236 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1905.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2268.32 ms /   429 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =     231.81 ms /     6 runs   (   38.63 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2523.79 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.08 ms /   113 runs   (    0.57 ms per token,  1763.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2070.43 ms /   398 tokens (    5.20 ms per token,   192.23 tokens per second)\n",
            "llama_print_timings:        eval time =    4360.01 ms /   112 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    6591.07 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1864.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1897.32 ms /   364 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
            "llama_print_timings:        eval time =     229.77 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2140.56 ms /   370 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.90 ms /    64 runs   (    0.70 ms per token,  1425.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1270.97 ms /   248 tokens (    5.12 ms per token,   195.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2486.23 ms /    64 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3867.21 ms /   312 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.16 ms /    69 runs   (    0.55 ms per token,  1808.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2552.61 ms /   483 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2659.66 ms /    68 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5308.87 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.65 ms /   256 runs   (    0.60 ms per token,  1677.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.22 ms /   386 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9931.54 ms /   255 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12375.89 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.43 ms /    70 runs   (    0.56 ms per token,  1775.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1223.85 ms /   236 tokens (    5.19 ms per token,   192.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2644.39 ms /    69 runs   (   38.32 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    3961.38 ms /   305 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     7 runs   (    0.70 ms per token,  1425.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.24 ms /   460 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =     235.07 ms /     6 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2668.51 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1450.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2272.25 ms /   430 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =     234.79 ms /     6 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2526.00 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.80 ms /   101 runs   (    0.55 ms per token,  1810.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1607.95 ms /   310 tokens (    5.19 ms per token,   192.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3858.88 ms /   100 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    5601.96 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1858.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2678.28 ms /   512 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     196.17 ms /     5 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2888.47 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.08 ms /    58 runs   (    0.55 ms per token,  1807.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4969.43 ms /   907 tokens (    5.48 ms per token,   182.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2294.99 ms /    57 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    7355.42 ms /   964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1832.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1809.08 ms /   348 tokens (    5.20 ms per token,   192.36 tokens per second)\n",
            "llama_print_timings:        eval time =     232.52 ms /     6 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2054.84 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     110.20 ms /   184 runs   (    0.60 ms per token,  1669.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4938.39 ms /   912 tokens (    5.41 ms per token,   184.68 tokens per second)\n",
            "llama_print_timings:        eval time =    7417.97 ms /   183 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   12654.32 ms /  1095 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1915.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2502.42 ms /   476 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =     232.65 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2750.26 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.62 ms /    97 runs   (    0.64 ms per token,  1574.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4989.45 ms /   915 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3890.49 ms /    96 runs   (   40.53 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    9050.68 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.62 ms /   256 runs   (    0.59 ms per token,  1688.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1682.86 ms /   322 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =    9936.21 ms /   255 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =   12038.98 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.60 ms /   256 runs   (    0.56 ms per token,  1782.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1766.15 ms /   341 tokens (    5.18 ms per token,   193.08 tokens per second)\n",
            "llama_print_timings:        eval time =    9950.50 ms /   255 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12113.02 ms /   596 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.02 ms /    11 runs   (    0.55 ms per token,  1826.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2558.57 ms /   482 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     393.37 ms /    10 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2973.09 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.07 ms /    63 runs   (    0.52 ms per token,  1904.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3926.85 ms /   735 tokens (    5.34 ms per token,   187.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2445.95 ms /    62 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6459.75 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.59 ms /   256 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3050.21 ms /   572 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =   10062.56 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13501.97 ms /   827 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.14 ms /     9 runs   (    0.57 ms per token,  1751.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     481.66 ms /    96 tokens (    5.02 ms per token,   199.31 tokens per second)\n",
            "llama_print_timings:        eval time =     341.45 ms /     9 runs   (   37.94 ms per token,    26.36 tokens per second)\n",
            "llama_print_timings:       total time =     836.19 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.64 ms /    66 runs   (    0.60 ms per token,  1664.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2610.61 ms /   490 tokens (    5.33 ms per token,   187.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2549.08 ms /    65 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5269.64 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1825.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2025.31 ms /   389 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =     193.49 ms /     5 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2231.57 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.95 ms /   256 runs   (    0.60 ms per token,  1662.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1646.52 ms /   320 tokens (    5.15 ms per token,   194.35 tokens per second)\n",
            "llama_print_timings:        eval time =    9905.44 ms /   255 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =   11969.57 ms /   575 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.12 ms /    51 runs   (    0.55 ms per token,  1813.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2203.07 ms /   422 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1953.99 ms /    50 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4226.68 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.80 ms /    12 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2500.28 ms /   474 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =     429.55 ms /    11 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2951.75 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.44 ms /    85 runs   (    0.61 ms per token,  1652.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2521.60 ms /   477 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3288.19 ms /    84 runs   (   39.15 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5943.65 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.03 ms /    75 runs   (    0.57 ms per token,  1743.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5264.60 ms /   968 tokens (    5.44 ms per token,   183.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3031.63 ms /    75 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    8408.62 ms /  1043 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.87 ms /     7 runs   (    0.70 ms per token,  1437.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2358.25 ms /   442 tokens (    5.34 ms per token,   187.43 tokens per second)\n",
            "llama_print_timings:        eval time =     236.51 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2613.58 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1693.36 ms /   323 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =     230.71 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    1938.69 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     7 runs   (    0.60 ms per token,  1661.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2281.33 ms /   434 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =     231.85 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2527.81 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.26 ms /    96 runs   (    0.60 ms per token,  1676.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3073.42 ms /   579 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3743.19 ms /    95 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6961.57 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.81 ms /    95 runs   (    0.52 ms per token,  1907.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4190.97 ms /   776 tokens (    5.40 ms per token,   185.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3772.06 ms /    95 runs   (   39.71 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    8096.53 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.08 ms /   256 runs   (    0.59 ms per token,  1705.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.00 ms /   467 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
            "llama_print_timings:        eval time =   10007.77 ms /   255 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12880.08 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     161.67 ms /   256 runs   (    0.63 ms per token,  1583.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     974.14 ms /   186 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9836.73 ms /   255 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =   11234.51 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2283.75 ms /   434 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     229.27 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2528.23 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1776.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1853.26 ms /   358 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
            "llama_print_timings:        eval time =     229.95 ms /     6 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2096.87 ms /   364 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.44 ms /   363 tokens (    5.22 ms per token,   191.41 tokens per second)\n",
            "llama_print_timings:        eval time =     230.65 ms /     6 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2146.11 ms /   369 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Kraft Heinz Co_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Amcor plc_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Amcor plc_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.34 ms /    70 runs   (    0.63 ms per token,  1578.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2577.65 ms /   488 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2708.15 ms /    69 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5401.04 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.48 ms /    69 runs   (    0.56 ms per token,  1793.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2697.20 ms /    69 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2788.56 ms /    69 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.90 ms /   147 runs   (    0.65 ms per token,  1548.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5307.53 ms /   970 tokens (    5.47 ms per token,   182.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5948.34 ms /   146 runs   (   40.74 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =   11507.68 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.06 ms /    90 runs   (    0.59 ms per token,  1696.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4468.56 ms /   827 tokens (    5.40 ms per token,   185.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3556.18 ms /    89 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    8161.49 ms /   916 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.73 ms /    70 runs   (    0.64 ms per token,  1564.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1795.76 ms /   344 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2714.82 ms /    70 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    4617.68 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1841.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4198.35 ms /   779 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
            "llama_print_timings:        eval time =     197.21 ms /     5 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    4413.29 ms /   784 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.77 ms /    83 runs   (    0.66 ms per token,  1515.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4478.31 ms /   832 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3351.84 ms /    83 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    7984.90 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.07 ms /    97 runs   (    0.55 ms per token,  1827.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4425.96 ms /   820 tokens (    5.40 ms per token,   185.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3829.50 ms /    96 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    8392.15 ms /   916 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1842.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5687.31 ms /  1032 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
            "llama_print_timings:        eval time =     245.06 ms /     6 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    5956.99 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.15 ms /    56 runs   (    0.54 ms per token,  1857.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5355.37 ms /   980 tokens (    5.46 ms per token,   182.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2222.35 ms /    55 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    7660.15 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.96 ms /    70 runs   (    0.71 ms per token,  1401.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3324.16 ms /   624 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2716.67 ms /    69 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6161.06 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.99 ms /   149 runs   (    0.64 ms per token,  1568.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5685.37 ms /  1035 tokens (    5.49 ms per token,   182.05 tokens per second)\n",
            "llama_print_timings:        eval time =    6059.62 ms /   148 runs   (   40.94 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =   12011.73 ms /  1183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.45 ms /   109 runs   (    0.56 ms per token,  1773.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3297.82 ms /   624 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =    4241.11 ms /   108 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    7690.56 ms /   732 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.84 ms /    94 runs   (    0.71 ms per token,  1406.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1899.69 ms /   365 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3617.67 ms /    93 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    5680.91 ms /   458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     137.19 ms /   241 runs   (    0.57 ms per token,  1756.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4475.27 ms /   832 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
            "llama_print_timings:        eval time =    9719.42 ms /   241 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =   14591.17 ms /  1073 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     128.40 ms /   241 runs   (    0.53 ms per token,  1876.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    9687.61 ms /   241 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =   10041.13 ms /   241 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.06 ms /    65 runs   (    0.54 ms per token,  1854.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2231.83 ms /   420 tokens (    5.31 ms per token,   188.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2494.12 ms /    64 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4819.46 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.26 ms /    65 runs   (    0.54 ms per token,  1843.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2527.70 ms /    65 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2609.74 ms /    65 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.77 ms /   256 runs   (    0.59 ms per token,  1697.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.45 ms /   471 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =    9998.32 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12868.15 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.94 ms /   256 runs   (    0.59 ms per token,  1707.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   10059.73 ms /   256 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   10465.78 ms /   256 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.03 ms /    62 runs   (    0.58 ms per token,  1720.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1351.83 ms /   264 tokens (    5.12 ms per token,   195.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2375.12 ms /    62 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    3810.79 ms /   326 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.55 ms /   107 runs   (    0.62 ms per token,  1607.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.69 ms /   420 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4148.00 ms /   106 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6515.91 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.01 ms /    73 runs   (    0.55 ms per token,  1824.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2216.35 ms /   423 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2814.34 ms /    72 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5128.61 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1706.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.80 ms /   440 tokens (    5.20 ms per token,   192.41 tokens per second)\n",
            "llama_print_timings:        eval time =     271.51 ms /     7 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2573.85 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1697.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.94 ms /    21 tokens (    6.00 ms per token,   166.74 tokens per second)\n",
            "llama_print_timings:        eval time =     232.51 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =     369.57 ms /    27 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1872.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.46 ms /   442 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =     234.40 ms /     6 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2574.24 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.89 ms /     7 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1961.37 ms /   376 tokens (    5.22 ms per token,   191.70 tokens per second)\n",
            "llama_print_timings:        eval time =     271.37 ms /     7 runs   (   38.77 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2251.30 ms /   383 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.61 ms /   120 runs   (    0.56 ms per token,  1774.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3048.88 ms /   574 tokens (    5.31 ms per token,   188.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4669.46 ms /   119 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7887.73 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.97 ms /    84 runs   (    0.65 ms per token,  1528.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3117.66 ms /   584 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3295.43 ms /    83 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6556.15 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.91 ms /    64 runs   (    0.53 ms per token,  1887.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4347.45 ms /   806 tokens (    5.39 ms per token,   185.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2505.01 ms /    63 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6942.63 ms /   869 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.97 ms /   122 runs   (    0.66 ms per token,  1506.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3467.60 ms /   650 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4803.31 ms /   121 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    8476.37 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.54 ms /    63 runs   (    0.60 ms per token,  1678.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.60 ms /   447 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2412.95 ms /    62 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4835.48 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.34 ms /    65 runs   (    0.59 ms per token,  1695.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1728.90 ms /   336 tokens (    5.15 ms per token,   194.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2516.23 ms /    65 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    4339.52 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.05 ms /    65 runs   (    0.69 ms per token,  1442.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2520.53 ms /    65 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2628.11 ms /    65 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.50 ms /   147 runs   (    0.52 ms per token,  1921.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3256.55 ms /   611 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5740.43 ms /   146 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    9196.28 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      90.42 ms /   147 runs   (    0.62 ms per token,  1625.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    5826.22 ms /   147 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    6064.78 ms /   147 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.48 ms /    11 runs   (    0.59 ms per token,  1697.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2458.03 ms /   468 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     385.29 ms /    10 runs   (   38.53 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2864.12 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.53 ms /   230 runs   (    0.60 ms per token,  1660.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2414.30 ms /   459 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    8987.77 ms /   229 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   11780.93 ms /   688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.71 ms /   255 runs   (    0.61 ms per token,  1648.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1984.69 ms /   381 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9933.35 ms /   254 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12335.81 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.00 ms /   255 runs   (    0.59 ms per token,  1688.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    9957.60 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   10356.96 ms /   255 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.06 ms /   256 runs   (    0.56 ms per token,  1789.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2178.17 ms /   410 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =    9964.19 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12534.92 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.07 ms /    90 runs   (    0.55 ms per token,  1834.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2316.03 ms /   438 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3472.45 ms /    89 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5915.94 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.38 ms /    72 runs   (    0.55 ms per token,  1828.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2805.07 ms /   530 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2790.99 ms /    71 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5693.97 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.65 ms /    96 runs   (    0.59 ms per token,  1694.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2964.03 ms /   558 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3725.06 ms /    95 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6837.15 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1757.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2679.69 ms /   511 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     236.03 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2934.45 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.74 ms /    79 runs   (    0.65 ms per token,  1526.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.94 ms /   454 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3051.22 ms /    78 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5546.74 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.03 ms /    93 runs   (    0.60 ms per token,  1659.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1573.12 ms /   298 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3549.74 ms /    92 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    5257.93 ms /   390 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.50 ms /    93 runs   (    0.58 ms per token,  1738.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3584.48 ms /    93 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    3708.56 ms /    93 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.94 ms /    66 runs   (    0.62 ms per token,  1612.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1601.05 ms /   307 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2512.23 ms /    65 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    4210.46 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.45 ms /    11 runs   (    0.50 ms per token,  2019.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2977.43 ms /   560 tokens (    5.32 ms per token,   188.08 tokens per second)\n",
            "llama_print_timings:        eval time =     389.05 ms /    10 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3388.96 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.43 ms /    12 runs   (    0.54 ms per token,  1867.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.04 ms /   455 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
            "llama_print_timings:        eval time =     429.82 ms /    11 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2821.56 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     7 runs   (    0.64 ms per token,  1565.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1767.70 ms /   340 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
            "llama_print_timings:        eval time =     235.82 ms /     6 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2017.87 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.17 ms /    93 runs   (    0.59 ms per token,  1685.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.62 ms /   344 tokens (    5.14 ms per token,   194.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3602.48 ms /    93 runs   (   38.74 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    5511.07 ms /   437 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.25 ms /    88 runs   (    0.58 ms per token,  1717.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2143.74 ms /   406 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3386.55 ms /    87 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5654.55 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.47 ms /     9 runs   (    0.61 ms per token,  1645.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1390.50 ms /   272 tokens (    5.11 ms per token,   195.61 tokens per second)\n",
            "llama_print_timings:        eval time =     305.66 ms /     8 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    1711.59 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2635.20 ms /   502 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =     235.75 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    2887.04 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.11 ms /   112 runs   (    0.67 ms per token,  1491.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2161.15 ms /   415 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
            "llama_print_timings:        eval time =    4328.78 ms /   111 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    6681.22 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1851.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.45 ms /   456 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =     269.84 ms /     7 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2656.92 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     114.59 ms /   179 runs   (    0.64 ms per token,  1562.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.56 ms /   438 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =    6984.86 ms /   178 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    9565.46 ms /   616 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     117.39 ms /   210 runs   (    0.56 ms per token,  1788.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2121.34 ms /   408 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
            "llama_print_timings:        eval time =    8156.42 ms /   209 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   10582.21 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.02 ms /     7 runs   (    0.72 ms per token,  1394.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2058.30 ms /   387 tokens (    5.32 ms per token,   188.02 tokens per second)\n",
            "llama_print_timings:        eval time =     232.43 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2309.25 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.32 ms /    96 runs   (    0.56 ms per token,  1800.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1692.76 ms /   326 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3676.60 ms /    95 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    5498.10 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.25 ms /    95 runs   (    0.59 ms per token,  1688.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2238.64 ms /   427 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3677.01 ms /    94 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6058.15 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Amcor plc_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Square, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Square, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1935.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2493.71 ms /   468 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =     229.91 ms /     6 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2740.07 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.52 ms /     6 runs   (    0.59 ms per token,  1706.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3428.89 ms /   644 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =     195.38 ms /     5 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3641.57 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.08 ms /   104 runs   (    0.56 ms per token,  1790.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.48 ms /   397 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4013.34 ms /   103 runs   (   38.96 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6225.39 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     115.42 ms /   210 runs   (    0.55 ms per token,  1819.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3117.66 ms /   581 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
            "llama_print_timings:        eval time =    8217.92 ms /   209 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   11642.34 ms /   790 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.78 ms /     7 runs   (    0.83 ms per token,  1210.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.97 ms /   387 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
            "llama_print_timings:        eval time =     234.78 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2282.80 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.44 ms /    69 runs   (    0.63 ms per token,  1588.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1666.03 ms /   320 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2621.80 ms /    68 runs   (   38.56 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    4400.30 ms /   388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1938.83 ms /   374 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
            "llama_print_timings:        eval time =     231.10 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2184.56 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.62 ms /    96 runs   (    0.56 ms per token,  1790.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1860.14 ms /   359 tokens (    5.18 ms per token,   193.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3690.50 ms /    95 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    5681.27 ms /   454 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.02 ms /     6 runs   (    0.50 ms per token,  1986.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5635.45 ms /  1023 tokens (    5.51 ms per token,   181.53 tokens per second)\n",
            "llama_print_timings:        eval time =     203.41 ms /     5 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    5861.87 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.39 ms /   256 runs   (    0.59 ms per token,  1702.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.44 ms /   450 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
            "llama_print_timings:        eval time =   10018.46 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12803.58 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.54 ms /    72 runs   (    0.55 ms per token,  1820.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3295.02 ms /   622 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2798.67 ms /    71 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6190.82 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.94 ms /    62 runs   (    0.55 ms per token,  1826.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5631.84 ms /  1024 tokens (    5.50 ms per token,   181.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2512.79 ms /    62 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    8238.92 ms /  1086 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.26 ms /    82 runs   (    0.66 ms per token,  1511.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8133.90 ms /  1439 tokens (    5.65 ms per token,   176.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3418.86 ms /    81 runs   (   42.21 ms per token,    23.69 tokens per second)\n",
            "llama_print_timings:       total time =   11709.97 ms /  1520 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.95 ms /   256 runs   (    0.59 ms per token,  1707.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1683.72 ms /   322 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
            "llama_print_timings:        eval time =    9932.57 ms /   255 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12025.33 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cash flow generated from operations and are there any notable trends or fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.08 ms /     9 runs   (    0.56 ms per token,  1770.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2642.49 ms /   499 tokens (    5.30 ms per token,   188.84 tokens per second)\n",
            "llama_print_timings:        eval time =     313.69 ms /     8 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2974.44 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      25.89 ms /    47 runs   (    0.55 ms per token,  1815.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3735.06 ms /   699 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1811.60 ms /    46 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5613.85 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.50 ms /   256 runs   (    0.57 ms per token,  1747.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1983.19 ms /   384 tokens (    5.16 ms per token,   193.63 tokens per second)\n",
            "llama_print_timings:        eval time =    9993.51 ms /   256 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12361.20 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.45 ms /    90 runs   (    0.55 ms per token,  1819.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5715.51 ms /  1040 tokens (    5.50 ms per token,   181.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3662.60 ms /    90 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    9509.16 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.34 ms /   123 runs   (    0.55 ms per token,  1826.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.03 ms /   472 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4817.94 ms /   123 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    7436.29 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.56 ms /    79 runs   (    0.54 ms per token,  1856.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5012.51 ms /   918 tokens (    5.46 ms per token,   183.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3135.77 ms /    78 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    8256.73 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.79 ms /    79 runs   (    0.66 ms per token,  1525.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3073.67 ms /   580 tokens (    5.30 ms per token,   188.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3078.69 ms /    78 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6275.42 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.71 ms /   255 runs   (    0.54 ms per token,  1838.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2130.10 ms /   402 tokens (    5.30 ms per token,   188.72 tokens per second)\n",
            "llama_print_timings:        eval time =    9927.17 ms /   254 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12413.16 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.46 ms /    70 runs   (    0.56 ms per token,  1773.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2444.76 ms /   462 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2703.95 ms /    69 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5239.64 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.42 ms /    70 runs   (    0.53 ms per token,  1870.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2456.18 ms /   470 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2702.85 ms /    69 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5246.26 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.99 ms /    54 runs   (    0.69 ms per token,  1459.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1980.73 ms /   379 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2061.08 ms /    53 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4128.16 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    14 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     988.88 ms /   192 tokens (    5.15 ms per token,   194.16 tokens per second)\n",
            "llama_print_timings:        eval time =     537.07 ms /    14 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    1551.95 ms /   206 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1863.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2454.49 ms /   466 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2701.59 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.49 ms /     7 runs   (    0.50 ms per token,  2008.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2239.59 ms /   430 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =     230.17 ms /     6 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    2482.73 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.16 ms /    12 runs   (    0.51 ms per token,  1949.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.52 ms /   471 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     429.74 ms /    11 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2907.31 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     7 runs   (    0.65 ms per token,  1539.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2468.81 ms /   469 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =     240.26 ms /     6 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    2725.91 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.99 ms /    78 runs   (    0.54 ms per token,  1857.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5671.31 ms /  1030 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3123.82 ms /    77 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    8902.23 ms /  1107 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.43 ms /    76 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5418.81 ms /   989 tokens (    5.48 ms per token,   182.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3048.52 ms /    75 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8589.36 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     100.00 ms /   179 runs   (    0.56 ms per token,  1790.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2108.47 ms /   402 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =    6944.27 ms /   178 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    9298.86 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.93 ms /   100 runs   (    0.55 ms per token,  1820.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2097.79 ms /   400 tokens (    5.24 ms per token,   190.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3846.32 ms /    99 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    6073.70 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1814.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2980.10 ms /   566 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =     232.74 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3227.85 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.55 ms /    91 runs   (    0.62 ms per token,  1609.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     972.02 ms /   190 tokens (    5.12 ms per token,   195.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3460.36 ms /    90 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    4564.35 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.02 ms /   154 runs   (    0.57 ms per token,  1769.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2298.98 ms /   434 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =    5976.59 ms /   153 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    8484.15 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1882.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1723.03 ms /   336 tokens (    5.13 ms per token,   195.00 tokens per second)\n",
            "llama_print_timings:        eval time =     194.26 ms /     5 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    1928.27 ms /   341 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.32 ms /    58 runs   (    0.52 ms per token,  1913.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5337.73 ms /   970 tokens (    5.50 ms per token,   181.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2297.86 ms /    57 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7715.72 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.98 ms /   127 runs   (    0.58 ms per token,  1716.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4469.18 ms /   832 tokens (    5.37 ms per token,   186.16 tokens per second)\n",
            "llama_print_timings:        eval time =    5067.53 ms /   126 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    9734.90 ms /   958 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.37 ms /   256 runs   (    0.55 ms per token,  1823.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3034.95 ms /   570 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =   10062.62 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13477.49 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2292.83 ms /   440 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
            "llama_print_timings:        eval time =     268.21 ms /     7 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2576.95 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.33 ms /    73 runs   (    0.54 ms per token,  1855.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2194.37 ms /   420 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2804.41 ms /    72 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5089.94 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.23 ms /   114 runs   (    0.63 ms per token,  1578.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1386.25 ms /   267 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4374.91 ms /   113 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    5933.95 ms /   380 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.09 ms /    75 runs   (    0.55 ms per token,  1825.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.60 ms /   431 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2888.16 ms /    74 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5231.34 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.12 ms /    14 runs   (    0.51 ms per token,  1965.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     973.18 ms /   186 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =     492.70 ms /    13 runs   (   37.90 ms per token,    26.39 tokens per second)\n",
            "llama_print_timings:       total time =    1484.22 ms /   199 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.07 ms /    66 runs   (    0.67 ms per token,  1497.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3379.15 ms /   634 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.76 ms /    65 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6068.08 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.37 ms /    72 runs   (    0.52 ms per token,  1926.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3746.89 ms /   699 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2803.33 ms /    71 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6646.12 ms /   770 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1865.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2454.72 ms /   468 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =     230.85 ms /     6 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2699.53 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.35 ms /    67 runs   (    0.65 ms per token,  1545.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2558.68 ms /   484 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2572.99 ms /    66 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5237.12 ms /   550 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.95 ms /    55 runs   (    0.54 ms per token,  1836.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2239.23 ms /   429 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2103.02 ms /    54 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    4411.74 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.67 ms /   256 runs   (    0.55 ms per token,  1819.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2807.86 ms /   536 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =   10052.90 ms /   255 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13244.56 ms /   791 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.83 ms /    64 runs   (    0.53 ms per token,  1891.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.72 ms /   446 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2457.15 ms /    63 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4864.59 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.47 ms /   256 runs   (    0.55 ms per token,  1809.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2265.15 ms /   431 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
            "llama_print_timings:        eval time =    9984.34 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12608.60 ms /   686 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.01 ms /    99 runs   (    0.60 ms per token,  1677.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2300.47 ms /   440 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3839.75 ms /    98 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6280.31 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.17 ms /    11 runs   (    0.56 ms per token,  1782.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2896.58 ms /   548 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =     391.85 ms /    10 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    3308.06 ms /   558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.11 ms /    96 runs   (    0.65 ms per token,  1545.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4467.33 ms /   828 tokens (    5.40 ms per token,   185.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3825.41 ms /    95 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    8447.86 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.59 ms /   256 runs   (    0.58 ms per token,  1711.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2991.64 ms /   568 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =   10114.82 ms /   256 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   13502.92 ms /   824 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.11 ms /   256 runs   (    0.61 ms per token,  1650.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2633.00 ms /   504 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
            "llama_print_timings:        eval time =   10051.82 ms /   255 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13089.00 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2453.16 ms /   468 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     230.31 ms /     6 runs   (   38.38 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2697.66 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.80 ms /   256 runs   (    0.59 ms per token,  1708.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2806.45 ms /   533 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
            "llama_print_timings:        eval time =   10041.79 ms /   255 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   13238.85 ms /   788 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.93 ms /    76 runs   (    0.53 ms per token,  1903.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2294.00 ms /   429 tokens (    5.35 ms per token,   187.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2955.94 ms /    75 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    5342.93 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.73 ms /     9 runs   (    0.53 ms per token,  1903.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1012.20 ms /   194 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =     301.72 ms /     8 runs   (   37.71 ms per token,    26.51 tokens per second)\n",
            "llama_print_timings:       total time =    1327.09 ms /   202 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.63 ms /    97 runs   (    0.60 ms per token,  1654.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2044.20 ms /   386 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3729.76 ms /    96 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    5912.51 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1922.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.95 ms /   456 tokens (    5.20 ms per token,   192.41 tokens per second)\n",
            "llama_print_timings:        eval time =     233.75 ms /     6 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2617.88 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Square, Inc._l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_3M CO_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_3M CO_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.29 ms /   256 runs   (    0.59 ms per token,  1692.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3024.13 ms /   570 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =   10039.98 ms /   255 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   13448.31 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     129.10 ms /   228 runs   (    0.57 ms per token,  1766.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2982.53 ms /   568 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    8991.13 ms /   228 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   12312.97 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.24 ms /    89 runs   (    0.55 ms per token,  1807.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3113.09 ms /   587 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3466.89 ms /    88 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6699.98 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.86 ms /     7 runs   (    0.69 ms per token,  1439.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1830.02 ms /   348 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =     236.60 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    2086.48 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.70 ms /    62 runs   (    0.53 ms per token,  1896.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3611.83 ms /   677 tokens (    5.34 ms per token,   187.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2413.10 ms /    61 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6108.93 ms /   738 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.11 ms /    73 runs   (    0.55 ms per token,  1820.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2152.13 ms /   413 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2801.47 ms /    72 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    5048.15 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.56 ms /   160 runs   (    0.55 ms per token,  1806.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2262.91 ms /   426 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =    6218.26 ms /   159 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    8696.25 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.17 ms /   119 runs   (    0.64 ms per token,  1562.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2850.20 ms /   540 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =    4656.47 ms /   118 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7692.49 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.63 ms /   256 runs   (    0.59 ms per token,  1688.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2761.40 ms /   526 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =   10053.82 ms /   255 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13225.81 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.63 ms /    70 runs   (    0.54 ms per token,  1860.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5304.50 ms /   976 tokens (    5.43 ms per token,   183.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2824.01 ms /    70 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    8224.51 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.40 ms /    85 runs   (    0.59 ms per token,  1686.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3764.86 ms /   701 tokens (    5.37 ms per token,   186.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3315.48 ms /    84 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7205.32 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2673.07 ms /   511 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     233.68 ms /     6 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2922.48 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.84 ms /    75 runs   (    0.62 ms per token,  1601.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3245.44 ms /   613 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2914.65 ms /    74 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6274.58 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     131.21 ms /   242 runs   (    0.54 ms per token,  1844.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3009.52 ms /   568 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =    9509.91 ms /   242 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12859.19 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     130.49 ms /   256 runs   (    0.51 ms per token,  1961.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2136.26 ms /   408 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =   10014.01 ms /   256 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12494.74 ms /   664 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     132.22 ms /   256 runs   (    0.52 ms per token,  1936.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2839.26 ms /   535 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =   10024.50 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13214.95 ms /   790 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.78 ms /   256 runs   (    0.56 ms per token,  1792.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2173.03 ms /   412 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =    9983.75 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12518.91 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.95 ms /   114 runs   (    0.57 ms per token,  1755.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2648.13 ms /   502 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =    4427.84 ms /   113 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    7239.60 ms /   615 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.70 ms /    86 runs   (    0.54 ms per token,  1841.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2716.47 ms /   520 tokens (    5.22 ms per token,   191.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3330.31 ms /    85 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6157.63 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.00 ms /    78 runs   (    0.67 ms per token,  1500.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2164.15 ms /   412 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3004.63 ms /    77 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5294.74 ms /   489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.87 ms /    79 runs   (    0.57 ms per token,  1760.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2849.55 ms /   544 tokens (    5.24 ms per token,   190.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3102.64 ms /    79 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6056.43 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.41 ms /   256 runs   (    0.58 ms per token,  1713.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1895.30 ms /   366 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
            "llama_print_timings:        eval time =    9953.42 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12228.59 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.64 ms /   256 runs   (    0.59 ms per token,  1699.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1555.32 ms /   300 tokens (    5.18 ms per token,   192.89 tokens per second)\n",
            "llama_print_timings:        eval time =    9913.23 ms /   255 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =   11852.07 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.87 ms /    54 runs   (    0.52 ms per token,  1937.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1766.75 ms /   344 tokens (    5.14 ms per token,   194.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2084.76 ms /    54 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    3916.51 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.87 ms /    78 runs   (    0.69 ms per token,  1447.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2556.74 ms /   484 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3020.43 ms /    77 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5712.24 ms /   561 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.39 ms /    59 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5348.10 ms /   979 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2340.12 ms /    58 runs   (   40.35 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    7770.70 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.37 ms /    14 runs   (    0.60 ms per token,  1672.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1138.45 ms /   221 tokens (    5.15 ms per token,   194.12 tokens per second)\n",
            "llama_print_timings:        eval time =     496.05 ms /    13 runs   (   38.16 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    1655.37 ms /   234 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.79 ms /    56 runs   (    0.64 ms per token,  1564.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2268.15 ms /   427 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2136.37 ms /    55 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4493.50 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.75 ms /   256 runs   (    0.59 ms per token,  1687.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2284.63 ms /   440 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =   10053.59 ms /   256 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   12732.63 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.83 ms /   256 runs   (    0.59 ms per token,  1708.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1660.56 ms /   314 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    9969.85 ms /   255 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12016.84 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.69 ms /    68 runs   (    0.54 ms per token,  1853.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4250.32 ms /   787 tokens (    5.40 ms per token,   185.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2657.07 ms /    67 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    6999.35 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.81 ms /   256 runs   (    0.60 ms per token,  1653.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3022.96 ms /   570 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10064.59 ms /   255 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13476.86 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.32 ms /   116 runs   (    0.65 ms per token,  1540.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1472.21 ms /   288 tokens (    5.11 ms per token,   195.62 tokens per second)\n",
            "llama_print_timings:        eval time =    4480.26 ms /   116 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    6125.95 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.16 ms /   256 runs   (    0.54 ms per token,  1839.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1530.01 ms /   295 tokens (    5.19 ms per token,   192.81 tokens per second)\n",
            "llama_print_timings:        eval time =    9905.23 ms /   255 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =   11793.04 ms /   550 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     6 runs   (    0.72 ms per token,  1393.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2050.44 ms /   388 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     194.47 ms /     5 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2263.00 ms /   393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.49 ms /     6 runs   (    0.58 ms per token,  1720.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2118.12 ms /   404 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =     193.32 ms /     5 runs   (   38.66 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2327.51 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.69 ms /   392 tokens (    5.17 ms per token,   193.32 tokens per second)\n",
            "llama_print_timings:        eval time =     230.15 ms /     6 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    2271.23 ms /   398 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.03 ms /     9 runs   (    0.56 ms per token,  1790.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1100.70 ms /   216 tokens (    5.10 ms per token,   196.24 tokens per second)\n",
            "llama_print_timings:        eval time =     340.73 ms /     9 runs   (   37.86 ms per token,    26.41 tokens per second)\n",
            "llama_print_timings:       total time =    1455.78 ms /   225 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1921.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2071.72 ms /   398 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
            "llama_print_timings:        eval time =     193.47 ms /     5 runs   (   38.69 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2276.67 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.93 ms /     9 runs   (    0.55 ms per token,  1824.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     762.91 ms /   146 tokens (    5.23 ms per token,   191.37 tokens per second)\n",
            "llama_print_timings:        eval time =     307.13 ms /     8 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    1083.79 ms /   154 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.42 ms /     9 runs   (    0.71 ms per token,  1402.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1019.22 ms /   197 tokens (    5.17 ms per token,   193.29 tokens per second)\n",
            "llama_print_timings:        eval time =     309.30 ms /     8 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    1345.51 ms /   205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.62 ms /     7 runs   (    0.66 ms per token,  1514.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2531.59 ms /   480 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =     277.31 ms /     7 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    2830.15 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1873.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.22 ms /   469 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =     232.70 ms /     6 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2704.32 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1912.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.16 ms /   464 tokens (    5.21 ms per token,   191.96 tokens per second)\n",
            "llama_print_timings:        eval time =     232.95 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2663.91 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.16 ms /    86 runs   (    0.62 ms per token,  1617.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3117.69 ms /   591 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3358.09 ms /    85 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6613.75 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.47 ms /    68 runs   (    0.55 ms per token,  1814.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2868.37 ms /   542 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2627.80 ms /    67 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5590.02 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.31 ms /    70 runs   (    0.56 ms per token,  1780.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1358.78 ms /   264 tokens (    5.15 ms per token,   194.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2693.84 ms /    70 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    4151.08 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.25 ms /   107 runs   (    0.65 ms per token,  1545.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2124.23 ms /   406 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4131.37 ms /   106 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6427.23 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.83 ms /    12 runs   (    0.57 ms per token,  1757.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2852.30 ms /   542 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =     432.33 ms /    11 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3306.42 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1822.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1684.92 ms /   326 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
            "llama_print_timings:        eval time =     194.47 ms /     5 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    1891.27 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.98 ms /    72 runs   (    0.65 ms per token,  1532.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2502.02 ms /   477 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2777.86 ms /    71 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5395.87 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.43 ms /    71 runs   (    0.56 ms per token,  1800.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2440.27 ms /   461 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2733.31 ms /    70 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5270.72 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.68 ms /    76 runs   (    0.55 ms per token,  1823.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2239.07 ms /   428 tokens (    5.23 ms per token,   191.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2923.64 ms /    75 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5264.34 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.35 ms /    69 runs   (    0.72 ms per token,  1398.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1911.01 ms /   364 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2651.06 ms /    68 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4684.71 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.80 ms /    91 runs   (    0.56 ms per token,  1791.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4426.17 ms /   821 tokens (    5.39 ms per token,   185.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3592.52 ms /    90 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    8151.25 ms /   911 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.76 ms /   142 runs   (    0.55 ms per token,  1802.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5454.28 ms /   992 tokens (    5.50 ms per token,   181.88 tokens per second)\n",
            "llama_print_timings:        eval time =    5716.11 ms /   141 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   11379.07 ms /  1133 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.76 ms /    62 runs   (    0.67 ms per token,  1484.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.57 ms /   424 tokens (    5.19 ms per token,   192.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2370.68 ms /    61 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    4676.39 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.97 ms /    97 runs   (    0.57 ms per token,  1764.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2929.53 ms /   551 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3771.07 ms /    96 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6838.60 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.23 ms /    67 runs   (    0.56 ms per token,  1799.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.79 ms /   407 tokens (    5.20 ms per token,   192.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2569.12 ms /    66 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4774.20 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.84 ms /    82 runs   (    0.68 ms per token,  1468.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2744.45 ms /   515 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3173.64 ms /    81 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6049.49 ms /   596 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.45 ms /    76 runs   (    0.51 ms per token,  1976.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4608.45 ms /   850 tokens (    5.42 ms per token,   184.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2999.08 ms /    75 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    7710.50 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.32 ms /    90 runs   (    0.54 ms per token,  1862.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3648.77 ms /   660 tokens (    5.53 ms per token,   180.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3540.20 ms /    89 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7315.21 ms /   749 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.34 ms /   113 runs   (    0.63 ms per token,  1583.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3167.80 ms /   599 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4405.15 ms /   112 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7748.51 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.35 ms /   256 runs   (    0.57 ms per token,  1761.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2700.09 ms /   506 tokens (    5.34 ms per token,   187.40 tokens per second)\n",
            "llama_print_timings:        eval time =   10007.22 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   13100.46 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.74 ms /   115 runs   (    0.60 ms per token,  1673.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1621.67 ms /   307 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =    4422.56 ms /   114 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    6210.44 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.26 ms /    92 runs   (    0.60 ms per token,  1664.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3212.05 ms /   608 tokens (    5.28 ms per token,   189.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3575.68 ms /    91 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6926.10 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_3M CO_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.35 ms /    71 runs   (    0.53 ms per token,  1900.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3377.47 ms /   631 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2746.19 ms /    70 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6224.08 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.77 ms /    96 runs   (    0.53 ms per token,  1890.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2677.74 ms /   512 tokens (    5.23 ms per token,   191.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3729.03 ms /    95 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6533.17 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.14 ms /    93 runs   (    0.60 ms per token,  1656.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2183.32 ms /   410 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3596.33 ms /    92 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5918.64 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.27 ms /   101 runs   (    0.56 ms per token,  1794.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1984.08 ms /   382 tokens (    5.19 ms per token,   192.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3895.81 ms /   100 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    6013.85 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.26 ms /    59 runs   (    0.58 ms per token,  1722.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4055.94 ms /   752 tokens (    5.39 ms per token,   185.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2349.41 ms /    59 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    6501.37 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.45 ms /    53 runs   (    0.56 ms per token,  1799.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2289.27 ms /   440 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =    2027.81 ms /    52 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4389.46 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.61 ms /   494 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     236.23 ms /     6 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    2843.15 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     6 runs   (    0.68 ms per token,  1468.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2041.17 ms /   386 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =     194.16 ms /     5 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2251.27 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.12 ms /    91 runs   (    0.54 ms per token,  1852.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2710.11 ms /   507 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3523.77 ms /    90 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6361.68 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.77 ms /   470 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
            "llama_print_timings:        eval time =     231.97 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2706.51 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.50 ms /    93 runs   (    0.61 ms per token,  1646.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5439.90 ms /   992 tokens (    5.48 ms per token,   182.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3782.67 ms /    93 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    9372.49 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.65 ms /    81 runs   (    0.61 ms per token,  1631.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5788.97 ms /  1050 tokens (    5.51 ms per token,   181.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3279.92 ms /    80 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    9206.59 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.35 ms /    54 runs   (    0.56 ms per token,  1779.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4181.58 ms /   775 tokens (    5.40 ms per token,   185.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2102.21 ms /    53 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6364.75 ms /   828 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.70 ms /    97 runs   (    0.67 ms per token,  1499.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4992.95 ms /   918 tokens (    5.44 ms per token,   183.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3906.04 ms /    96 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    9075.30 ms /  1014 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.19 ms /   256 runs   (    0.58 ms per token,  1715.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1391.19 ms /   270 tokens (    5.15 ms per token,   194.08 tokens per second)\n",
            "llama_print_timings:        eval time =    9901.80 ms /   255 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =   11705.83 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.93 ms /   256 runs   (    0.56 ms per token,  1791.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2391.43 ms /   450 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    9987.40 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12781.05 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.38 ms /   107 runs   (    0.56 ms per token,  1772.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1968.40 ms /   370 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
            "llama_print_timings:        eval time =    4121.84 ms /   106 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    6240.85 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.34 ms /    14 runs   (    0.60 ms per token,  1678.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.05 ms /   338 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =     503.90 ms /    13 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2296.02 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.48 ms /    53 runs   (    0.59 ms per token,  1683.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5868.93 ms /  1058 tokens (    5.55 ms per token,   180.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2124.70 ms /    52 runs   (   40.86 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    8087.67 ms /  1110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     101.62 ms /   173 runs   (    0.59 ms per token,  1702.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3524.17 ms /   661 tokens (    5.33 ms per token,   187.56 tokens per second)\n",
            "llama_print_timings:        eval time =    6806.72 ms /   172 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   10601.44 ms /   833 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2396.83 ms /   455 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =     233.54 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2647.23 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1826.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.89 ms /   397 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
            "llama_print_timings:        eval time =     233.20 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2320.59 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.34 ms /   256 runs   (    0.59 ms per token,  1691.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.14 ms /   416 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
            "llama_print_timings:        eval time =    9981.24 ms /   255 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12563.29 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.67 ms /   256 runs   (    0.60 ms per token,  1655.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.36 ms /   379 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9975.17 ms /   255 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12382.22 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.69 ms /    71 runs   (    0.54 ms per token,  1834.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2071.48 ms /   397 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2722.63 ms /    70 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4888.33 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.98 ms /    78 runs   (    0.59 ms per token,  1696.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5614.93 ms /  1019 tokens (    5.51 ms per token,   181.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3136.21 ms /    77 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    8881.54 ms /  1096 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.61 ms /    75 runs   (    0.55 ms per token,  1802.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.04 ms /   451 tokens (    5.26 ms per token,   190.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2899.64 ms /    74 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5369.60 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.05 ms /   112 runs   (    0.68 ms per token,  1472.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.51 ms /   392 tokens (    5.17 ms per token,   193.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4365.53 ms /   112 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6587.32 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.89 ms /   256 runs   (    0.60 ms per token,  1674.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.59 ms /   389 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
            "llama_print_timings:        eval time =    9977.69 ms /   255 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12422.04 ms /   644 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.54 ms per token,  1866.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2034.14 ms /   391 tokens (    5.20 ms per token,   192.22 tokens per second)\n",
            "llama_print_timings:        eval time =     193.07 ms /     5 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2242.21 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1868.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.26 ms /   453 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =     230.71 ms /     6 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2618.07 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.04 ms /    80 runs   (    0.56 ms per token,  1776.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     972.09 ms /   188 tokens (    5.17 ms per token,   193.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3017.65 ms /    79 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    4094.64 ms /   267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.41 ms /    79 runs   (    0.64 ms per token,  1567.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2872.72 ms /   544 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3074.04 ms /    78 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6080.11 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.31 ms /    77 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3163.04 ms /   595 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2973.82 ms /    76 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6246.92 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.30 ms /    69 runs   (    0.69 ms per token,  1458.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3353.07 ms /   632 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2703.66 ms /    68 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6181.72 ms /   700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.56 ms per token,  1800.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.51 ms /   408 tokens (    5.19 ms per token,   192.86 tokens per second)\n",
            "llama_print_timings:        eval time =     229.30 ms /     6 runs   (   38.22 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2358.03 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1747.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.46 ms /   392 tokens (    5.17 ms per token,   193.35 tokens per second)\n",
            "llama_print_timings:        eval time =     192.84 ms /     5 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2233.29 ms /   397 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1741.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.07 ms /   372 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =     229.66 ms /     6 runs   (   38.28 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2184.90 ms /   378 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.99 ms /    92 runs   (    0.73 ms per token,  1373.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.37 ms /   424 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3564.07 ms /    91 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5925.77 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.83 ms /     6 runs   (    0.47 ms per token,  2123.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2815.92 ms /   530 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =     195.38 ms /     5 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3025.26 ms /   535 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.04 ms /     6 runs   (    0.51 ms per token,  1970.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3391.92 ms /   640 tokens (    5.30 ms per token,   188.68 tokens per second)\n",
            "llama_print_timings:        eval time =     197.25 ms /     5 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3605.70 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.01 ms /   412 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
            "llama_print_timings:        eval time =     233.02 ms /     6 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2404.90 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.53 ms /   256 runs   (    0.60 ms per token,  1678.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2082.33 ms /   399 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =    9962.63 ms /   255 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12445.58 ms /   654 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.87 ms /    83 runs   (    0.69 ms per token,  1459.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1950.28 ms /   373 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3197.14 ms /    82 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5291.46 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.65 ms /   122 runs   (    0.51 ms per token,  1947.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2037.61 ms /   392 tokens (    5.20 ms per token,   192.38 tokens per second)\n",
            "llama_print_timings:        eval time =    4718.50 ms /   121 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    6921.88 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.66 ms /    73 runs   (    0.65 ms per token,  1531.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2161.21 ms /   415 tokens (    5.21 ms per token,   192.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2811.23 ms /    72 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5088.04 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.02 ms /    62 runs   (    0.55 ms per token,  1822.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3148.39 ms /   592 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2391.23 ms /    61 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5632.77 ms /   653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.09 ms /    69 runs   (    0.64 ms per token,  1564.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5742.13 ms /  1045 tokens (    5.49 ms per token,   181.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2784.23 ms /    68 runs   (   40.94 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    8653.61 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.01 ms /   103 runs   (    0.55 ms per token,  1806.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3142.13 ms /   591 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4001.29 ms /   102 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7285.72 ms /   693 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.38 ms /    89 runs   (    0.73 ms per token,  1361.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3525.60 ms /   662 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3511.76 ms /    88 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    7201.51 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1701.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.50 ms /   430 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
            "llama_print_timings:        eval time =     192.48 ms /     5 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2453.47 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.41 ms /    63 runs   (    0.56 ms per token,  1779.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3038.98 ms /   571 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2426.97 ms /    62 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5553.63 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.51 ms /     6 runs   (    0.59 ms per token,  1708.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1858.42 ms /   356 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =     195.13 ms /     5 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2067.20 ms /   361 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.99 ms /    66 runs   (    0.61 ms per token,  1650.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2317.52 ms /   434 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2541.95 ms /    65 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4965.67 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2595.71 ms /   496 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =     232.55 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2844.50 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.51 ms /    12 runs   (    0.63 ms per token,  1598.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2464.28 ms /   471 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =     428.69 ms /    11 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2917.95 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.92 ms /   114 runs   (    0.60 ms per token,  1678.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4274.06 ms /   791 tokens (    5.40 ms per token,   185.07 tokens per second)\n",
            "llama_print_timings:        eval time =    4517.01 ms /   113 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    8971.00 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.20 ms /   115 runs   (    0.59 ms per token,  1686.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4296.90 ms /   795 tokens (    5.40 ms per token,   185.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4564.57 ms /   114 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    9047.87 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.79 ms /    76 runs   (    0.55 ms per token,  1818.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1580.49 ms /   302 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2889.00 ms /    75 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    4574.62 ms /   377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.91 ms /    12 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.13 ms /   458 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =     429.61 ms /    11 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2867.39 ms /   469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1749.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.69 ms /   510 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =     236.08 ms /     6 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2927.51 ms /   516 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.33 ms /    81 runs   (    0.55 ms per token,  1827.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5681.23 ms /  1026 tokens (    5.54 ms per token,   180.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3244.24 ms /    80 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    9051.40 ms /  1106 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.09 ms /    64 runs   (    0.77 ms per token,  1303.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5546.52 ms /  1012 tokens (    5.48 ms per token,   182.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2586.17 ms /    63 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    8270.45 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.43 ms /    77 runs   (    0.59 ms per token,  1695.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2215.95 ms /   423 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2959.24 ms /    76 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5283.29 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     117.43 ms /   180 runs   (    0.65 ms per token,  1532.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.43 ms /   405 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =    7009.73 ms /   179 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    9428.21 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.54 ms /    68 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2204.89 ms /   424 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2607.65 ms /    67 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4905.63 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     159.96 ms /   256 runs   (    0.62 ms per token,  1600.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.81 ms /   414 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
            "llama_print_timings:        eval time =    9967.76 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12554.72 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_MICROSOFT CORP_l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     7 runs   (    0.48 ms per token,  2082.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2895.78 ms /   549 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =     236.07 ms /     6 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    3147.60 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.29 ms /    98 runs   (    0.68 ms per token,  1478.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2548.63 ms /   486 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3807.47 ms /    97 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6525.54 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.53 ms /    84 runs   (    0.55 ms per token,  1805.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2587.45 ms /   493 tokens (    5.25 ms per token,   190.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3251.39 ms /    83 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5955.12 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.40 ms /    78 runs   (    0.70 ms per token,  1433.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4211.56 ms /   784 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3131.27 ms /    78 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7482.41 ms /   862 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1815.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3392.35 ms /   637 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =     195.04 ms /     5 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3604.56 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.40 ms /    81 runs   (    0.65 ms per token,  1545.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4427.98 ms /   819 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3215.38 ms /    80 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7779.01 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.81 ms /    64 runs   (    0.54 ms per token,  1838.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2876.00 ms /   541 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2478.64 ms /    63 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5442.84 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.65 ms /    56 runs   (    0.57 ms per token,  1769.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4242.34 ms /   786 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2193.88 ms /    55 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    6524.32 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.56 ms /    91 runs   (    0.52 ms per token,  1913.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6163.63 ms /  1108 tokens (    5.56 ms per token,   179.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3685.23 ms /    90 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    9985.42 ms /  1198 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.66 ms /    79 runs   (    0.64 ms per token,  1559.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4312.27 ms /   794 tokens (    5.43 ms per token,   184.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3130.99 ms /    78 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7574.73 ms /   872 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.25 ms /    80 runs   (    0.55 ms per token,  1807.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3571.95 ms /   671 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3108.83 ms /    79 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6793.27 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.27 ms /    12 runs   (    0.69 ms per token,  1451.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2383.05 ms /   456 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =     426.23 ms /    11 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2833.94 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.54 ms /   126 runs   (    0.56 ms per token,  1786.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7322.78 ms /  1298 tokens (    5.64 ms per token,   177.25 tokens per second)\n",
            "llama_print_timings:        eval time =    5195.63 ms /   125 runs   (   41.57 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =   12711.11 ms /  1423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.75 ms /    90 runs   (    0.64 ms per token,  1558.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.22 ms /   557 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3500.70 ms /    89 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6622.70 ms /   646 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.15 ms /   137 runs   (    0.61 ms per token,  1628.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2945.75 ms /   560 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =    5356.48 ms /   136 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    8516.52 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.60 ms /   256 runs   (    0.58 ms per token,  1722.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3007.67 ms /   565 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10046.68 ms /   255 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   13459.09 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1845.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2614.53 ms /   495 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =     232.72 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2864.20 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.81 ms /   111 runs   (    0.56 ms per token,  1795.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3300.45 ms /   623 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =    4317.20 ms /   110 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7770.08 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.46 ms /    77 runs   (    0.68 ms per token,  1467.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2264.02 ms /   431 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2955.39 ms /    76 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    5351.31 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.60 ms /    83 runs   (    0.56 ms per token,  1781.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.76 ms /   380 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3184.45 ms /    82 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    5281.01 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.32 ms /    88 runs   (    0.64 ms per token,  1562.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2547.59 ms /   485 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3418.12 ms /    87 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6107.37 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.74 ms /    77 runs   (    0.54 ms per token,  1844.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3359.87 ms /   632 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2978.31 ms /    76 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6445.90 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.92 ms /    64 runs   (    0.56 ms per token,  1781.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.69 ms /   427 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2457.27 ms /    63 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4786.87 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.50 ms /    84 runs   (    0.61 ms per token,  1630.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1964.50 ms /   376 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3238.24 ms /    83 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5337.83 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1840.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.90 ms /   432 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
            "llama_print_timings:        eval time =     268.91 ms /     7 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2524.04 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1667.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2067.77 ms /   396 tokens (    5.22 ms per token,   191.51 tokens per second)\n",
            "llama_print_timings:        eval time =     232.42 ms /     6 runs   (   38.74 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2314.95 ms /   402 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1866.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.08 ms /   461 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     234.31 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2664.29 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.48 ms /   256 runs   (    0.58 ms per token,  1735.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2397.73 ms /   456 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =    9957.89 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12747.78 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.97 ms /   256 runs   (    0.58 ms per token,  1730.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2033.05 ms /   386 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =    9949.84 ms /   255 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12382.27 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.50 ms /    68 runs   (    0.73 ms per token,  1373.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.07 ms /   432 tokens (    5.19 ms per token,   192.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2650.13 ms /    68 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    5021.16 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.59 ms /   256 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2508.04 ms /   475 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =   10013.59 ms /   255 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   12930.70 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2170.52 ms /   412 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
            "llama_print_timings:        eval time =     230.27 ms /     6 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2416.41 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1777.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1643.47 ms /   317 tokens (    5.18 ms per token,   192.88 tokens per second)\n",
            "llama_print_timings:        eval time =     192.39 ms /     5 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    1848.23 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.73 ms /    71 runs   (    0.55 ms per token,  1833.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.49 ms /   414 tokens (    5.21 ms per token,   192.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2726.68 ms /    70 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4977.13 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.30 ms /    69 runs   (    0.83 ms per token,  1204.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.70 ms /   419 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2662.82 ms /    68 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4992.31 ms /   487 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.77 ms /     6 runs   (    0.46 ms per token,  2163.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4889.45 ms /   898 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =     201.51 ms /     5 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5112.35 ms /   903 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.00 ms /    12 runs   (    0.58 ms per token,  1715.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.09 ms /   445 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =     424.47 ms /    11 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2774.58 ms /   456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.98 ms /   256 runs   (    0.59 ms per token,  1695.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3529.26 ms /   659 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
            "llama_print_timings:        eval time =   10107.00 ms /   255 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =   14037.56 ms /   914 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.55 ms /   256 runs   (    0.53 ms per token,  1874.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2956.41 ms /   555 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =   10018.54 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   13357.72 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.85 ms /   256 runs   (    0.55 ms per token,  1817.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2781.36 ms /   528 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =   10052.49 ms /   256 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   13218.87 ms /   784 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.32 ms /    12 runs   (    0.69 ms per token,  1441.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2202.83 ms /   420 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =     424.82 ms /    11 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2656.89 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.55 ms /    84 runs   (    0.59 ms per token,  1695.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1921.28 ms /   368 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3263.38 ms /    84 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    5307.86 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.00 ms /    80 runs   (    0.66 ms per token,  1509.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7280.24 ms /  1300 tokens (    5.60 ms per token,   178.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3306.64 ms /    79 runs   (   41.86 ms per token,    23.89 tokens per second)\n",
            "llama_print_timings:       total time =   10742.14 ms /  1379 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.60 ms /    73 runs   (    0.56 ms per token,  1798.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2725.46 ms /   519 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2826.98 ms /    72 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5654.96 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.81 ms /   164 runs   (    0.58 ms per token,  1711.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.00 ms /    24 tokens (    5.38 ms per token,   186.05 tokens per second)\n",
            "llama_print_timings:        eval time =    6442.35 ms /   164 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6819.73 ms /   188 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1749.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2260.94 ms /   426 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =     229.66 ms /     6 runs   (   38.28 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    2512.08 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.87 ms /     6 runs   (    0.48 ms per token,  2094.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.86 ms /   439 tokens (    5.21 ms per token,   192.05 tokens per second)\n",
            "llama_print_timings:        eval time =     195.26 ms /     5 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2493.59 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.39 ms /    89 runs   (    0.61 ms per token,  1636.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2811.95 ms /   534 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3451.56 ms /    88 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6394.29 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     6 runs   (    0.66 ms per token,  1508.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1711.84 ms /   328 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =     193.38 ms /     5 runs   (   38.68 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    1920.83 ms /   333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      26.24 ms /    47 runs   (    0.56 ms per token,  1791.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2174.12 ms /   411 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1787.10 ms /    46 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4026.94 ms /   457 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1863.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1767.83 ms /   339 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
            "llama_print_timings:        eval time =     235.05 ms /     6 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2016.29 ms /   345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.81 ms /    68 runs   (    0.56 ms per token,  1798.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2900.27 ms /   550 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2633.32 ms /    67 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5630.66 ms /   617 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.24 ms /    65 runs   (    0.57 ms per token,  1745.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2582.11 ms /   487 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2500.42 ms /    64 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5176.47 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.54 ms /    68 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1900.35 ms /   368 tokens (    5.16 ms per token,   193.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2633.93 ms /    68 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    4627.05 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.57 ms /   256 runs   (    0.59 ms per token,  1700.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1682.76 ms /   325 tokens (    5.18 ms per token,   193.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9929.62 ms /   255 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12029.77 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.40 ms /   131 runs   (    0.64 ms per token,  1570.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.21 ms /   416 tokens (    5.19 ms per token,   192.57 tokens per second)\n",
            "llama_print_timings:        eval time =    5106.77 ms /   131 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    7476.57 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.60 ms /   256 runs   (    0.59 ms per token,  1699.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2164.26 ms /   414 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
            "llama_print_timings:        eval time =    9973.90 ms /   255 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12544.22 ms /   669 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.42 ms /    82 runs   (    0.55 ms per token,  1805.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2656.14 ms /   504 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3219.20 ms /    82 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5992.46 ms /   586 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.30 ms /    77 runs   (    0.65 ms per token,  1530.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6026.42 ms /  1091 tokens (    5.52 ms per token,   181.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3127.10 ms /    76 runs   (   41.15 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =    9294.94 ms /  1167 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.54 ms /    77 runs   (    0.55 ms per token,  1809.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.73 ms /   432 tokens (    5.20 ms per token,   192.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3003.55 ms /    77 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    5355.52 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.12 ms /     9 runs   (    0.57 ms per token,  1758.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1018.54 ms /   198 tokens (    5.14 ms per token,   194.40 tokens per second)\n",
            "llama_print_timings:        eval time =     302.02 ms /     8 runs   (   37.75 ms per token,    26.49 tokens per second)\n",
            "llama_print_timings:       total time =    1334.87 ms /   206 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     161.40 ms /   256 runs   (    0.63 ms per token,  1586.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2153.85 ms /   413 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =    9968.45 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12542.84 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_Ulta Beauty, Inc._l2_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_AES CORP_cosine_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_cosine_2.json\n",
            "KeyError occurred: 'l2'. Skipping approach 1 for dataframe results_approach_AES CORP_ip_1.json\n",
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_ip_2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.01 ms /    12 runs   (    0.50 ms per token,  1997.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2863.09 ms /   544 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     431.27 ms /    11 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    3316.07 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.26 ms /     7 runs   (    0.61 ms per token,  1641.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2308.11 ms /   435 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =     234.85 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2559.17 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.32 ms /   104 runs   (    0.57 ms per token,  1753.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5567.40 ms /  1011 tokens (    5.51 ms per token,   181.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4176.70 ms /   103 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    9899.32 ms /  1114 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.48 ms /    53 runs   (    0.80 ms per token,  1247.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2121.99 ms /   408 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2062.89 ms /    53 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4287.40 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.95 ms /    72 runs   (    0.55 ms per token,  1802.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2869.92 ms /   538 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2781.66 ms /    71 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5753.62 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.55 ms /    66 runs   (    0.57 ms per token,  1757.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.65 ms /   472 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2534.74 ms /    65 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    5090.15 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.38 ms /    70 runs   (    0.59 ms per token,  1691.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3167.01 ms /   590 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2716.20 ms /    69 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5990.30 ms /   659 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.13 ms /    73 runs   (    0.56 ms per token,  1774.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3299.75 ms /   620 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2824.39 ms /    72 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6229.73 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.66 ms /    68 runs   (    0.64 ms per token,  1557.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4003.63 ms /   739 tokens (    5.42 ms per token,   184.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2670.00 ms /    67 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    6797.31 ms /   806 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.01 ms /    69 runs   (    0.58 ms per token,  1724.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     133.94 ms /    24 tokens (    5.58 ms per token,   179.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2697.01 ms /    68 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    2926.92 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.86 ms /   113 runs   (    0.63 ms per token,  1594.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2765.54 ms /   528 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =    4442.82 ms /   113 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7389.65 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.68 ms /    63 runs   (    0.55 ms per token,  1816.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2740.86 ms /   516 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2431.43 ms /    62 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5260.27 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.55 ms /    65 runs   (    0.58 ms per token,  1731.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.78 ms /   442 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2507.43 ms /    64 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4924.41 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.75 ms /   159 runs   (    0.60 ms per token,  1678.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2560.22 ms /   486 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =    6191.83 ms /   158 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    8994.90 ms /   644 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.07 ms /   117 runs   (    0.66 ms per token,  1518.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4790.11 ms /   883 tokens (    5.42 ms per token,   184.34 tokens per second)\n",
            "llama_print_timings:        eval time =    4690.60 ms /   116 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    9691.29 ms /   999 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.02 ms /    66 runs   (    0.56 ms per token,  1782.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4427.45 ms /   821 tokens (    5.39 ms per token,   185.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2590.75 ms /    65 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7115.10 ms /   886 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.29 ms /   152 runs   (    0.63 ms per token,  1595.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3090.66 ms /   584 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =    5997.48 ms /   152 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    9329.61 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.56 ms /   117 runs   (    0.57 ms per token,  1757.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1901.17 ms /   367 tokens (    5.18 ms per token,   193.04 tokens per second)\n",
            "llama_print_timings:        eval time =    4508.40 ms /   116 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    6575.17 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1552.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2619.09 ms /   494 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =     232.94 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2871.39 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.50 ms /   256 runs   (    0.58 ms per token,  1723.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2641.61 ms /   503 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =   10026.00 ms /   255 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   13080.28 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.18 ms /   256 runs   (    0.55 ms per token,  1813.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2000.68 ms /   378 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9965.18 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12356.21 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.91 ms /    89 runs   (    0.55 ms per token,  1819.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2279.65 ms /   431 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3430.71 ms /    88 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5830.82 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.93 ms /    67 runs   (    0.55 ms per token,  1814.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2545.85 ms /   487 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2575.59 ms /    66 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5214.20 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.26 ms /    12 runs   (    0.69 ms per token,  1453.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1609.04 ms /   312 tokens (    5.16 ms per token,   193.91 tokens per second)\n",
            "llama_print_timings:        eval time =     427.41 ms /    11 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2060.10 ms /   323 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.07 ms /    95 runs   (    0.56 ms per token,  1790.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3772.53 ms /   702 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3713.40 ms /    94 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    7619.21 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.31 ms /   127 runs   (    0.62 ms per token,  1621.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1598.62 ms /   310 tokens (    5.16 ms per token,   193.92 tokens per second)\n",
            "llama_print_timings:        eval time =    4877.16 ms /   126 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    6669.28 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.23 ms /   126 runs   (    0.55 ms per token,  1820.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1960.50 ms /   374 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =    4861.22 ms /   125 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    6990.97 ms /   499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1713.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1681.18 ms /   322 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
            "llama_print_timings:        eval time =     191.76 ms /     5 runs   (   38.35 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    1887.68 ms /   327 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.84 ms /   256 runs   (    0.61 ms per token,  1642.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1429.07 ms /   277 tokens (    5.16 ms per token,   193.83 tokens per second)\n",
            "llama_print_timings:        eval time =    9892.09 ms /   255 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =   11731.97 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.48 ms /    61 runs   (    0.65 ms per token,  1545.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3695.69 ms /   691 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
            "llama_print_timings:        eval time =    2388.73 ms /    60 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6191.18 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.70 ms /   256 runs   (    0.57 ms per token,  1769.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2088.02 ms /   397 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9949.06 ms /   255 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12426.15 ms /   652 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.67 ms /     9 runs   (    0.74 ms per token,  1349.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1582.20 ms /   303 tokens (    5.22 ms per token,   191.51 tokens per second)\n",
            "llama_print_timings:        eval time =     309.21 ms /     8 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    1911.93 ms /   311 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.86 ms /    14 runs   (    0.56 ms per token,  1781.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1528.23 ms /   292 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
            "llama_print_timings:        eval time =     500.29 ms /    13 runs   (   38.48 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2051.09 ms /   305 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.40 ms /   416 tokens (    5.19 ms per token,   192.74 tokens per second)\n",
            "llama_print_timings:        eval time =     230.61 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2403.82 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1867.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2023.80 ms /   388 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
            "llama_print_timings:        eval time =     232.43 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2269.53 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2377.08 ms /   456 tokens (    5.21 ms per token,   191.83 tokens per second)\n",
            "llama_print_timings:        eval time =     234.02 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2626.47 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      93.73 ms /   168 runs   (    0.56 ms per token,  1792.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3229.92 ms /   604 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
            "llama_print_timings:        eval time =    6561.85 ms /   167 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   10044.61 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.98 ms /   256 runs   (    0.57 ms per token,  1765.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3076.56 ms /   582 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =   10085.89 ms /   255 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   13573.86 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.75 ms /    12 runs   (    0.56 ms per token,  1777.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2501.86 ms /   480 tokens (    5.21 ms per token,   191.86 tokens per second)\n",
            "llama_print_timings:        eval time =     471.81 ms /    12 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2995.64 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.45 ms /    72 runs   (    0.71 ms per token,  1399.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2426.30 ms /   464 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2781.21 ms /    71 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5336.42 ms /   535 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.14 ms /    75 runs   (    0.56 ms per token,  1779.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2676.78 ms /   507 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2897.40 ms /    74 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5677.24 ms /   581 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.95 ms /    78 runs   (    0.59 ms per token,  1697.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2111.85 ms /   406 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3008.83 ms /    77 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5237.74 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.26 ms /    90 runs   (    0.56 ms per token,  1790.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2883.18 ms /   543 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3496.56 ms /    89 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6505.01 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.31 ms /   256 runs   (    0.58 ms per token,  1726.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2763.76 ms /   528 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =   10057.65 ms /   255 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13232.68 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.42 ms /    64 runs   (    0.55 ms per token,  1807.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2716.29 ms /   518 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2460.83 ms /    63 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5265.31 ms /   581 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.62 ms /    67 runs   (    0.73 ms per token,  1378.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2131.46 ms /   405 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2572.83 ms /    66 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4822.95 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.66 ms /    80 runs   (    0.55 ms per token,  1832.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4016.51 ms /   750 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3124.74 ms /    79 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    7252.36 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.50 ms /    64 runs   (    0.76 ms per token,  1319.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2729.57 ms /   517 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2481.07 ms /    63 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5336.68 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      21.25 ms /    41 runs   (    0.52 ms per token,  1929.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1484.98 ms /   288 tokens (    5.16 ms per token,   193.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.59 ms /    40 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    3076.37 ms /   328 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.30 ms /   256 runs   (    0.59 ms per token,  1692.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2504.20 ms /   480 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =   10028.55 ms /   255 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   12959.30 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.90 ms /   256 runs   (    0.62 ms per token,  1621.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1686.11 ms /   327 tokens (    5.16 ms per token,   193.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9933.63 ms /   255 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12043.46 ms /   582 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.27 ms /    65 runs   (    0.56 ms per token,  1792.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3977.90 ms /   744 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2569.49 ms /    65 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6638.82 ms /   809 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.79 ms /    83 runs   (    0.58 ms per token,  1736.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4730.05 ms /   868 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3298.72 ms /    82 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8157.44 ms /   950 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.42 ms /    85 runs   (    0.56 ms per token,  1792.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1141.28 ms /   222 tokens (    5.14 ms per token,   194.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3217.09 ms /    84 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    4468.11 ms /   306 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.40 ms /   256 runs   (    0.60 ms per token,  1658.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1606.13 ms /   312 tokens (    5.15 ms per token,   194.26 tokens per second)\n",
            "llama_print_timings:        eval time =    9915.89 ms /   255 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =   11931.95 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.83 ms /    77 runs   (    0.65 ms per token,  1545.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3481.12 ms /   656 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3059.84 ms /    77 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    6672.15 ms /   733 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.87 ms /    76 runs   (    0.55 ms per token,  1815.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3674.06 ms /   685 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2961.53 ms /    75 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6740.86 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.04 ms /    12 runs   (    0.59 ms per token,  1705.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2376.32 ms /   452 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =     430.74 ms /    11 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2829.38 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.32 ms /    97 runs   (    0.74 ms per token,  1360.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1561.65 ms /   304 tokens (    5.14 ms per token,   194.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3753.87 ms /    97 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    5486.00 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.37 ms /    95 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2333.02 ms /   447 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3670.90 ms /    94 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    6135.18 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.31 ms /     7 runs   (    0.62 ms per token,  1624.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2548.96 ms /   488 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =     276.75 ms /     7 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2842.67 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     100.28 ms /   161 runs   (    0.62 ms per token,  1605.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1702.65 ms /   327 tokens (    5.21 ms per token,   192.05 tokens per second)\n",
            "llama_print_timings:        eval time =    6217.46 ms /   160 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    8166.48 ms /   487 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question'. Skipping approach 1 for dataframe results_approach_AES CORP_l2_2.json\n",
            "Total score for approach 1 and distance function l2 is 0.5722819593787336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(2, 'cosine')"
      ],
      "metadata": {
        "id": "GFsk-Yx53iMu",
        "outputId": "be51476a-6ef6-4578-a20e-ccdd43975152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.31 ms /   109 runs   (    0.64 ms per token,  1572.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5940.10 ms /  1079 tokens (    5.51 ms per token,   181.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4438.85 ms /   108 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   10574.71 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.33 ms /    86 runs   (    0.54 ms per token,  1856.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5028.75 ms /   922 tokens (    5.45 ms per token,   183.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3421.88 ms /    85 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8574.26 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.16 ms /    80 runs   (    0.55 ms per token,  1811.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4422.50 ms /   810 tokens (    5.46 ms per token,   183.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3148.51 ms /    79 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7688.63 ms /   889 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.54 ms /    69 runs   (    0.66 ms per token,  1515.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5029.59 ms /   926 tokens (    5.43 ms per token,   184.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2754.02 ms /    68 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    7911.42 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.79 ms /    74 runs   (    0.56 ms per token,  1770.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4039.30 ms /   752 tokens (    5.37 ms per token,   186.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2892.16 ms /    73 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    7041.22 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.61 ms /    88 runs   (    0.68 ms per token,  1476.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3928.08 ms /   736 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3485.26 ms /    87 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    7571.01 ms /   823 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.28 ms /    82 runs   (    0.55 ms per token,  1810.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4982.73 ms /   919 tokens (    5.42 ms per token,   184.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3261.29 ms /    81 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8364.77 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.12 ms /    86 runs   (    0.59 ms per token,  1682.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4367.79 ms /   803 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3392.40 ms /    85 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    7895.03 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.93 ms /    80 runs   (    0.62 ms per token,  1602.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5924.30 ms /  1074 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3238.10 ms /    79 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =    9305.17 ms /  1153 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.01 ms /    81 runs   (    0.56 ms per token,  1799.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5007.02 ms /   917 tokens (    5.46 ms per token,   183.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3217.63 ms /    80 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8344.86 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.24 ms /   136 runs   (    0.57 ms per token,  1760.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6008.84 ms /  1083 tokens (    5.55 ms per token,   180.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5518.24 ms /   135 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =   11733.18 ms /  1218 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.59 ms /    91 runs   (    0.70 ms per token,  1431.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4699.33 ms /   866 tokens (    5.43 ms per token,   184.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3643.08 ms /    90 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    8511.23 ms /   956 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.82 ms /   126 runs   (    0.56 ms per token,  1779.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4062.12 ms /   755 tokens (    5.38 ms per token,   185.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4955.46 ms /   125 runs   (   39.64 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    9198.26 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.43 ms /    70 runs   (    0.53 ms per token,  1870.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4010.81 ms /   739 tokens (    5.43 ms per token,   184.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2722.97 ms /    69 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6835.28 ms /   808 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.56 ms /    79 runs   (    0.67 ms per token,  1503.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5307.82 ms /   972 tokens (    5.46 ms per token,   183.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3164.55 ms /    78 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    8611.38 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.24 ms /   256 runs   (    0.58 ms per token,  1726.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5234.89 ms /   954 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =   10378.77 ms /   255 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =   16054.73 ms /  1209 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.14 ms /    14 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1303.30 ms /   250 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
            "llama_print_timings:        eval time =     499.72 ms /    13 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    1823.84 ms /   263 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.29 ms /    97 runs   (    0.56 ms per token,  1786.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3696.55 ms /   692 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3777.21 ms /    96 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7612.85 ms /   788 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.71 ms /    89 runs   (    0.59 ms per token,  1688.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2313.50 ms /   440 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3481.56 ms /    89 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5930.56 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.69 ms /    71 runs   (    0.56 ms per token,  1788.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3973.22 ms /   743 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2772.56 ms /    70 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    6847.05 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.50 ms /   256 runs   (    0.54 ms per token,  1835.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2523.28 ms /   474 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
            "llama_print_timings:        eval time =    9967.53 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12881.29 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.97 ms /    67 runs   (    0.58 ms per token,  1719.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4002.45 ms /   738 tokens (    5.42 ms per token,   184.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2612.41 ms /    66 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    6718.04 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.22 ms /   256 runs   (    0.61 ms per token,  1638.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2114.46 ms /   407 tokens (    5.20 ms per token,   192.48 tokens per second)\n",
            "llama_print_timings:        eval time =   10002.64 ms /   255 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   12545.76 ms /   662 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.51 ms /    70 runs   (    0.55 ms per token,  1817.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2065.75 ms /   397 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2682.41 ms /    69 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    4841.17 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.09 ms /   106 runs   (    0.68 ms per token,  1470.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2673.83 ms /   509 tokens (    5.25 ms per token,   190.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4132.88 ms /   105 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6991.22 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.70 ms /   256 runs   (    0.59 ms per token,  1698.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2636.88 ms /   502 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =   10037.17 ms /   255 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   13103.04 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.10 ms /   256 runs   (    0.58 ms per token,  1728.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2551.55 ms /   483 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =   10016.35 ms /   255 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   12987.22 ms /   738 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1858.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1499.80 ms /   279 tokens (    5.38 ms per token,   186.03 tokens per second)\n",
            "llama_print_timings:        eval time =     231.85 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    1744.87 ms /   285 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     7 runs   (    0.50 ms per token,  2002.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.41 ms /   471 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =     230.79 ms /     6 runs   (   38.47 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2707.62 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.84 ms /   250 runs   (    0.62 ms per token,  1625.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2026.52 ms /   391 tokens (    5.18 ms per token,   192.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9734.25 ms /   249 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12175.42 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.54 ms /   256 runs   (    0.60 ms per token,  1656.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.18 ms /   424 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
            "llama_print_timings:        eval time =   10026.37 ms /   256 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12657.80 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.39 ms /    79 runs   (    0.55 ms per token,  1820.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2854.95 ms /   544 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3094.32 ms /    79 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6058.11 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.78 ms /   256 runs   (    0.59 ms per token,  1686.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.88 ms /   416 tokens (    5.18 ms per token,   192.96 tokens per second)\n",
            "llama_print_timings:        eval time =    9953.60 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12516.94 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.82 ms /   256 runs   (    0.59 ms per token,  1686.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.58 ms /   536 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
            "llama_print_timings:        eval time =   10028.00 ms /   255 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   13256.31 ms /   791 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1893.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2988.87 ms /   568 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     233.47 ms /     6 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3237.48 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     231.10 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =     241.35 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     7 runs   (    0.65 ms per token,  1536.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2055.71 ms /   388 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =     233.16 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2306.41 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1827.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1829.67 ms /   351 tokens (    5.21 ms per token,   191.84 tokens per second)\n",
            "llama_print_timings:        eval time =     230.76 ms /     6 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2075.46 ms /   357 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.00 ms /     6 runs   (    0.50 ms per token,  1996.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5874.63 ms /  1066 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
            "llama_print_timings:        eval time =     203.15 ms /     5 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    6100.06 ms /  1071 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.05 ms /   462 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
            "llama_print_timings:        eval time =     233.00 ms /     6 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2660.32 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.99 ms /    74 runs   (    0.54 ms per token,  1850.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3556.14 ms /   662 tokens (    5.37 ms per token,   186.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2877.60 ms /    73 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6540.82 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.52 ms /    86 runs   (    0.55 ms per token,  1809.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3925.71 ms /   734 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3365.60 ms /    85 runs   (   39.60 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    7416.41 ms /   819 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.92 ms /    66 runs   (    0.68 ms per token,  1469.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.97 ms /    19 tokens (    6.84 ms per token,   146.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2599.71 ms /    65 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    2845.37 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.68 ms /    71 runs   (    0.57 ms per token,  1745.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2763.93 ms /   526 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2751.11 ms /    70 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5619.34 ms /   596 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.08 ms /   109 runs   (    0.69 ms per token,  1451.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4058.88 ms /   760 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =    4371.20 ms /   109 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    8621.67 ms /   869 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     101.08 ms /   169 runs   (    0.60 ms per token,  1671.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3919.47 ms /   731 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
            "llama_print_timings:        eval time =    6687.17 ms /   168 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =   10869.90 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.61 ms /   100 runs   (    0.53 ms per token,  1900.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4684.59 ms /   861 tokens (    5.44 ms per token,   183.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3963.65 ms /    99 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    8794.30 ms /   960 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.58 ms /    85 runs   (    0.70 ms per token,  1426.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4814.81 ms /   888 tokens (    5.42 ms per token,   184.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3431.42 ms /    85 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8397.46 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.35 ms /    84 runs   (    0.55 ms per token,  1812.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2153.68 ms /   412 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3230.32 ms /    83 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5494.81 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.09 ms /    88 runs   (    0.66 ms per token,  1514.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1783.08 ms /   335 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3405.39 ms /    87 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5334.23 ms /   422 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.32 ms /   100 runs   (    0.56 ms per token,  1775.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3488.22 ms /   653 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3881.97 ms /    99 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7514.59 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.19 ms /   104 runs   (    0.64 ms per token,  1571.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3881.55 ms /   723 tokens (    5.37 ms per token,   186.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4108.91 ms /   103 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    8166.52 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.36 ms /   256 runs   (    0.60 ms per token,  1680.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.82 ms /   475 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =   10044.94 ms /   255 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   12973.15 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.48 ms /    65 runs   (    0.55 ms per token,  1832.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4060.76 ms /   756 tokens (    5.37 ms per token,   186.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2531.34 ms /    64 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6685.17 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.94 ms /   256 runs   (    0.59 ms per token,  1684.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.04 ms /   443 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =    9960.32 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12695.88 ms /   698 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.50 ms /   256 runs   (    0.60 ms per token,  1667.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.46 ms /   432 tokens (    5.19 ms per token,   192.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9943.57 ms /   255 runs   (   38.99 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12596.05 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.70 ms /   256 runs   (    0.58 ms per token,  1721.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2946.25 ms /   560 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10056.19 ms /   255 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13422.79 ms /   815 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.72 ms /   256 runs   (    0.60 ms per token,  1654.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.65 ms /   503 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =   10032.37 ms /   255 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   13084.33 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.69 ms /    68 runs   (    0.61 ms per token,  1631.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.03 ms /   436 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2610.45 ms /    67 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4994.52 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.50 ms /   256 runs   (    0.56 ms per token,  1796.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2185.36 ms /   415 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
            "llama_print_timings:        eval time =    9962.52 ms /   255 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12524.91 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.24 ms /    92 runs   (    0.57 ms per token,  1760.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4193.05 ms /   775 tokens (    5.41 ms per token,   184.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3611.61 ms /    91 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    7938.51 ms /   866 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.31 ms /    81 runs   (    0.56 ms per token,  1787.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2324.67 ms /   444 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =    3127.86 ms /    80 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5560.80 ms /   524 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.69 ms /    64 runs   (    0.54 ms per token,  1844.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5308.53 ms /   965 tokens (    5.50 ms per token,   181.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2539.02 ms /    63 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7944.70 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.59 ms /    70 runs   (    0.71 ms per token,  1411.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5979.94 ms /  1084 tokens (    5.52 ms per token,   181.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2843.76 ms /    69 runs   (   41.21 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =    8961.36 ms /  1153 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1808.28 ms /   349 tokens (    5.18 ms per token,   193.00 tokens per second)\n",
            "llama_print_timings:        eval time =     233.90 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2059.60 ms /   355 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1767.64 ms /   340 tokens (    5.20 ms per token,   192.35 tokens per second)\n",
            "llama_print_timings:        eval time =     234.85 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2016.08 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.79 ms /   135 runs   (    0.64 ms per token,  1555.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2419.85 ms /   464 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =    5256.20 ms /   134 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7892.36 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.37 ms /   116 runs   (    0.55 ms per token,  1802.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5281.77 ms /   965 tokens (    5.47 ms per token,   182.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4645.39 ms /   115 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   10096.61 ms /  1080 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.57 ms /    76 runs   (    0.65 ms per token,  1533.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2826.41 ms /   532 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2949.97 ms /    75 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5902.50 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.23 ms /   114 runs   (    0.61 ms per token,  1646.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5304.78 ms /   971 tokens (    5.46 ms per token,   183.04 tokens per second)\n",
            "llama_print_timings:        eval time =    4580.15 ms /   113 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   10067.42 ms /  1084 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.47 ms /    74 runs   (    0.56 ms per token,  1784.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2789.65 ms /   526 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2869.68 ms /    73 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5762.85 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      23.78 ms /    41 runs   (    0.58 ms per token,  1724.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3026.41 ms /   573 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.61 ms /    40 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    4660.39 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.28 ms /    72 runs   (    0.68 ms per token,  1461.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2779.95 ms /   528 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2836.16 ms /    72 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5737.75 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.18 ms /    75 runs   (    0.56 ms per token,  1778.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     167.49 ms /    26 tokens (    6.44 ms per token,   155.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2905.12 ms /    74 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3173.13 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.08 ms /    94 runs   (    0.60 ms per token,  1676.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3028.18 ms /   574 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3660.62 ms /    93 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6828.84 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.23 ms /    79 runs   (    0.55 ms per token,  1827.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5306.69 ms /   968 tokens (    5.48 ms per token,   182.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3188.15 ms /    79 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    8612.50 ms /  1047 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     6 runs   (    0.68 ms per token,  1466.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5321.64 ms /   971 tokens (    5.48 ms per token,   182.46 tokens per second)\n",
            "llama_print_timings:        eval time =     204.09 ms /     5 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    5551.45 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.58 ms /    85 runs   (    0.56 ms per token,  1786.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5384.80 ms /   979 tokens (    5.50 ms per token,   181.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3395.97 ms /    84 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    8911.75 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.33 ms /    69 runs   (    0.64 ms per token,  1556.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4904.97 ms /   899 tokens (    5.46 ms per token,   183.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2745.10 ms /    68 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    7767.53 ms /   967 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     119.26 ms /   207 runs   (    0.58 ms per token,  1735.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2805.38 ms /   534 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    8118.45 ms /   206 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   11246.00 ms /   740 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.68 ms /   256 runs   (    0.56 ms per token,  1794.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3093.19 ms /   581 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =   10065.68 ms /   255 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   13568.69 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.22 ms /   101 runs   (    0.54 ms per token,  1862.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2345.04 ms /   447 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3914.45 ms /   100 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6395.92 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.50 ms /    76 runs   (    0.65 ms per token,  1535.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5944.52 ms /  1080 tokens (    5.50 ms per token,   181.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3075.90 ms /    75 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    9157.74 ms /  1155 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3387.16 ms /   639 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =     236.78 ms /     6 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3641.18 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.08 ms /    70 runs   (    0.72 ms per token,  1397.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5360.07 ms /   983 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2815.88 ms /    69 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    8313.76 ms /  1052 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.45 ms /    79 runs   (    0.55 ms per token,  1818.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4898.23 ms /   903 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3131.71 ms /    78 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    8146.32 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.21 ms /   256 runs   (    0.58 ms per token,  1715.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2196.18 ms /   421 tokens (    5.22 ms per token,   191.70 tokens per second)\n",
            "llama_print_timings:        eval time =    9972.87 ms /   255 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12574.80 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.83 ms /   256 runs   (    0.60 ms per token,  1675.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2071.41 ms /   397 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =    9945.05 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12422.72 ms /   652 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.68 ms /   113 runs   (    0.66 ms per token,  1513.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2807.11 ms /   533 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =    4405.93 ms /   112 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7406.43 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.34 ms /    69 runs   (    0.54 ms per token,  1848.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3071.03 ms /   580 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2675.90 ms /    68 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5840.59 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     161.19 ms /   256 runs   (    0.63 ms per token,  1588.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1853.53 ms /   359 tokens (    5.16 ms per token,   193.69 tokens per second)\n",
            "llama_print_timings:        eval time =    9918.31 ms /   255 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =   12221.76 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.28 ms /    75 runs   (    0.75 ms per token,  1332.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4887.80 ms /   899 tokens (    5.44 ms per token,   183.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2997.35 ms /    74 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    8028.47 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1877.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2422.65 ms /   464 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
            "llama_print_timings:        eval time =     232.58 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2671.97 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.54 ms /    71 runs   (    0.54 ms per token,  1842.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3566.27 ms /   670 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2746.79 ms /    70 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6412.30 ms /   740 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.38 ms /     7 runs   (    0.63 ms per token,  1597.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2513.52 ms /   480 tokens (    5.24 ms per token,   190.97 tokens per second)\n",
            "llama_print_timings:        eval time =     236.83 ms /     6 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2767.76 ms /   486 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.87 ms /   112 runs   (    0.52 ms per token,  1935.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3193.57 ms /   598 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =    4366.91 ms /   111 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7717.74 ms /   709 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.19 ms /     6 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.57 ms /   464 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
            "llama_print_timings:        eval time =     233.57 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2665.32 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.51 ms /    80 runs   (    0.63 ms per token,  1583.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3270.78 ms /   615 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3118.73 ms /    79 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6521.51 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.43 ms /    70 runs   (    0.52 ms per token,  1921.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2410.70 ms /   458 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2702.74 ms /    69 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5206.95 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.98 ms /    66 runs   (    0.67 ms per token,  1500.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3209.40 ms /   608 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2566.01 ms /    65 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    5889.05 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.09 ms /   256 runs   (    0.57 ms per token,  1764.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1569.71 ms /   301 tokens (    5.21 ms per token,   191.76 tokens per second)\n",
            "llama_print_timings:        eval time =    9905.36 ms /   255 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =   11867.00 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.63 ms /   256 runs   (    0.57 ms per token,  1745.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1343.85 ms /   248 tokens (    5.42 ms per token,   184.54 tokens per second)\n",
            "llama_print_timings:        eval time =   10037.84 ms /   256 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   11768.10 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.02 ms /   102 runs   (    0.61 ms per token,  1644.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2393.57 ms /   456 tokens (    5.25 ms per token,   190.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3956.68 ms /   101 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6505.05 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.58 ms /    84 runs   (    0.55 ms per token,  1803.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2630.17 ms /   500 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3258.67 ms /    83 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6007.66 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.60 ms /    70 runs   (    0.64 ms per token,  1569.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3450.31 ms /   644 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2730.06 ms /    69 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    6295.90 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.78 ms /   256 runs   (    0.56 ms per token,  1792.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1265.51 ms /   248 tokens (    5.10 ms per token,   195.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9864.21 ms /   255 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =   11530.32 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.37 ms /    69 runs   (    0.56 ms per token,  1798.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2379.28 ms /   456 tokens (    5.22 ms per token,   191.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2695.24 ms /    69 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5169.05 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      91.34 ms /   133 runs   (    0.69 ms per token,  1456.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3207.24 ms /   605 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
            "llama_print_timings:        eval time =    5218.18 ms /   132 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    8655.67 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.13 ms /    67 runs   (    0.55 ms per token,  1804.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5217.29 ms /   954 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2664.36 ms /    66 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    7984.01 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.05 ms /    93 runs   (    0.70 ms per token,  1429.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2730.81 ms /   520 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3659.13 ms /    93 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6546.11 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.75 ms /    69 runs   (    0.56 ms per token,  1780.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.09 ms /    22 tokens (    5.78 ms per token,   173.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2673.03 ms /    68 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2888.43 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.08 ms /     9 runs   (    0.56 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2590.34 ms /   495 tokens (    5.23 ms per token,   191.09 tokens per second)\n",
            "llama_print_timings:        eval time =     314.13 ms /     8 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2923.27 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.92 ms /   256 runs   (    0.59 ms per token,  1685.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.45 ms /   531 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10031.79 ms /   255 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   13251.46 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.34 ms /   103 runs   (    0.61 ms per token,  1652.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5198.75 ms /   952 tokens (    5.46 ms per token,   183.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4136.09 ms /   102 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    9500.02 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.87 ms /    68 runs   (    0.60 ms per token,  1663.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5365.13 ms /   981 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2719.09 ms /    67 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    8193.02 ms /  1048 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.62 ms /   256 runs   (    0.58 ms per token,  1734.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1493.77 ms /   284 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    9906.73 ms /   255 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =   11783.55 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.82 ms /    70 runs   (    0.65 ms per token,  1527.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1917.40 ms /   364 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2683.26 ms /    69 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4713.85 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.08 ms /    63 runs   (    0.56 ms per token,  1796.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.08 ms /   451 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2428.45 ms /    62 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    4887.43 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.05 ms /    59 runs   (    0.64 ms per token,  1550.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3478.87 ms /   656 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2346.45 ms /    59 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    5926.61 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.19 ms /    12 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1665.18 ms /   319 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
            "llama_print_timings:        eval time =     423.63 ms /    11 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2109.71 ms /   330 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.89 ms /    12 runs   (    0.57 ms per token,  1740.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1456.86 ms /   267 tokens (    5.46 ms per token,   183.27 tokens per second)\n",
            "llama_print_timings:        eval time =     434.40 ms /    11 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    1910.49 ms /   278 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.46 ms /    93 runs   (    0.56 ms per token,  1772.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3075.82 ms /   580 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3610.28 ms /    92 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6815.58 ms /   672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.95 ms /    72 runs   (    0.62 ms per token,  1601.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2845.75 ms /   533 tokens (    5.34 ms per token,   187.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2795.54 ms /    71 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5756.83 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     7 runs   (    0.48 ms per token,  2061.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.32 ms /   500 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =     235.75 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    2881.04 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.25 ms /   120 runs   (    0.64 ms per token,  1573.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2439.21 ms /   460 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4683.41 ms /   119 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    7309.99 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.90 ms /   125 runs   (    0.56 ms per token,  1788.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1916.45 ms /   362 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
            "llama_print_timings:        eval time =    4820.75 ms /   124 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    6908.64 ms /   486 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.46 ms /   256 runs   (    0.60 ms per token,  1657.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2895.13 ms /   548 tokens (    5.28 ms per token,   189.28 tokens per second)\n",
            "llama_print_timings:        eval time =   10084.29 ms /   255 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =   13390.64 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.68 ms /    74 runs   (    0.67 ms per token,  1489.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5368.66 ms /   984 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
            "llama_print_timings:        eval time =    3019.76 ms /    74 runs   (   40.81 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    8523.02 ms /  1058 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.51 ms /    67 runs   (    0.53 ms per token,  1886.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4891.31 ms /   904 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2693.50 ms /    67 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7679.65 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     7 runs   (    0.70 ms per token,  1421.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2249.73 ms /   432 tokens (    5.21 ms per token,   192.02 tokens per second)\n",
            "llama_print_timings:        eval time =     276.36 ms /     7 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2543.62 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.81 ms /   256 runs   (    0.58 ms per token,  1731.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3509.26 ms /   650 tokens (    5.40 ms per token,   185.22 tokens per second)\n",
            "llama_print_timings:        eval time =   10096.31 ms /   255 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =   14008.79 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.83 ms /    97 runs   (    0.59 ms per token,  1706.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3150.00 ms /   591 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3765.94 ms /    96 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7055.63 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.75 ms /    90 runs   (    0.65 ms per token,  1532.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5364.43 ms /   984 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3627.16 ms /    89 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    9149.70 ms /  1073 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.24 ms /    77 runs   (    0.54 ms per token,  1867.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4983.37 ms /   917 tokens (    5.43 ms per token,   184.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3056.41 ms /    76 runs   (   40.22 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    8149.29 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.32 ms /    64 runs   (    0.55 ms per token,  1811.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5442.60 ms /   987 tokens (    5.51 ms per token,   181.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2547.91 ms /    63 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8089.66 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.64 ms /    84 runs   (    0.63 ms per token,  1595.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4984.75 ms /   920 tokens (    5.42 ms per token,   184.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3359.80 ms /    83 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    8488.34 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.97 ms /    71 runs   (    0.52 ms per token,  1920.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3089.20 ms /   584 tokens (    5.29 ms per token,   189.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2784.97 ms /    71 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5973.49 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.07 ms /    69 runs   (    0.70 ms per token,  1435.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5314.48 ms /   976 tokens (    5.45 ms per token,   183.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2816.95 ms /    69 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    8263.14 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.30 ms /    83 runs   (    0.55 ms per token,  1832.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     182.82 ms /    27 tokens (    6.77 ms per token,   147.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3317.29 ms /    82 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    3613.15 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.50 ms /    86 runs   (    0.54 ms per token,  1849.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3027.84 ms /   573 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3329.80 ms /    85 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6472.47 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.98 ms /   108 runs   (    0.49 ms per token,  2038.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5395.62 ms /   978 tokens (    5.52 ms per token,   181.26 tokens per second)\n",
            "llama_print_timings:        eval time =    4330.40 ms /   107 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    9875.88 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.94 ms /   117 runs   (    0.61 ms per token,  1626.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4955.47 ms /   911 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4699.46 ms /   116 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    9846.24 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.83 ms /    87 runs   (    0.54 ms per token,  1857.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3070.29 ms /   580 tokens (    5.29 ms per token,   188.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3381.66 ms /    86 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6570.37 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.83 ms /    75 runs   (    0.61 ms per token,  1636.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3687.49 ms /   685 tokens (    5.38 ms per token,   185.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2925.25 ms /    74 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6732.74 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.44 ms /   110 runs   (    0.53 ms per token,  1882.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3114.83 ms /   588 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =    4275.94 ms /   109 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7536.27 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.36 ms /   148 runs   (    0.57 ms per token,  1754.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5395.91 ms /   980 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5952.10 ms /   147 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =   11569.23 ms /  1127 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.63 ms /    74 runs   (    0.56 ms per token,  1777.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5017.38 ms /   918 tokens (    5.47 ms per token,   182.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2938.48 ms /    73 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8073.38 ms /   991 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.96 ms /   256 runs   (    0.61 ms per token,  1631.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.86 ms /   432 tokens (    5.19 ms per token,   192.78 tokens per second)\n",
            "llama_print_timings:        eval time =    9997.34 ms /   255 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12665.23 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     108.37 ms /   178 runs   (    0.61 ms per token,  1642.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3032.44 ms /   576 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =    6969.81 ms /   177 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   10288.62 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.47 ms /   256 runs   (    0.54 ms per token,  1835.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3137.34 ms /   591 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =   10074.34 ms /   255 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   13608.60 ms /   846 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.02 ms /    79 runs   (    0.54 ms per token,  1836.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3935.17 ms /   735 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3089.70 ms /    78 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7138.39 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.61 ms /    69 runs   (    0.66 ms per token,  1512.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5036.03 ms /   923 tokens (    5.46 ms per token,   183.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2756.49 ms /    68 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    7918.50 ms /   991 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.79 ms /   159 runs   (    0.56 ms per token,  1770.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3028.23 ms /   576 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =    6237.86 ms /   159 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    9490.54 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.15 ms /    68 runs   (    0.62 ms per token,  1613.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3155.31 ms /   588 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2626.30 ms /    67 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5882.49 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.09 ms /    67 runs   (    0.57 ms per token,  1758.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3027.50 ms /   573 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2590.86 ms /    66 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5716.18 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.83 ms /    80 runs   (    0.64 ms per token,  1573.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     173.85 ms /    32 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3111.34 ms /    79 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3418.39 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.92 ms /   115 runs   (    0.56 ms per token,  1799.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3139.76 ms /   588 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
            "llama_print_timings:        eval time =    4478.28 ms /   114 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7781.22 ms /   702 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.88 ms /    91 runs   (    0.65 ms per token,  1545.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2118.15 ms /   408 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3498.13 ms /    90 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    5763.98 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.10 ms /   256 runs   (    0.54 ms per token,  1840.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3139.41 ms /   592 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =   10072.96 ms /   255 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   13619.24 ms /   847 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.81 ms /   256 runs   (    0.56 ms per token,  1792.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1870.57 ms /   358 tokens (    5.23 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9948.51 ms /   255 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12217.50 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.92 ms /   105 runs   (    0.56 ms per token,  1781.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4506.43 ms /   832 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4192.42 ms /   105 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    8854.38 ms /   937 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.75 ms /    98 runs   (    0.68 ms per token,  1468.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3203.43 ms /   605 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3843.81 ms /    97 runs   (   39.63 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    7221.52 ms /   702 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.84 ms /    65 runs   (    0.55 ms per token,  1813.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.40 ms /    21 tokens (    6.11 ms per token,   163.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2511.03 ms /    64 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2726.22 ms /    85 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.17 ms /    11 runs   (    0.65 ms per token,  1534.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3161.49 ms /   600 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =     427.07 ms /    11 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3612.52 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.21 ms /   256 runs   (    0.60 ms per token,  1670.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3115.89 ms /   586 tokens (    5.32 ms per token,   188.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10066.39 ms /   255 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   13604.04 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     103.83 ms /   166 runs   (    0.63 ms per token,  1598.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3167.21 ms /   594 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =    6512.45 ms /   165 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    9954.93 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.44 ms /   256 runs   (    0.56 ms per token,  1772.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3078.09 ms /   581 tokens (    5.30 ms per token,   188.75 tokens per second)\n",
            "llama_print_timings:        eval time =   10095.19 ms /   255 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =   13589.68 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.56 ms per token,  1801.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2989.15 ms /   568 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =     233.90 ms /     6 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3237.34 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.36 ms /   256 runs   (    0.56 ms per token,  1773.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3079.51 ms /   583 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =   10090.84 ms /   255 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   13575.89 ms /   838 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      97.73 ms /   145 runs   (    0.67 ms per token,  1483.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3124.84 ms /   591 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =    5700.38 ms /   144 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    9072.04 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.95 ms /    80 runs   (    0.52 ms per token,  1906.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3565.16 ms /   669 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3102.33 ms /    79 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6777.75 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.03 ms /    11 runs   (    0.73 ms per token,  1370.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3109.28 ms /   579 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =     393.14 ms /    10 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3529.63 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.61 ms /    11 runs   (    0.69 ms per token,  1446.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     133.10 ms /    24 tokens (    5.55 ms per token,   180.31 tokens per second)\n",
            "llama_print_timings:        eval time =     397.30 ms /    10 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =     553.42 ms /    34 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.41 ms /    66 runs   (    0.57 ms per token,  1764.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3613.57 ms /   674 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2557.01 ms /    65 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6268.75 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.89 ms /   256 runs   (    0.56 ms per token,  1791.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3079.80 ms /   581 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =   10100.34 ms /   255 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =   13598.10 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.44 ms /     9 runs   (    0.60 ms per token,  1653.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5350.62 ms /   973 tokens (    5.50 ms per token,   181.85 tokens per second)\n",
            "llama_print_timings:        eval time =     325.17 ms /     8 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    5703.42 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.21 ms /   256 runs   (    0.54 ms per token,  1838.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3094.28 ms /   582 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =   10136.02 ms /   255 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =   13642.29 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.14 ms /   256 runs   (    0.58 ms per token,  1716.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2126.93 ms /   402 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =    9972.64 ms /   255 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12508.01 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.27 ms /    77 runs   (    0.56 ms per token,  1779.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3958.49 ms /   736 tokens (    5.38 ms per token,   185.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3053.71 ms /    77 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    7128.56 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.91 ms /   116 runs   (    0.64 ms per token,  1569.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3120.29 ms /   590 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4548.53 ms /   115 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    7864.92 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.07 ms /   256 runs   (    0.59 ms per token,  1683.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2469.00 ms /   469 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
            "llama_print_timings:        eval time =   10025.41 ms /   255 runs   (   39.32 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12916.81 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.93 ms /    67 runs   (    0.55 ms per token,  1814.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4350.78 ms /   805 tokens (    5.40 ms per token,   185.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2626.43 ms /    66 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    7079.42 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.28 ms /    60 runs   (    0.67 ms per token,  1489.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3564.83 ms /   667 tokens (    5.34 ms per token,   187.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2348.57 ms /    59 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6020.35 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.47 ms /   103 runs   (    0.57 ms per token,  1761.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3090.55 ms /   579 tokens (    5.34 ms per token,   187.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3998.53 ms /   102 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7245.00 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.71 ms /    12 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.65 ms /   460 tokens (    5.25 ms per token,   190.43 tokens per second)\n",
            "llama_print_timings:        eval time =     427.16 ms /    11 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2864.96 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.15 ms /     7 runs   (    0.74 ms per token,  1358.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1907.87 ms /   365 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =     235.32 ms /     6 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2161.62 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.75 ms /   115 runs   (    0.57 ms per token,  1748.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3202.76 ms /   599 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    4474.72 ms /   114 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7848.90 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.56 ms /   126 runs   (    0.66 ms per token,  1526.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2899.30 ms /   549 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4938.16 ms /   125 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    8062.99 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.83 ms /   107 runs   (    0.56 ms per token,  1788.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3123.16 ms /   592 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =    4153.74 ms /   106 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    7428.22 ms /   698 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     106.55 ms /   160 runs   (    0.67 ms per token,  1501.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.62 ms /   426 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =    6213.22 ms /   159 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    8729.46 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     163.13 ms /   256 runs   (    0.64 ms per token,  1569.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.74 ms /   429 tokens (    5.23 ms per token,   191.20 tokens per second)\n",
            "llama_print_timings:        eval time =   10007.78 ms /   255 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12706.25 ms /   684 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     122.07 ms /   192 runs   (    0.64 ms per token,  1572.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2860.45 ms /   544 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =    7564.73 ms /   192 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   10753.81 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.19 ms /    64 runs   (    0.57 ms per token,  1768.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5371.14 ms /   983 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2545.11 ms /    63 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    8018.71 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.14 ms /   236 runs   (    0.61 ms per token,  1637.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3077.65 ms /   579 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9271.46 ms /   235 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   12731.26 ms /   814 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.86 ms /   118 runs   (    0.66 ms per token,  1515.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3119.70 ms /   590 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4612.34 ms /   117 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7930.75 ms /   707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.65 ms /    76 runs   (    0.55 ms per token,  1824.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1853.83 ms /   356 tokens (    5.21 ms per token,   192.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2900.84 ms /    75 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    4850.40 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.95 ms /   256 runs   (    0.60 ms per token,  1662.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3159.72 ms /   599 tokens (    5.27 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =   10061.33 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13609.28 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.47 ms /    81 runs   (    0.66 ms per token,  1514.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4014.51 ms /   746 tokens (    5.38 ms per token,   185.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3198.38 ms /    80 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    7346.40 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.10 ms /   256 runs   (    0.61 ms per token,  1629.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3837.75 ms /   720 tokens (    5.33 ms per token,   187.61 tokens per second)\n",
            "llama_print_timings:        eval time =   10193.35 ms /   255 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =   14444.07 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.78 ms /    66 runs   (    0.54 ms per token,  1844.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5505.48 ms /  1008 tokens (    5.46 ms per token,   183.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2674.61 ms /    66 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    8272.80 ms /  1074 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.38 ms /    92 runs   (    0.55 ms per token,  1825.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3652.53 ms /   680 tokens (    5.37 ms per token,   186.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3585.07 ms /    91 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    7359.48 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.98 ms /   108 runs   (    0.53 ms per token,  1895.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2851.33 ms /   542 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4203.61 ms /   107 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    7202.49 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.97 ms /   142 runs   (    0.52 ms per token,  1919.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4874.40 ms /   896 tokens (    5.44 ms per token,   183.82 tokens per second)\n",
            "llama_print_timings:        eval time =    5674.59 ms /   141 runs   (   40.25 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =   10740.29 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.43 ms /    91 runs   (    0.61 ms per token,  1641.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3581.85 ms /   670 tokens (    5.35 ms per token,   187.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3548.59 ms /    90 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7263.17 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.94 ms /    80 runs   (    0.55 ms per token,  1820.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     173.54 ms /    30 tokens (    5.78 ms per token,   172.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3104.91 ms /    79 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3376.67 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.36 ms /   247 runs   (    0.57 ms per token,  1759.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4798.83 ms /   887 tokens (    5.41 ms per token,   184.84 tokens per second)\n",
            "llama_print_timings:        eval time =    9948.06 ms /   246 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =   15113.20 ms /  1133 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.87 ms /    95 runs   (    0.66 ms per token,  1511.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2812.56 ms /   533 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3687.26 ms /    94 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6658.49 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.90 ms /    82 runs   (    0.55 ms per token,  1826.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4825.28 ms /   890 tokens (    5.42 ms per token,   184.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3247.31 ms /    81 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    8183.28 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.64 ms /   121 runs   (    0.57 ms per token,  1762.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3906.57 ms /   724 tokens (    5.40 ms per token,   185.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4735.91 ms /   120 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    8808.47 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     6 runs   (    0.71 ms per token,  1404.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5492.22 ms /  1006 tokens (    5.46 ms per token,   183.17 tokens per second)\n",
            "llama_print_timings:        eval time =     203.50 ms /     5 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    5721.24 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.05 ms /   114 runs   (    0.54 ms per token,  1837.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5300.54 ms /   966 tokens (    5.49 ms per token,   182.25 tokens per second)\n",
            "llama_print_timings:        eval time =    4563.25 ms /   113 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   10020.21 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.20 ms /   118 runs   (    0.57 ms per token,  1756.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5507.73 ms /  1002 tokens (    5.50 ms per token,   181.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4750.44 ms /   117 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =   10425.92 ms /  1119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      85.74 ms /   141 runs   (    0.61 ms per token,  1644.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5299.70 ms /   970 tokens (    5.46 ms per token,   183.03 tokens per second)\n",
            "llama_print_timings:        eval time =    5688.48 ms /   140 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =   11210.55 ms /  1110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.19 ms /    67 runs   (    0.57 ms per token,  1754.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4648.55 ms /   862 tokens (    5.39 ms per token,   185.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2641.57 ms /    66 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    7383.15 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.94 ms /    95 runs   (    0.56 ms per token,  1794.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5300.91 ms /   968 tokens (    5.48 ms per token,   182.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3831.37 ms /    95 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    9265.38 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.68 ms /    75 runs   (    0.66 ms per token,  1509.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4327.49 ms /   802 tokens (    5.40 ms per token,   185.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2976.09 ms /    74 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7429.79 ms /   876 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     131.13 ms /   226 runs   (    0.58 ms per token,  1723.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5980.88 ms /  1085 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9237.26 ms /   225 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =   15581.31 ms /  1310 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.62 ms /    59 runs   (    0.55 ms per token,  1808.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3425.54 ms /   648 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2274.49 ms /    58 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5779.65 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.29 ms /    75 runs   (    0.67 ms per token,  1491.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3842.97 ms /   720 tokens (    5.34 ms per token,   187.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2986.23 ms /    75 runs   (   39.82 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6952.29 ms /   795 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.03 ms /   112 runs   (    0.60 ms per token,  1670.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5917.18 ms /  1077 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
            "llama_print_timings:        eval time =    4529.88 ms /   111 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =   10618.58 ms /  1188 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.75 ms /   111 runs   (    0.55 ms per token,  1827.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4809.95 ms /   886 tokens (    5.43 ms per token,   184.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4410.68 ms /   110 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    9371.91 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.96 ms /    63 runs   (    0.55 ms per token,  1801.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     223.05 ms /    35 tokens (    6.37 ms per token,   156.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2490.10 ms /    62 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    2794.63 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.01 ms /    10 runs   (    0.70 ms per token,  1427.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2888.62 ms /   539 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
            "llama_print_timings:        eval time =     352.20 ms /     9 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    3267.67 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.55 ms /    81 runs   (    0.56 ms per token,  1778.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =      86.71 ms /    16 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3179.41 ms /    81 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3370.86 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.40 ms /    74 runs   (    0.64 ms per token,  1561.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4788.85 ms /   887 tokens (    5.40 ms per token,   185.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2932.18 ms /    73 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    7837.10 ms /   960 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2483.10 ms /   466 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =     232.37 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2731.26 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.96 ms /    72 runs   (    0.54 ms per token,  1848.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2630.57 ms /   502 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2788.42 ms /    71 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5510.32 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.58 ms /   112 runs   (    0.63 ms per token,  1586.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2110.21 ms /   405 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
            "llama_print_timings:        eval time =    4326.51 ms /   111 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6604.92 ms /   516 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1929.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2462.72 ms /   467 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =     230.09 ms /     6 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2707.69 ms /   473 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1812.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3731.51 ms /   698 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
            "llama_print_timings:        eval time =     198.39 ms /     5 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    3950.62 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.92 ms /    89 runs   (    0.64 ms per token,  1563.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4839.21 ms /   892 tokens (    5.43 ms per token,   184.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3561.04 ms /    88 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    8541.87 ms /   980 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.24 ms /    71 runs   (    0.52 ms per token,  1906.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     181.42 ms /    31 tokens (    5.85 ms per token,   170.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2809.09 ms /    70 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    3078.15 ms /   101 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.47 ms /    70 runs   (    0.55 ms per token,  1819.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1766.54 ms /   341 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2666.92 ms /    69 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    4521.53 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.08 ms /    68 runs   (    0.55 ms per token,  1834.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4593.42 ms /   844 tokens (    5.44 ms per token,   183.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2673.03 ms /    67 runs   (   39.90 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7360.11 ms /   911 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.65 ms /     9 runs   (    0.52 ms per token,  1935.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4747.00 ms /   879 tokens (    5.40 ms per token,   185.17 tokens per second)\n",
            "llama_print_timings:        eval time =     318.92 ms /     8 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    5087.54 ms /   887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.12 ms /    68 runs   (    0.68 ms per token,  1474.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2414.26 ms /   458 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2621.88 ms /    67 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5153.89 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.59 ms /   102 runs   (    0.55 ms per token,  1834.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1518.50 ms /   293 tokens (    5.18 ms per token,   192.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3890.84 ms /   101 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    5542.71 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.12 ms /    69 runs   (    0.65 ms per token,  1529.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4980.28 ms /   916 tokens (    5.44 ms per token,   183.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2761.21 ms /    68 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    7859.10 ms /   984 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.77 ms /     6 runs   (    0.46 ms per token,  2162.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5358.19 ms /   981 tokens (    5.46 ms per token,   183.08 tokens per second)\n",
            "llama_print_timings:        eval time =     200.63 ms /     5 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    5577.20 ms /   986 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.32 ms /    79 runs   (    0.75 ms per token,  1331.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4981.45 ms /   920 tokens (    5.41 ms per token,   184.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3210.38 ms /    79 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    8334.55 ms /   999 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.67 ms /    90 runs   (    0.53 ms per token,  1888.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5448.41 ms /  1000 tokens (    5.45 ms per token,   183.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3647.24 ms /    90 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    9216.31 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.95 ms /    65 runs   (    0.71 ms per token,  1414.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     936.04 ms /   179 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2476.45 ms /    64 runs   (   38.69 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3516.42 ms /   243 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.79 ms /   256 runs   (    0.58 ms per token,  1720.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3791.98 ms /   711 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =   10161.16 ms /   255 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =   14357.23 ms /   966 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.80 ms /    65 runs   (    0.52 ms per token,  1923.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2760.60 ms /   528 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2520.45 ms /    64 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5363.90 ms /   592 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.77 ms /    80 runs   (    0.67 ms per token,  1487.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4756.10 ms /   880 tokens (    5.40 ms per token,   185.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3195.37 ms /    79 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8086.15 ms /   959 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.71 ms /    72 runs   (    0.54 ms per token,  1859.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4106.03 ms /   766 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2822.15 ms /    71 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    7021.49 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.36 ms /    96 runs   (    0.56 ms per token,  1799.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5820.70 ms /  1055 tokens (    5.52 ms per token,   181.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3865.89 ms /    95 runs   (   40.69 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    9822.77 ms /  1150 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.13 ms /    79 runs   (    0.74 ms per token,  1358.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4792.35 ms /   882 tokens (    5.43 ms per token,   184.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3166.79 ms /    78 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    8096.44 ms /   960 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.58 ms /    65 runs   (    0.55 ms per token,  1827.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4866.47 ms /   896 tokens (    5.43 ms per token,   184.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2613.45 ms /    65 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7569.02 ms /   961 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.85 ms /    82 runs   (    0.68 ms per token,  1468.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3519.41 ms /   664 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3261.71 ms /    82 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    6918.54 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.20 ms /    68 runs   (    0.55 ms per token,  1828.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2963.38 ms /   558 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2638.37 ms /    67 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5689.92 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.81 ms /    14 runs   (    0.56 ms per token,  1793.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1600.46 ms /   312 tokens (    5.13 ms per token,   194.94 tokens per second)\n",
            "llama_print_timings:        eval time =     507.03 ms /    13 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2128.12 ms /   325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.28 ms /    68 runs   (    0.64 ms per token,  1571.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     828.90 ms /   160 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2598.52 ms /    67 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3529.77 ms /   227 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.29 ms /    73 runs   (    0.50 ms per token,  2011.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2826.85 ms /   534 tokens (    5.29 ms per token,   188.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2830.13 ms /    72 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5749.23 ms /   606 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.87 ms /   256 runs   (    0.57 ms per token,  1754.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2543.36 ms /   485 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =   10006.97 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12934.62 ms /   740 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.03 ms /    82 runs   (    0.73 ms per token,  1365.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5539.86 ms /  1010 tokens (    5.49 ms per token,   182.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3302.75 ms /    81 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    8988.81 ms /  1091 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.82 ms /    92 runs   (    0.53 ms per token,  1884.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4848.36 ms /   891 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3654.13 ms /    91 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8624.59 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     106.79 ms /   184 runs   (    0.58 ms per token,  1723.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3904.85 ms /   727 tokens (    5.37 ms per token,   186.18 tokens per second)\n",
            "llama_print_timings:        eval time =    7284.75 ms /   183 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =   11455.54 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1678.32 ms /   323 tokens (    5.20 ms per token,   192.45 tokens per second)\n",
            "llama_print_timings:        eval time =     233.20 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    1923.11 ms /   329 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1785.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     205.13 ms /    34 tokens (    6.03 ms per token,   165.75 tokens per second)\n",
            "llama_print_timings:        eval time =     229.19 ms /     6 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =     445.10 ms /    40 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1832.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     916.28 ms /   173 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =     229.20 ms /     6 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
            "llama_print_timings:       total time =    1156.41 ms /   179 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.47 ms /    79 runs   (    0.55 ms per token,  1817.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3687.32 ms /   683 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3065.85 ms /    78 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6862.79 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.59 ms /    76 runs   (    0.55 ms per token,  1827.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3056.08 ms /   576 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2953.47 ms /    75 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6106.92 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.05 ms /     7 runs   (    0.72 ms per token,  1386.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2433.28 ms /   464 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     273.81 ms /     7 runs   (   39.12 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2724.74 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.69 ms /    68 runs   (    0.54 ms per token,  1853.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4723.17 ms /   870 tokens (    5.43 ms per token,   184.20 tokens per second)\n",
            "llama_print_timings:        eval time =    2681.86 ms /    67 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7497.46 ms /   937 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.36 ms /    87 runs   (    0.58 ms per token,  1727.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5947.83 ms /  1080 tokens (    5.51 ms per token,   181.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3522.37 ms /    86 runs   (   40.96 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    9605.06 ms /  1166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.35 ms /    67 runs   (    0.56 ms per token,  1793.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5763.68 ms /  1046 tokens (    5.51 ms per token,   181.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2695.30 ms /    66 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    8556.80 ms /  1112 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.48 ms /   256 runs   (    0.56 ms per token,  1771.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2971.58 ms /   558 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =   10024.77 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13366.72 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.00 ms /   108 runs   (    0.55 ms per token,  1830.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3501.93 ms /   651 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
            "llama_print_timings:        eval time =    4215.64 ms /   107 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    7858.55 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.22 ms /    73 runs   (    0.62 ms per token,  1614.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3704.39 ms /   685 tokens (    5.41 ms per token,   184.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2881.52 ms /    72 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    6702.57 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.15 ms /    68 runs   (    0.55 ms per token,  1830.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2211.01 ms /   423 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2609.78 ms /    67 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4906.92 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.13 ms /   256 runs   (    0.59 ms per token,  1705.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.70 ms /   430 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.59 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12631.06 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      91.87 ms /   155 runs   (    0.59 ms per token,  1687.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2458.18 ms /   471 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =    6050.38 ms /   154 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    8731.65 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.98 ms /     6 runs   (    0.50 ms per token,  2016.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5705.14 ms /  1040 tokens (    5.49 ms per token,   182.29 tokens per second)\n",
            "llama_print_timings:        eval time =     242.09 ms /     6 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    5967.50 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.36 ms /    87 runs   (    0.58 ms per token,  1727.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2939.26 ms /   556 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3383.26 ms /    86 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6443.67 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.69 ms /    99 runs   (    0.53 ms per token,  1878.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3642.88 ms /   676 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3862.49 ms /    98 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7634.89 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.84 ms /    99 runs   (    0.62 ms per token,  1600.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3696.19 ms /   694 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3894.57 ms /    98 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    7747.93 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.64 ms /    70 runs   (    0.55 ms per token,  1811.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4254.03 ms /   790 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2740.21 ms /    69 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7093.20 ms /   859 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.42 ms /    89 runs   (    0.70 ms per token,  1425.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3649.55 ms /   687 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3510.31 ms /    88 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7310.56 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.82 ms /   111 runs   (    0.54 ms per token,  1855.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5581.71 ms /  1018 tokens (    5.48 ms per token,   182.38 tokens per second)\n",
            "llama_print_timings:        eval time =    4467.04 ms /   110 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =   10205.67 ms /  1128 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.97 ms /   162 runs   (    0.54 ms per token,  1841.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5761.49 ms /  1042 tokens (    5.53 ms per token,   180.86 tokens per second)\n",
            "llama_print_timings:        eval time =    6555.64 ms /   161 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =   12541.06 ms /  1203 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     6 runs   (    0.65 ms per token,  1530.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3379.45 ms /   631 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
            "llama_print_timings:        eval time =     196.74 ms /     5 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3594.42 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.52 ms /   134 runs   (    0.54 ms per token,  1847.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3782.05 ms /   709 tokens (    5.33 ms per token,   187.46 tokens per second)\n",
            "llama_print_timings:        eval time =    5242.66 ms /   133 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    9198.15 ms /   842 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.85 ms /    77 runs   (    0.52 ms per token,  1932.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5624.63 ms /  1021 tokens (    5.51 ms per token,   181.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3077.90 ms /    76 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    8806.08 ms /  1097 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.27 ms /   256 runs   (    0.57 ms per token,  1762.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4281.51 ms /   794 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =   10242.79 ms /   255 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =   14914.16 ms /  1049 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.97 ms /    76 runs   (    0.71 ms per token,  1408.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3697.00 ms /   695 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2990.10 ms /    75 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    6819.78 ms /   770 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.97 ms /    77 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.29 ms /   471 tokens (    5.22 ms per token,   191.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2971.39 ms /    76 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5528.09 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.80 ms /    75 runs   (    0.65 ms per token,  1536.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3690.55 ms /   693 tokens (    5.33 ms per token,   187.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2940.84 ms /    74 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    6750.07 ms /   767 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.33 ms /    69 runs   (    0.53 ms per token,  1899.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3530.47 ms /   660 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2677.03 ms /    68 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6304.54 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.03 ms /    69 runs   (    0.65 ms per token,  1532.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3692.22 ms /   693 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.69 ms /    68 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    6513.20 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.62 ms /    76 runs   (    0.53 ms per token,  1871.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2921.68 ms /   551 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2936.99 ms /    75 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5963.73 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.05 ms /    76 runs   (    0.57 ms per token,  1765.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3247.32 ms /   612 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2939.12 ms /    75 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6295.01 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.67 ms /     7 runs   (    1.10 ms per token,   912.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2094.26 ms /   398 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     234.96 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    2350.41 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.00 ms /   155 runs   (    0.54 ms per token,  1845.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2826.84 ms /   536 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
            "llama_print_timings:        eval time =    6068.06 ms /   155 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    9107.78 ms /   691 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.46 ms /   256 runs   (    0.58 ms per token,  1724.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2512.00 ms /   480 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =   10021.99 ms /   256 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12939.66 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.80 ms /    68 runs   (    0.73 ms per token,  1365.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1942.18 ms /   372 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2596.55 ms /    67 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    4662.10 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.64 ms /    78 runs   (    0.61 ms per token,  1637.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     598.30 ms /   106 tokens (    5.64 ms per token,   177.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3008.58 ms /    77 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3724.73 ms /   183 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.12 ms /    63 runs   (    0.54 ms per token,  1846.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.53 ms /   478 tokens (    5.23 ms per token,   191.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2421.88 ms /    62 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5011.03 ms /   540 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.15 ms /    66 runs   (    0.68 ms per token,  1461.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1811.51 ms /   342 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2551.91 ms /    65 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    4479.22 ms /   407 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1808.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1956.82 ms /   373 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =     193.13 ms /     5 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2163.74 ms /   378 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     7 runs   (    0.59 ms per token,  1707.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.46 ms /   458 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =     234.32 ms /     6 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2662.92 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.60 ms /    82 runs   (    0.54 ms per token,  1838.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.09 ms /   514 tokens (    5.30 ms per token,   188.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3180.70 ms /    81 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6016.63 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      10.97 ms /    11 runs   (    1.00 ms per token,  1002.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     126.72 ms /    21 tokens (    6.03 ms per token,   165.72 tokens per second)\n",
            "llama_print_timings:        eval time =     389.95 ms /    10 runs   (   38.99 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =     540.64 ms /    31 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.48 ms /    66 runs   (    0.55 ms per token,  1809.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2939.46 ms /   547 tokens (    5.37 ms per token,   186.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2554.06 ms /    65 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5589.61 ms /   612 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.74 ms /   111 runs   (    0.54 ms per token,  1858.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3296.71 ms /   621 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =    4325.13 ms /   110 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7779.42 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.46 ms /   256 runs   (    0.54 ms per token,  1835.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2758.91 ms /   519 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
            "llama_print_timings:        eval time =   10014.75 ms /   255 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   13161.21 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.06 ms /    67 runs   (    0.55 ms per token,  1807.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3162.83 ms /   586 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2584.84 ms /    66 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5846.77 ms /   652 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.18 ms /    85 runs   (    0.57 ms per token,  1764.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4523.22 ms /   839 tokens (    5.39 ms per token,   185.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3365.57 ms /    84 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    8018.62 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.16 ms /    72 runs   (    0.53 ms per token,  1887.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5264.05 ms /   960 tokens (    5.48 ms per token,   182.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2908.50 ms /    72 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    8281.89 ms /  1032 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.76 ms /   256 runs   (    0.59 ms per token,  1686.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2551.26 ms /   486 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
            "llama_print_timings:        eval time =   10019.27 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12986.77 ms /   741 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.11 ms /   118 runs   (    0.64 ms per token,  1571.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1726.95 ms /   328 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4581.85 ms /   117 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6490.88 ms /   445 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.54 ms /    66 runs   (    0.58 ms per token,  1712.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3823.44 ms /   712 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2575.05 ms /    65 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    6501.69 ms /   777 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.05 ms /    70 runs   (    0.60 ms per token,  1664.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3660.01 ms /   684 tokens (    5.35 ms per token,   186.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2741.84 ms /    69 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6514.84 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.36 ms /    14 runs   (    0.60 ms per token,  1674.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2583.60 ms /   488 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
            "llama_print_timings:        eval time =     510.65 ms /    13 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3122.16 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.49 ms /    58 runs   (    0.54 ms per token,  1842.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3839.94 ms /   714 tokens (    5.38 ms per token,   185.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2250.35 ms /    57 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6175.84 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.13 ms /    12 runs   (    0.68 ms per token,  1476.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2905.58 ms /   552 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
            "llama_print_timings:        eval time =     476.91 ms /    12 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    3409.90 ms /   564 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     111.68 ms /   206 runs   (    0.54 ms per token,  1844.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2980.96 ms /   555 tokens (    5.37 ms per token,   186.18 tokens per second)\n",
            "llama_print_timings:        eval time =    8049.74 ms /   205 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   11333.83 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.34 ms /   256 runs   (    0.57 ms per token,  1749.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2556.75 ms /   482 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =   10008.29 ms /   255 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12966.63 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.90 ms /   256 runs   (    0.60 ms per token,  1663.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.85 ms /   373 tokens (    5.20 ms per token,   192.28 tokens per second)\n",
            "llama_print_timings:        eval time =    9939.99 ms /   255 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =   12299.07 ms /   628 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.34 ms /    83 runs   (    0.68 ms per token,  1473.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2056.20 ms /   389 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3213.89 ms /    82 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5410.64 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.90 ms /   256 runs   (    0.61 ms per token,  1652.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3137.56 ms /   589 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =   10067.45 ms /   255 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   13639.20 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.12 ms /    88 runs   (    0.58 ms per token,  1721.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2478.68 ms /   467 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3409.64 ms /    87 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6014.29 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.52 ms /    55 runs   (    0.68 ms per token,  1465.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5180.53 ms /   952 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2203.43 ms /    54 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    7490.81 ms /  1006 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.66 ms /    90 runs   (    0.56 ms per token,  1776.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3803.16 ms /   706 tokens (    5.39 ms per token,   185.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3520.79 ms /    89 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    7459.15 ms /   795 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.01 ms /   429 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
            "llama_print_timings:        eval time =     231.23 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2489.48 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.97 ms /    82 runs   (    0.63 ms per token,  1577.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2928.89 ms /   552 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3233.81 ms /    82 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6295.55 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.55 ms /   256 runs   (    0.58 ms per token,  1711.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2899.29 ms /   549 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =   10075.79 ms /   255 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   13405.81 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.95 ms /   113 runs   (    0.51 ms per token,  1950.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3217.38 ms /   604 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =    4403.57 ms /   112 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7772.59 ms /   716 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.26 ms /    90 runs   (    0.56 ms per token,  1790.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4465.65 ms /   818 tokens (    5.46 ms per token,   183.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3550.24 ms /    89 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    8154.88 ms /   907 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.64 ms /   136 runs   (    0.65 ms per token,  1534.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3030.66 ms /   576 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
            "llama_print_timings:        eval time =    5326.02 ms /   135 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    8583.67 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.59 ms /    75 runs   (    0.53 ms per token,  1894.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4076.33 ms /   756 tokens (    5.39 ms per token,   185.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2931.14 ms /    74 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7115.39 ms /   830 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.75 ms /   256 runs   (    0.55 ms per token,  1831.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5383.98 ms /   984 tokens (    5.47 ms per token,   182.76 tokens per second)\n",
            "llama_print_timings:        eval time =   10433.56 ms /   256 runs   (   40.76 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =   16213.96 ms /  1240 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.89 ms /    67 runs   (    0.66 ms per token,  1526.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     180.46 ms /    28 tokens (    6.44 ms per token,   155.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2693.51 ms /    66 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    2988.39 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.70 ms /    90 runs   (    0.55 ms per token,  1811.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5183.14 ms /   946 tokens (    5.48 ms per token,   182.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3587.65 ms /    89 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    8905.95 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.20 ms /   133 runs   (    0.52 ms per token,  1921.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5440.61 ms /   986 tokens (    5.52 ms per token,   181.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5347.72 ms /   132 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =   10981.17 ms /  1118 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.79 ms /   121 runs   (    0.58 ms per token,  1733.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5140.06 ms /   944 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    4872.37 ms /   120 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =   10207.87 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.48 ms /     6 runs   (    0.58 ms per token,  1726.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5450.75 ms /   995 tokens (    5.48 ms per token,   182.54 tokens per second)\n",
            "llama_print_timings:        eval time =     201.50 ms /     5 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5674.54 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.40 ms /   117 runs   (    0.53 ms per token,  1875.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5222.47 ms /   952 tokens (    5.49 ms per token,   182.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4725.34 ms /   117 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   10118.49 ms /  1069 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.94 ms /   107 runs   (    0.65 ms per token,  1529.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5405.10 ms /   988 tokens (    5.47 ms per token,   182.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4323.01 ms /   106 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    9916.07 ms /  1094 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.80 ms /   242 runs   (    0.57 ms per token,  1769.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5165.07 ms /   946 tokens (    5.46 ms per token,   183.15 tokens per second)\n",
            "llama_print_timings:        eval time =    9799.09 ms /   241 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =   15366.98 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     114.62 ms /   190 runs   (    0.60 ms per token,  1657.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4103.26 ms /   764 tokens (    5.37 ms per token,   186.19 tokens per second)\n",
            "llama_print_timings:        eval time =    7561.56 ms /   189 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =   11982.56 ms /   953 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.02 ms /    82 runs   (    0.51 ms per token,  1951.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4469.32 ms /   828 tokens (    5.40 ms per token,   185.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3235.88 ms /    81 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    7819.34 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.56 ms /    57 runs   (    0.57 ms per token,  1750.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5125.22 ms /   936 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2293.25 ms /    57 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7510.55 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.10 ms /   143 runs   (    0.62 ms per token,  1623.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4840.19 ms /   895 tokens (    5.41 ms per token,   184.91 tokens per second)\n",
            "llama_print_timings:        eval time =    5744.61 ms /   142 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =   10824.87 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.88 ms /    73 runs   (    0.55 ms per token,  1830.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4474.37 ms /   830 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2876.93 ms /    72 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    7457.39 ms /   902 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.50 ms /    90 runs   (    0.57 ms per token,  1747.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4430.71 ms /   815 tokens (    5.44 ms per token,   183.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3551.53 ms /    89 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    8117.57 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.76 ms /    78 runs   (    0.63 ms per token,  1599.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4704.20 ms /   871 tokens (    5.40 ms per token,   185.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3092.49 ms /    77 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    7923.07 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.17 ms /    75 runs   (    0.55 ms per token,  1821.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4455.07 ms /   822 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2951.72 ms /    74 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7517.87 ms /   896 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.96 ms /    68 runs   (    0.71 ms per token,  1417.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4192.92 ms /   778 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2685.84 ms /    67 runs   (   40.09 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7000.76 ms /   845 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.81 ms /    68 runs   (    0.56 ms per token,  1798.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3001.60 ms /   567 tokens (    5.29 ms per token,   188.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2633.94 ms /    67 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5730.40 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.02 ms /    64 runs   (    0.59 ms per token,  1683.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3246.86 ms /   612 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2469.90 ms /    63 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5814.23 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.89 ms /    76 runs   (    0.55 ms per token,  1814.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3286.34 ms /   616 tokens (    5.33 ms per token,   187.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2990.33 ms /    76 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6382.59 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.17 ms /    71 runs   (    0.55 ms per token,  1812.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3206.39 ms /   608 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2757.33 ms /    70 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6060.86 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1551.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2487.50 ms /   472 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =     238.24 ms /     6 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    2743.26 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1877.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.74 ms /   382 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     231.99 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2275.05 ms /   388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.88 ms /    97 runs   (    0.55 ms per token,  1834.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1898.33 ms /   368 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3725.47 ms /    96 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    5751.85 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1773.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2414.98 ms /   462 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =     233.33 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2663.88 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.11 ms /   106 runs   (    0.56 ms per token,  1793.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3338.64 ms /   622 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =    4130.96 ms /   105 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7620.23 ms /   727 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.87 ms /   131 runs   (    0.59 ms per token,  1682.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3090.66 ms /   582 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
            "llama_print_timings:        eval time =    5136.07 ms /   130 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    8434.21 ms /   712 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.64 ms /   107 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3070.11 ms /   575 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4163.63 ms /   106 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7381.67 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.95 ms /    91 runs   (    0.64 ms per token,  1570.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3054.54 ms /   575 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3566.15 ms /    90 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    6775.84 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.17 ms /    66 runs   (    0.56 ms per token,  1775.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2294.74 ms /   440 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2571.18 ms /    66 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4956.23 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.51 ms /    11 runs   (    0.50 ms per token,  1995.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2988.09 ms /   568 tokens (    5.26 ms per token,   190.09 tokens per second)\n",
            "llama_print_timings:        eval time =     427.77 ms /    11 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    3436.44 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.41 ms /    72 runs   (    0.62 ms per token,  1621.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3440.54 ms /   642 tokens (    5.36 ms per token,   186.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2808.31 ms /    71 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6365.23 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.68 ms /    77 runs   (    0.55 ms per token,  1803.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.24 ms /   478 tokens (    5.23 ms per token,   191.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2966.62 ms /    76 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5570.87 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.95 ms /    64 runs   (    0.67 ms per token,  1490.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2894.51 ms /   549 tokens (    5.27 ms per token,   189.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2471.97 ms /    63 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5480.02 ms /   612 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.37 ms /    77 runs   (    0.54 ms per token,  1861.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3672.28 ms /   683 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2980.84 ms /    76 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6760.95 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.39 ms /    90 runs   (    0.70 ms per token,  1419.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3610.73 ms /   680 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3541.13 ms /    89 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    7312.94 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.63 ms /   256 runs   (    0.60 ms per token,  1677.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2506.89 ms /   479 tokens (    5.23 ms per token,   191.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10023.46 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12943.85 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.94 ms /    70 runs   (    0.54 ms per token,  1845.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4343.25 ms /   803 tokens (    5.41 ms per token,   184.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2740.30 ms /    69 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7188.18 ms /   872 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.88 ms /    92 runs   (    0.64 ms per token,  1562.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5041.82 ms /   927 tokens (    5.44 ms per token,   183.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3680.36 ms /    91 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8877.34 ms /  1018 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.59 ms /    78 runs   (    0.56 ms per token,  1789.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2199.74 ms /   424 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2998.22 ms /    77 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5302.68 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.96 ms /    78 runs   (    0.67 ms per token,  1501.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1752.88 ms /   336 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3044.46 ms /    78 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4922.78 ms /   414 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.83 ms /    92 runs   (    0.56 ms per token,  1774.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3007.20 ms /   565 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3560.50 ms /    91 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6696.84 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.81 ms /    59 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     845.72 ms /   164 tokens (    5.16 ms per token,   193.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2212.57 ms /    58 runs   (   38.15 ms per token,    26.21 tokens per second)\n",
            "llama_print_timings:       total time =    3137.91 ms /   222 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     132.04 ms /   224 runs   (    0.59 ms per token,  1696.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2602.87 ms /   492 tokens (    5.29 ms per token,   189.02 tokens per second)\n",
            "llama_print_timings:        eval time =    8728.94 ms /   223 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   11680.42 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     129.43 ms /   207 runs   (    0.63 ms per token,  1599.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2942.68 ms /   556 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =    8112.66 ms /   206 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   11391.93 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.65 ms /   256 runs   (    0.62 ms per token,  1613.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.78 ms /   516 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =   10041.89 ms /   255 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   13187.18 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.91 ms /   256 runs   (    0.59 ms per token,  1707.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   10112.40 ms /   256 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   10538.95 ms /   256 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.95 ms /     7 runs   (    0.56 ms per token,  1773.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.60 ms /   448 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
            "llama_print_timings:        eval time =     270.96 ms /     7 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2617.96 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1774.00 ms /   344 tokens (    5.16 ms per token,   193.91 tokens per second)\n",
            "llama_print_timings:        eval time =     271.12 ms /     7 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2058.54 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.30 ms /    72 runs   (    0.66 ms per token,  1522.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4397.32 ms /   815 tokens (    5.40 ms per token,   185.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2860.82 ms /    71 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    7386.56 ms /   886 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.00 ms /    12 runs   (    0.58 ms per token,  1714.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2202.26 ms /   421 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     422.19 ms /    11 runs   (   38.38 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2645.77 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.48 ms /   109 runs   (    0.54 ms per token,  1863.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1817.03 ms /   352 tokens (    5.16 ms per token,   193.72 tokens per second)\n",
            "llama_print_timings:        eval time =    4236.09 ms /   109 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    6199.71 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.76 ms /     7 runs   (    0.68 ms per token,  1471.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2799.26 ms /   524 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =     238.13 ms /     6 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    3057.37 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.04 ms /    12 runs   (    0.59 ms per token,  1705.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2957.31 ms /   555 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =     425.66 ms /    11 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    3414.45 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.44 ms /    83 runs   (    0.58 ms per token,  1713.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4427.97 ms /   818 tokens (    5.41 ms per token,   184.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3268.37 ms /    82 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7817.13 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.07 ms /     7 runs   (    0.72 ms per token,  1380.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2453.98 ms /   461 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =     231.82 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2706.22 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.63 ms /   138 runs   (    0.56 ms per token,  1800.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2250.55 ms /   432 tokens (    5.21 ms per token,   191.95 tokens per second)\n",
            "llama_print_timings:        eval time =    5361.39 ms /   137 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    7805.55 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.27 ms /     7 runs   (    0.61 ms per token,  1638.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2458.44 ms /   470 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
            "llama_print_timings:        eval time =     234.65 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2709.71 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.34 ms /    64 runs   (    0.55 ms per token,  1811.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5175.47 ms /   944 tokens (    5.48 ms per token,   182.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2582.51 ms /    64 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7860.00 ms /  1008 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.66 ms /   125 runs   (    0.59 ms per token,  1697.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4990.68 ms /   917 tokens (    5.44 ms per token,   183.74 tokens per second)\n",
            "llama_print_timings:        eval time =    5046.73 ms /   124 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =   10245.72 ms /  1041 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.26 ms /   145 runs   (    0.51 ms per token,  1979.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     181.79 ms /    30 tokens (    6.06 ms per token,   165.02 tokens per second)\n",
            "llama_print_timings:        eval time =    5816.34 ms /   144 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    6191.52 ms /   174 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.38 ms /   110 runs   (    0.52 ms per token,  1917.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6116.22 ms /  1098 tokens (    5.57 ms per token,   179.52 tokens per second)\n",
            "llama_print_timings:        eval time =    4459.72 ms /   109 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =   10740.08 ms /  1207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.47 ms /   103 runs   (    0.67 ms per token,  1482.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4942.53 ms /   911 tokens (    5.43 ms per token,   184.32 tokens per second)\n",
            "llama_print_timings:        eval time =    4138.84 ms /   102 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    9269.79 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.86 ms /    68 runs   (    0.56 ms per token,  1796.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2374.62 ms /   452 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2621.54 ms /    67 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5093.00 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.29 ms /   160 runs   (    0.51 ms per token,  1944.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7234.56 ms /  1288 tokens (    5.62 ms per token,   178.03 tokens per second)\n",
            "llama_print_timings:        eval time =    6651.98 ms /   160 runs   (   41.57 ms per token,    24.05 tokens per second)\n",
            "llama_print_timings:       total time =   14124.55 ms /  1448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.83 ms /    85 runs   (    0.60 ms per token,  1672.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5428.10 ms /   988 tokens (    5.49 ms per token,   182.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3414.54 ms /    84 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8986.54 ms /  1072 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.89 ms /    75 runs   (    0.59 ms per token,  1708.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4939.55 ms /   912 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2980.24 ms /    74 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    8037.66 ms /   986 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1934.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7282.76 ms /  1296 tokens (    5.62 ms per token,   177.95 tokens per second)\n",
            "llama_print_timings:        eval time =     204.94 ms /     5 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =    7517.82 ms /  1301 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.16 ms /   121 runs   (    0.63 ms per token,  1588.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6036.94 ms /  1096 tokens (    5.51 ms per token,   181.55 tokens per second)\n",
            "llama_print_timings:        eval time =    4931.41 ms /   120 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   11175.20 ms /  1216 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.84 ms /   128 runs   (    0.62 ms per token,  1603.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4976.53 ms /   914 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    5145.97 ms /   127 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =   10350.69 ms /  1041 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.34 ms /   110 runs   (    0.53 ms per token,  1885.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5418.90 ms /   992 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4458.57 ms /   110 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   10040.55 ms /  1102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.55 ms /    91 runs   (    0.52 ms per token,  1913.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5497.00 ms /  1000 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3645.26 ms /    90 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    9279.84 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.63 ms /    59 runs   (    0.71 ms per token,  1417.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5377.47 ms /   980 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2368.26 ms /    58 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    7859.31 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.08 ms /    81 runs   (    0.56 ms per token,  1796.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6510.17 ms /  1171 tokens (    5.56 ms per token,   179.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3282.71 ms /    80 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    9918.48 ms /  1251 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.68 ms /    67 runs   (    0.67 ms per token,  1499.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     188.96 ms /    32 tokens (    5.91 ms per token,   169.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2781.10 ms /    67 runs   (   41.51 ms per token,    24.09 tokens per second)\n",
            "llama_print_timings:       total time =    3090.39 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.84 ms /    76 runs   (    0.54 ms per token,  1860.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6421.50 ms /  1158 tokens (    5.55 ms per token,   180.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3078.10 ms /    75 runs   (   41.04 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    9623.23 ms /  1233 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.44 ms /    73 runs   (    0.57 ms per token,  1761.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7276.30 ms /  1293 tokens (    5.63 ms per token,   177.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2982.61 ms /    72 runs   (   41.43 ms per token,    24.14 tokens per second)\n",
            "llama_print_timings:       total time =   10379.66 ms /  1365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.37 ms /    68 runs   (    0.61 ms per token,  1643.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.10 ms /   454 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2625.64 ms /    67 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5101.80 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.42 ms /    70 runs   (    0.53 ms per token,  1870.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6052.57 ms /  1090 tokens (    5.55 ms per token,   180.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2812.28 ms /    69 runs   (   40.76 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    8973.55 ms /  1159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.23 ms /    72 runs   (    0.64 ms per token,  1557.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5007.45 ms /   918 tokens (    5.45 ms per token,   183.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2877.49 ms /    71 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    8011.74 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.11 ms /    59 runs   (    0.54 ms per token,  1837.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5452.53 ms /   999 tokens (    5.46 ms per token,   183.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2348.27 ms /    58 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    7891.70 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.59 ms /    85 runs   (    0.64 ms per token,  1557.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2388.58 ms /   455 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3270.72 ms /    84 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5796.61 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.14 ms /    86 runs   (    0.56 ms per token,  1786.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.80 ms /   534 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3336.15 ms /    85 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6265.56 ms /   619 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.27 ms /    67 runs   (    0.69 ms per token,  1448.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2377.26 ms /   456 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2588.39 ms /    66 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5084.85 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.95 ms /    88 runs   (    0.54 ms per token,  1835.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3886.86 ms /   723 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3446.03 ms /    87 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7457.12 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.04 ms /    71 runs   (    0.69 ms per token,  1447.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3702.41 ms /   692 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2798.36 ms /    70 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    6645.41 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.39 ms /    72 runs   (    0.56 ms per token,  1782.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.30 ms /   460 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2779.20 ms /    71 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5294.19 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.18 ms /    84 runs   (    0.67 ms per token,  1495.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4292.78 ms /   800 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3379.07 ms /    84 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7826.32 ms /   884 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.64 ms /    96 runs   (    0.56 ms per token,  1789.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.18 ms /   450 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3718.09 ms /    95 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6225.12 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1845.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1985.25 ms /   384 tokens (    5.17 ms per token,   193.43 tokens per second)\n",
            "llama_print_timings:        eval time =     193.80 ms /     5 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2192.07 ms /   389 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.70 ms /    79 runs   (    0.63 ms per token,  1589.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     124.37 ms /    20 tokens (    6.22 ms per token,   160.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3028.59 ms /    78 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3272.89 ms /    98 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.20 ms /    99 runs   (    0.55 ms per token,  1826.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7170.98 ms /  1279 tokens (    5.61 ms per token,   178.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4058.40 ms /    98 runs   (   41.41 ms per token,    24.15 tokens per second)\n",
            "llama_print_timings:       total time =   11383.85 ms /  1377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.98 ms /     9 runs   (    0.55 ms per token,  1808.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4283.76 ms /   791 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
            "llama_print_timings:        eval time =     319.00 ms /     8 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    4628.28 ms /   799 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.01 ms /    11 runs   (    0.55 ms per token,  1829.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2368.69 ms /   450 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
            "llama_print_timings:        eval time =     384.19 ms /    10 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2772.78 ms /   460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.84 ms /    88 runs   (    0.68 ms per token,  1470.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7147.24 ms /  1280 tokens (    5.58 ms per token,   179.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3666.49 ms /    88 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
            "llama_print_timings:       total time =   10983.65 ms /  1368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.15 ms /    96 runs   (    0.54 ms per token,  1840.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4932.50 ms /   906 tokens (    5.44 ms per token,   183.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3818.90 ms /    95 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    8894.69 ms /  1001 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.08 ms /    66 runs   (    0.55 ms per token,  1829.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3879.13 ms /   714 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2558.89 ms /    65 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6536.56 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.04 ms /    97 runs   (    0.56 ms per token,  1795.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.08 ms /   448 tokens (    5.20 ms per token,   192.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3759.94 ms /    96 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6222.91 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.94 ms /    69 runs   (    0.54 ms per token,  1868.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5490.83 ms /   994 tokens (    5.52 ms per token,   181.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2750.92 ms /    68 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8345.11 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.65 ms /    64 runs   (    0.70 ms per token,  1433.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6028.24 ms /  1093 tokens (    5.52 ms per token,   181.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2600.62 ms /    63 runs   (   41.28 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =    8761.04 ms /  1156 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.39 ms /    69 runs   (    0.56 ms per token,  1797.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3032.55 ms /   571 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2669.51 ms /    68 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5798.55 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.51 ms /    94 runs   (    0.59 ms per token,  1693.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1768.04 ms /   340 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3595.78 ms /    93 runs   (   38.66 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    5504.22 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.06 ms /    58 runs   (    0.54 ms per token,  1867.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4230.80 ms /   784 tokens (    5.40 ms per token,   185.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2259.46 ms /    57 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    6575.73 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.99 ms /    72 runs   (    0.56 ms per token,  1800.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2326.98 ms /   443 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2777.79 ms /    71 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5203.55 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.85 ms /    66 runs   (    0.69 ms per token,  1439.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =      85.69 ms /    16 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2579.91 ms /    66 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2777.61 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.94 ms /    73 runs   (    0.63 ms per token,  1589.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3996.35 ms /   744 tokens (    5.37 ms per token,   186.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2865.88 ms /    72 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6988.83 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.91 ms /    72 runs   (    0.65 ms per token,  1534.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4199.21 ms /   784 tokens (    5.36 ms per token,   186.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2901.77 ms /    72 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7239.04 ms /   856 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.04 ms /   141 runs   (    0.62 ms per token,  1619.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7245.18 ms /  1293 tokens (    5.60 ms per token,   178.46 tokens per second)\n",
            "llama_print_timings:        eval time =    5834.71 ms /   140 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
            "llama_print_timings:       total time =   13328.13 ms /  1433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.93 ms /   119 runs   (    0.57 ms per token,  1751.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.93 ms /   437 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4618.20 ms /   118 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    7079.98 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1669.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1684.79 ms /   326 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
            "llama_print_timings:        eval time =     233.55 ms /     6 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    1932.85 ms /   332 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.09 ms /    76 runs   (    0.65 ms per token,  1548.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3095.15 ms /   582 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2949.76 ms /    75 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6174.11 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.71 ms /    70 runs   (    0.54 ms per token,  1856.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6024.74 ms /  1096 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2855.95 ms /    70 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    8988.14 ms /  1166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.22 ms /    87 runs   (    0.54 ms per token,  1842.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6555.55 ms /  1175 tokens (    5.58 ms per token,   179.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3531.47 ms /    86 runs   (   41.06 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   10223.66 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.79 ms /    66 runs   (    0.74 ms per token,  1352.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2376.51 ms /   456 tokens (    5.21 ms per token,   191.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2552.82 ms /    65 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5047.19 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1766.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2828.77 ms /   534 tokens (    5.30 ms per token,   188.77 tokens per second)\n",
            "llama_print_timings:        eval time =     194.52 ms /     5 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    3039.39 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1786.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1854.12 ms /   360 tokens (    5.15 ms per token,   194.16 tokens per second)\n",
            "llama_print_timings:        eval time =     270.60 ms /     7 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2139.29 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.44 ms /   342 tokens (    5.17 ms per token,   193.28 tokens per second)\n",
            "llama_print_timings:        eval time =     233.50 ms /     6 runs   (   38.92 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2016.79 ms /   348 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.78 ms /   119 runs   (    0.66 ms per token,  1510.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3651.84 ms /   683 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    4697.53 ms /   118 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    8562.77 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.87 ms /    68 runs   (    0.51 ms per token,  1949.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4018.30 ms /   750 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2657.43 ms /    67 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6771.76 ms /   817 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.51 ms /    82 runs   (    0.69 ms per token,  1451.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3089.43 ms /   580 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3194.66 ms /    81 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6431.33 ms /   661 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.30 ms /    78 runs   (    0.56 ms per token,  1801.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.53 ms /   562 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3019.51 ms /    77 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6113.77 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.68 ms /    71 runs   (    0.63 ms per token,  1589.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3754.35 ms /   704 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2802.53 ms /    70 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6681.36 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.81 ms /    71 runs   (    0.55 ms per token,  1829.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5309.94 ms /   973 tokens (    5.46 ms per token,   183.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2829.55 ms /    70 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    8246.60 ms /  1043 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.83 ms /   141 runs   (    0.59 ms per token,  1702.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3055.37 ms /   573 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =    5513.06 ms /   140 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    8788.95 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.21 ms /   122 runs   (    0.61 ms per token,  1644.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2941.76 ms /   555 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
            "llama_print_timings:        eval time =    4765.16 ms /   121 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    7901.83 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.23 ms /   159 runs   (    0.55 ms per token,  1822.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3411.05 ms /   639 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =    6215.67 ms /   158 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    9855.08 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.25 ms /   110 runs   (    0.61 ms per token,  1635.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3407.22 ms /   635 tokens (    5.37 ms per token,   186.37 tokens per second)\n",
            "llama_print_timings:        eval time =    4302.51 ms /   109 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    7888.36 ms /   744 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.80 ms /    54 runs   (    0.57 ms per token,  1753.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5361.61 ms /   983 tokens (    5.45 ms per token,   183.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2142.25 ms /    53 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    7592.68 ms /  1036 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.73 ms /   135 runs   (    0.55 ms per token,  1831.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2758.82 ms /   520 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =    5294.67 ms /   135 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    8251.58 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     6 runs   (    0.68 ms per token,  1481.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5078.99 ms /   936 tokens (    5.43 ms per token,   184.29 tokens per second)\n",
            "llama_print_timings:        eval time =     245.26 ms /     6 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    5345.13 ms /   942 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.48 ms /    95 runs   (    0.53 ms per token,  1881.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4678.08 ms /   852 tokens (    5.49 ms per token,   182.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3777.82 ms /    94 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    8596.09 ms /   946 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.72 ms /    63 runs   (    0.68 ms per token,  1474.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4948.22 ms /   911 tokens (    5.43 ms per token,   184.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2518.04 ms /    62 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    7589.46 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.88 ms /   103 runs   (    0.59 ms per token,  1691.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4335.68 ms /   802 tokens (    5.41 ms per token,   184.98 tokens per second)\n",
            "llama_print_timings:        eval time =    4061.48 ms /   102 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    8555.82 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.92 ms /    75 runs   (    0.53 ms per token,  1878.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4649.99 ms /   854 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2959.71 ms /    74 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    7720.48 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.87 ms /    75 runs   (    0.54 ms per token,  1835.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3000.55 ms /    75 runs   (   40.01 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    3106.64 ms /    75 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.60 ms /    82 runs   (    0.65 ms per token,  1529.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4807.40 ms /   887 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3282.50 ms /    81 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    8238.70 ms /   968 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.36 ms /    85 runs   (    0.55 ms per token,  1833.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4940.54 ms /   912 tokens (    5.42 ms per token,   184.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3418.15 ms /    85 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    8484.75 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.45 ms /    58 runs   (    0.56 ms per token,  1787.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5777.01 ms /  1042 tokens (    5.54 ms per token,   180.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2314.99 ms /    57 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8187.94 ms /  1099 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.51 ms /    71 runs   (    0.71 ms per token,  1405.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4401.13 ms /   812 tokens (    5.42 ms per token,   184.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2813.35 ms /    70 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7341.30 ms /   882 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.79 ms /    68 runs   (    0.61 ms per token,  1627.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1882.30 ms /   356 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2605.51 ms /    67 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4594.66 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.04 ms /   256 runs   (    0.59 ms per token,  1694.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2500.69 ms /   474 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =   10018.42 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12949.53 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.92 ms /    78 runs   (    0.54 ms per token,  1860.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2944.69 ms /   559 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3018.39 ms /    77 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6071.33 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.31 ms /    78 runs   (    0.62 ms per token,  1614.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3059.30 ms /    78 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3178.03 ms /    78 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.54 ms /    93 runs   (    0.58 ms per token,  1737.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2446.68 ms /   459 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3598.09 ms /    92 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    6182.08 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.77 ms /   256 runs   (    0.60 ms per token,  1675.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.67 ms /   411 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =    9958.90 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12536.88 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.09 ms /   445 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
            "llama_print_timings:        eval time =     231.31 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2574.84 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.08 ms /   140 runs   (    0.68 ms per token,  1472.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.06 ms /   464 tokens (    5.21 ms per token,   192.05 tokens per second)\n",
            "llama_print_timings:        eval time =    5444.06 ms /   139 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    8108.28 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2284.59 ms /   434 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =     231.98 ms /     6 runs   (   38.66 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2531.91 ms /   440 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     126.29 ms /   207 runs   (    0.61 ms per token,  1639.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.50 ms /   470 tokens (    5.24 ms per token,   190.94 tokens per second)\n",
            "llama_print_timings:        eval time =    8099.55 ms /   206 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   10911.94 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     110.13 ms /   190 runs   (    0.58 ms per token,  1725.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2336.11 ms /   443 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
            "llama_print_timings:        eval time =    7400.61 ms /   189 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   10023.14 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.33 ms /    70 runs   (    0.53 ms per token,  1875.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4414.73 ms /   812 tokens (    5.44 ms per token,   183.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2746.82 ms /    69 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7267.81 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.12 ms /    11 runs   (    0.47 ms per token,  2149.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.59 ms /   567 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =     387.86 ms /    10 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    3396.26 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.00 ms /   256 runs   (    0.58 ms per token,  1718.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2862.60 ms /   542 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =   10037.28 ms /   255 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   13314.68 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.20 ms /   256 runs   (    0.62 ms per token,  1618.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2113.55 ms /   403 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =    9934.48 ms /   255 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12466.17 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.58 ms /   129 runs   (    0.66 ms per token,  1525.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3480.23 ms /   655 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =    5086.57 ms /   128 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    8796.50 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.44 ms /    11 runs   (    0.49 ms per token,  2020.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2583.47 ms /   487 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =     394.29 ms /    10 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    2998.08 ms /   497 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.19 ms /    43 runs   (    0.70 ms per token,  1424.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5646.25 ms /  1028 tokens (    5.49 ms per token,   182.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1725.19 ms /    42 runs   (   41.08 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    7458.95 ms /  1070 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.02 ms /     6 runs   (    0.50 ms per token,  1985.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3582.23 ms /   672 tokens (    5.33 ms per token,   187.59 tokens per second)\n",
            "llama_print_timings:        eval time =     236.95 ms /     6 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3837.76 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.74 ms /    89 runs   (    0.59 ms per token,  1687.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4517.32 ms /   835 tokens (    5.41 ms per token,   184.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3532.85 ms /    88 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    8194.41 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.91 ms /   102 runs   (    0.56 ms per token,  1792.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4416.22 ms /   814 tokens (    5.43 ms per token,   184.32 tokens per second)\n",
            "llama_print_timings:        eval time =    4025.86 ms /   101 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    8595.39 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.08 ms /   256 runs   (    0.60 ms per token,  1661.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.84 ms /   565 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =   10053.87 ms /   255 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13464.20 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.00 ms /    81 runs   (    0.67 ms per token,  1500.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4346.21 ms /   808 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3258.80 ms /    81 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7753.58 ms /   889 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.72 ms /    90 runs   (    0.54 ms per token,  1847.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2899.74 ms /   548 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3490.86 ms /    89 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6518.77 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.43 ms /    90 runs   (    0.60 ms per token,  1653.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3523.22 ms /    90 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3659.23 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.81 ms /    92 runs   (    0.55 ms per token,  1810.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2930.97 ms /   552 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3560.61 ms /    91 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6623.46 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.09 ms /    73 runs   (    0.62 ms per token,  1618.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4024.37 ms /   749 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2856.73 ms /    72 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    7002.59 ms /   821 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.52 ms /    72 runs   (    0.55 ms per token,  1822.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4644.36 ms /   854 tokens (    5.44 ms per token,   183.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2841.87 ms /    71 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7595.57 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.15 ms /    66 runs   (    0.71 ms per token,  1399.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4468.60 ms /   828 tokens (    5.40 ms per token,   185.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2622.24 ms /    65 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    7220.60 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.86 ms /    75 runs   (    0.54 ms per token,  1835.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4351.20 ms /   807 tokens (    5.39 ms per token,   185.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2946.30 ms /    74 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7407.81 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.88 ms /    44 runs   (    0.70 ms per token,  1424.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5238.29 ms /   957 tokens (    5.47 ms per token,   182.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1747.68 ms /    43 runs   (   40.64 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    7075.96 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.81 ms /   256 runs   (    0.58 ms per token,  1732.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.09 ms /   456 tokens (    5.20 ms per token,   192.15 tokens per second)\n",
            "llama_print_timings:        eval time =   10061.57 ms /   256 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12859.97 ms /   712 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.41 ms /   256 runs   (    0.60 ms per token,  1679.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2470.63 ms /   469 tokens (    5.27 ms per token,   189.83 tokens per second)\n",
            "llama_print_timings:        eval time =   10002.72 ms /   255 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   12897.59 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.39 ms /    69 runs   (    0.57 ms per token,  1751.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3900.40 ms /   725 tokens (    5.38 ms per token,   185.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2683.72 ms /    68 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6686.24 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.55 ms /    69 runs   (    0.54 ms per token,  1837.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2727.51 ms /    69 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2819.04 ms /    69 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.47 ms /    12 runs   (    0.71 ms per token,  1416.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2208.18 ms /   423 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =     431.81 ms /    11 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2665.96 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.76 ms /   119 runs   (    0.58 ms per token,  1730.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2138.88 ms /   404 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
            "llama_print_timings:        eval time =    4607.52 ms /   118 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    6921.87 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.40 ms /   225 runs   (    0.63 ms per token,  1591.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2198.65 ms /   418 tokens (    5.26 ms per token,   190.12 tokens per second)\n",
            "llama_print_timings:        eval time =    8774.71 ms /   224 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   11358.45 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.82 ms /   460 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
            "llama_print_timings:        eval time =     232.93 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2666.56 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      97.46 ms /   148 runs   (    0.66 ms per token,  1518.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4750.84 ms /   880 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
            "llama_print_timings:        eval time =    5942.87 ms /   147 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =   10958.95 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.85 ms /   148 runs   (    0.57 ms per token,  1744.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    5955.27 ms /   148 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    6169.84 ms /   148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.05 ms /     7 runs   (    0.72 ms per token,  1385.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2043.37 ms /   390 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =     232.74 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2293.98 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     101.54 ms /   173 runs   (    0.59 ms per token,  1703.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2486.30 ms /   469 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =    6714.19 ms /   172 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    9454.73 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.02 ms /    12 runs   (    0.67 ms per token,  1495.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2762.72 ms /   523 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =     432.21 ms /    11 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3220.86 ms /   534 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Amcor plc_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Amcor plc_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.93 ms /    96 runs   (    0.52 ms per token,  1922.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5823.71 ms /  1054 tokens (    5.53 ms per token,   180.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3863.85 ms /    95 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    9829.34 ms /  1149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.44 ms /    99 runs   (    0.55 ms per token,  1818.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5721.62 ms /  1036 tokens (    5.52 ms per token,   181.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3990.27 ms /    98 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    9866.47 ms /  1134 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.90 ms /    83 runs   (    0.54 ms per token,  1848.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3075.28 ms /   583 tokens (    5.27 ms per token,   189.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3215.39 ms /    82 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6407.10 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.46 ms /   256 runs   (    0.55 ms per token,  1809.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3019.80 ms /   564 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =   10024.24 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13431.26 ms /   819 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.41 ms /    73 runs   (    0.53 ms per token,  1900.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5790.89 ms /  1047 tokens (    5.53 ms per token,   180.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2924.97 ms /    72 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8827.67 ms /  1119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.68 ms /    64 runs   (    0.56 ms per token,  1793.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2237.94 ms /   427 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2456.28 ms /    63 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4782.46 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.18 ms /    68 runs   (    0.53 ms per token,  1879.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4289.23 ms /   792 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2664.30 ms /    67 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7052.02 ms /   859 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.62 ms /    85 runs   (    0.58 ms per token,  1713.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4155.20 ms /   776 tokens (    5.35 ms per token,   186.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3350.64 ms /    84 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7640.38 ms /   860 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.97 ms /    71 runs   (    0.58 ms per token,  1732.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3648.59 ms /   680 tokens (    5.37 ms per token,   186.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2793.62 ms /    71 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6553.29 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.70 ms /   126 runs   (    0.69 ms per token,  1453.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4938.19 ms /   912 tokens (    5.41 ms per token,   184.68 tokens per second)\n",
            "llama_print_timings:        eval time =    5109.38 ms /   126 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =   10280.06 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.25 ms /    90 runs   (    0.60 ms per token,  1658.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6312.49 ms /  1140 tokens (    5.54 ms per token,   180.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3655.00 ms /    89 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   10118.79 ms /  1229 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.12 ms /    77 runs   (    0.55 ms per token,  1827.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5059.46 ms /   922 tokens (    5.49 ms per token,   182.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3059.83 ms /    76 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8248.17 ms /   998 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.63 ms /    82 runs   (    0.65 ms per token,  1528.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3877.12 ms /   722 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3250.14 ms /    81 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    7279.63 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.99 ms /   118 runs   (    0.56 ms per token,  1788.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3651.77 ms /   683 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    4603.15 ms /   117 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    8425.13 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.84 ms /     9 runs   (    0.76 ms per token,  1315.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2647.94 ms /   501 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
            "llama_print_timings:        eval time =     316.15 ms /     8 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2987.20 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.73 ms /    85 runs   (    0.55 ms per token,  1818.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2835.57 ms /   535 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3300.17 ms /    84 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6257.65 ms /   619 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.40 ms /    72 runs   (    0.56 ms per token,  1782.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.83 ms /   432 tokens (    5.19 ms per token,   192.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2818.82 ms /    72 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5162.30 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.38 ms /    55 runs   (    0.57 ms per token,  1752.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3923.59 ms /   725 tokens (    5.41 ms per token,   184.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2134.54 ms /    54 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6143.84 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      91.14 ms /   161 runs   (    0.57 ms per token,  1766.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.01 ms /   566 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =    6294.10 ms /   160 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    9537.57 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.39 ms /    70 runs   (    0.55 ms per token,  1823.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3906.03 ms /   726 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2730.56 ms /    69 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    6738.56 ms /   795 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.66 ms /    66 runs   (    0.62 ms per token,  1623.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3655.83 ms /   687 tokens (    5.32 ms per token,   187.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2579.75 ms /    65 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    6347.30 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.53 ms /    73 runs   (    0.68 ms per token,  1473.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     133.37 ms /    24 tokens (    5.56 ms per token,   179.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2911.76 ms /    73 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    3168.49 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.66 ms /    67 runs   (    0.53 ms per token,  1878.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5779.61 ms /  1050 tokens (    5.50 ms per token,   181.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2683.27 ms /    66 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8564.24 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.05 ms /     7 runs   (    0.72 ms per token,  1387.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1823.30 ms /   346 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =     237.01 ms /     6 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    2078.32 ms /   352 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.17 ms /    99 runs   (    0.59 ms per token,  1702.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2396.32 ms /   455 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3835.44 ms /    98 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6373.25 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.32 ms /    83 runs   (    0.69 ms per token,  1448.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4246.29 ms /   790 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3284.64 ms /    82 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    7677.75 ms /   872 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.03 ms /   256 runs   (    0.57 ms per token,  1765.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1920.63 ms /   368 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =    9949.37 ms /   255 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12265.29 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.57 ms /   236 runs   (    0.57 ms per token,  1740.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3830.77 ms /   711 tokens (    5.39 ms per token,   185.60 tokens per second)\n",
            "llama_print_timings:        eval time =    9343.85 ms /   235 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =   13546.01 ms /   946 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.84 ms /    91 runs   (    0.56 ms per token,  1790.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4281.73 ms /   791 tokens (    5.41 ms per token,   184.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3578.62 ms /    90 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    8000.96 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.81 ms /   134 runs   (    0.63 ms per token,  1598.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1516.76 ms /   295 tokens (    5.14 ms per token,   194.49 tokens per second)\n",
            "llama_print_timings:        eval time =    5148.37 ms /   133 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    6881.02 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.91 ms /    75 runs   (    0.55 ms per token,  1833.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2085.22 ms /   397 tokens (    5.25 ms per token,   190.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2886.26 ms /    74 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    5073.90 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.75 ms /    77 runs   (    0.54 ms per token,  1844.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2028.26 ms /   389 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2946.30 ms /    76 runs   (   38.77 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    5076.59 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.58 ms /    66 runs   (    0.55 ms per token,  1804.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3872.75 ms /   715 tokens (    5.42 ms per token,   184.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2560.06 ms /    65 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6532.07 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.78 ms /    67 runs   (    0.58 ms per token,  1727.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.12 ms /   432 tokens (    5.20 ms per token,   192.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2572.21 ms /    66 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4917.16 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.66 ms /    49 runs   (    0.69 ms per token,  1455.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3764.22 ms /   704 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1959.47 ms /    49 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    5820.07 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.40 ms /   256 runs   (    0.61 ms per token,  1647.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3038.38 ms /   574 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =   10050.76 ms /   255 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13535.62 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.72 ms /   115 runs   (    0.55 ms per token,  1804.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3388.97 ms /   636 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4464.02 ms /   114 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    8017.81 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.08 ms /    77 runs   (    0.73 ms per token,  1372.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.80 ms /   446 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2982.78 ms /    76 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5462.49 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.17 ms /   256 runs   (    0.58 ms per token,  1727.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2206.56 ms /   421 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =    9987.88 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12612.06 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.01 ms /    57 runs   (    0.53 ms per token,  1899.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3619.56 ms /   674 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2202.97 ms /    56 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5903.34 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.29 ms /    14 runs   (    0.59 ms per token,  1689.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1601.05 ms /   309 tokens (    5.18 ms per token,   193.00 tokens per second)\n",
            "llama_print_timings:        eval time =     503.08 ms /    13 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2128.48 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.25 ms /     9 runs   (    0.58 ms per token,  1713.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.25 ms /   400 tokens (    5.18 ms per token,   193.03 tokens per second)\n",
            "llama_print_timings:        eval time =     309.33 ms /     8 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2399.15 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.57 ms /    71 runs   (    0.54 ms per token,  1841.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5787.78 ms /  1043 tokens (    5.55 ms per token,   180.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2842.81 ms /    70 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8742.33 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      26.70 ms /    48 runs   (    0.56 ms per token,  1798.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2199.85 ms /   423 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1839.48 ms /    47 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    4106.23 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     117.03 ms /   196 runs   (    0.60 ms per token,  1674.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2302.52 ms /   439 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =    7618.10 ms /   195 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   10227.72 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.29 ms /    74 runs   (    0.65 ms per token,  1532.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4894.78 ms /   898 tokens (    5.45 ms per token,   183.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2958.56 ms /    73 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    7994.58 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1802.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1987.02 ms /   379 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =     229.90 ms /     6 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2232.36 ms /   385 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.77 ms /   256 runs   (    0.59 ms per token,  1686.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1772.60 ms /   344 tokens (    5.15 ms per token,   194.07 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.15 ms /   256 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12217.82 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.13 ms /    68 runs   (    0.55 ms per token,  1831.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2374.14 ms /   454 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2628.11 ms /    67 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5096.17 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.27 ms /   141 runs   (    0.63 ms per token,  1597.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.90 ms /   432 tokens (    5.19 ms per token,   192.52 tokens per second)\n",
            "llama_print_timings:        eval time =    5469.36 ms /   140 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    7949.92 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.96 ms /   236 runs   (    0.60 ms per token,  1662.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2197.53 ms /   421 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =    9204.72 ms /   235 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   11794.07 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.44 ms /    60 runs   (    0.54 ms per token,  1849.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3178.30 ms /   600 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2353.66 ms /    60 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5618.38 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.79 ms /   256 runs   (    0.61 ms per token,  1643.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2547.14 ms /   488 tokens (    5.22 ms per token,   191.59 tokens per second)\n",
            "llama_print_timings:        eval time =   10007.43 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12975.93 ms /   743 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.68 ms /    82 runs   (    0.62 ms per token,  1618.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3477.24 ms /   654 tokens (    5.32 ms per token,   188.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3207.42 ms /    81 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    6818.88 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.47 ms /    78 runs   (    0.54 ms per token,  1836.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5712.53 ms /  1036 tokens (    5.51 ms per token,   181.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3125.35 ms /    77 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    8957.31 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.10 ms /    68 runs   (    0.58 ms per token,  1739.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5821.00 ms /  1054 tokens (    5.52 ms per token,   181.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2728.60 ms /    67 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    8666.97 ms /  1121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      24.72 ms /    45 runs   (    0.55 ms per token,  1820.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2680.28 ms /   512 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1725.46 ms /    44 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    4470.34 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     160.90 ms /   256 runs   (    0.63 ms per token,  1591.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2633.73 ms /   500 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =   10005.71 ms /   255 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   13066.75 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1805.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.15 ms /   470 tokens (    5.23 ms per token,   191.12 tokens per second)\n",
            "llama_print_timings:        eval time =     232.66 ms /     6 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2707.52 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.92 ms /    69 runs   (    0.55 ms per token,  1819.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3920.23 ms /   728 tokens (    5.38 ms per token,   185.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2688.27 ms /    68 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6711.62 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.22 ms /   121 runs   (    0.61 ms per token,  1630.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4246.85 ms /   792 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4787.87 ms /   120 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    9230.60 ms /   912 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.37 ms /   102 runs   (    0.54 ms per token,  1842.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1961.67 ms /   370 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3924.74 ms /   101 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    6029.06 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.79 ms /   109 runs   (    0.62 ms per token,  1607.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2112.26 ms /   402 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
            "llama_print_timings:        eval time =    4219.09 ms /   108 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    6496.23 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Square, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Square, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.54 ms /    87 runs   (    0.55 ms per token,  1830.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2799.95 ms /   528 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3371.90 ms /    86 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6299.32 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.92 ms /    74 runs   (    0.54 ms per token,  1853.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.93 ms /   472 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2896.02 ms /    74 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5463.69 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.14 ms /   112 runs   (    0.60 ms per token,  1668.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2835.57 ms /   532 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =    4359.02 ms /   111 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7366.09 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.66 ms /   105 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.37 ms /   447 tokens (    5.21 ms per token,   191.98 tokens per second)\n",
            "llama_print_timings:        eval time =    4068.96 ms /   104 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6543.74 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.45 ms /    74 runs   (    0.59 ms per token,  1703.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2795.81 ms /   522 tokens (    5.36 ms per token,   186.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2864.59 ms /    73 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5776.72 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.15 ms /    66 runs   (    0.53 ms per token,  1877.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3293.84 ms /   619 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2557.78 ms /    65 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5944.32 ms /   684 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.03 ms /    95 runs   (    0.68 ms per token,  1460.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.02 ms /   416 tokens (    5.19 ms per token,   192.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3700.35 ms /    95 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    6024.30 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.71 ms /   256 runs   (    0.62 ms per token,  1613.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2807.57 ms /   534 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
            "llama_print_timings:        eval time =   10045.57 ms /   255 runs   (   39.39 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   13305.70 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.18 ms /    83 runs   (    0.57 ms per token,  1759.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3610.45 ms /   680 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3271.88 ms /    83 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7005.59 ms /   763 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.80 ms /   111 runs   (    0.64 ms per token,  1567.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2993.67 ms /   564 tokens (    5.31 ms per token,   188.40 tokens per second)\n",
            "llama_print_timings:        eval time =    4334.32 ms /   110 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    7512.73 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.90 ms /   109 runs   (    0.52 ms per token,  1915.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3748.66 ms /   703 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4266.12 ms /   108 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    8164.58 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.21 ms /    95 runs   (    0.59 ms per token,  1690.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2892.37 ms /   543 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3686.26 ms /    94 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6723.48 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.77 ms /   256 runs   (    0.55 ms per token,  1805.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.23 ms /   412 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =    9984.27 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12556.11 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      98.01 ms /   159 runs   (    0.62 ms per token,  1622.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3031.28 ms /   571 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =    6204.80 ms /   158 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    9490.65 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.85 ms /   153 runs   (    0.55 ms per token,  1803.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2875.26 ms /   538 tokens (    5.34 ms per token,   187.11 tokens per second)\n",
            "llama_print_timings:        eval time =    5951.92 ms /   152 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    9053.01 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.49 ms /   416 tokens (    5.19 ms per token,   192.55 tokens per second)\n",
            "llama_print_timings:        eval time =     269.62 ms /     7 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2444.64 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     6 runs   (    0.68 ms per token,  1473.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2666.70 ms /   501 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
            "llama_print_timings:        eval time =     195.34 ms /     5 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2882.90 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     112.40 ms /   206 runs   (    0.55 ms per token,  1832.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2823.01 ms /   536 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =    8088.07 ms /   206 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   11215.24 ms /   742 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.35 ms /    74 runs   (    0.65 ms per token,  1530.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1370.01 ms /   264 tokens (    5.19 ms per token,   192.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2818.17 ms /    73 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    4304.58 ms /   337 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.25 ms /     7 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.29 ms /   416 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =     269.27 ms /     7 runs   (   38.47 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2443.22 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.40 ms /    62 runs   (    0.55 ms per token,  1802.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2246.01 ms /   432 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2378.38 ms /    61 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4713.36 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.14 ms /   100 runs   (    0.72 ms per token,  1386.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1562.17 ms /   303 tokens (    5.16 ms per token,   193.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3840.50 ms /    99 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    5582.22 ms /   402 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.45 ms /    65 runs   (    0.53 ms per token,  1886.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.70 ms /   451 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2505.92 ms /    64 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4963.13 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.21 ms /    12 runs   (    0.52 ms per token,  1932.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.10 ms /   495 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =     433.24 ms /    11 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3046.36 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.25 ms /    64 runs   (    0.66 ms per token,  1514.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2474.61 ms /   472 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2513.13 ms /    64 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5102.18 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.04 ms /   256 runs   (    0.57 ms per token,  1741.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     168.32 ms /    27 tokens (    6.23 ms per token,   160.41 tokens per second)\n",
            "llama_print_timings:        eval time =    9989.46 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   10554.16 ms /   282 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.67 ms /   103 runs   (    0.55 ms per token,  1817.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3460.10 ms /   647 tokens (    5.35 ms per token,   186.99 tokens per second)\n",
            "llama_print_timings:        eval time =    4000.25 ms /   102 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7606.49 ms /   749 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.57 ms /    81 runs   (    0.55 ms per token,  1817.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1431.99 ms /   274 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3078.55 ms /    80 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    4618.02 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.13 ms /   256 runs   (    0.57 ms per token,  1739.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2266.60 ms /   427 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =    9969.86 ms /   255 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12626.44 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.21 ms /    68 runs   (    0.58 ms per token,  1734.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4287.97 ms /   790 tokens (    5.43 ms per token,   184.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2666.27 ms /    67 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    7060.52 ms /   857 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.25 ms /   117 runs   (    0.59 ms per token,  1689.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3033.73 ms /   573 tokens (    5.29 ms per token,   188.88 tokens per second)\n",
            "llama_print_timings:        eval time =    4547.21 ms /   116 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7754.77 ms /   689 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.25 ms /    72 runs   (    0.50 ms per token,  1985.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4153.90 ms /   766 tokens (    5.42 ms per token,   184.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2810.92 ms /    71 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    7066.09 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.35 ms /    58 runs   (    0.54 ms per token,  1850.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.10 ms /   428 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2220.53 ms /    57 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4545.55 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.41 ms /     6 runs   (    0.73 ms per token,  1360.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1648.86 ms /   317 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
            "llama_print_timings:        eval time =     195.68 ms /     5 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    1859.29 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     6 runs   (    0.66 ms per token,  1506.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2672.17 ms /   504 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     240.13 ms /     6 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    2931.07 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1818.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1811.06 ms /   347 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =     233.99 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2059.03 ms /   353 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1801.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     999.95 ms /   186 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
            "llama_print_timings:        eval time =     230.75 ms /     6 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    1243.53 ms /   192 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.71 ms /   256 runs   (    0.60 ms per token,  1676.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.62 ms /   420 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =    9978.42 ms /   255 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12604.09 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.48 ms /    70 runs   (    0.56 ms per token,  1772.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.75 ms /   536 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2703.75 ms /    69 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5613.36 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.16 ms /   256 runs   (    0.59 ms per token,  1704.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2164.97 ms /   411 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =    9929.07 ms /   255 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12503.24 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1902.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     551.55 ms /   100 tokens (    5.52 ms per token,   181.31 tokens per second)\n",
            "llama_print_timings:        eval time =     232.36 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =     795.26 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.23 ms /     7 runs   (    0.75 ms per token,  1338.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2554.88 ms /   484 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =     234.72 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2809.42 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.34 ms /    71 runs   (    0.54 ms per token,  1852.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2487.92 ms /   467 tokens (    5.33 ms per token,   187.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2733.02 ms /    70 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5322.82 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.10 ms /   256 runs   (    0.60 ms per token,  1661.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.31 ms /   394 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9984.25 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12481.07 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.83 ms /    80 runs   (    0.57 ms per token,  1745.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1559.01 ms /   304 tokens (    5.13 ms per token,   195.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3084.15 ms /    80 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    4754.59 ms /   384 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.11 ms /   256 runs   (    0.57 ms per token,  1764.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2691.59 ms /   508 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =   10053.28 ms /   255 runs   (   39.42 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13160.12 ms /   763 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     7 runs   (    0.48 ms per token,  2062.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.30 ms /   495 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =     232.35 ms /     6 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2839.08 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      10.32 ms /    12 runs   (    0.86 ms per token,  1163.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2888.21 ms /   544 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =     476.85 ms /    12 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    3400.42 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1697.33 ms /   328 tokens (    5.17 ms per token,   193.25 tokens per second)\n",
            "llama_print_timings:        eval time =     234.50 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    1945.68 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      23.28 ms /    42 runs   (    0.55 ms per token,  1804.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2422.13 ms /   464 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1603.58 ms /    41 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4085.88 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.11 ms /    11 runs   (    0.56 ms per token,  1800.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2116.28 ms /   408 tokens (    5.19 ms per token,   192.79 tokens per second)\n",
            "llama_print_timings:        eval time =     386.66 ms /    10 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2522.57 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.05 ms /    66 runs   (    0.80 ms per token,  1244.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.18 ms /   431 tokens (    5.21 ms per token,   191.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2536.53 ms /    65 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4908.84 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.17 ms /    75 runs   (    0.59 ms per token,  1697.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2337.56 ms /   443 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2896.16 ms /    74 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5343.46 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.56 ms /    69 runs   (    0.56 ms per token,  1789.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2498.06 ms /   474 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2656.12 ms /    68 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5250.73 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.24 ms /   256 runs   (    0.56 ms per token,  1774.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2008.43 ms /   378 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =    9951.96 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12351.67 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.81 ms /   256 runs   (    0.60 ms per token,  1653.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1953.82 ms /   370 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =    9920.05 ms /   255 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =   12294.69 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      99.48 ms /   166 runs   (    0.60 ms per token,  1668.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2728.88 ms /   520 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =    6479.70 ms /   165 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    9462.97 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.67 ms /    82 runs   (    0.57 ms per token,  1757.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.61 ms /   419 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3162.31 ms /    81 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5475.96 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.63 ms /   112 runs   (    0.55 ms per token,  1817.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4421.80 ms /   814 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4423.93 ms /   111 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    9005.84 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.42 ms /    65 runs   (    0.64 ms per token,  1569.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3839.62 ms /   702 tokens (    5.47 ms per token,   182.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2569.85 ms /    64 runs   (   40.15 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    6521.72 ms /   766 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1818.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2843.27 ms /   536 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =     236.39 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3100.29 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.54 ms /    75 runs   (    0.57 ms per token,  1763.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.05 ms /   416 tokens (    5.19 ms per token,   192.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2888.62 ms /    74 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5146.89 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.96 ms /   131 runs   (    0.60 ms per token,  1658.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     210.47 ms /    36 tokens (    5.85 ms per token,   171.05 tokens per second)\n",
            "llama_print_timings:        eval time =    5082.11 ms /   130 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5488.38 ms /   166 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_3M CO_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_3M CO_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.60 ms /   131 runs   (    0.52 ms per token,  1909.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3500.88 ms /   655 tokens (    5.34 ms per token,   187.10 tokens per second)\n",
            "llama_print_timings:        eval time =    5113.05 ms /   130 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    8794.24 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1573.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2633.82 ms /   502 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =     235.70 ms /     6 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2889.76 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.06 ms /     7 runs   (    0.87 ms per token,  1155.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2402.26 ms /   456 tokens (    5.27 ms per token,   189.82 tokens per second)\n",
            "llama_print_timings:        eval time =     272.14 ms /     7 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2697.22 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1839.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2598.93 ms /   496 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =     232.90 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2852.64 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.54 ms /    65 runs   (    0.56 ms per token,  1779.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.38 ms /   447 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2503.77 ms /    64 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    4922.45 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.89 ms /    84 runs   (    0.70 ms per token,  1426.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2629.63 ms /   501 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3259.57 ms /    83 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6041.35 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.29 ms /   118 runs   (    0.54 ms per token,  1864.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2332.09 ms /   448 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4581.22 ms /   117 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    7071.25 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.66 ms /   164 runs   (    0.58 ms per token,  1714.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4075.78 ms /   760 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
            "llama_print_timings:        eval time =    6547.81 ms /   164 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =   10880.90 ms /   924 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2678.66 ms /   509 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =     235.16 ms /     6 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2929.07 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.19 ms /     7 runs   (    0.60 ms per token,  1672.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2590.79 ms /   495 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =     232.59 ms /     6 runs   (   38.77 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2839.77 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.08 ms /    82 runs   (    0.57 ms per token,  1741.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2752.75 ms /   516 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3170.41 ms /    81 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6041.32 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.07 ms /   446 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =     232.58 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2578.78 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.72 ms /   103 runs   (    0.60 ms per token,  1668.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.42 ms /   456 tokens (    5.20 ms per token,   192.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4039.63 ms /   103 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6570.34 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.38 ms /   256 runs   (    0.56 ms per token,  1785.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1450.64 ms /   277 tokens (    5.24 ms per token,   190.95 tokens per second)\n",
            "llama_print_timings:        eval time =    9883.53 ms /   255 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =   11714.30 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.99 ms /   106 runs   (    0.59 ms per token,  1682.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1967.62 ms /   376 tokens (    5.23 ms per token,   191.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4138.73 ms /   106 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    6261.13 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.98 ms /    77 runs   (    0.65 ms per token,  1540.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5450.84 ms /   995 tokens (    5.48 ms per token,   182.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3094.22 ms /    76 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8678.77 ms /  1071 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.11 ms /    82 runs   (    0.57 ms per token,  1740.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3585.29 ms /   668 tokens (    5.37 ms per token,   186.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3184.12 ms /    81 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6897.03 ms /   749 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.24 ms /    67 runs   (    0.76 ms per token,  1307.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4991.68 ms /   917 tokens (    5.44 ms per token,   183.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2698.17 ms /    66 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    7838.78 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.68 ms /    66 runs   (    0.62 ms per token,  1622.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4609.88 ms /   845 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2606.49 ms /    65 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    7340.29 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.39 ms /    70 runs   (    0.78 ms per token,  1286.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2643.74 ms /   502 tokens (    5.27 ms per token,   189.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2720.61 ms /    69 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    5510.32 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.80 ms /    60 runs   (    0.60 ms per token,  1676.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3206.51 ms /   600 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2303.97 ms /    59 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5610.76 ms /   659 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.77 ms /    72 runs   (    0.68 ms per token,  1476.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5655.84 ms /  1026 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2909.65 ms /    71 runs   (   40.98 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =    8706.54 ms /  1097 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.74 ms /    80 runs   (    0.56 ms per token,  1788.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3495.95 ms /   652 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3108.03 ms /    79 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6722.84 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1787.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2636.69 ms /   503 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     236.50 ms /     6 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2892.50 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     6 runs   (    0.65 ms per token,  1542.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2123.12 ms /   405 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
            "llama_print_timings:        eval time =     193.37 ms /     5 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2331.29 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.93 ms /     7 runs   (    0.70 ms per token,  1419.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2145.52 ms /   403 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =     234.56 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2402.83 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1947.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2332.22 ms /   442 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =     230.55 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2577.75 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.98 ms /   113 runs   (    0.57 ms per token,  1766.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1351.09 ms /   263 tokens (    5.14 ms per token,   194.66 tokens per second)\n",
            "llama_print_timings:        eval time =    4314.32 ms /   112 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    5816.34 ms /   375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.59 ms /   120 runs   (    0.63 ms per token,  1587.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2919.01 ms /   551 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =    4679.60 ms /   119 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7790.43 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.57 ms /   256 runs   (    0.59 ms per token,  1688.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3212.84 ms /   602 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =   10106.19 ms /   255 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =   13746.49 ms /   857 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.05 ms /   256 runs   (    0.60 ms per token,  1672.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2335.54 ms /   448 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
            "llama_print_timings:        eval time =   10012.61 ms /   255 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   12783.20 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.65 ms /   256 runs   (    0.59 ms per token,  1699.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1644.53 ms /   320 tokens (    5.14 ms per token,   194.58 tokens per second)\n",
            "llama_print_timings:        eval time =    9988.95 ms /   256 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12056.71 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1785.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.90 ms /   370 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =     195.60 ms /     5 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2148.81 ms /   375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1795.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2547.61 ms /   486 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     193.55 ms /     5 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2755.17 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1687.08 ms /   326 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
            "llama_print_timings:        eval time =     192.92 ms /     5 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    1891.87 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1789.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1642.97 ms /   316 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
            "llama_print_timings:        eval time =     191.07 ms /     5 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    1847.42 ms /   321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.38 ms /    65 runs   (    0.59 ms per token,  1693.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2844.50 ms /   536 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2553.81 ms /    65 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5499.96 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      23.19 ms /    42 runs   (    0.55 ms per token,  1811.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.18 ms /   528 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1646.77 ms /    42 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    4477.65 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.08 ms /    93 runs   (    0.64 ms per token,  1574.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1687.59 ms /   327 tokens (    5.16 ms per token,   193.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3562.76 ms /    92 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    5398.26 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     128.11 ms /   225 runs   (    0.57 ms per token,  1756.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3327.96 ms /   624 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =    8873.67 ms /   225 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   12545.86 ms /   849 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1591.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2798.80 ms /   524 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =     237.20 ms /     6 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    3056.19 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.23 ms /   107 runs   (    0.57 ms per token,  1747.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.74 ms /   437 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4139.41 ms /   106 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    6579.62 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     6 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.91 ms /   442 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =     193.48 ms /     5 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2535.86 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.35 ms /    69 runs   (    0.54 ms per token,  1847.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5032.16 ms /   915 tokens (    5.50 ms per token,   181.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2738.17 ms /    68 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    7877.40 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.00 ms /    64 runs   (    0.66 ms per token,  1523.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4570.20 ms /   843 tokens (    5.42 ms per token,   184.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2532.30 ms /    63 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7220.66 ms /   906 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3383.52 ms /   629 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
            "llama_print_timings:        eval time =     233.07 ms /     6 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3642.18 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.86 ms /   256 runs   (    0.60 ms per token,  1653.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.20 ms /   437 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =   10013.84 ms /   255 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   12739.73 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.45 ms /   116 runs   (    0.56 ms per token,  1799.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4796.90 ms /   888 tokens (    5.40 ms per token,   185.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4621.19 ms /   115 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    9583.89 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     6 runs   (    0.70 ms per token,  1425.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1922.03 ms /   363 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =     194.56 ms /     5 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2133.26 ms /   368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.45 ms /    12 runs   (    0.54 ms per token,  1859.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2827.55 ms /   536 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =     466.04 ms /    12 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3316.46 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.82 ms /   254 runs   (    0.60 ms per token,  1672.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2503.94 ms /   478 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =    9962.93 ms /   253 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   12896.89 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2676.19 ms /   506 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =     236.90 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2928.48 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.21 ms /    64 runs   (    0.63 ms per token,  1591.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3481.55 ms /   656 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2487.16 ms /    63 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6071.04 ms /   719 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.10 ms /   120 runs   (    0.62 ms per token,  1619.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1623.14 ms /   309 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =    4613.02 ms /   119 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    6419.58 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.56 ms /   151 runs   (    0.56 ms per token,  1785.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2112.64 ms /   403 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5866.28 ms /   150 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    8211.10 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.20 ms /    12 runs   (    0.60 ms per token,  1667.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2444.62 ms /   464 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =     470.16 ms /    12 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    2938.88 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2722.80 ms /   517 tokens (    5.27 ms per token,   189.88 tokens per second)\n",
            "llama_print_timings:        eval time =     234.88 ms /     6 runs   (   39.15 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2973.43 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.15 ms /    72 runs   (    0.68 ms per token,  1464.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4984.47 ms /   919 tokens (    5.42 ms per token,   184.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2874.72 ms /    71 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    7990.05 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     120.42 ms /   217 runs   (    0.55 ms per token,  1802.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2388.20 ms /   454 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =    8449.35 ms /   216 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   11152.81 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    12 runs   (    0.73 ms per token,  1361.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2974.27 ms /   556 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
            "llama_print_timings:        eval time =     436.56 ms /    11 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    3441.05 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.69 ms /   256 runs   (    0.60 ms per token,  1654.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1731.80 ms /   332 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
            "llama_print_timings:        eval time =    9929.74 ms /   255 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12076.03 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      19.05 ms /    37 runs   (    0.51 ms per token,  1942.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6048.71 ms /  1094 tokens (    5.53 ms per token,   180.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.05 ms /    36 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    7578.93 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.49 ms /    94 runs   (    0.69 ms per token,  1457.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3024.93 ms /   570 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3661.31 ms /    93 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6854.98 ms /   663 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.00 ms /    89 runs   (    0.54 ms per token,  1854.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6469.68 ms /  1168 tokens (    5.54 ms per token,   180.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3656.79 ms /    89 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =   10260.97 ms /  1257 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      91.70 ms /   176 runs   (    0.52 ms per token,  1919.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6065.08 ms /  1095 tokens (    5.54 ms per token,   180.54 tokens per second)\n",
            "llama_print_timings:        eval time =    7168.97 ms /   175 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =   13496.11 ms /  1270 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.29 ms /    64 runs   (    0.65 ms per token,  1550.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2006.90 ms /   381 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2446.39 ms /    63 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    4556.69 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.10 ms /    68 runs   (    0.55 ms per token,  1832.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2984.77 ms /   563 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2636.22 ms /    67 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5714.81 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.45 ms /   119 runs   (    0.53 ms per token,  1875.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6490.25 ms /  1162 tokens (    5.59 ms per token,   179.04 tokens per second)\n",
            "llama_print_timings:        eval time =    4849.46 ms /   118 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   11516.67 ms /  1280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     119.53 ms /   219 runs   (    0.55 ms per token,  1832.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6178.61 ms /  1115 tokens (    5.54 ms per token,   180.46 tokens per second)\n",
            "llama_print_timings:        eval time =    8977.03 ms /   218 runs   (   41.18 ms per token,    24.28 tokens per second)\n",
            "llama_print_timings:       total time =   15495.05 ms /  1333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.36 ms /    98 runs   (    0.56 ms per token,  1770.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     140.58 ms /    24 tokens (    5.86 ms per token,   170.72 tokens per second)\n",
            "llama_print_timings:        eval time =    4021.27 ms /    98 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    4309.33 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.44 ms /    11 runs   (    0.59 ms per token,  1707.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3061.10 ms /   573 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =     388.40 ms /    10 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3475.02 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.83 ms /   136 runs   (    0.62 ms per token,  1603.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6213.41 ms /  1123 tokens (    5.53 ms per token,   180.74 tokens per second)\n",
            "llama_print_timings:        eval time =    5563.74 ms /   135 runs   (   41.21 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =   12018.38 ms /  1258 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.65 ms /   110 runs   (    0.56 ms per token,  1784.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.08 ms /   566 tokens (    5.27 ms per token,   189.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4280.26 ms /   109 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    7421.63 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.89 ms /    77 runs   (    0.54 ms per token,  1838.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6061.29 ms /  1090 tokens (    5.56 ms per token,   179.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3099.09 ms /    76 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    9279.72 ms /  1166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.64 ms /   229 runs   (    0.60 ms per token,  1675.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6454.82 ms /  1165 tokens (    5.54 ms per token,   180.49 tokens per second)\n",
            "llama_print_timings:        eval time =    9434.86 ms /   228 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   16273.45 ms /  1393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.08 ms /   148 runs   (    0.58 ms per token,  1719.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6199.84 ms /  1120 tokens (    5.54 ms per token,   180.65 tokens per second)\n",
            "llama_print_timings:        eval time =    6039.48 ms /   147 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =   12474.79 ms /  1267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.09 ms /   256 runs   (    0.59 ms per token,  1683.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2720.06 ms /   520 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =   10025.01 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13161.25 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.95 ms /    66 runs   (    0.56 ms per token,  1786.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.38 ms /   387 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2525.08 ms /    65 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4642.02 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.87 ms /   100 runs   (    0.55 ms per token,  1822.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3654.96 ms /   676 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3897.22 ms /    99 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    7698.54 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.34 ms /    86 runs   (    0.56 ms per token,  1779.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3159.36 ms /   596 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3336.06 ms /    85 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6622.15 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.09 ms /    95 runs   (    0.57 ms per token,  1756.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3068.62 ms /   570 tokens (    5.38 ms per token,   185.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3681.98 ms /    94 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6887.84 ms /   664 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.43 ms /   232 runs   (    0.61 ms per token,  1652.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1984.31 ms /   384 tokens (    5.17 ms per token,   193.52 tokens per second)\n",
            "llama_print_timings:        eval time =    9021.07 ms /   231 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   11391.66 ms /   615 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.52 ms /    82 runs   (    0.54 ms per token,  1841.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2896.13 ms /   550 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3177.82 ms /    81 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6188.17 ms /   631 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.56 ms /    87 runs   (    0.54 ms per token,  1868.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6495.69 ms /  1166 tokens (    5.57 ms per token,   179.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3530.27 ms /    86 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =   10157.84 ms /  1252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.79 ms /    87 runs   (    0.58 ms per token,  1712.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.26 ms /   432 tokens (    5.19 ms per token,   192.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3358.23 ms /    86 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5719.33 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.90 ms /     7 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2315.40 ms /   440 tokens (    5.26 ms per token,   190.03 tokens per second)\n",
            "llama_print_timings:        eval time =     232.75 ms /     6 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2567.11 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.90 ms /    96 runs   (    0.55 ms per token,  1814.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2028.45 ms /   390 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3691.72 ms /    95 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    5842.29 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.89 ms /    94 runs   (    0.65 ms per token,  1543.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2366.76 ms /   451 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3625.46 ms /    93 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    6134.19 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1844.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2214.81 ms /   421 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =     229.25 ms /     6 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
            "llama_print_timings:       total time =    2459.03 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.86 ms /   105 runs   (    0.56 ms per token,  1783.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5964.27 ms /  1083 tokens (    5.51 ms per token,   181.58 tokens per second)\n",
            "llama_print_timings:        eval time =    4251.66 ms /   104 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =   10367.79 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.09 ms /    92 runs   (    0.57 ms per token,  1766.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2048.71 ms /   387 tokens (    5.29 ms per token,   188.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3540.29 ms /    91 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    5710.18 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.63 ms /   256 runs   (    0.61 ms per token,  1634.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.88 ms /   400 tokens (    5.17 ms per token,   193.25 tokens per second)\n",
            "llama_print_timings:        eval time =    9989.61 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12462.69 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.88 ms /   115 runs   (    0.53 ms per token,  1888.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2679.49 ms /   512 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =    4473.72 ms /   114 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    7300.88 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      26.62 ms /    42 runs   (    0.63 ms per token,  1577.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2008.21 ms /   382 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.54 ms /    41 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    3676.09 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1852.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1860.33 ms /   359 tokens (    5.18 ms per token,   192.98 tokens per second)\n",
            "llama_print_timings:        eval time =     230.83 ms /     6 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2105.09 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.90 ms /     7 runs   (    0.56 ms per token,  1796.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.27 ms /   416 tokens (    5.19 ms per token,   192.66 tokens per second)\n",
            "llama_print_timings:        eval time =     269.25 ms /     7 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2443.41 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1929.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1857.36 ms /   360 tokens (    5.16 ms per token,   193.82 tokens per second)\n",
            "llama_print_timings:        eval time =     269.80 ms /     7 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2139.70 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1809.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3840.49 ms /   714 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
            "llama_print_timings:        eval time =     198.42 ms /     5 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    4055.67 ms /   719 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     6 runs   (    0.63 ms per token,  1577.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2224.15 ms /   418 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =     194.53 ms /     5 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2435.25 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     9 runs   (    0.53 ms per token,  1894.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2070.76 ms /   400 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
            "llama_print_timings:        eval time =     310.94 ms /     8 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2396.86 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.56 ms /    86 runs   (    0.54 ms per token,  1847.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.52 ms /   376 tokens (    5.16 ms per token,   193.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3336.36 ms /    86 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    5383.79 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.08 ms /    67 runs   (    0.67 ms per token,  1486.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2289.06 ms /   440 tokens (    5.20 ms per token,   192.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2617.57 ms /    67 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5017.83 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.02 ms /    69 runs   (    0.52 ms per token,  1915.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2809.47 ms /   530 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2662.59 ms /    68 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5560.12 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.34 ms /    65 runs   (    0.61 ms per token,  1652.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6461.80 ms /  1164 tokens (    5.55 ms per token,   180.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2634.01 ms /    64 runs   (   41.16 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =    9204.91 ms /  1228 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.55 ms /    76 runs   (    0.55 ms per token,  1829.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3819.80 ms /   714 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2957.79 ms /    75 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6881.96 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.99 ms /   256 runs   (    0.57 ms per token,  1765.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1938.14 ms /   375 tokens (    5.17 ms per token,   193.48 tokens per second)\n",
            "llama_print_timings:        eval time =    9957.06 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12277.05 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.28 ms /   256 runs   (    0.58 ms per token,  1726.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1892.27 ms /   366 tokens (    5.17 ms per token,   193.42 tokens per second)\n",
            "llama_print_timings:        eval time =    9923.28 ms /   255 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =   12202.61 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.50 ms /   256 runs   (    0.58 ms per token,  1723.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1942.79 ms /   376 tokens (    5.17 ms per token,   193.54 tokens per second)\n",
            "llama_print_timings:        eval time =    9989.03 ms /   256 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12316.28 ms /   632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.55 ms /    65 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     163.88 ms /    28 tokens (    5.85 ms per token,   170.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2469.39 ms /    64 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2713.93 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.81 ms /     7 runs   (    0.69 ms per token,  1455.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2630.62 ms /   498 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =     239.04 ms /     6 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    2886.55 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.60 ms /    99 runs   (    0.56 ms per token,  1780.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3062.43 ms /   570 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3849.64 ms /    98 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7044.73 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.48 ms /   256 runs   (    0.61 ms per token,  1646.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.07 ms /   390 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =    9963.99 ms /   255 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12393.89 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.13 ms /    70 runs   (    0.63 ms per token,  1586.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6506.60 ms /  1172 tokens (    5.55 ms per token,   180.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2859.34 ms /    69 runs   (   41.44 ms per token,    24.13 tokens per second)\n",
            "llama_print_timings:       total time =    9488.62 ms /  1241 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.14 ms /   138 runs   (    0.52 ms per token,  1939.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3750.88 ms /   704 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =    5452.07 ms /   138 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    9381.76 ms /   842 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.94 ms /   124 runs   (    0.64 ms per token,  1551.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2204.95 ms /   421 tokens (    5.24 ms per token,   190.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4806.79 ms /   123 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    7200.61 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.86 ms /   100 runs   (    0.55 ms per token,  1822.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.28 ms /   420 tokens (    5.23 ms per token,   191.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3861.73 ms /    99 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    6183.10 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.68 ms /    75 runs   (    0.61 ms per token,  1641.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2919.01 ms /   552 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2920.72 ms /    74 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5951.78 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.40 ms /    86 runs   (    0.59 ms per token,  1706.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6203.56 ms /  1122 tokens (    5.53 ms per token,   180.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3482.04 ms /    85 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    9816.29 ms /  1207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.94 ms /   256 runs   (    0.57 ms per token,  1754.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2176.97 ms /   410 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =    9948.10 ms /   255 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12486.45 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     6 runs   (    0.68 ms per token,  1480.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2103.54 ms /   397 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     196.39 ms /     5 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2315.61 ms /   402 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     129.87 ms /   232 runs   (    0.56 ms per token,  1786.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1820.46 ms /   349 tokens (    5.22 ms per token,   191.71 tokens per second)\n",
            "llama_print_timings:        eval time =    8997.47 ms /   231 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   11129.60 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_cosine_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     113.11 ms /   220 runs   (    0.51 ms per token,  1945.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4512.77 ms /   831 tokens (    5.43 ms per token,   184.14 tokens per second)\n",
            "llama_print_timings:        eval time =    8785.45 ms /   219 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   13598.95 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.68 ms /    71 runs   (    0.53 ms per token,  1884.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3108.31 ms /   581 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2757.10 ms /    70 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5961.08 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.58 ms /    65 runs   (    0.53 ms per token,  1879.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4512.23 ms /   835 tokens (    5.40 ms per token,   185.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2552.47 ms /    64 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7153.93 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.34 ms /    91 runs   (    0.54 ms per token,  1844.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4049.27 ms /   752 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =    3594.08 ms /    91 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7768.05 ms /   843 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.33 ms /    71 runs   (    0.65 ms per token,  1532.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4421.97 ms /   824 tokens (    5.37 ms per token,   186.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2845.27 ms /    71 runs   (   40.07 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7382.96 ms /   895 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.45 ms /    84 runs   (    0.52 ms per token,  1933.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3045.41 ms /   575 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3267.55 ms /    83 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6420.68 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.78 ms /    84 runs   (    0.66 ms per token,  1505.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4329.55 ms /   807 tokens (    5.36 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3326.83 ms /    83 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7797.43 ms /   890 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.32 ms /    74 runs   (    0.54 ms per token,  1835.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4756.69 ms /   874 tokens (    5.44 ms per token,   183.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2920.79 ms /    73 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    7780.36 ms /   947 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.05 ms /   101 runs   (    0.57 ms per token,  1739.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4484.14 ms /   826 tokens (    5.43 ms per token,   184.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3998.09 ms /   100 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    8630.63 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.43 ms /   100 runs   (    0.55 ms per token,  1804.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4331.03 ms /   805 tokens (    5.38 ms per token,   185.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3952.61 ms /    99 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    8424.61 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.35 ms /   243 runs   (    0.56 ms per token,  1782.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3097.15 ms /   584 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9578.48 ms /   243 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13020.98 ms /   827 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.86 ms /    68 runs   (    0.53 ms per token,  1896.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4273.97 ms /   788 tokens (    5.42 ms per token,   184.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2653.63 ms /    67 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7022.38 ms /   855 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.48 ms /    68 runs   (    0.60 ms per token,  1680.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4005.04 ms /   746 tokens (    5.37 ms per token,   186.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2663.70 ms /    67 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6769.07 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.05 ms /   256 runs   (    0.56 ms per token,  1789.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2616.64 ms /   490 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.02 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12986.95 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.65 ms /    68 runs   (    0.54 ms per token,  1855.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3870.70 ms /   719 tokens (    5.38 ms per token,   185.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2636.04 ms /    67 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6597.52 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.45 ms /    69 runs   (    0.54 ms per token,  1842.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2063.76 ms /   395 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2640.39 ms /    68 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    4792.06 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.81 ms /     7 runs   (    0.69 ms per token,  1455.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2822.38 ms /   536 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =     239.37 ms /     6 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    3079.62 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.12 ms /    99 runs   (    0.53 ms per token,  1899.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4034.92 ms /   750 tokens (    5.38 ms per token,   185.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3877.52 ms /    98 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    8040.70 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.85 ms /    75 runs   (    0.65 ms per token,  1535.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4345.03 ms /   806 tokens (    5.39 ms per token,   185.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2970.91 ms /    74 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7437.90 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.93 ms /    61 runs   (    0.56 ms per token,  1797.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2768.49 ms /   528 tokens (    5.24 ms per token,   190.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2389.98 ms /    61 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5238.47 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.84 ms /    64 runs   (    0.72 ms per token,  1396.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4377.39 ms /   811 tokens (    5.40 ms per token,   185.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2533.99 ms /    63 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7034.05 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.79 ms /    66 runs   (    0.54 ms per token,  1843.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3120.33 ms /   592 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2591.37 ms /    66 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5799.79 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.46 ms /    72 runs   (    0.63 ms per token,  1583.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2800.25 ms /   530 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2778.49 ms /    71 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5683.26 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.24 ms /    12 runs   (    0.60 ms per token,  1658.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2836.69 ms /   536 tokens (    5.29 ms per token,   188.95 tokens per second)\n",
            "llama_print_timings:        eval time =     471.64 ms /    12 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3335.11 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.42 ms /    69 runs   (    0.54 ms per token,  1843.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2068.98 ms /   398 tokens (    5.20 ms per token,   192.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2635.43 ms /    68 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    4790.52 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     7 runs   (    0.48 ms per token,  2069.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2588.98 ms /   495 tokens (    5.23 ms per token,   191.20 tokens per second)\n",
            "llama_print_timings:        eval time =     236.44 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2840.05 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.88 ms /   256 runs   (    0.56 ms per token,  1779.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3957.85 ms /   735 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =   10147.96 ms /   255 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =   14474.38 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.79 ms /    93 runs   (    0.54 ms per token,  1867.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4780.01 ms /   879 tokens (    5.44 ms per token,   183.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3678.15 ms /    92 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    8585.36 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.57 ms /    70 runs   (    0.52 ms per token,  1914.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2322.71 ms /   443 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2682.95 ms /    69 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    5093.35 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.88 ms /    91 runs   (    0.56 ms per token,  1788.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2185.84 ms /   412 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3499.19 ms /    90 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    5816.56 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.55 ms /    64 runs   (    0.54 ms per token,  1852.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1983.65 ms /   384 tokens (    5.17 ms per token,   193.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2440.03 ms /    63 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    4503.59 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.60 ms /    14 runs   (    0.54 ms per token,  1842.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1596.70 ms /   307 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
            "llama_print_timings:        eval time =     501.63 ms /    13 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2118.57 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.74 ms /     7 runs   (    0.68 ms per token,  1476.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2521.22 ms /   477 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =     236.94 ms /     6 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    2774.77 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1876.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2305.23 ms /   440 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =     271.14 ms /     7 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2591.23 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.90 ms /    81 runs   (    0.54 ms per token,  1844.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5964.21 ms /  1088 tokens (    5.48 ms per token,   182.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3257.46 ms /    80 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    9338.68 ms /  1168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      20.71 ms /    39 runs   (    0.53 ms per token,  1883.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3954.90 ms /   736 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.77 ms /    38 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5511.57 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.67 ms /   113 runs   (    0.63 ms per token,  1576.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6014.21 ms /  1093 tokens (    5.50 ms per token,   181.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4596.37 ms /   112 runs   (   41.04 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =   10802.56 ms /  1205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.62 ms /    99 runs   (    0.53 ms per token,  1881.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4156.94 ms /   776 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3885.56 ms /    98 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    8177.55 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.88 ms /   256 runs   (    0.57 ms per token,  1766.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2772.08 ms /   528 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =   10034.66 ms /   256 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   13196.14 ms /   784 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.68 ms /    82 runs   (    0.59 ms per token,  1684.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3807.46 ms /   709 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3214.27 ms /    81 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    7153.19 ms /   790 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.58 ms /    67 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3611.40 ms /   680 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2636.58 ms /    67 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6344.14 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.51 ms /    83 runs   (    0.55 ms per token,  1823.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4734.71 ms /   867 tokens (    5.46 ms per token,   183.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3287.70 ms /    82 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    8146.76 ms /   949 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.52 ms /    65 runs   (    0.59 ms per token,  1687.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4013.07 ms /   748 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2536.67 ms /    64 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    6649.39 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.18 ms /   256 runs   (    0.54 ms per token,  1852.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2839.94 ms /   532 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =   10001.57 ms /   255 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13222.68 ms /   787 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.95 ms /   132 runs   (    0.62 ms per token,  1610.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     177.44 ms /    29 tokens (    6.12 ms per token,   163.43 tokens per second)\n",
            "llama_print_timings:        eval time =    5147.14 ms /   131 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5542.72 ms /   160 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.18 ms /   256 runs   (    0.58 ms per token,  1727.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2852.28 ms /   539 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =   10046.50 ms /   255 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   13332.52 ms /   794 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.30 ms /   135 runs   (    0.56 ms per token,  1792.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2940.74 ms /   558 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =    5259.28 ms /   134 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    8389.66 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.42 ms /    60 runs   (    0.56 ms per token,  1795.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3750.73 ms /   694 tokens (    5.40 ms per token,   185.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2321.61 ms /    59 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6164.74 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.13 ms /    67 runs   (    0.57 ms per token,  1756.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2504.34 ms /   476 tokens (    5.26 ms per token,   190.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2589.35 ms /    66 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5188.12 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.48 ms /   256 runs   (    0.60 ms per token,  1678.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2030.56 ms /   387 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =    9960.56 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12401.36 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.38 ms /    66 runs   (    0.60 ms per token,  1675.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     934.56 ms /   184 tokens (    5.08 ms per token,   196.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2524.63 ms /    66 runs   (   38.25 ms per token,    26.14 tokens per second)\n",
            "llama_print_timings:       total time =    3557.00 ms /   250 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.38 ms /    12 runs   (    0.70 ms per token,  1431.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2542.35 ms /   480 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =     432.13 ms /    11 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3002.74 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1842.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2814.01 ms /   536 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =     196.25 ms /     5 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3026.10 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.24 ms /    68 runs   (    0.55 ms per token,  1825.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4477.72 ms /   832 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2677.48 ms /    67 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    7255.79 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.70 ms /   256 runs   (    0.57 ms per token,  1769.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2007.97 ms /   382 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    9941.60 ms /   255 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =   12339.68 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1485.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.42 ms /   413 tokens (    5.27 ms per token,   189.67 tokens per second)\n",
            "llama_print_timings:        eval time =     233.25 ms /     6 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2428.96 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.98 ms /    79 runs   (    0.54 ms per token,  1838.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4407.63 ms /   810 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3108.05 ms /    78 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    7632.74 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.16 ms /    69 runs   (    0.57 ms per token,  1761.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     134.23 ms /    23 tokens (    5.84 ms per token,   171.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2713.58 ms /    68 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    2942.32 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.17 ms /    69 runs   (    0.52 ms per token,  1907.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4796.93 ms /   880 tokens (    5.45 ms per token,   183.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2728.75 ms /    68 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    7628.36 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2549.38 ms /   486 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =     232.82 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2799.39 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.91 ms /    67 runs   (    0.57 ms per token,  1767.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2028.96 ms /   389 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2566.72 ms /    66 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4691.85 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.95 ms /   256 runs   (    0.55 ms per token,  1829.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3430.11 ms /   636 tokens (    5.39 ms per token,   185.42 tokens per second)\n",
            "llama_print_timings:        eval time =   10099.02 ms /   255 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =   13923.74 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.71 ms /   158 runs   (    0.53 ms per token,  1887.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4835.22 ms /   884 tokens (    5.47 ms per token,   182.83 tokens per second)\n",
            "llama_print_timings:        eval time =    6325.49 ms /   157 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =   11388.06 ms /  1041 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_ip_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_AES CORP_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_l2_1.json\n",
            "KeyError occurred: 'cosine'. Skipping approach 2 for dataframe results_approach_AES CORP_l2_2.json\n",
            "Total score for approach 2 and distance function cosine is 0.3793939393939394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(2, 'ip')"
      ],
      "metadata": {
        "id": "Y3m_VPxW3kL1",
        "outputId": "4d0eb07b-462f-4c2a-8a4a-abab29e6aa20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.93 ms /    81 runs   (    0.54 ms per token,  1843.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5224.77 ms /   947 tokens (    5.52 ms per token,   181.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3229.38 ms /    80 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8579.29 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.84 ms /    85 runs   (    0.68 ms per token,  1469.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4340.14 ms /   806 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =    3373.15 ms /    84 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    7864.26 ms /   890 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.68 ms /    80 runs   (    0.63 ms per token,  1578.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     181.88 ms /    31 tokens (    5.87 ms per token,   170.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3169.74 ms /    79 runs   (   40.12 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    3476.94 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.86 ms /    70 runs   (    0.54 ms per token,  1848.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5177.94 ms /   951 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2786.06 ms /    69 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8068.14 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.48 ms /   119 runs   (    0.58 ms per token,  1712.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2765.28 ms /   516 tokens (    5.36 ms per token,   186.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4624.86 ms /   118 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7568.72 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.94 ms /    88 runs   (    0.62 ms per token,  1601.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3931.77 ms /   736 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3469.83 ms /    87 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7551.51 ms /   823 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.63 ms /    86 runs   (    0.55 ms per token,  1805.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4367.76 ms /   803 tokens (    5.44 ms per token,   183.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3389.32 ms /    85 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7887.27 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.92 ms /   131 runs   (    0.56 ms per token,  1796.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5144.12 ms /   944 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
            "llama_print_timings:        eval time =    5273.85 ms /   130 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =   10630.66 ms /  1074 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.24 ms /   145 runs   (    0.53 ms per token,  1901.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     137.25 ms /    24 tokens (    5.72 ms per token,   174.86 tokens per second)\n",
            "llama_print_timings:        eval time =    5827.32 ms /   144 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    6164.74 ms /   168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.62 ms /   109 runs   (    0.52 ms per token,  1925.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5215.10 ms /   947 tokens (    5.51 ms per token,   181.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4364.52 ms /   108 runs   (   40.41 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    9740.73 ms /  1055 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.62 ms /    81 runs   (    0.70 ms per token,  1430.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4200.28 ms /   779 tokens (    5.39 ms per token,   185.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3211.93 ms /    80 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7562.81 ms /   859 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.76 ms /    85 runs   (    0.56 ms per token,  1779.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4801.89 ms /   885 tokens (    5.43 ms per token,   184.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3377.15 ms /    84 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    8309.34 ms /   969 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.00 ms /    70 runs   (    0.57 ms per token,  1749.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4011.99 ms /   739 tokens (    5.43 ms per token,   184.20 tokens per second)\n",
            "llama_print_timings:        eval time =    2738.30 ms /    69 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    6861.25 ms /   808 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.12 ms /   256 runs   (    0.58 ms per token,  1728.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5216.74 ms /   954 tokens (    5.47 ms per token,   182.87 tokens per second)\n",
            "llama_print_timings:        eval time =   10383.59 ms /   255 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =   16039.98 ms /  1209 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     6 runs   (    0.68 ms per token,  1474.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5456.98 ms /  1000 tokens (    5.46 ms per token,   183.25 tokens per second)\n",
            "llama_print_timings:        eval time =     201.95 ms /     5 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    5681.93 ms /  1005 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      10.18 ms /    14 runs   (    0.73 ms per token,  1375.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1324.42 ms /   250 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =     497.45 ms /    13 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
            "llama_print_timings:       total time =    1852.14 ms /   263 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.51 ms /    97 runs   (    0.55 ms per token,  1812.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3715.46 ms /   692 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3779.37 ms /    96 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    7632.70 ms /   788 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.84 ms /    80 runs   (    0.67 ms per token,  1485.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.85 ms /   564 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3119.08 ms /    79 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6244.65 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.94 ms /    71 runs   (    0.55 ms per token,  1823.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3983.52 ms /   743 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2764.05 ms /    70 runs   (   39.49 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6848.46 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.43 ms /    67 runs   (    0.54 ms per token,  1839.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     172.40 ms /    26 tokens (    6.63 ms per token,   150.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2611.34 ms /    66 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    2876.90 ms /    92 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.19 ms /   106 runs   (    0.57 ms per token,  1761.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5974.44 ms /  1077 tokens (    5.55 ms per token,   180.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4284.02 ms /   105 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =   10428.71 ms /  1182 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.56 ms /   256 runs   (    0.60 ms per token,  1656.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2112.83 ms /   407 tokens (    5.19 ms per token,   192.63 tokens per second)\n",
            "llama_print_timings:        eval time =    9958.83 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12493.52 ms /   662 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.01 ms /    84 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1899.74 ms /   364 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3228.13 ms /    83 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    5246.32 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.51 ms /   106 runs   (    0.58 ms per token,  1723.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2712.76 ms /   509 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4111.20 ms /   105 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6979.62 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.39 ms /    83 runs   (    0.57 ms per token,  1751.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2436.07 ms /   464 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3202.13 ms /    82 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5755.71 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.94 ms /     7 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2618.63 ms /   494 tokens (    5.30 ms per token,   188.65 tokens per second)\n",
            "llama_print_timings:        eval time =     234.74 ms /     6 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2873.87 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.94 ms /   256 runs   (    0.56 ms per token,  1778.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1453.70 ms /   268 tokens (    5.42 ms per token,   184.36 tokens per second)\n",
            "llama_print_timings:        eval time =    9985.37 ms /   255 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   11837.62 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.39 ms /   130 runs   (    0.56 ms per token,  1795.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2149.76 ms /   408 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =    5078.25 ms /   130 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    7410.44 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.19 ms /    99 runs   (    0.61 ms per token,  1644.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.71 ms /   383 tokens (    5.18 ms per token,   193.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3814.56 ms /    98 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5951.70 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.12 ms /   256 runs   (    0.57 ms per token,  1752.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2233.34 ms /   424 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.73 ms /   256 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12636.61 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.55 ms /   256 runs   (    0.56 ms per token,  1771.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2794.06 ms /   523 tokens (    5.34 ms per token,   187.18 tokens per second)\n",
            "llama_print_timings:        eval time =    9997.08 ms /   255 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   13185.82 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.79 ms /   256 runs   (    0.57 ms per token,  1768.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2185.07 ms /   416 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =    9958.34 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12544.06 ms /   671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.64 ms /   256 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2748.24 ms /   514 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.22 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13140.59 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     6 runs   (    0.67 ms per token,  1486.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3014.16 ms /   568 tokens (    5.31 ms per token,   188.44 tokens per second)\n",
            "llama_print_timings:        eval time =     235.27 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3267.78 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     6 runs   (    0.67 ms per token,  1497.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =     235.06 ms /     6 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =     246.31 ms /     6 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1919.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2038.00 ms /   388 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =     229.38 ms /     6 runs   (   38.23 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    2282.65 ms /   394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.44 ms /    75 runs   (    0.55 ms per token,  1809.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1770.94 ms /   342 tokens (    5.18 ms per token,   193.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2863.20 ms /    74 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    4736.70 ms /   416 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.58 ms /     6 runs   (    0.60 ms per token,  1677.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5905.40 ms /  1066 tokens (    5.54 ms per token,   180.51 tokens per second)\n",
            "llama_print_timings:        eval time =     203.51 ms /     5 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    6134.22 ms /  1071 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.96 ms /    84 runs   (    0.54 ms per token,  1868.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3316.65 ms /   624 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3260.82 ms /    83 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6697.07 ms /   707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.02 ms /    74 runs   (    0.64 ms per token,  1573.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3519.61 ms /   662 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2901.36 ms /    73 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    6546.52 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.93 ms /    86 runs   (    0.56 ms per token,  1794.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3939.83 ms /   734 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3366.45 ms /    85 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7432.82 ms /   819 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.36 ms /    66 runs   (    0.55 ms per token,  1814.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.19 ms /    19 tokens (    6.80 ms per token,   147.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2568.62 ms /    65 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    2786.29 ms /    84 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.85 ms /    12 runs   (    0.65 ms per token,  1529.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2964.58 ms /   557 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =     429.29 ms /    11 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3421.20 ms /   568 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.94 ms /   109 runs   (    0.55 ms per token,  1818.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4076.92 ms /   760 tokens (    5.36 ms per token,   186.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4317.95 ms /   109 runs   (   39.61 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    8551.14 ms /   869 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.74 ms /     9 runs   (    0.64 ms per token,  1569.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.94 ms /   428 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =     311.17 ms /     8 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2573.37 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.75 ms /   100 runs   (    0.52 ms per token,  1932.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4694.47 ms /   861 tokens (    5.45 ms per token,   183.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3970.16 ms /    99 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    8808.32 ms /   960 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.95 ms /    85 runs   (    0.68 ms per token,  1466.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4810.16 ms /   888 tokens (    5.42 ms per token,   184.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3442.97 ms /    85 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    8410.97 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.18 ms /    94 runs   (    0.56 ms per token,  1801.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2680.33 ms /   512 tokens (    5.24 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3643.16 ms /    93 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6456.14 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.09 ms /    73 runs   (    0.60 ms per token,  1655.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1044.91 ms /   195 tokens (    5.36 ms per token,   186.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2794.92 ms /    72 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3949.55 ms /   267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.88 ms /    87 runs   (    0.54 ms per token,  1855.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3814.64 ms /   706 tokens (    5.40 ms per token,   185.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3400.90 ms /    86 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    7343.91 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.00 ms /   100 runs   (    0.65 ms per token,  1538.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3428.57 ms /   648 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3970.93 ms /   100 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7572.59 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.15 ms /   256 runs   (    0.57 ms per token,  1763.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2518.23 ms /   475 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =   10021.37 ms /   255 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12956.22 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.46 ms /    99 runs   (    0.54 ms per token,  1851.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2171.79 ms /   411 tokens (    5.28 ms per token,   189.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3823.16 ms /    98 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    6128.88 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.28 ms /   129 runs   (    0.62 ms per token,  1606.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.98 ms /   453 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
            "llama_print_timings:        eval time =    5019.66 ms /   128 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7603.73 ms /   581 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1809.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2305.23 ms /   440 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =     271.49 ms /     7 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2593.17 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.35 ms /    96 runs   (    0.59 ms per token,  1703.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5173.23 ms /   948 tokens (    5.46 ms per token,   183.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3838.50 ms /    95 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    9169.54 ms /  1043 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.06 ms /    69 runs   (    0.54 ms per token,  1862.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4367.24 ms /   807 tokens (    5.41 ms per token,   184.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.48 ms /    68 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7175.32 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.80 ms /   117 runs   (    0.60 ms per token,  1676.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.33 ms /   464 tokens (    5.21 ms per token,   191.95 tokens per second)\n",
            "llama_print_timings:        eval time =    4554.38 ms /   116 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    7151.78 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.57 ms /   256 runs   (    0.57 ms per token,  1758.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.87 ms /   415 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9963.87 ms /   255 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12537.78 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.63 ms /    81 runs   (    0.58 ms per token,  1737.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2364.88 ms /   444 tokens (    5.33 ms per token,   187.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3132.71 ms /    80 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5617.23 ms /   524 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.56 ms /   256 runs   (    0.58 ms per token,  1734.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2632.45 ms /   501 tokens (    5.25 ms per token,   190.32 tokens per second)\n",
            "llama_print_timings:        eval time =   10041.28 ms /   255 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   13091.16 ms /   756 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.62 ms /   129 runs   (    0.62 ms per token,  1620.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3787.27 ms /   707 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
            "llama_print_timings:        eval time =    5091.65 ms /   128 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    9093.14 ms /   835 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     101.47 ms /   183 runs   (    0.55 ms per token,  1803.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4172.82 ms /   772 tokens (    5.41 ms per token,   185.01 tokens per second)\n",
            "llama_print_timings:        eval time =    7268.54 ms /   182 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =   11724.49 ms /   954 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.82 ms /     7 runs   (    0.69 ms per token,  1452.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1835.19 ms /   349 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
            "llama_print_timings:        eval time =     236.89 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2088.91 ms /   355 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.62 ms /   135 runs   (    0.55 ms per token,  1809.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2427.71 ms /   464 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =    5244.82 ms /   134 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    7860.29 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1851.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1851.60 ms /   358 tokens (    5.17 ms per token,   193.35 tokens per second)\n",
            "llama_print_timings:        eval time =     231.23 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2096.40 ms /   364 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.61 ms /    76 runs   (    0.65 ms per token,  1531.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2832.12 ms /   532 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2948.91 ms /    75 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5906.49 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.35 ms /   108 runs   (    0.55 ms per token,  1819.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2760.18 ms /   522 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4185.88 ms /   107 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    7096.37 ms /   629 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.40 ms /   114 runs   (    0.56 ms per token,  1798.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5347.93 ms /   971 tokens (    5.51 ms per token,   181.57 tokens per second)\n",
            "llama_print_timings:        eval time =    4569.51 ms /   113 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =   10087.08 ms /  1084 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.36 ms /    78 runs   (    0.62 ms per token,  1612.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2764.31 ms /   526 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3019.32 ms /    77 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5917.95 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.33 ms /    74 runs   (    0.56 ms per token,  1790.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2790.05 ms /   526 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2869.47 ms /    73 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5765.87 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      22.38 ms /    41 runs   (    0.55 ms per token,  1832.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3030.28 ms /   573 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.68 ms /    40 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    4652.62 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.99 ms /    72 runs   (    0.72 ms per token,  1384.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2777.81 ms /   528 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2830.80 ms /    72 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5738.61 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.87 ms /    75 runs   (    0.54 ms per token,  1834.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     167.47 ms /    26 tokens (    6.44 ms per token,   155.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2905.96 ms /    74 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3173.35 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.19 ms /    94 runs   (    0.59 ms per token,  1703.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3030.20 ms /   574 tokens (    5.28 ms per token,   189.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3663.51 ms /    93 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6838.89 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1899.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2853.64 ms /   536 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =     235.77 ms /     6 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3108.35 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.48 ms /    79 runs   (    0.55 ms per token,  1817.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5266.44 ms /   968 tokens (    5.44 ms per token,   183.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3191.13 ms /    79 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    8574.07 ms /  1047 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.01 ms /    85 runs   (    0.54 ms per token,  1847.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5407.44 ms /   979 tokens (    5.52 ms per token,   181.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3394.41 ms /    84 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    8930.48 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.70 ms /    85 runs   (    0.68 ms per token,  1473.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5263.08 ms /   962 tokens (    5.47 ms per token,   182.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3420.58 ms /    84 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8849.77 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     124.38 ms /   207 runs   (    0.60 ms per token,  1664.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.61 ms /   534 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
            "llama_print_timings:        eval time =    8084.48 ms /   206 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   11228.79 ms /   740 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     137.72 ms /   256 runs   (    0.54 ms per token,  1858.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3113.95 ms /   581 tokens (    5.36 ms per token,   186.58 tokens per second)\n",
            "llama_print_timings:        eval time =   10056.56 ms /   255 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13570.03 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.63 ms /   101 runs   (    0.54 ms per token,  1848.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2355.98 ms /   447 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3906.87 ms /   100 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    6406.19 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.70 ms /    90 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2804.50 ms /   531 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3504.78 ms /    89 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6444.20 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.38 ms /    70 runs   (    0.66 ms per token,  1509.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     215.41 ms /    36 tokens (    5.98 ms per token,   167.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2719.57 ms /    69 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    3057.20 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.04 ms /    76 runs   (    0.55 ms per token,  1807.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5404.62 ms /   986 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3034.95 ms /    75 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    8559.00 ms /  1061 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.91 ms /    79 runs   (    0.54 ms per token,  1840.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4929.74 ms /   903 tokens (    5.46 ms per token,   183.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3132.75 ms /    78 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8179.77 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2632.59 ms /   499 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =     237.03 ms /     6 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    2886.37 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.62 ms /    98 runs   (    0.60 ms per token,  1671.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5245.42 ms /   960 tokens (    5.46 ms per token,   183.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3968.37 ms /    98 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    9374.26 ms /  1058 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.12 ms /   113 runs   (    0.56 ms per token,  1790.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2811.83 ms /   533 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =    4388.91 ms /   112 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    7362.33 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.05 ms /    69 runs   (    0.55 ms per token,  1813.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3112.49 ms /   580 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2664.49 ms /    68 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5876.24 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.41 ms /    75 runs   (    0.61 ms per token,  1651.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4885.95 ms /   899 tokens (    5.43 ms per token,   184.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2977.69 ms /    74 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7986.14 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.84 ms /    77 runs   (    0.56 ms per token,  1797.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2802.18 ms /   528 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3021.59 ms /    77 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5934.28 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.54 ms /     7 runs   (    0.51 ms per token,  1974.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2414.14 ms /   464 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =     231.93 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2660.80 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.62 ms /   256 runs   (    0.60 ms per token,  1677.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.56 ms /   532 tokens (    5.28 ms per token,   189.42 tokens per second)\n",
            "llama_print_timings:        eval time =   10020.59 ms /   255 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   13245.10 ms /   787 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.35 ms /    91 runs   (    0.58 ms per token,  1738.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2895.19 ms /   546 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3544.41 ms /    90 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6585.20 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1935.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2522.83 ms /   477 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =     231.91 ms /     6 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2771.55 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1855.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     125.73 ms /    21 tokens (    5.99 ms per token,   167.02 tokens per second)\n",
            "llama_print_timings:        eval time =     192.02 ms /     5 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =     327.87 ms /    26 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.96 ms /    94 runs   (    0.55 ms per token,  1808.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3073.04 ms /   581 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3647.36 ms /    93 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6855.04 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.50 ms /    70 runs   (    0.65 ms per token,  1538.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2430.57 ms /   458 tokens (    5.31 ms per token,   188.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2702.66 ms /    69 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5251.98 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.15 ms /    86 runs   (    0.54 ms per token,  1863.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2853.68 ms /   543 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3336.26 ms /    85 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6308.00 ms /   628 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.30 ms /   256 runs   (    0.59 ms per token,  1680.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2723.97 ms /   520 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =   10000.50 ms /   255 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13137.90 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1806.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.89 ms /   454 tokens (    5.23 ms per token,   191.33 tokens per second)\n",
            "llama_print_timings:        eval time =     192.20 ms /     5 runs   (   38.44 ms per token,    26.01 tokens per second)\n",
            "llama_print_timings:       total time =    2578.77 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.25 ms /    73 runs   (    0.63 ms per token,  1578.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2748.35 ms /   520 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
            "llama_print_timings:        eval time =    2871.63 ms /    73 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5741.45 ms /   593 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.49 ms /    74 runs   (    0.61 ms per token,  1626.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2721.45 ms /   519 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2859.35 ms /    73 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5689.60 ms /   592 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.65 ms /    11 runs   (    0.60 ms per token,  1655.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.57 ms /   455 tokens (    5.21 ms per token,   191.77 tokens per second)\n",
            "llama_print_timings:        eval time =     390.01 ms /    10 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2784.95 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     9 runs   (    0.55 ms per token,  1829.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5261.90 ms /   957 tokens (    5.50 ms per token,   181.87 tokens per second)\n",
            "llama_print_timings:        eval time =     323.12 ms /     8 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    5611.17 ms /   965 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.05 ms /    67 runs   (    0.55 ms per token,  1808.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     134.83 ms /    21 tokens (    6.42 ms per token,   155.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2661.39 ms /    66 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    2888.09 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.09 ms /    93 runs   (    0.61 ms per token,  1628.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2725.23 ms /   520 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3651.95 ms /    93 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6524.99 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.16 ms /    69 runs   (    0.63 ms per token,  1598.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.31 ms /    22 tokens (    5.83 ms per token,   171.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2676.56 ms /    68 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2912.75 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     119.88 ms /   194 runs   (    0.62 ms per token,  1618.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2630.61 ms /   499 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =    7594.00 ms /   193 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   10545.36 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.28 ms /   256 runs   (    0.56 ms per token,  1786.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2821.85 ms /   531 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =   10031.06 ms /   255 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   13258.80 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.20 ms /    65 runs   (    0.54 ms per token,  1846.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5287.28 ms /   964 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2582.83 ms /    64 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7970.04 ms /  1028 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.86 ms /   103 runs   (    0.62 ms per token,  1612.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5188.70 ms /   952 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =    4139.79 ms /   102 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    9501.41 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.25 ms /    68 runs   (    0.61 ms per token,  1648.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5357.06 ms /   981 tokens (    5.46 ms per token,   183.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2713.64 ms /    67 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    8183.60 ms /  1048 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.94 ms /    79 runs   (    0.54 ms per token,  1839.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2358.77 ms /   448 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3054.03 ms /    78 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5523.04 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.50 ms /    55 runs   (    0.55 ms per token,  1803.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2546.15 ms /   483 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2106.38 ms /    54 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4730.18 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.52 ms /    63 runs   (    0.75 ms per token,  1325.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.71 ms /   451 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2428.94 ms /    62 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    4916.70 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.89 ms /    74 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2828.85 ms /   536 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2861.00 ms /    73 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5793.02 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.61 ms /    12 runs   (    0.55 ms per token,  1815.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2849.59 ms /   538 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =     431.93 ms /    11 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3303.34 ms /   549 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.30 ms /     7 runs   (    1.04 ms per token,   958.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.80 ms /   470 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =     236.32 ms /     6 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2722.09 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.52 ms /    93 runs   (    0.54 ms per token,  1840.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3105.82 ms /   580 tokens (    5.35 ms per token,   186.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3605.78 ms /    92 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6847.26 ms /   672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.57 ms /    72 runs   (    0.58 ms per token,  1732.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2806.90 ms /   533 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2788.75 ms /    71 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5701.77 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.67 ms /   120 runs   (    0.60 ms per token,  1674.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2755.93 ms /   518 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4665.69 ms /   119 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7604.55 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2351.66 ms /   442 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
            "llama_print_timings:        eval time =     231.81 ms /     6 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    2599.18 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.78 ms /   256 runs   (    0.59 ms per token,  1697.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2895.25 ms /   548 tokens (    5.28 ms per token,   189.28 tokens per second)\n",
            "llama_print_timings:        eval time =   10046.53 ms /   255 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   13353.77 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.08 ms /   110 runs   (    0.68 ms per token,  1465.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.15 ms /   532 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4297.23 ms /   109 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7297.79 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.81 ms /    74 runs   (    0.55 ms per token,  1813.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5361.72 ms /   984 tokens (    5.45 ms per token,   183.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2993.53 ms /    74 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8466.28 ms /  1058 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.70 ms /    67 runs   (    0.53 ms per token,  1876.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4934.22 ms /   904 tokens (    5.46 ms per token,   183.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2690.38 ms /    67 runs   (   40.15 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    7726.21 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.80 ms /   256 runs   (    0.61 ms per token,  1643.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1512.95 ms /   290 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =    9871.03 ms /   255 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =   11819.22 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.43 ms /   256 runs   (    0.60 ms per token,  1657.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3476.69 ms /   650 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =   10122.25 ms /   255 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =   14040.25 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.90 ms /    86 runs   (    0.53 ms per token,  1873.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3429.69 ms /   643 tokens (    5.33 ms per token,   187.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3335.46 ms /    85 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6884.49 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.76 ms /    77 runs   (    0.54 ms per token,  1843.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5031.38 ms /   917 tokens (    5.49 ms per token,   182.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3056.10 ms /    76 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    8201.96 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.57 ms /    64 runs   (    0.54 ms per token,  1851.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3035.82 ms /   576 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2520.45 ms /    64 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5647.32 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.90 ms /    84 runs   (    0.53 ms per token,  1871.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5029.48 ms /   920 tokens (    5.47 ms per token,   182.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3341.29 ms /    83 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8495.21 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.62 ms /    74 runs   (    0.68 ms per token,  1461.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4337.34 ms /   808 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2931.53 ms /    73 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    7404.41 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.84 ms /    79 runs   (    0.53 ms per token,  1888.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3037.48 ms /   570 tokens (    5.33 ms per token,   187.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3059.94 ms /    78 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6209.52 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.26 ms /    96 runs   (    0.64 ms per token,  1567.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4946.06 ms /   910 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3853.94 ms /    95 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    8966.55 ms /  1005 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.73 ms /    86 runs   (    0.54 ms per token,  1840.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3030.36 ms /   573 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3341.39 ms /    85 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6491.94 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.85 ms /   117 runs   (    0.56 ms per token,  1776.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4965.99 ms /   911 tokens (    5.45 ms per token,   183.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4680.06 ms /   116 runs   (   40.35 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    9826.27 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.72 ms /   116 runs   (    0.62 ms per token,  1617.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3029.77 ms /   571 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =    4523.15 ms /   115 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7743.93 ms /   686 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.49 ms /    87 runs   (    0.59 ms per token,  1689.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     131.96 ms /    24 tokens (    5.50 ms per token,   181.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3378.63 ms /    86 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3639.77 ms /   110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.14 ms /    75 runs   (    0.54 ms per token,  1868.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3650.62 ms /   685 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2925.29 ms /    74 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6681.84 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.57 ms /    70 runs   (    0.62 ms per token,  1606.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3052.89 ms /   573 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2717.57 ms /    69 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5883.90 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.05 ms /    83 runs   (    0.52 ms per token,  1928.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4940.80 ms /   912 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3339.43 ms /    83 runs   (   40.23 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    8399.55 ms /   995 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.40 ms /    74 runs   (    0.68 ms per token,  1468.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     134.35 ms /    22 tokens (    6.11 ms per token,   163.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2968.09 ms /    73 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    3230.70 ms /    95 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.54 ms /   108 runs   (    0.53 ms per token,  1876.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4437.82 ms /   821 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
            "llama_print_timings:        eval time =    4270.08 ms /   107 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    8860.76 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     105.65 ms /   178 runs   (    0.59 ms per token,  1684.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3051.19 ms /   576 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =    6957.14 ms /   177 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   10282.15 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.12 ms /    73 runs   (    0.67 ms per token,  1486.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4340.99 ms /   808 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2910.44 ms /    72 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    7382.75 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.44 ms /    69 runs   (    0.53 ms per token,  1893.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5040.70 ms /   923 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2735.03 ms /    68 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7875.90 ms /   991 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     105.81 ms /   159 runs   (    0.67 ms per token,  1502.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3032.41 ms /   576 tokens (    5.26 ms per token,   189.95 tokens per second)\n",
            "llama_print_timings:        eval time =    6263.64 ms /   159 runs   (   39.39 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    9574.20 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.09 ms /    67 runs   (    0.57 ms per token,  1758.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     169.66 ms /    28 tokens (    6.06 ms per token,   165.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2595.24 ms /    66 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2855.49 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.89 ms /    66 runs   (    0.68 ms per token,  1470.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4949.07 ms /   909 tokens (    5.44 ms per token,   183.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2632.06 ms /    65 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    7706.65 ms /   974 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.34 ms /    80 runs   (    0.54 ms per token,  1845.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3035.57 ms /   576 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3130.66 ms /    80 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6278.46 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.08 ms /    91 runs   (    0.65 ms per token,  1540.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2118.94 ms /   408 tokens (    5.19 ms per token,   192.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3508.38 ms /    90 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5778.65 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.72 ms /   114 runs   (    0.57 ms per token,  1761.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3041.60 ms /   573 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =    4428.19 ms /   113 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    7634.35 ms /   686 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.20 ms /   256 runs   (    0.58 ms per token,  1727.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1852.40 ms /   358 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
            "llama_print_timings:        eval time =    9943.04 ms /   255 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =   12199.81 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.74 ms /   256 runs   (    0.59 ms per token,  1687.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.81 ms /   412 tokens (    5.23 ms per token,   191.02 tokens per second)\n",
            "llama_print_timings:        eval time =    9956.83 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12525.43 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.69 ms /   105 runs   (    0.66 ms per token,  1506.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4480.10 ms /   832 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =    4232.01 ms /   105 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    8904.39 ms /   937 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.34 ms /    11 runs   (    0.58 ms per token,  1734.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3162.57 ms /   600 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =     388.76 ms /    10 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3574.43 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.51 ms /   127 runs   (    0.59 ms per token,  1681.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2498.80 ms /   474 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =    4932.26 ms /   126 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    7628.12 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.55 ms /   166 runs   (    0.54 ms per token,  1853.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3190.99 ms /   594 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
            "llama_print_timings:        eval time =    6495.71 ms /   165 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    9919.73 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     106.23 ms /   169 runs   (    0.63 ms per token,  1590.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2466.36 ms /   467 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
            "llama_print_timings:        eval time =    6578.81 ms /   168 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    9314.45 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.08 ms /   146 runs   (    0.60 ms per token,  1676.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3115.12 ms /   589 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =    5725.77 ms /   145 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    9082.00 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.56 ms /     6 runs   (    0.59 ms per token,  1687.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2991.16 ms /   568 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =     236.72 ms /     6 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3244.19 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1667.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1815.07 ms /   352 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
            "llama_print_timings:        eval time =     232.61 ms /     6 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2062.60 ms /   358 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.01 ms /    64 runs   (    0.55 ms per token,  1828.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1226.93 ms /   240 tokens (    5.11 ms per token,   195.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2412.47 ms /    63 runs   (   38.29 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    3723.47 ms /   303 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.92 ms /    80 runs   (    0.59 ms per token,  1705.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3593.12 ms /   669 tokens (    5.37 ms per token,   186.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3120.95 ms /    79 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6847.53 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.51 ms /    66 runs   (    0.55 ms per token,  1807.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     132.07 ms /    24 tokens (    5.50 ms per token,   181.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2552.13 ms /    65 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2771.95 ms /    89 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     113.69 ms /   187 runs   (    0.61 ms per token,  1644.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3076.09 ms /   579 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =    7348.55 ms /   186 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   10735.68 ms /   765 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      24.14 ms /    46 runs   (    0.52 ms per token,  1905.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3570.01 ms /   671 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1769.58 ms /    45 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5406.94 ms /   716 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.01 ms /    11 runs   (    0.64 ms per token,  1570.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3001.05 ms /   566 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =     396.96 ms /    10 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3424.02 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.37 ms /   256 runs   (    0.55 ms per token,  1810.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2138.42 ms /   402 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =    9957.64 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12480.49 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.24 ms /    67 runs   (    0.53 ms per token,  1901.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4416.82 ms /   810 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2625.66 ms /    66 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7143.04 ms /   876 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.42 ms /    68 runs   (    0.64 ms per token,  1566.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5357.51 ms /   981 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2727.00 ms /    67 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    8212.78 ms /  1048 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.24 ms /    73 runs   (    0.55 ms per token,  1813.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4996.09 ms /   915 tokens (    5.46 ms per token,   183.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2897.29 ms /    72 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    8005.38 ms /   987 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.41 ms /   256 runs   (    0.61 ms per token,  1626.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.73 ms /   469 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =   10002.00 ms /   255 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   12882.66 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.13 ms /    74 runs   (    0.66 ms per token,  1506.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4435.86 ms /   819 tokens (    5.42 ms per token,   184.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2939.14 ms /    73 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    7506.69 ms /   892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.96 ms /    11 runs   (    0.54 ms per token,  1846.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.49 ms /   397 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =     387.07 ms /    10 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2479.25 ms /   407 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.89 ms /    67 runs   (    0.54 ms per token,  1866.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4335.97 ms /   805 tokens (    5.39 ms per token,   185.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2622.66 ms /    66 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    7055.00 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.98 ms /    12 runs   (    0.67 ms per token,  1503.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2453.35 ms /   460 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =     429.87 ms /    11 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2915.03 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.09 ms /   132 runs   (    0.53 ms per token,  1883.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1776.89 ms /   344 tokens (    5.17 ms per token,   193.60 tokens per second)\n",
            "llama_print_timings:        eval time =    5118.95 ms /   132 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    7070.28 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     207.12 ms /    38 tokens (    5.45 ms per token,   183.47 tokens per second)\n",
            "llama_print_timings:        eval time =     230.48 ms /     6 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =     449.24 ms /    44 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      97.67 ms /   149 runs   (    0.66 ms per token,  1525.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3209.64 ms /   607 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =    5852.69 ms /   148 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    9313.09 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.81 ms /    73 runs   (    0.55 ms per token,  1833.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3650.70 ms /   682 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2837.69 ms /    72 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6592.70 ms /   754 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.61 ms /   256 runs   (    0.55 ms per token,  1820.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2171.82 ms /   412 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    9967.16 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12530.11 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.06 ms /   256 runs   (    0.57 ms per token,  1740.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2250.15 ms /   429 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    9953.80 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12679.27 ms /   684 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.53 ms /    80 runs   (    0.66 ms per token,  1523.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1812.40 ms /   352 tokens (    5.15 ms per token,   194.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3109.40 ms /    80 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    5063.00 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.58 ms /    64 runs   (    0.54 ms per token,  1850.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5372.71 ms /   983 tokens (    5.47 ms per token,   182.96 tokens per second)\n",
            "llama_print_timings:        eval time =    2547.70 ms /    63 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8019.01 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.65 ms /   116 runs   (    0.64 ms per token,  1553.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3041.23 ms /   576 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =    4519.75 ms /   115 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7752.83 ms /   691 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.84 ms /   236 runs   (    0.59 ms per token,  1687.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.92 ms /    23 tokens (    5.65 ms per token,   177.03 tokens per second)\n",
            "llama_print_timings:        eval time =    9257.88 ms /   235 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    9766.13 ms /   258 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.33 ms /    76 runs   (    0.54 ms per token,  1839.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1875.29 ms /   356 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2907.20 ms /    75 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    4890.37 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     166.45 ms /   256 runs   (    0.65 ms per token,  1537.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2155.32 ms /   410 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
            "llama_print_timings:        eval time =    9966.41 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12572.55 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.13 ms /    81 runs   (    0.57 ms per token,  1755.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4984.59 ms /   920 tokens (    5.42 ms per token,   184.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3227.12 ms /    80 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    8338.02 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.37 ms /   138 runs   (    0.55 ms per token,  1806.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4462.22 ms /   824 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =    5480.61 ms /   137 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =   10145.15 ms /   961 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.29 ms /    84 runs   (    0.67 ms per token,  1492.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3455.19 ms /   647 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3300.47 ms /    83 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6900.45 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.46 ms /    68 runs   (    0.55 ms per token,  1815.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5308.34 ms /   970 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2705.78 ms /    67 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    8114.62 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.90 ms /   106 runs   (    0.56 ms per token,  1799.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4892.81 ms /   894 tokens (    5.47 ms per token,   182.72 tokens per second)\n",
            "llama_print_timings:        eval time =    4222.67 ms /   105 runs   (   40.22 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    9277.19 ms /   999 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.74 ms /    76 runs   (    0.65 ms per token,  1527.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3880.64 ms /   724 tokens (    5.36 ms per token,   186.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2989.43 ms /    75 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7001.41 ms /   799 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.78 ms /   142 runs   (    0.52 ms per token,  1924.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4868.56 ms /   896 tokens (    5.43 ms per token,   184.04 tokens per second)\n",
            "llama_print_timings:        eval time =    5675.80 ms /   141 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =   10751.09 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1877.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5780.66 ms /  1048 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =     243.38 ms /     6 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    6048.86 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.20 ms /    75 runs   (    0.56 ms per token,  1777.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4752.55 ms /   880 tokens (    5.40 ms per token,   185.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2965.31 ms /    74 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    7829.88 ms /   954 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.92 ms /    68 runs   (    0.57 ms per token,  1746.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4907.42 ms /   895 tokens (    5.48 ms per token,   182.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2691.96 ms /    67 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    7706.68 ms /   962 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.68 ms /    80 runs   (    0.66 ms per token,  1518.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5031.91 ms /   928 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3247.41 ms /    80 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    8423.16 ms /  1008 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     6 runs   (    0.61 ms per token,  1626.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3845.26 ms /   715 tokens (    5.38 ms per token,   185.94 tokens per second)\n",
            "llama_print_timings:        eval time =     196.92 ms /     5 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    4061.78 ms /   720 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.81 ms /   121 runs   (    0.56 ms per token,  1784.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     133.24 ms /    24 tokens (    5.55 ms per token,   180.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4749.11 ms /   120 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    5050.40 ms /   144 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1787.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5490.27 ms /   998 tokens (    5.50 ms per token,   181.78 tokens per second)\n",
            "llama_print_timings:        eval time =     203.97 ms /     5 runs   (   40.79 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    5718.52 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.98 ms /   114 runs   (    0.58 ms per token,  1727.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5267.11 ms /   967 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4574.82 ms /   113 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =   10021.10 ms /  1080 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.58 ms /   137 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5112.60 ms /   931 tokens (    5.49 ms per token,   182.10 tokens per second)\n",
            "llama_print_timings:        eval time =    5486.40 ms /   136 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =   10799.23 ms /  1067 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.96 ms /    74 runs   (    0.51 ms per token,  1949.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5971.96 ms /  1076 tokens (    5.55 ms per token,   180.18 tokens per second)\n",
            "llama_print_timings:        eval time =    2969.39 ms /    73 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    9054.66 ms /  1149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.58 ms /    76 runs   (    0.68 ms per token,  1473.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5312.42 ms /   971 tokens (    5.47 ms per token,   182.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3051.73 ms /    75 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    8510.50 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.08 ms /    86 runs   (    0.56 ms per token,  1788.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4816.80 ms /   888 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3451.71 ms /    86 runs   (   40.14 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    8396.45 ms /   974 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.19 ms /    95 runs   (    0.59 ms per token,  1690.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5302.85 ms /   968 tokens (    5.48 ms per token,   182.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3852.62 ms /    95 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    9309.12 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.23 ms /    75 runs   (    0.56 ms per token,  1775.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4330.78 ms /   802 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2947.24 ms /    74 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7391.18 ms /   876 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.79 ms /    91 runs   (    0.55 ms per token,  1827.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4198.27 ms /   771 tokens (    5.45 ms per token,   183.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3575.99 ms /    90 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    7906.35 ms /   861 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.49 ms /    59 runs   (    0.64 ms per token,  1573.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3434.18 ms /   648 tokens (    5.30 ms per token,   188.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2284.13 ms /    58 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5813.85 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.12 ms /    53 runs   (    0.55 ms per token,  1819.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5344.13 ms /   971 tokens (    5.50 ms per token,   181.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2097.69 ms /    52 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    7526.42 ms /  1023 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.07 ms /   111 runs   (    0.65 ms per token,  1540.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4795.07 ms /   886 tokens (    5.41 ms per token,   184.77 tokens per second)\n",
            "llama_print_timings:        eval time =    4449.67 ms /   110 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    9439.30 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      92.56 ms /   150 runs   (    0.62 ms per token,  1620.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5266.37 ms /   966 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
            "llama_print_timings:        eval time =    6056.28 ms /   149 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   11574.66 ms /  1115 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.26 ms /    87 runs   (    0.57 ms per token,  1766.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     229.62 ms /    35 tokens (    6.56 ms per token,   152.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3484.67 ms /    86 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    3839.67 ms /   121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.66 ms /    65 runs   (    0.61 ms per token,  1638.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5504.19 ms /  1008 tokens (    5.46 ms per token,   183.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2646.29 ms /    65 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8263.56 ms /  1073 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.47 ms /    78 runs   (    0.57 ms per token,  1754.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3776.03 ms /   704 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3035.87 ms /    77 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6930.71 ms /   781 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.69 ms /    96 runs   (    0.65 ms per token,  1531.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5082.07 ms /   931 tokens (    5.46 ms per token,   183.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3861.62 ms /    95 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    9115.47 ms /  1026 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1886.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.13 ms /   466 tokens (    5.27 ms per token,   189.65 tokens per second)\n",
            "llama_print_timings:        eval time =     233.86 ms /     6 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    2705.93 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.17 ms /   468 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
            "llama_print_timings:        eval time =     232.81 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2708.25 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      96.18 ms /   153 runs   (    0.63 ms per token,  1590.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3837.79 ms /   719 tokens (    5.34 ms per token,   187.35 tokens per second)\n",
            "llama_print_timings:        eval time =    6067.73 ms /   152 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =   10162.96 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.64 ms /   112 runs   (    0.55 ms per token,  1816.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2111.64 ms /   405 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =    4338.53 ms /   111 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6605.88 ms /   516 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.37 ms /    79 runs   (    0.60 ms per token,  1667.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2394.10 ms /   451 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3044.01 ms /    78 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5561.31 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.76 ms /    76 runs   (    0.56 ms per token,  1777.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2506.99 ms /   480 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2932.42 ms /    75 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5547.19 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.48 ms /   256 runs   (    0.58 ms per token,  1735.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.57 ms /   446 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
            "llama_print_timings:        eval time =    9962.01 ms /   255 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12699.44 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     163.45 ms /   256 runs   (    0.64 ms per token,  1566.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1645.50 ms /   320 tokens (    5.14 ms per token,   194.47 tokens per second)\n",
            "llama_print_timings:        eval time =    9929.99 ms /   256 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =   12010.15 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.64 ms /    64 runs   (    0.56 ms per token,  1795.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2068.25 ms /   398 tokens (    5.20 ms per token,   192.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2441.94 ms /    63 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    4599.54 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.60 ms /     6 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3653.58 ms /   680 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
            "llama_print_timings:        eval time =     199.45 ms /     5 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    3873.48 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.94 ms /   104 runs   (    0.56 ms per token,  1794.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1724.71 ms /   331 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3987.40 ms /   103 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    5853.45 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.63 ms /    70 runs   (    0.57 ms per token,  1766.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1268.82 ms /   245 tokens (    5.18 ms per token,   193.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2644.82 ms /    69 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    4008.66 ms /   314 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.79 ms /     6 runs   (    0.46 ms per token,  2153.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5403.15 ms /   981 tokens (    5.51 ms per token,   181.56 tokens per second)\n",
            "llama_print_timings:        eval time =     202.06 ms /     5 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    5627.24 ms /   986 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.41 ms /    64 runs   (    0.52 ms per token,  1915.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4203.73 ms /   784 tokens (    5.36 ms per token,   186.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2546.48 ms /    64 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    6841.08 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.10 ms /    81 runs   (    0.56 ms per token,  1796.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5448.63 ms /   986 tokens (    5.53 ms per token,   180.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3235.67 ms /    80 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8806.10 ms /  1066 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.30 ms /    65 runs   (    0.73 ms per token,  1374.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5125.02 ms /   944 tokens (    5.43 ms per token,   184.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2600.78 ms /    64 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    7853.57 ms /  1008 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.54 ms /    75 runs   (    0.55 ms per token,  1805.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4764.91 ms /   879 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2970.44 ms /    74 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7852.52 ms /   953 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.66 ms /    70 runs   (    0.62 ms per token,  1603.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4626.40 ms /   852 tokens (    5.43 ms per token,   184.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2779.22 ms /    69 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    7525.60 ms /   921 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.85 ms /   256 runs   (    0.60 ms per token,  1674.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2546.69 ms /   488 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
            "llama_print_timings:        eval time =   10077.29 ms /   256 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   13051.26 ms /   744 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.74 ms /    64 runs   (    0.53 ms per token,  1896.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4110.67 ms /   768 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2535.01 ms /    64 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    6735.72 ms /   832 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.12 ms /    96 runs   (    0.55 ms per token,  1807.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5829.30 ms /  1055 tokens (    5.53 ms per token,   180.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3867.06 ms /    95 runs   (   40.71 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    9841.46 ms /  1150 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.61 ms /    77 runs   (    0.67 ms per token,  1492.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5268.02 ms /   968 tokens (    5.44 ms per token,   183.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3138.59 ms /    77 runs   (   40.76 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    8550.01 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.83 ms /    79 runs   (    0.55 ms per token,  1802.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4807.02 ms /   882 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3129.82 ms /    78 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    8053.54 ms /   960 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.71 ms /    78 runs   (    0.61 ms per token,  1634.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4544.49 ms /   837 tokens (    5.43 ms per token,   184.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3094.74 ms /    77 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7772.25 ms /   914 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.45 ms /    68 runs   (    0.55 ms per token,  1816.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3210.88 ms /   605 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2635.84 ms /    67 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5942.75 ms /   672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.07 ms /    82 runs   (    0.65 ms per token,  1545.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3334.34 ms /   618 tokens (    5.40 ms per token,   185.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3220.92 ms /    81 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6694.36 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.72 ms /    14 runs   (    0.55 ms per token,  1813.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1606.09 ms /   312 tokens (    5.15 ms per token,   194.26 tokens per second)\n",
            "llama_print_timings:        eval time =     499.48 ms /    13 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
            "llama_print_timings:       total time =    2127.44 ms /   325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.27 ms /    65 runs   (    0.56 ms per token,  1792.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.93 ms /   466 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2501.03 ms /    64 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5051.33 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.87 ms /   256 runs   (    0.59 ms per token,  1685.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     214.06 ms /    40 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.52 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   10636.15 ms /   295 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.29 ms /    73 runs   (    0.54 ms per token,  1857.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2814.08 ms /   534 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2819.18 ms /    72 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5740.14 ms /   606 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.78 ms /    92 runs   (    0.55 ms per token,  1811.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4882.81 ms /   891 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3657.56 ms /    91 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    8679.75 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.26 ms /    92 runs   (    0.70 ms per token,  1431.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3431.85 ms /   648 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3619.65 ms /    91 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    7217.35 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.14 ms /    14 runs   (    0.58 ms per token,  1718.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1304.35 ms /   254 tokens (    5.14 ms per token,   194.73 tokens per second)\n",
            "llama_print_timings:        eval time =     497.66 ms /    13 runs   (   38.28 ms per token,    26.12 tokens per second)\n",
            "llama_print_timings:       total time =    1823.44 ms /   267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     160.50 ms /   256 runs   (    0.63 ms per token,  1595.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1770.92 ms /   340 tokens (    5.21 ms per token,   191.99 tokens per second)\n",
            "llama_print_timings:        eval time =    9947.41 ms /   255 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12153.21 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1780.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.96 ms /   324 tokens (    5.20 ms per token,   192.18 tokens per second)\n",
            "llama_print_timings:        eval time =     234.81 ms /     6 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    1933.94 ms /   330 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.50 ms /   136 runs   (    0.60 ms per token,  1668.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3702.64 ms /   696 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
            "llama_print_timings:        eval time =    5355.41 ms /   135 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    9279.84 ms /   831 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.49 ms /    79 runs   (    0.56 ms per token,  1775.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3669.90 ms /   683 tokens (    5.37 ms per token,   186.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3076.46 ms /    78 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6860.96 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.11 ms /    76 runs   (    0.65 ms per token,  1547.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3059.70 ms /   576 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2966.74 ms /    75 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6151.71 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     7 runs   (    0.60 ms per token,  1674.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2784.13 ms /   525 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =     234.97 ms /     6 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3037.18 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2500.59 ms /   476 tokens (    5.25 ms per token,   190.36 tokens per second)\n",
            "llama_print_timings:        eval time =     231.10 ms /     6 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
            "llama_print_timings:       total time =    2747.57 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1835.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2679.25 ms /   506 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =     236.87 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2932.76 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.22 ms /    68 runs   (    0.62 ms per token,  1610.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4725.46 ms /   870 tokens (    5.43 ms per token,   184.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2702.14 ms /    67 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    7542.71 ms /   937 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.25 ms /    72 runs   (    0.55 ms per token,  1834.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5747.53 ms /  1047 tokens (    5.49 ms per token,   182.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2884.61 ms /    71 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    8743.66 ms /  1118 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.91 ms /   122 runs   (    0.56 ms per token,  1770.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2977.52 ms /   555 tokens (    5.36 ms per token,   186.40 tokens per second)\n",
            "llama_print_timings:        eval time =    4741.65 ms /   121 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    7898.12 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.13 ms /   256 runs   (    0.61 ms per token,  1650.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2941.37 ms /   558 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =   10054.86 ms /   255 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13416.01 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.55 ms /    75 runs   (    0.74 ms per token,  1350.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4517.91 ms /   836 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2976.52 ms /    74 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7632.43 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.75 ms /    68 runs   (    0.56 ms per token,  1801.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2216.53 ms /   423 tokens (    5.24 ms per token,   190.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2616.55 ms /    67 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    4927.61 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.97 ms /    82 runs   (    0.59 ms per token,  1709.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3389.87 ms /   640 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3227.25 ms /    82 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6740.15 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.60 ms /   118 runs   (    0.54 ms per token,  1855.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3250.54 ms /   605 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4583.94 ms /   117 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    8004.17 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.57 ms /   106 runs   (    0.65 ms per token,  1545.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5557.27 ms /  1015 tokens (    5.48 ms per token,   182.64 tokens per second)\n",
            "llama_print_timings:        eval time =    4283.60 ms /   105 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =   10026.00 ms /  1120 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.06 ms /     6 runs   (    0.51 ms per token,  1963.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5694.71 ms /  1040 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
            "llama_print_timings:        eval time =     244.91 ms /     6 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    5960.87 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.68 ms /    87 runs   (    0.67 ms per token,  1482.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2952.68 ms /   556 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3389.76 ms /    86 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6492.47 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.18 ms /    99 runs   (    0.54 ms per token,  1861.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3699.89 ms /   694 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3866.86 ms /    98 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7705.44 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     103.06 ms /   183 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6018.35 ms /  1088 tokens (    5.53 ms per token,   180.78 tokens per second)\n",
            "llama_print_timings:        eval time =    7447.90 ms /   182 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =   13747.44 ms /  1270 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.71 ms /    91 runs   (    0.58 ms per token,  1726.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3733.94 ms /   693 tokens (    5.39 ms per token,   185.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3558.04 ms /    90 runs   (   39.53 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    7427.75 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.98 ms /    91 runs   (    0.56 ms per token,  1785.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2968.37 ms /   551 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3543.51 ms /    90 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6638.80 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1887.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5636.23 ms /  1020 tokens (    5.53 ms per token,   180.97 tokens per second)\n",
            "llama_print_timings:        eval time =     201.48 ms /     5 runs   (   40.30 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    5864.11 ms /  1025 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     100.31 ms /   162 runs   (    0.62 ms per token,  1614.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5734.28 ms /  1042 tokens (    5.50 ms per token,   181.71 tokens per second)\n",
            "llama_print_timings:        eval time =    6592.85 ms /   161 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =   12608.82 ms /  1203 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.98 ms /   114 runs   (    0.56 ms per token,  1781.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2113.79 ms /   403 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4402.64 ms /   113 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    6672.68 ms /   516 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.88 ms /    49 runs   (    0.67 ms per token,  1490.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3721.70 ms /   694 tokens (    5.36 ms per token,   186.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1909.97 ms /    48 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    5721.82 ms /   742 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.32 ms /    71 runs   (    0.53 ms per token,  1902.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5263.58 ms /   966 tokens (    5.45 ms per token,   183.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2825.39 ms /    70 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    8193.46 ms /  1036 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.28 ms /    79 runs   (    0.52 ms per token,  1913.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5396.49 ms /   979 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3152.13 ms /    78 runs   (   40.41 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    8668.55 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.97 ms /    76 runs   (    0.59 ms per token,  1689.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3701.86 ms /   695 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2978.67 ms /    75 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    6801.36 ms /   770 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.05 ms /    53 runs   (    0.55 ms per token,  1824.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5151.35 ms /   940 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2092.05 ms /    52 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7332.55 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.79 ms /    87 runs   (    0.56 ms per token,  1783.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     137.72 ms /    24 tokens (    5.74 ms per token,   174.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3504.01 ms /    87 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    3760.92 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.09 ms /   123 runs   (    0.55 ms per token,  1833.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5161.82 ms /   942 tokens (    5.48 ms per token,   182.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4923.69 ms /   122 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =   10267.92 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.16 ms /    59 runs   (    0.68 ms per token,  1469.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5130.88 ms /   939 tokens (    5.46 ms per token,   183.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2361.48 ms /    58 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    7604.10 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.17 ms /    59 runs   (    0.55 ms per token,  1834.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5172.25 ms /   946 tokens (    5.47 ms per token,   182.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2337.93 ms /    58 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7601.73 ms /  1004 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.74 ms /    76 runs   (    0.80 ms per token,  1251.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2899.96 ms /   551 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2953.97 ms /    75 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6000.82 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1843.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.48 ms /   398 tokens (    5.21 ms per token,   192.04 tokens per second)\n",
            "llama_print_timings:        eval time =     229.83 ms /     6 runs   (   38.30 ms per token,    26.11 tokens per second)\n",
            "llama_print_timings:       total time =    2317.93 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.69 ms /   155 runs   (    0.57 ms per token,  1747.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.04 ms /   536 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =    6103.09 ms /   155 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    9147.87 ms /   691 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1839.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2438.76 ms /   460 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =     230.33 ms /     6 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2689.10 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.60 ms /    99 runs   (    0.55 ms per token,  1813.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.09 ms /   311 tokens (    5.15 ms per token,   194.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3782.81 ms /    98 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    5517.77 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.77 ms /    68 runs   (    0.64 ms per token,  1553.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1940.92 ms /   372 tokens (    5.22 ms per token,   191.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2608.07 ms /    67 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4657.11 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.10 ms /    73 runs   (    0.55 ms per token,  1820.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2186.63 ms /   414 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2803.50 ms /    72 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5095.82 ms /   486 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.73 ms /    63 runs   (    0.55 ms per token,  1814.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2504.09 ms /   478 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2420.84 ms /    62 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5016.55 ms /   540 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.80 ms /    12 runs   (    0.57 ms per token,  1765.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1678.99 ms /   320 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =     426.21 ms /    11 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2126.47 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     6 runs   (    0.67 ms per token,  1481.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2710.76 ms /   510 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =     196.83 ms /     5 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    2930.81 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.83 ms /   402 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     229.68 ms /     6 runs   (   38.28 ms per token,    26.12 tokens per second)\n",
            "llama_print_timings:       total time =    2360.61 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.89 ms /     7 runs   (    0.56 ms per token,  1799.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.51 ms /   458 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =     232.32 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2660.17 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.94 ms /     9 runs   (    0.55 ms per token,  1820.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1305.94 ms /   251 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =     306.87 ms /     8 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
            "llama_print_timings:       total time =    1628.41 ms /   259 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.32 ms /    82 runs   (    0.63 ms per token,  1597.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2715.49 ms /   514 tokens (    5.28 ms per token,   189.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3177.11 ms /    81 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6024.73 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.86 ms /    11 runs   (    0.71 ms per token,  1398.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.16 ms /    21 tokens (    6.10 ms per token,   163.86 tokens per second)\n",
            "llama_print_timings:        eval time =     391.23 ms /    10 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =     542.08 ms /    31 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.55 ms /    65 runs   (    0.55 ms per token,  1828.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4250.35 ms /   786 tokens (    5.41 ms per token,   184.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2542.04 ms /    64 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    6888.61 ms /   850 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.85 ms /    54 runs   (    0.68 ms per token,  1465.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4437.07 ms /   822 tokens (    5.40 ms per token,   185.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2143.51 ms /    53 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    6680.65 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.71 ms /    92 runs   (    0.55 ms per token,  1814.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2043.95 ms /   392 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3590.24 ms /    92 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5759.62 ms /   484 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.43 ms /   256 runs   (    0.59 ms per token,  1690.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2723.03 ms /   519 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10036.68 ms /   255 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   13190.93 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.19 ms /    64 runs   (    0.58 ms per token,  1720.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2503.12 ms /   477 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2459.47 ms /    63 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5055.72 ms /   540 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.00 ms /    57 runs   (    0.53 ms per token,  1899.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4289.22 ms /   792 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2221.28 ms /    56 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6596.89 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.14 ms /    73 runs   (    0.63 ms per token,  1582.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5314.16 ms /   976 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2967.12 ms /    73 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8409.40 ms /  1049 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.00 ms /   118 runs   (    0.58 ms per token,  1735.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2442.85 ms /   460 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =    4581.37 ms /   117 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    7196.61 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.68 ms /    88 runs   (    0.59 ms per token,  1702.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1771.65 ms /   334 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3411.32 ms /    87 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5313.40 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.66 ms /   256 runs   (    0.56 ms per token,  1794.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1837.60 ms /   352 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9972.26 ms /   256 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12192.06 ms /   608 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.57 ms /   150 runs   (    0.59 ms per token,  1693.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.86 ms /   486 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =    5834.71 ms /   149 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    8650.06 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.33 ms /    53 runs   (    0.55 ms per token,  1806.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.66 ms /   442 tokens (    5.27 ms per token,   189.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2022.84 ms /    52 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4427.64 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.43 ms /    90 runs   (    0.59 ms per token,  1684.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2833.59 ms /   536 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3489.36 ms /    89 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6461.41 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.90 ms /   256 runs   (    0.61 ms per token,  1652.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1980.18 ms /   378 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    9979.41 ms /   255 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12386.27 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.51 ms /    11 runs   (    0.59 ms per token,  1690.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.57 ms /   452 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =     385.72 ms /    10 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2776.24 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     123.12 ms /   206 runs   (    0.60 ms per token,  1673.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2938.68 ms /   555 tokens (    5.29 ms per token,   188.86 tokens per second)\n",
            "llama_print_timings:        eval time =    8083.68 ms /   205 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   11357.52 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.64 ms /   256 runs   (    0.58 ms per token,  1710.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2541.19 ms /   482 tokens (    5.27 ms per token,   189.68 tokens per second)\n",
            "llama_print_timings:        eval time =   10021.04 ms /   255 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12984.03 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     120.66 ms /   204 runs   (    0.59 ms per token,  1690.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1724.63 ms /   334 tokens (    5.16 ms per token,   193.66 tokens per second)\n",
            "llama_print_timings:        eval time =    7891.19 ms /   203 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    9932.35 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1818.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1708.25 ms /   325 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
            "llama_print_timings:        eval time =     235.55 ms /     6 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    1966.03 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.48 ms /    88 runs   (    0.56 ms per token,  1778.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2458.41 ms /   467 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3402.55 ms /    87 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5983.06 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.16 ms /    81 runs   (    0.63 ms per token,  1583.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1677.06 ms /   319 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3119.72 ms /    80 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    4926.51 ms /   399 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.42 ms /    55 runs   (    0.53 ms per token,  1869.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5197.01 ms /   949 tokens (    5.48 ms per token,   182.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2173.15 ms /    54 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7455.11 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.53 ms /   114 runs   (    0.68 ms per token,  1470.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3566.88 ms /   671 tokens (    5.32 ms per token,   188.12 tokens per second)\n",
            "llama_print_timings:        eval time =    4500.82 ms /   113 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    8272.70 ms /   784 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.45 ms /    66 runs   (    0.51 ms per token,  1973.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1898.90 ms /   366 tokens (    5.19 ms per token,   192.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2520.51 ms /    65 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    4505.17 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.24 ms /   129 runs   (    0.60 ms per token,  1670.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2652.41 ms /   499 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =    5045.64 ms /   128 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7904.07 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.18 ms /    82 runs   (    0.54 ms per token,  1855.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2912.51 ms /   552 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3213.54 ms /    82 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6238.09 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.43 ms /   120 runs   (    0.64 ms per token,  1570.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.24 ms /   536 tokens (    5.24 ms per token,   190.73 tokens per second)\n",
            "llama_print_timings:        eval time =    4691.35 ms /   119 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    7707.35 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.91 ms /   113 runs   (    0.52 ms per token,  1918.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3307.85 ms /   622 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
            "llama_print_timings:        eval time =    4403.58 ms /   112 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7869.09 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.66 ms /    84 runs   (    0.58 ms per token,  1726.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5203.48 ms /   949 tokens (    5.48 ms per token,   182.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3350.26 ms /    83 runs   (   40.36 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8686.31 ms /  1032 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.69 ms /    70 runs   (    0.57 ms per token,  1763.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3338.07 ms /   626 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2715.31 ms /    69 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6153.49 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.87 ms /    83 runs   (    0.64 ms per token,  1569.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2608.09 ms /   491 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3219.39 ms /    82 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5961.18 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.82 ms /   256 runs   (    0.56 ms per token,  1792.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5363.02 ms /   984 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =   10445.58 ms /   256 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =   16229.24 ms /  1240 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.64 ms /    67 runs   (    0.55 ms per token,  1828.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     180.05 ms /    28 tokens (    6.43 ms per token,   155.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2669.56 ms /    66 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    2939.17 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.22 ms /    90 runs   (    0.58 ms per token,  1723.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5196.99 ms /   946 tokens (    5.49 ms per token,   182.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3592.73 ms /    89 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8930.34 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.50 ms /   133 runs   (    0.61 ms per token,  1631.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5406.36 ms /   986 tokens (    5.48 ms per token,   182.38 tokens per second)\n",
            "llama_print_timings:        eval time =    5383.38 ms /   132 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =   11022.82 ms /  1118 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.11 ms /   117 runs   (    0.56 ms per token,  1797.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5169.39 ms /   952 tokens (    5.43 ms per token,   184.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4726.96 ms /   117 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   10076.50 ms /  1069 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.43 ms /     6 runs   (    0.57 ms per token,  1750.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5488.29 ms /   995 tokens (    5.52 ms per token,   181.30 tokens per second)\n",
            "llama_print_timings:        eval time =     203.34 ms /     5 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    5715.43 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.89 ms /    89 runs   (    0.57 ms per token,  1748.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4793.05 ms /   883 tokens (    5.43 ms per token,   184.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3544.46 ms /    88 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    8480.40 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.64 ms /    83 runs   (    0.53 ms per token,  1901.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4406.23 ms /   811 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3264.51 ms /    82 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7790.52 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.15 ms /    82 runs   (    0.62 ms per token,  1603.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4476.64 ms /   828 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3263.53 ms /    81 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    7887.47 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.00 ms /   128 runs   (    0.55 ms per token,  1828.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5170.36 ms /   951 tokens (    5.44 ms per token,   183.93 tokens per second)\n",
            "llama_print_timings:        eval time =    5140.31 ms /   127 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =   10506.62 ms /  1078 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.84 ms /   256 runs   (    0.53 ms per token,  1884.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2534.42 ms /   479 tokens (    5.29 ms per token,   189.00 tokens per second)\n",
            "llama_print_timings:        eval time =    9979.49 ms /   255 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12903.55 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.06 ms /   143 runs   (    0.55 ms per token,  1831.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4878.32 ms /   895 tokens (    5.45 ms per token,   183.46 tokens per second)\n",
            "llama_print_timings:        eval time =    5713.24 ms /   142 runs   (   40.23 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =   10801.84 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.52 ms /    73 runs   (    0.62 ms per token,  1603.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4497.34 ms /   830 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2884.90 ms /    72 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    7503.66 ms /   902 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      85.17 ms /   146 runs   (    0.58 ms per token,  1714.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3029.06 ms /   570 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =    5701.10 ms /   145 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    8947.19 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.78 ms /    78 runs   (    0.56 ms per token,  1781.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4737.91 ms /   871 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3082.12 ms /    77 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7941.93 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.80 ms /    76 runs   (    0.69 ms per token,  1439.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4469.09 ms /   827 tokens (    5.40 ms per token,   185.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3025.80 ms /    75 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    7636.95 ms /   902 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.67 ms /    75 runs   (    0.56 ms per token,  1799.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     177.65 ms /    28 tokens (    6.34 ms per token,   157.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2959.93 ms /    74 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    3240.65 ms /   102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.57 ms /    65 runs   (    0.65 ms per token,  1526.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5122.05 ms /   942 tokens (    5.44 ms per token,   183.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2584.08 ms /    64 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    7817.21 ms /  1006 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.62 ms /    64 runs   (    0.56 ms per token,  1797.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3291.69 ms /   612 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2481.85 ms /    63 runs   (   39.39 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    5866.60 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.82 ms /    92 runs   (    0.61 ms per token,  1648.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4470.28 ms /   827 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3654.25 ms /    91 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8277.34 ms /   918 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.85 ms /    71 runs   (    0.58 ms per token,  1738.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3239.87 ms /   608 tokens (    5.33 ms per token,   187.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2750.94 ms /    70 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6096.42 ms /   678 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1878.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.79 ms /   459 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =     234.46 ms /     6 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2665.21 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     119.24 ms /   189 runs   (    0.63 ms per token,  1585.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2680.83 ms /   512 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
            "llama_print_timings:        eval time =    7413.36 ms /   189 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   10411.37 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.28 ms /    97 runs   (    0.55 ms per token,  1820.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1898.87 ms /   368 tokens (    5.16 ms per token,   193.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3725.09 ms /    96 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    5754.44 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.82 ms /   256 runs   (    0.57 ms per token,  1755.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2879.43 ms /   542 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =   10020.71 ms /   255 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   13299.75 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.56 ms /   106 runs   (    0.58 ms per token,  1721.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3327.90 ms /   622 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
            "llama_print_timings:        eval time =    4119.36 ms /   105 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7607.27 ms /   727 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.22 ms /    74 runs   (    0.56 ms per token,  1795.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2765.42 ms /   526 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2853.75 ms /    73 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5719.78 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.92 ms /   107 runs   (    0.55 ms per token,  1815.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3282.98 ms /   615 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4170.01 ms /   106 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7605.92 ms /   721 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.88 ms /    86 runs   (    0.53 ms per token,  1874.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2718.86 ms /   519 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3320.51 ms /    85 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    6156.36 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.46 ms /    11 runs   (    0.68 ms per token,  1473.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3027.09 ms /   568 tokens (    5.33 ms per token,   187.64 tokens per second)\n",
            "llama_print_timings:        eval time =     435.21 ms /    11 runs   (   39.56 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    3490.10 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      99.26 ms /   171 runs   (    0.58 ms per token,  1722.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3517.79 ms /   660 tokens (    5.33 ms per token,   187.62 tokens per second)\n",
            "llama_print_timings:        eval time =    6717.30 ms /   170 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   10487.13 ms /   830 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     6 runs   (    0.70 ms per token,  1429.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2404.22 ms /   454 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =     196.14 ms /     5 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    2619.37 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.26 ms /     9 runs   (    0.58 ms per token,  1710.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     771.40 ms /   150 tokens (    5.14 ms per token,   194.45 tokens per second)\n",
            "llama_print_timings:        eval time =     304.09 ms /     8 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
            "llama_print_timings:       total time =    1090.10 ms /   158 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.16 ms /    64 runs   (    0.55 ms per token,  1820.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2897.57 ms /   549 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2475.48 ms /    63 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5459.70 ms /   612 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.92 ms /    65 runs   (    0.71 ms per token,  1415.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3605.08 ms /   675 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2549.17 ms /    64 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    6270.15 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.13 ms /    90 runs   (    0.57 ms per token,  1760.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     133.65 ms /    24 tokens (    5.57 ms per token,   179.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3512.02 ms /    89 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3770.85 ms /   113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.31 ms /   256 runs   (    0.59 ms per token,  1680.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.43 ms /   479 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =   10014.61 ms /   255 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   12935.96 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.50 ms /   135 runs   (    0.57 ms per token,  1764.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3249.05 ms /   611 tokens (    5.32 ms per token,   188.05 tokens per second)\n",
            "llama_print_timings:        eval time =    5285.45 ms /   134 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    8733.03 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.53 ms /   256 runs   (    0.54 ms per token,  1848.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2487.23 ms /   469 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9984.27 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12851.30 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.08 ms /    79 runs   (    0.52 ms per token,  1923.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4692.37 ms /   858 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3123.60 ms /    78 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    7926.62 ms /   936 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.58 ms /    52 runs   (    0.67 ms per token,  1503.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4796.08 ms /   886 tokens (    5.41 ms per token,   184.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2063.03 ms /    51 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    6953.36 ms /   937 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.72 ms /    92 runs   (    0.56 ms per token,  1778.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2999.64 ms /   565 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3565.05 ms /    91 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6690.84 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.84 ms /    64 runs   (    0.61 ms per token,  1647.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3294.74 ms /   619 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2481.34 ms /    63 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5874.57 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.66 ms /   101 runs   (    0.57 ms per token,  1751.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3278.16 ms /   610 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3919.58 ms /   100 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7341.83 ms /   710 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1815.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3297.23 ms /   619 tokens (    5.33 ms per token,   187.73 tokens per second)\n",
            "llama_print_timings:        eval time =     194.84 ms /     5 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3508.25 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     118.71 ms /   207 runs   (    0.57 ms per token,  1743.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2957.55 ms /   556 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =    8087.42 ms /   206 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   11349.88 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.96 ms /   256 runs   (    0.57 ms per token,  1741.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2715.87 ms /   516 tokens (    5.26 ms per token,   189.99 tokens per second)\n",
            "llama_print_timings:        eval time =    9999.65 ms /   255 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13117.47 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.40 ms /    73 runs   (    0.66 ms per token,  1508.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2685.40 ms /   512 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2821.31 ms /    72 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5629.52 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2344.22 ms /   448 tokens (    5.23 ms per token,   191.11 tokens per second)\n",
            "llama_print_timings:        eval time =     271.72 ms /     7 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2633.01 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.99 ms /   344 tokens (    5.15 ms per token,   194.35 tokens per second)\n",
            "llama_print_timings:        eval time =     271.49 ms /     7 runs   (   38.78 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    2055.36 ms /   351 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.46 ms /    79 runs   (    0.52 ms per token,  1905.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3298.95 ms /   623 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3071.56 ms /    78 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6476.87 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.40 ms /    67 runs   (    0.54 ms per token,  1840.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5448.97 ms /   992 tokens (    5.49 ms per token,   182.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2668.94 ms /    66 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8221.81 ms /  1058 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.62 ms /    12 runs   (    0.55 ms per token,  1812.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2194.98 ms /   421 tokens (    5.21 ms per token,   191.80 tokens per second)\n",
            "llama_print_timings:        eval time =     423.10 ms /    11 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2637.75 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.19 ms /    69 runs   (    0.60 ms per token,  1675.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     846.29 ms /   165 tokens (    5.13 ms per token,   194.97 tokens per second)\n",
            "llama_print_timings:        eval time =    2607.78 ms /    68 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    3560.19 ms /   233 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.72 ms /     7 runs   (    0.53 ms per token,  1880.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2787.37 ms /   524 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =     238.38 ms /     6 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    3041.84 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.63 ms /    77 runs   (    0.51 ms per token,  1942.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4330.72 ms /   803 tokens (    5.39 ms per token,   185.42 tokens per second)\n",
            "llama_print_timings:        eval time =    3018.47 ms /    76 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7450.47 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.32 ms /    65 runs   (    0.57 ms per token,  1741.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4491.49 ms /   829 tokens (    5.42 ms per token,   184.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2552.74 ms /    64 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7141.22 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2412.42 ms /   461 tokens (    5.23 ms per token,   191.09 tokens per second)\n",
            "llama_print_timings:        eval time =     232.46 ms /     6 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2659.15 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.29 ms /   138 runs   (    0.60 ms per token,  1676.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.19 ms /   432 tokens (    5.20 ms per token,   192.41 tokens per second)\n",
            "llama_print_timings:        eval time =    5346.24 ms /   137 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    7797.93 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.28 ms /    11 runs   (    0.57 ms per token,  1752.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1320.64 ms /   248 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
            "llama_print_timings:        eval time =     389.66 ms /    10 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    1734.90 ms /   258 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.30 ms /   256 runs   (    0.56 ms per token,  1799.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1310.57 ms /   248 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =   10004.74 ms /   255 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   11690.37 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.89 ms /   125 runs   (    0.50 ms per token,  2019.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4994.97 ms /   917 tokens (    5.45 ms per token,   183.58 tokens per second)\n",
            "llama_print_timings:        eval time =    4998.55 ms /   124 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =   10152.78 ms /  1041 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.58 ms /    66 runs   (    0.52 ms per token,  1908.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6058.51 ms /  1094 tokens (    5.54 ms per token,   180.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2652.16 ms /    65 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    8805.97 ms /  1159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.51 ms /   145 runs   (    0.58 ms per token,  1736.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4984.81 ms /   920 tokens (    5.42 ms per token,   184.56 tokens per second)\n",
            "llama_print_timings:        eval time =    5885.62 ms /   145 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =   11089.60 ms /  1065 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.08 ms /   110 runs   (    0.61 ms per token,  1639.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6061.81 ms /  1098 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4477.28 ms /   109 runs   (   41.08 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   10718.77 ms /  1207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.47 ms /   103 runs   (    0.56 ms per token,  1792.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4928.71 ms /   911 tokens (    5.41 ms per token,   184.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4098.67 ms /   102 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    9168.35 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.16 ms /    88 runs   (    0.54 ms per token,  1865.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7208.11 ms /  1286 tokens (    5.61 ms per token,   178.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3595.03 ms /    87 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
            "llama_print_timings:       total time =   10926.70 ms /  1373 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.81 ms /   119 runs   (    0.61 ms per token,  1634.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3647.43 ms /   683 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =    4672.50 ms /   118 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    8494.60 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.82 ms /   125 runs   (    0.60 ms per token,  1670.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4967.76 ms /   914 tokens (    5.44 ms per token,   183.99 tokens per second)\n",
            "llama_print_timings:        eval time =    5009.10 ms /   124 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   10170.19 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.99 ms /    75 runs   (    0.60 ms per token,  1667.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     140.50 ms /    23 tokens (    6.11 ms per token,   163.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2988.67 ms /    74 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    3232.65 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     6 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7180.63 ms /  1287 tokens (    5.58 ms per token,   179.23 tokens per second)\n",
            "llama_print_timings:        eval time =     206.79 ms /     5 runs   (   41.36 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =    7409.62 ms /  1292 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.15 ms /     6 runs   (    0.53 ms per token,  1902.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     143.66 ms /    24 tokens (    5.99 ms per token,   167.07 tokens per second)\n",
            "llama_print_timings:        eval time =     205.82 ms /     5 runs   (   41.16 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =     358.50 ms /    29 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.95 ms /   160 runs   (    0.50 ms per token,  2001.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5028.43 ms /   920 tokens (    5.47 ms per token,   182.96 tokens per second)\n",
            "llama_print_timings:        eval time =    6451.44 ms /   160 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =   11687.66 ms /  1080 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.67 ms /   128 runs   (    0.66 ms per token,  1511.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =      90.47 ms /    16 tokens (    5.65 ms per token,   176.85 tokens per second)\n",
            "llama_print_timings:        eval time =    5186.08 ms /   128 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    5479.68 ms /   144 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.37 ms /   100 runs   (    0.62 ms per token,  1603.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7189.48 ms /  1288 tokens (    5.58 ms per token,   179.15 tokens per second)\n",
            "llama_print_timings:        eval time =    4160.79 ms /   100 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
            "llama_print_timings:       total time =   11511.54 ms /  1388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.37 ms /    91 runs   (    0.51 ms per token,  1962.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5466.72 ms /  1000 tokens (    5.47 ms per token,   182.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3646.47 ms /    90 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    9233.19 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.54 ms /   106 runs   (    0.54 ms per token,  1842.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6440.51 ms /  1156 tokens (    5.57 ms per token,   179.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4311.30 ms /   105 runs   (   41.06 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   10902.84 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.48 ms /   116 runs   (    0.55 ms per token,  1827.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     184.91 ms /    28 tokens (    6.60 ms per token,   151.43 tokens per second)\n",
            "llama_print_timings:        eval time =    4731.14 ms /   115 runs   (   41.14 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =    5071.64 ms /   143 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.56 ms /    58 runs   (    0.54 ms per token,  1837.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5436.99 ms /   988 tokens (    5.50 ms per token,   181.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2302.72 ms /    57 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    7821.58 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.07 ms /    67 runs   (    0.58 ms per token,  1714.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6525.68 ms /  1176 tokens (    5.55 ms per token,   180.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2723.40 ms /    66 runs   (   41.26 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =    9355.16 ms /  1242 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.82 ms /    76 runs   (    0.60 ms per token,  1658.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6407.74 ms /  1158 tokens (    5.53 ms per token,   180.72 tokens per second)\n",
            "llama_print_timings:        eval time =    3086.99 ms /    75 runs   (   41.16 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =    9612.55 ms /  1233 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.04 ms /    73 runs   (    0.53 ms per token,  1869.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7259.54 ms /  1293 tokens (    5.61 ms per token,   178.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2983.37 ms /    72 runs   (   41.44 ms per token,    24.13 tokens per second)\n",
            "llama_print_timings:       total time =   10346.86 ms /  1365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.08 ms /    86 runs   (    0.54 ms per token,  1866.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5480.12 ms /   994 tokens (    5.51 ms per token,   181.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3443.85 ms /    85 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    9039.89 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.46 ms /    98 runs   (    0.64 ms per token,  1568.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6357.43 ms /  1150 tokens (    5.53 ms per token,   180.89 tokens per second)\n",
            "llama_print_timings:        eval time =    4014.22 ms /    97 runs   (   41.38 ms per token,    24.16 tokens per second)\n",
            "llama_print_timings:       total time =   10540.36 ms /  1247 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.14 ms /    59 runs   (    0.51 ms per token,  1957.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5450.25 ms /   999 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2345.08 ms /    58 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    7875.07 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.59 ms /    62 runs   (    0.53 ms per token,  1902.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6010.08 ms /  1088 tokens (    5.52 ms per token,   181.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2483.53 ms /    61 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8586.51 ms /  1149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.86 ms /    85 runs   (    0.55 ms per token,  1813.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.20 ms /   455 tokens (    5.21 ms per token,   191.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3280.73 ms /    84 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5757.65 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.04 ms /    84 runs   (    0.61 ms per token,  1645.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2832.32 ms /   533 tokens (    5.31 ms per token,   188.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3261.88 ms /    83 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6216.20 ms /   616 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.57 ms /     9 runs   (    0.62 ms per token,  1616.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     170.22 ms /    27 tokens (    6.30 ms per token,   158.62 tokens per second)\n",
            "llama_print_timings:        eval time =     310.51 ms /     8 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =     498.38 ms /    35 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.74 ms /    67 runs   (    0.53 ms per token,  1874.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.10 ms /   456 tokens (    5.20 ms per token,   192.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2573.82 ms /    66 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    5029.87 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.36 ms /    88 runs   (    0.62 ms per token,  1618.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3904.71 ms /   723 tokens (    5.40 ms per token,   185.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3441.59 ms /    87 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    7475.96 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.40 ms /    71 runs   (    0.53 ms per token,  1898.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3690.03 ms /   692 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2762.78 ms /    70 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6547.45 ms /   762 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.25 ms /    84 runs   (    0.55 ms per token,  1816.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4318.21 ms /   797 tokens (    5.42 ms per token,   184.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3296.87 ms /    83 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7729.48 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1791.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2667.84 ms /   507 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     236.48 ms /     6 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    2919.30 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.19 ms /    96 runs   (    0.62 ms per token,  1621.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.81 ms /   450 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3705.31 ms /    95 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    6219.26 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.15 ms /    69 runs   (    0.52 ms per token,  1908.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3750.77 ms /   704 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2680.44 ms /    68 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    6521.38 ms /   772 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     6 runs   (    0.53 ms per token,  1892.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1980.11 ms /   384 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
            "llama_print_timings:        eval time =     193.72 ms /     5 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2185.09 ms /   389 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.48 ms /     6 runs   (    0.75 ms per token,  1338.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2322.13 ms /   443 tokens (    5.24 ms per token,   190.77 tokens per second)\n",
            "llama_print_timings:        eval time =     195.83 ms /     5 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    2532.97 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.29 ms /    79 runs   (    0.60 ms per token,  1670.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2044.57 ms /   386 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3044.49 ms /    78 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5204.44 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.20 ms /    99 runs   (    0.68 ms per token,  1473.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7132.47 ms /  1279 tokens (    5.58 ms per token,   179.32 tokens per second)\n",
            "llama_print_timings:        eval time =    4083.28 ms /    98 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
            "llama_print_timings:       total time =   11393.30 ms /  1377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.20 ms /    50 runs   (    0.54 ms per token,  1837.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3599.88 ms /   674 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1935.18 ms /    49 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5602.88 ms /   723 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.55 ms /    66 runs   (    0.58 ms per token,  1712.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6364.88 ms /  1146 tokens (    5.55 ms per token,   180.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2669.89 ms /    65 runs   (   41.08 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    9138.03 ms /  1211 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.57 ms /    96 runs   (    0.55 ms per token,  1826.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4922.45 ms /   906 tokens (    5.43 ms per token,   184.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3822.51 ms /    95 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    8881.25 ms /  1001 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.16 ms /    88 runs   (    0.54 ms per token,  1866.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7162.95 ms /  1280 tokens (    5.60 ms per token,   178.70 tokens per second)\n",
            "llama_print_timings:        eval time =    3638.92 ms /    88 runs   (   41.35 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =   10924.86 ms /  1368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.83 ms /    66 runs   (    0.62 ms per token,  1616.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3850.01 ms /   714 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2585.11 ms /    65 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    6537.93 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.36 ms /    97 runs   (    0.54 ms per token,  1852.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2322.42 ms /   448 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3748.32 ms /    96 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    6192.69 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.73 ms /    65 runs   (    0.52 ms per token,  1927.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6380.82 ms /  1152 tokens (    5.54 ms per token,   180.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2658.81 ms /    65 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    9131.62 ms /  1217 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.39 ms /    94 runs   (    0.54 ms per token,  1865.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1767.88 ms /   340 tokens (    5.20 ms per token,   192.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3591.79 ms /    93 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    5476.07 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.42 ms /     6 runs   (    0.74 ms per token,  1356.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2822.99 ms /   535 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =     196.41 ms /     5 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    3036.24 ms /   540 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.75 ms /    57 runs   (    0.54 ms per token,  1853.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4209.04 ms /   782 tokens (    5.38 ms per token,   185.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2220.93 ms /    56 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6508.44 ms /   838 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.71 ms /    72 runs   (    0.61 ms per token,  1647.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2321.62 ms /   443 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2762.17 ms /    71 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    5180.96 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.27 ms /    66 runs   (    0.78 ms per token,  1287.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =      85.05 ms /    16 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2587.99 ms /    66 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2784.59 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.55 ms /    72 runs   (    0.56 ms per token,  1775.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1352.66 ms /   259 tokens (    5.22 ms per token,   191.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2721.91 ms /    71 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    4167.68 ms /   330 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.24 ms /    73 runs   (    0.61 ms per token,  1650.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3966.42 ms /   744 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2852.16 ms /    72 runs   (   39.61 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    6923.00 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.37 ms /    72 runs   (    0.49 ms per token,  2035.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4223.46 ms /   784 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2852.52 ms /    72 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    7170.47 ms /   856 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.28 ms /    59 runs   (    0.73 ms per token,  1363.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6016.70 ms /  1095 tokens (    5.49 ms per token,   181.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2381.58 ms /    58 runs   (   41.06 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    8507.49 ms /  1153 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.66 ms /   141 runs   (    0.59 ms per token,  1685.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7226.54 ms /  1291 tokens (    5.60 ms per token,   178.65 tokens per second)\n",
            "llama_print_timings:        eval time =    5828.64 ms /   140 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
            "llama_print_timings:       total time =   13287.14 ms /  1431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.81 ms /   119 runs   (    0.57 ms per token,  1754.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2294.21 ms /   437 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =    4607.03 ms /   118 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    7058.45 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.30 ms /    97 runs   (    0.74 ms per token,  1360.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2714.13 ms /   517 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3772.32 ms /    96 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6654.05 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.21 ms /    91 runs   (    0.53 ms per token,  1887.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3790.62 ms /   712 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3550.36 ms /    90 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    7460.49 ms /   802 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1492.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.71 ms /   504 tokens (    5.22 ms per token,   191.51 tokens per second)\n",
            "llama_print_timings:        eval time =     273.81 ms /     7 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2922.47 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.52 ms /    69 runs   (    0.53 ms per token,  1889.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5487.24 ms /  1000 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2791.03 ms /    69 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8375.05 ms /  1069 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     103.31 ms /   172 runs   (    0.60 ms per token,  1664.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5447.90 ms /   994 tokens (    5.48 ms per token,   182.46 tokens per second)\n",
            "llama_print_timings:        eval time =    6970.37 ms /   171 runs   (   40.76 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =   12684.70 ms /  1165 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.82 ms /    66 runs   (    0.57 ms per token,  1745.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.59 ms /   456 tokens (    5.20 ms per token,   192.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2536.03 ms /    65 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4992.68 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.20 ms /     6 runs   (    0.87 ms per token,  1154.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2835.83 ms /   534 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =     198.46 ms /     5 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3052.45 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.77 ms /   111 runs   (    0.57 ms per token,  1740.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2428.02 ms /   464 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4348.48 ms /   111 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6925.02 ms /   575 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.80 ms /   256 runs   (    0.57 ms per token,  1767.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3650.03 ms /   688 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =   10193.91 ms /   256 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =   14229.40 ms /   944 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Amcor plc_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.91 ms /    68 runs   (    0.62 ms per token,  1622.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4027.60 ms /   750 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2675.10 ms /    67 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    6813.29 ms /   817 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.83 ms /    70 runs   (    0.51 ms per token,  1953.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3876.37 ms /   724 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2726.67 ms /    69 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6692.62 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.80 ms /    78 runs   (    0.74 ms per token,  1349.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2989.83 ms /   562 tokens (    5.32 ms per token,   187.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3038.91 ms /    77 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6161.79 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.99 ms /    78 runs   (    0.55 ms per token,  1814.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3061.99 ms /    78 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3155.34 ms /    78 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    71 runs   (    0.51 ms per token,  1951.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3744.55 ms /   704 tokens (    5.32 ms per token,   188.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2760.72 ms /    70 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6596.44 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.95 ms /    90 runs   (    0.53 ms per token,  1877.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3876.10 ms /   718 tokens (    5.40 ms per token,   185.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3514.81 ms /    89 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7508.91 ms /   807 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.48 ms /   256 runs   (    0.61 ms per token,  1646.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2418.44 ms /   463 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =   10001.15 ms /   255 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12816.28 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     106.45 ms /   176 runs   (    0.60 ms per token,  1653.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4288.37 ms /   797 tokens (    5.38 ms per token,   185.85 tokens per second)\n",
            "llama_print_timings:        eval time =    7028.13 ms /   175 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =   11591.93 ms /   972 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.07 ms /    99 runs   (    0.54 ms per token,  1865.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3383.89 ms /   638 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3861.98 ms /    98 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    7374.51 ms /   736 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.90 ms /   256 runs   (    0.53 ms per token,  1883.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2875.71 ms /   543 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =   10019.86 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   13260.32 ms /   798 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.13 ms /   113 runs   (    0.52 ms per token,  1911.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3870.42 ms /   714 tokens (    5.42 ms per token,   184.48 tokens per second)\n",
            "llama_print_timings:        eval time =    4434.29 ms /   112 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    8459.27 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.53 ms /    74 runs   (    0.63 ms per token,  1590.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4059.10 ms /   754 tokens (    5.38 ms per token,   185.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2910.94 ms /    73 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7086.40 ms /   827 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.06 ms /   101 runs   (    0.54 ms per token,  1868.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4771.16 ms /   874 tokens (    5.46 ms per token,   183.18 tokens per second)\n",
            "llama_print_timings:        eval time =    4012.54 ms /   100 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    8928.85 ms /   974 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.03 ms /   101 runs   (    0.55 ms per token,  1802.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    4061.82 ms /   101 runs   (   40.22 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    4203.95 ms /   101 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.72 ms /    63 runs   (    0.55 ms per token,  1814.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4975.05 ms /   911 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2492.60 ms /    62 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7566.94 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.17 ms /   103 runs   (    0.67 ms per token,  1489.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4339.87 ms /   802 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
            "llama_print_timings:        eval time =    4102.55 ms /   102 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8621.43 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.65 ms /    75 runs   (    0.53 ms per token,  1891.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4613.92 ms /   854 tokens (    5.40 ms per token,   185.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2963.14 ms /    74 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    7682.05 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.23 ms /   256 runs   (    0.58 ms per token,  1727.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2601.30 ms /   496 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =   10004.20 ms /   255 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   13007.16 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.16 ms /    85 runs   (    0.57 ms per token,  1765.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4968.56 ms /   912 tokens (    5.45 ms per token,   183.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3424.46 ms /    85 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    8521.82 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.64 ms /    69 runs   (    0.55 ms per token,  1833.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3881.92 ms /   728 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2685.38 ms /    68 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6663.10 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.48 ms /    88 runs   (    0.55 ms per token,  1815.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5409.39 ms /   980 tokens (    5.52 ms per token,   181.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3518.66 ms /    87 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    9056.64 ms /  1067 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.13 ms /    72 runs   (    0.70 ms per token,  1436.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4427.41 ms /   821 tokens (    5.39 ms per token,   185.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2857.59 ms /    71 runs   (   40.25 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7414.62 ms /   892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.32 ms /    88 runs   (    0.55 ms per token,  1821.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3798.62 ms /   706 tokens (    5.38 ms per token,   185.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3422.49 ms /    87 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7343.36 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.83 ms /   113 runs   (    0.64 ms per token,  1573.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4429.17 ms /   818 tokens (    5.41 ms per token,   184.68 tokens per second)\n",
            "llama_print_timings:        eval time =    4500.46 ms /   112 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    9117.11 ms /   930 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.74 ms /    78 runs   (    0.54 ms per token,  1868.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2945.72 ms /   559 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3020.51 ms /    77 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6069.71 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.84 ms /    62 runs   (    0.61 ms per token,  1638.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4038.62 ms /   751 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2428.35 ms /    61 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6566.22 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     164.24 ms /   256 runs   (    0.64 ms per token,  1558.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2154.02 ms /   411 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =    9988.63 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12599.40 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.34 ms /    78 runs   (    0.56 ms per token,  1799.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4013.72 ms /   747 tokens (    5.37 ms per token,   186.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3044.36 ms /    77 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    7168.07 ms /   824 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     137.91 ms /   256 runs   (    0.54 ms per token,  1856.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3891.00 ms /   722 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10176.59 ms /   255 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =   14455.91 ms /   977 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.67 ms /   256 runs   (    0.61 ms per token,  1644.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2165.42 ms /   412 tokens (    5.26 ms per token,   190.26 tokens per second)\n",
            "llama_print_timings:        eval time =    9966.83 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12532.86 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.42 ms /   140 runs   (    0.62 ms per token,  1620.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2421.48 ms /   464 tokens (    5.22 ms per token,   191.62 tokens per second)\n",
            "llama_print_timings:        eval time =    5429.85 ms /   139 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    8071.31 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1926.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1873.51 ms /   357 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =     231.63 ms /     6 runs   (   38.60 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2118.77 ms /   363 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.67 ms /    80 runs   (    0.57 ms per token,  1751.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2943.78 ms /   560 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3101.43 ms /    79 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6163.88 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     7 runs   (    0.66 ms per token,  1511.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2452.79 ms /   464 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
            "llama_print_timings:        eval time =     230.74 ms /     6 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
            "llama_print_timings:       total time =    2702.00 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.10 ms /   119 runs   (    0.54 ms per token,  1856.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3477.01 ms /   656 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4642.51 ms /   118 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    8282.89 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.19 ms /    73 runs   (    0.56 ms per token,  1772.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4466.53 ms /   824 tokens (    5.42 ms per token,   184.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2918.36 ms /    73 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    7497.73 ms /   897 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.12 ms /   256 runs   (    0.59 ms per token,  1682.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2113.61 ms /   403 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =    9991.50 ms /   255 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   12519.33 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1865.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2284.68 ms /   435 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =     230.27 ms /     6 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2529.90 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.82 ms /   129 runs   (    0.61 ms per token,  1636.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3479.15 ms /   655 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    5081.74 ms /   128 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    8774.82 ms /   783 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.29 ms /    67 runs   (    0.57 ms per token,  1750.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1331.91 ms /   251 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2554.98 ms /    66 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    3976.95 ms /   317 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1843.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3793.78 ms /   711 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =     201.16 ms /     5 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    4012.54 ms /   716 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.65 ms /    90 runs   (    0.63 ms per token,  1588.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3720.76 ms /   696 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3582.96 ms /    90 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7454.45 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.49 ms /   102 runs   (    0.56 ms per token,  1774.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4386.91 ms /   814 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
            "llama_print_timings:        eval time =    4037.81 ms /   101 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    8575.84 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.01 ms /    89 runs   (    0.55 ms per token,  1815.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4572.61 ms /   835 tokens (    5.48 ms per token,   182.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3516.42 ms /    88 runs   (   39.96 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    8216.56 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.39 ms /    81 runs   (    0.65 ms per token,  1546.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4347.24 ms /   808 tokens (    5.38 ms per token,   185.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3254.40 ms /    81 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    7744.40 ms /   889 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.01 ms /    97 runs   (    0.54 ms per token,  1864.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3982.03 ms /   739 tokens (    5.39 ms per token,   185.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3792.64 ms /    96 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    7913.21 ms /   835 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.99 ms /    90 runs   (    0.67 ms per token,  1500.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2899.63 ms /   548 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =    3515.40 ms /    89 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6575.31 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.19 ms /   256 runs   (    0.57 ms per token,  1751.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2370.12 ms /   450 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =   10016.34 ms /   255 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =   12798.59 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.20 ms /    92 runs   (    0.55 ms per token,  1832.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2905.13 ms /   552 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3568.03 ms /    91 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6597.54 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.59 ms /    85 runs   (    0.62 ms per token,  1616.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1637.59 ms /   316 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3246.37 ms /    84 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =    5010.68 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.87 ms /    73 runs   (    0.55 ms per token,  1831.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4043.22 ms /   749 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2854.65 ms /    72 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    7002.46 ms /   821 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.88 ms /    72 runs   (    0.68 ms per token,  1472.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4607.30 ms /   854 tokens (    5.39 ms per token,   185.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2866.78 ms /    71 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    7605.89 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.23 ms /    66 runs   (    0.55 ms per token,  1821.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4485.53 ms /   828 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2584.57 ms /    65 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7165.52 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.41 ms /    75 runs   (    0.67 ms per token,  1487.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4346.39 ms /   807 tokens (    5.39 ms per token,   185.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2982.64 ms /    74 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7465.73 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.27 ms /   256 runs   (    0.56 ms per token,  1774.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.95 ms /   456 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =   10069.97 ms /   256 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   12859.03 ms /   712 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.53 ms /    85 runs   (    0.57 ms per token,  1751.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3569.86 ms /   672 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3292.48 ms /    84 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6983.55 ms /   756 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.13 ms /   256 runs   (    0.60 ms per token,  1660.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2454.74 ms /   469 tokens (    5.23 ms per token,   191.06 tokens per second)\n",
            "llama_print_timings:        eval time =    9965.47 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12825.59 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.46 ms /    69 runs   (    0.70 ms per token,  1423.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3880.99 ms /   725 tokens (    5.35 ms per token,   186.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2716.16 ms /    68 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    6721.79 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.47 ms /    74 runs   (    0.56 ms per token,  1784.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2900.69 ms /   549 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2858.16 ms /    73 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5862.56 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.50 ms /    12 runs   (    0.54 ms per token,  1847.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.84 ms /   423 tokens (    5.20 ms per token,   192.20 tokens per second)\n",
            "llama_print_timings:        eval time =     422.30 ms /    11 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2643.13 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.55 ms /   119 runs   (    0.64 ms per token,  1554.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2110.97 ms /   404 tokens (    5.23 ms per token,   191.38 tokens per second)\n",
            "llama_print_timings:        eval time =    4603.69 ms /   118 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    6910.10 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.58 ms /    66 runs   (    0.55 ms per token,  1804.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4298.11 ms /   800 tokens (    5.37 ms per token,   186.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2586.42 ms /    65 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    6981.00 ms /   865 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.52 ms /    69 runs   (    0.60 ms per token,  1661.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4048.14 ms /   749 tokens (    5.40 ms per token,   185.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2699.28 ms /    68 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6856.50 ms /   817 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      92.19 ms /   148 runs   (    0.62 ms per token,  1605.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4753.08 ms /   880 tokens (    5.40 ms per token,   185.14 tokens per second)\n",
            "llama_print_timings:        eval time =    5939.11 ms /   147 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =   10943.78 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.54 ms /    91 runs   (    0.53 ms per token,  1874.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4440.25 ms /   824 tokens (    5.39 ms per token,   185.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3632.00 ms /    91 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    8198.43 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.07 ms /     7 runs   (    0.72 ms per token,  1380.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.28 ms /   460 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =     234.63 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2670.73 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     108.37 ms /   173 runs   (    0.63 ms per token,  1596.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     213.94 ms /    36 tokens (    5.94 ms per token,   168.27 tokens per second)\n",
            "llama_print_timings:        eval time =    6742.09 ms /   172 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7221.49 ms /   208 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Amcor plc_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Square, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.90 ms /    96 runs   (    0.68 ms per token,  1479.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5786.73 ms /  1054 tokens (    5.49 ms per token,   182.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3899.61 ms /    95 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    9860.42 ms /  1149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.45 ms /    99 runs   (    0.54 ms per token,  1852.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5684.59 ms /  1036 tokens (    5.49 ms per token,   182.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3987.04 ms /    98 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    9817.41 ms /  1134 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.68 ms /    80 runs   (    0.53 ms per token,  1874.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6253.09 ms /  1124 tokens (    5.56 ms per token,   179.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3228.64 ms /    79 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    9603.30 ms /  1203 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.68 ms /    86 runs   (    0.68 ms per token,  1465.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4485.41 ms /   832 tokens (    5.39 ms per token,   185.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3461.63 ms /    86 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8096.55 ms /   918 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.78 ms /    73 runs   (    0.53 ms per token,  1882.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5738.84 ms /  1047 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2926.45 ms /    72 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8772.74 ms /  1119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1910.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6308.94 ms /  1130 tokens (    5.58 ms per token,   179.11 tokens per second)\n",
            "llama_print_timings:        eval time =     204.07 ms /     5 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    6539.45 ms /  1135 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.69 ms /    75 runs   (    0.66 ms per token,  1509.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6219.12 ms /  1128 tokens (    5.51 ms per token,   181.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3050.27 ms /    74 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =    9407.44 ms /  1202 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.94 ms /    67 runs   (    0.55 ms per token,  1814.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5792.98 ms /  1050 tokens (    5.52 ms per token,   181.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2680.51 ms /    66 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8573.55 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.71 ms /    80 runs   (    0.55 ms per token,  1830.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5678.23 ms /  1030 tokens (    5.51 ms per token,   181.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3207.73 ms /    79 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    9006.63 ms /  1109 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1809.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6260.17 ms /  1131 tokens (    5.54 ms per token,   180.67 tokens per second)\n",
            "llama_print_timings:        eval time =     203.22 ms /     5 runs   (   40.64 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    6485.33 ms /  1136 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.98 ms /    91 runs   (    0.67 ms per token,  1492.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     142.16 ms /    24 tokens (    5.92 ms per token,   168.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3724.80 ms /    90 runs   (   41.39 ms per token,    24.16 tokens per second)\n",
            "llama_print_timings:       total time =    4028.40 ms /   114 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.19 ms /    70 runs   (    0.53 ms per token,  1882.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5689.01 ms /  1039 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2801.69 ms /    69 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    8592.81 ms /  1108 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.82 ms /    82 runs   (    0.53 ms per token,  1871.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3916.04 ms /   722 tokens (    5.42 ms per token,   184.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3197.18 ms /    81 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    7235.04 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.21 ms /    78 runs   (    0.63 ms per token,  1584.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5782.31 ms /  1050 tokens (    5.51 ms per token,   181.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3153.35 ms /    77 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    9069.81 ms /  1127 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.39 ms /   132 runs   (    0.56 ms per token,  1798.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6278.09 ms /  1133 tokens (    5.54 ms per token,   180.47 tokens per second)\n",
            "llama_print_timings:        eval time =    5377.58 ms /   131 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =   11853.49 ms /  1264 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.56 ms /    55 runs   (    0.56 ms per token,  1799.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3913.54 ms /   725 tokens (    5.40 ms per token,   185.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2122.53 ms /    54 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6117.41 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.76 ms /    72 runs   (    0.57 ms per token,  1766.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.32 ms /   432 tokens (    5.20 ms per token,   192.40 tokens per second)\n",
            "llama_print_timings:        eval time =    2810.98 ms /    72 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5155.05 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      92.02 ms /   161 runs   (    0.57 ms per token,  1749.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3009.04 ms /   566 tokens (    5.32 ms per token,   188.10 tokens per second)\n",
            "llama_print_timings:        eval time =    6288.84 ms /   160 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    9541.32 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.91 ms /    74 runs   (    0.54 ms per token,  1854.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.47 ms /   450 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2862.42 ms /    73 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5330.39 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.94 ms /    70 runs   (    0.57 ms per token,  1752.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3924.66 ms /   726 tokens (    5.41 ms per token,   184.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2730.85 ms /    69 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    6765.16 ms /   795 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.30 ms /    85 runs   (    0.64 ms per token,  1565.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5406.26 ms /   990 tokens (    5.46 ms per token,   183.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3417.20 ms /    84 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    8970.32 ms /  1074 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.89 ms /    93 runs   (    0.57 ms per token,  1758.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     139.29 ms /    24 tokens (    5.80 ms per token,   172.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3777.47 ms /    93 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    4057.19 ms /   117 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.22 ms /   256 runs   (    0.58 ms per token,  1715.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.52 ms /   562 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =   10069.11 ms /   255 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   13467.31 ms /   817 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.65 ms /    69 runs   (    0.59 ms per token,  1697.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1686.24 ms /   323 tokens (    5.22 ms per token,   191.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2625.40 ms /    68 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    4406.57 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.52 ms /   256 runs   (    0.62 ms per token,  1625.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2114.53 ms /   408 tokens (    5.18 ms per token,   192.95 tokens per second)\n",
            "llama_print_timings:        eval time =    9957.54 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12482.69 ms /   663 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.20 ms /    59 runs   (    0.61 ms per token,  1629.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5424.08 ms /   986 tokens (    5.50 ms per token,   181.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2360.40 ms /    58 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    7891.86 ms /  1044 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.37 ms /    90 runs   (    0.55 ms per token,  1822.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2980.45 ms /   562 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3484.68 ms /    89 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6588.14 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.46 ms /   256 runs   (    0.60 ms per token,  1657.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1903.37 ms /   368 tokens (    5.17 ms per token,   193.34 tokens per second)\n",
            "llama_print_timings:        eval time =    9971.09 ms /   256 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12283.57 ms /   624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.49 ms /    78 runs   (    0.65 ms per token,  1544.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.58 ms /   446 tokens (    5.22 ms per token,   191.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3021.45 ms /    77 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5479.09 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.75 ms /   134 runs   (    0.55 ms per token,  1816.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1541.32 ms /   295 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    5140.69 ms /   133 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    6869.08 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.47 ms /    75 runs   (    0.58 ms per token,  1725.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2070.35 ms /   397 tokens (    5.21 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2883.02 ms /    74 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5063.04 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.68 ms /    77 runs   (    0.61 ms per token,  1649.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2059.36 ms /   389 tokens (    5.29 ms per token,   188.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2962.45 ms /    76 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5139.56 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.88 ms /   256 runs   (    0.57 ms per token,  1754.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.07 ms /   454 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
            "llama_print_timings:        eval time =   10018.94 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12814.79 ms /   709 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.23 ms /    67 runs   (    0.54 ms per token,  1849.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.39 ms /   432 tokens (    5.20 ms per token,   192.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2579.60 ms /    66 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4915.23 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.83 ms /    63 runs   (    0.62 ms per token,  1622.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2287.65 ms /   440 tokens (    5.20 ms per token,   192.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2428.77 ms /    62 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    4816.71 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.29 ms /   256 runs   (    0.57 ms per token,  1749.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3055.07 ms /   574 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =   10046.44 ms /   255 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   13512.72 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.14 ms /   115 runs   (    0.55 ms per token,  1821.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3407.82 ms /   636 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4483.60 ms /   114 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    8053.56 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.86 ms /     9 runs   (    0.54 ms per token,  1851.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     478.88 ms /    90 tokens (    5.32 ms per token,   187.94 tokens per second)\n",
            "llama_print_timings:        eval time =     302.19 ms /     8 runs   (   37.77 ms per token,    26.47 tokens per second)\n",
            "llama_print_timings:       total time =     794.16 ms /    98 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.08 ms /    77 runs   (    0.68 ms per token,  1478.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.82 ms /   446 tokens (    5.22 ms per token,   191.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2978.01 ms /    76 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5440.83 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.64 ms /    84 runs   (    0.54 ms per token,  1840.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5706.73 ms /  1040 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3415.48 ms /    84 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    9247.82 ms /  1124 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.52 ms /    66 runs   (    0.55 ms per token,  1807.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6218.52 ms /  1119 tokens (    5.56 ms per token,   179.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2656.09 ms /    65 runs   (   40.86 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    8981.82 ms /  1184 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.84 ms /    14 runs   (    0.56 ms per token,  1785.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1600.64 ms /   309 tokens (    5.18 ms per token,   193.05 tokens per second)\n",
            "llama_print_timings:        eval time =     505.37 ms /    13 runs   (   38.87 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2128.35 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.24 ms /     9 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2074.82 ms /   400 tokens (    5.19 ms per token,   192.79 tokens per second)\n",
            "llama_print_timings:        eval time =     309.66 ms /     8 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2401.52 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.64 ms /    71 runs   (    0.53 ms per token,  1886.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5782.02 ms /  1043 tokens (    5.54 ms per token,   180.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2842.08 ms /    70 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    8734.77 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.27 ms /    51 runs   (    0.63 ms per token,  1580.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5601.91 ms /  1024 tokens (    5.47 ms per token,   182.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2088.58 ms /    51 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    7787.94 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     108.16 ms /   196 runs   (    0.55 ms per token,  1812.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2318.77 ms /   439 tokens (    5.28 ms per token,   189.32 tokens per second)\n",
            "llama_print_timings:        eval time =    7624.78 ms /   195 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   10227.76 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.49 ms /    85 runs   (    0.62 ms per token,  1619.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3408.09 ms /   637 tokens (    5.35 ms per token,   186.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3316.07 ms /    84 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6863.62 ms /   721 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.82 ms /    70 runs   (    0.53 ms per token,  1901.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3882.17 ms /   724 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2728.95 ms /    69 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6713.90 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.40 ms /    71 runs   (    0.54 ms per token,  1849.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5727.34 ms /  1034 tokens (    5.54 ms per token,   180.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2842.94 ms /    70 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8680.32 ms /  1104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.93 ms /   256 runs   (    0.61 ms per token,  1641.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.31 ms /   536 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =   10119.55 ms /   256 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   13354.00 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.94 ms /   256 runs   (    0.61 ms per token,  1631.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2460.99 ms /   471 tokens (    5.23 ms per token,   191.39 tokens per second)\n",
            "llama_print_timings:        eval time =   10019.40 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12909.50 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.89 ms /    74 runs   (    0.61 ms per token,  1648.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5082.67 ms /   934 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2952.17 ms /    73 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8160.18 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.36 ms /   256 runs   (    0.58 ms per token,  1737.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2792.97 ms /   523 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =   10004.75 ms /   255 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   13196.03 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     9 runs   (    0.53 ms per token,  1895.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2314.36 ms /   436 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =     308.51 ms /     8 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2644.22 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.41 ms /    11 runs   (    0.49 ms per token,  2032.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3384.32 ms /   634 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =     393.97 ms /    10 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3799.75 ms /   644 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.25 ms /   104 runs   (    0.62 ms per token,  1618.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3120.75 ms /   592 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4066.77 ms /   103 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    7353.01 ms /   695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.82 ms /    82 runs   (    0.55 ms per token,  1829.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3501.74 ms /   654 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3184.84 ms /    81 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6802.33 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.49 ms /    78 runs   (    0.65 ms per token,  1544.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5699.99 ms /  1036 tokens (    5.50 ms per token,   181.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3153.31 ms /    77 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    9000.45 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.35 ms /    68 runs   (    0.53 ms per token,  1870.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5786.91 ms /  1054 tokens (    5.49 ms per token,   182.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2726.41 ms /    67 runs   (   40.69 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    8617.36 ms /  1121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.42 ms /    74 runs   (    0.71 ms per token,  1411.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2130.90 ms /   408 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2853.75 ms /    73 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5112.89 ms /   481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      25.05 ms /    45 runs   (    0.56 ms per token,  1796.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2682.30 ms /   512 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1720.01 ms /    44 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    4467.67 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1851.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     168.82 ms /    28 tokens (    6.03 ms per token,   165.86 tokens per second)\n",
            "llama_print_timings:        eval time =     232.12 ms /     6 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =     412.17 ms /    34 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1822.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2588.68 ms /   496 tokens (    5.22 ms per token,   191.60 tokens per second)\n",
            "llama_print_timings:        eval time =     275.31 ms /     7 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    2880.40 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.18 ms /    69 runs   (    0.57 ms per token,  1760.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3916.54 ms /   728 tokens (    5.38 ms per token,   185.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2698.04 ms /    68 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    6723.82 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.00 ms /   102 runs   (    0.53 ms per token,  1888.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1943.23 ms /   370 tokens (    5.25 ms per token,   190.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3927.86 ms /   101 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    6006.85 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.12 ms /   256 runs   (    0.60 ms per token,  1671.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2334.68 ms /   447 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =    9956.35 ms /   255 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12700.72 ms /   702 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.84 ms /   109 runs   (    0.69 ms per token,  1456.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2111.14 ms /   402 tokens (    5.25 ms per token,   190.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4221.82 ms /   108 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6532.15 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.20 ms /   256 runs   (    0.58 ms per token,  1715.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.78 ms /   311 tokens (    5.15 ms per token,   194.04 tokens per second)\n",
            "llama_print_timings:        eval time =    9944.09 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   11962.45 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Square, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_3M CO_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.65 ms /    74 runs   (    0.54 ms per token,  1866.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2478.45 ms /   472 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2895.71 ms /    74 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5474.76 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.88 ms /    90 runs   (    0.61 ms per token,  1640.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3298.51 ms /   624 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3552.10 ms /    90 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6996.47 ms /   714 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.40 ms /    95 runs   (    0.58 ms per token,  1714.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2229.91 ms /   423 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3663.96 ms /    94 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6031.92 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.52 ms /    78 runs   (    0.56 ms per token,  1792.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3341.01 ms /   629 tokens (    5.31 ms per token,   188.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3032.59 ms /    77 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6487.01 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.03 ms /    66 runs   (    0.67 ms per token,  1498.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =      87.62 ms /    14 tokens (    6.26 ms per token,   159.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.86 ms /    65 runs   (   39.67 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    2777.32 ms /    79 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2677.19 ms /   507 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =     234.56 ms /     6 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    2928.48 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.27 ms /   106 runs   (    0.58 ms per token,  1730.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2895.72 ms /   546 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
            "llama_print_timings:        eval time =    4117.21 ms /   105 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7167.96 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.52 ms /    97 runs   (    0.55 ms per token,  1812.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2949.91 ms /   552 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3812.99 ms /    97 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6900.59 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.62 ms /    74 runs   (    0.56 ms per token,  1778.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2632.03 ms /   504 tokens (    5.22 ms per token,   191.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2861.57 ms /    73 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5597.34 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.32 ms /   256 runs   (    0.55 ms per token,  1824.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2129.37 ms /   405 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
            "llama_print_timings:        eval time =    9959.45 ms /   255 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12480.51 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.51 ms /   109 runs   (    0.56 ms per token,  1772.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3767.86 ms /   704 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4293.45 ms /   108 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    8228.74 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.43 ms /   112 runs   (    0.61 ms per token,  1636.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4845.51 ms /   893 tokens (    5.43 ms per token,   184.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4490.97 ms /   111 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    9528.22 ms /  1004 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.51 ms /    95 runs   (    0.56 ms per token,  1775.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2876.82 ms /   543 tokens (    5.30 ms per token,   188.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3692.29 ms /    94 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6703.09 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.95 ms /   101 runs   (    0.55 ms per token,  1805.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7073.63 ms /  1262 tokens (    5.61 ms per token,   178.41 tokens per second)\n",
            "llama_print_timings:        eval time =    4145.63 ms /   100 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   11376.76 ms /  1362 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.41 ms /   256 runs   (    0.56 ms per token,  1785.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2159.88 ms /   412 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =    9983.62 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12555.79 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.16 ms /    93 runs   (    0.57 ms per token,  1749.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1983.91 ms /   384 tokens (    5.17 ms per token,   193.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3582.41 ms /    92 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5693.89 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.28 ms /     7 runs   (    0.75 ms per token,  1324.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2212.83 ms /   419 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
            "llama_print_timings:        eval time =     235.48 ms /     6 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2466.69 ms /   425 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2185.94 ms /   415 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
            "llama_print_timings:        eval time =     231.35 ms /     6 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    2432.94 ms /   421 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.86 ms /   256 runs   (    0.59 ms per token,  1685.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.46 ms /   432 tokens (    5.20 ms per token,   192.47 tokens per second)\n",
            "llama_print_timings:        eval time =   10044.79 ms /   256 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   12718.91 ms /   688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.32 ms /    77 runs   (    0.54 ms per token,  1863.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3207.41 ms /   606 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2991.55 ms /    76 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6306.94 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.30 ms /    93 runs   (    0.63 ms per token,  1595.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1989.00 ms /   383 tokens (    5.19 ms per token,   192.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3589.14 ms /    92 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5724.33 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1760.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2217.94 ms /   418 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =     232.27 ms /     6 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2468.54 ms /   424 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.64 ms /   256 runs   (    0.59 ms per token,  1688.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.91 ms /   446 tokens (    5.22 ms per token,   191.51 tokens per second)\n",
            "llama_print_timings:        eval time =   10025.63 ms /   255 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   12794.06 ms /   701 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.95 ms /   256 runs   (    0.57 ms per token,  1742.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1723.69 ms /   334 tokens (    5.16 ms per token,   193.77 tokens per second)\n",
            "llama_print_timings:        eval time =    9944.81 ms /   255 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12078.40 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.28 ms /    65 runs   (    0.54 ms per token,  1842.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2384.18 ms /   451 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2506.01 ms /    64 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4983.33 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.64 ms /    56 runs   (    0.53 ms per token,  1889.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1812.48 ms /   348 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2130.40 ms /    55 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    4016.59 ms /   403 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.58 ms /    12 runs   (    0.63 ms per token,  1583.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2598.53 ms /   495 tokens (    5.25 ms per token,   190.49 tokens per second)\n",
            "llama_print_timings:        eval time =     435.80 ms /    11 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    3059.36 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.26 ms /    77 runs   (    0.55 ms per token,  1822.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2841.57 ms /   531 tokens (    5.35 ms per token,   186.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2973.45 ms /    76 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5924.13 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.44 ms /    79 runs   (    0.54 ms per token,  1861.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     169.72 ms /    27 tokens (    6.29 ms per token,   159.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3065.39 ms /    78 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    3337.61 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.49 ms /    12 runs   (    0.54 ms per token,  1848.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2590.10 ms /   496 tokens (    5.22 ms per token,   191.50 tokens per second)\n",
            "llama_print_timings:        eval time =     432.63 ms /    11 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3045.43 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.43 ms /     7 runs   (    0.63 ms per token,  1579.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3019.99 ms /   565 tokens (    5.35 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =     237.94 ms /     6 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    3279.18 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.01 ms /    75 runs   (    0.55 ms per token,  1828.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1985.11 ms /   381 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2875.23 ms /    74 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4961.23 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.16 ms /    68 runs   (    0.65 ms per token,  1539.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4244.01 ms /   790 tokens (    5.37 ms per token,   186.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2681.96 ms /    67 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7043.28 ms /   857 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.73 ms /     6 runs   (    0.62 ms per token,  1606.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.43 ms /   412 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =     192.35 ms /     5 runs   (   38.47 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2388.24 ms /   417 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.84 ms /   256 runs   (    0.60 ms per token,  1664.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.43 ms /   442 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =   10022.90 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12785.36 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.31 ms /   165 runs   (    0.54 ms per token,  1847.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2634.95 ms /   503 tokens (    5.24 ms per token,   190.90 tokens per second)\n",
            "llama_print_timings:        eval time =    6429.74 ms /   164 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    9292.13 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.23 ms /     6 runs   (    0.70 ms per token,  1419.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2664.93 ms /   504 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =     237.85 ms /     6 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    2920.19 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2168.77 ms /   414 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =     229.39 ms /     6 runs   (   38.23 ms per token,    26.16 tokens per second)\n",
            "llama_print_timings:       total time =    2414.06 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1812.19 ms /   348 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
            "llama_print_timings:        eval time =     231.08 ms /     6 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2057.47 ms /   354 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.11 ms /     7 runs   (    0.59 ms per token,  1701.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     958.98 ms /   184 tokens (    5.21 ms per token,   191.87 tokens per second)\n",
            "llama_print_timings:        eval time =     267.29 ms /     7 runs   (   38.18 ms per token,    26.19 tokens per second)\n",
            "llama_print_timings:       total time =    1238.96 ms /   191 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.24 ms /    70 runs   (    0.59 ms per token,  1697.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2815.80 ms /   536 tokens (    5.25 ms per token,   190.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2714.18 ms /    69 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    5636.53 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.06 ms /   256 runs   (    0.57 ms per token,  1764.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2184.15 ms /   411 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    9954.62 ms /   255 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12528.56 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.07 ms /     7 runs   (    0.72 ms per token,  1380.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     554.55 ms /   100 tokens (    5.55 ms per token,   180.33 tokens per second)\n",
            "llama_print_timings:        eval time =     232.05 ms /     6 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =     801.70 ms /   106 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.96 ms /     7 runs   (    0.71 ms per token,  1410.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2578.03 ms /   484 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =     238.32 ms /     6 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    2836.87 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.24 ms /   256 runs   (    0.58 ms per token,  1738.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2117.97 ms /   408 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
            "llama_print_timings:        eval time =   10031.28 ms /   256 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   12564.65 ms /   664 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.24 ms /   256 runs   (    0.58 ms per token,  1726.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2133.34 ms /   408 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =    9969.37 ms /   255 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12506.89 ms /   663 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.17 ms /    11 runs   (    0.56 ms per token,  1782.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1970.09 ms /   376 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =     424.93 ms /    11 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
            "llama_print_timings:       total time =    2416.39 ms /   387 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.87 ms /   256 runs   (    0.58 ms per token,  1731.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2860.01 ms /   544 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =   10102.76 ms /   256 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13390.78 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.44 ms /     7 runs   (    0.49 ms per token,  2033.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2588.60 ms /   495 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
            "llama_print_timings:        eval time =     234.78 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2838.19 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1889.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2902.31 ms /   552 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =     275.20 ms /     7 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3193.38 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.33 ms /   256 runs   (    0.61 ms per token,  1648.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1770.18 ms /   344 tokens (    5.15 ms per token,   194.33 tokens per second)\n",
            "llama_print_timings:        eval time =    9927.73 ms /   255 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =   12112.95 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1847.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1688.20 ms /   328 tokens (    5.15 ms per token,   194.29 tokens per second)\n",
            "llama_print_timings:        eval time =     231.54 ms /     6 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    1931.85 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.85 ms /    11 runs   (    0.53 ms per token,  1879.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2114.97 ms /   408 tokens (    5.18 ms per token,   192.91 tokens per second)\n",
            "llama_print_timings:        eval time =     385.49 ms /    10 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2519.06 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.90 ms /     9 runs   (    0.66 ms per token,  1524.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2572.48 ms /   483 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
            "llama_print_timings:        eval time =     318.07 ms /     8 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    2912.34 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.77 ms /    66 runs   (    0.59 ms per token,  1702.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2257.50 ms /   431 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2540.88 ms /    65 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    4899.21 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.00 ms /    94 runs   (    0.55 ms per token,  1807.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1771.09 ms /   344 tokens (    5.15 ms per token,   194.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3640.03 ms /    94 runs   (   38.72 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    5536.14 ms /   438 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.63 ms /    69 runs   (    0.62 ms per token,  1618.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2529.21 ms /   474 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2654.66 ms /    68 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    5297.98 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.73 ms /    75 runs   (    0.56 ms per token,  1797.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.12 ms /   443 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2895.00 ms /    74 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5322.65 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.67 ms /   256 runs   (    0.59 ms per token,  1687.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.66 ms /   378 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    9926.45 ms /   255 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =   12326.84 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.62 ms /   256 runs   (    0.60 ms per token,  1655.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1939.30 ms /   370 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =    9934.21 ms /   255 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =   12300.92 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.69 ms /    82 runs   (    0.59 ms per token,  1684.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2197.72 ms /   419 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3149.06 ms /    81 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    5463.42 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.07 ms /   112 runs   (    0.55 ms per token,  1834.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4425.36 ms /   814 tokens (    5.44 ms per token,   183.94 tokens per second)\n",
            "llama_print_timings:        eval time =    4423.80 ms /   111 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    9011.70 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1984.64 ms /   384 tokens (    5.17 ms per token,   193.49 tokens per second)\n",
            "llama_print_timings:        eval time =     269.44 ms /     7 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2268.06 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.44 ms /    88 runs   (    0.55 ms per token,  1816.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4053.78 ms /   750 tokens (    5.41 ms per token,   185.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3463.10 ms /    87 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7648.13 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.47 ms /   131 runs   (    0.55 ms per token,  1807.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2239.69 ms /   427 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    5079.18 ms /   130 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    7497.93 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.18 ms /   102 runs   (    0.59 ms per token,  1695.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2224.97 ms /   424 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3991.34 ms /   102 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6365.41 ms /   526 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_3M CO_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.80 ms /    78 runs   (    0.54 ms per token,  1865.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3217.21 ms /   608 tokens (    5.29 ms per token,   188.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3056.30 ms /    78 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6378.52 ms /   686 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     133.90 ms /   256 runs   (    0.52 ms per token,  1911.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2661.76 ms /   504 tokens (    5.28 ms per token,   189.35 tokens per second)\n",
            "llama_print_timings:        eval time =   10049.07 ms /   256 runs   (   39.25 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   13086.55 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.96 ms /     7 runs   (    0.71 ms per token,  1412.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2387.68 ms /   456 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
            "llama_print_timings:        eval time =     276.69 ms /     7 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2684.19 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.14 ms /    61 runs   (    0.56 ms per token,  1786.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2698.97 ms /   509 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2358.95 ms /    60 runs   (   39.32 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5145.57 ms /   569 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1921.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.45 ms /   496 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =     236.40 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2842.58 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.50 ms /    65 runs   (    0.61 ms per token,  1645.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2331.49 ms /   447 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2497.20 ms /    64 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4926.25 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2840.08 ms /   532 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
            "llama_print_timings:        eval time =     236.44 ms /     6 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3097.21 ms /   538 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.78 ms /   256 runs   (    0.59 ms per token,  1697.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2375.83 ms /   450 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =   10036.99 ms /   255 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   12832.20 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.27 ms /    69 runs   (    0.55 ms per token,  1803.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4290.65 ms /   796 tokens (    5.39 ms per token,   185.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2702.29 ms /    68 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    7091.25 ms /   864 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.05 ms /     7 runs   (    0.72 ms per token,  1386.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2636.50 ms /   503 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =     237.44 ms /     6 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    2892.41 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     7 runs   (    0.72 ms per token,  1398.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2710.16 ms /   509 tokens (    5.32 ms per token,   187.81 tokens per second)\n",
            "llama_print_timings:        eval time =     236.40 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2969.81 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.92 ms /    96 runs   (    0.56 ms per token,  1780.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3255.89 ms /   613 tokens (    5.31 ms per token,   188.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3745.94 ms /    95 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7139.00 ms /   708 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.25 ms /    75 runs   (    0.60 ms per token,  1657.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4630.90 ms /   852 tokens (    5.44 ms per token,   183.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2985.27 ms /    74 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    7747.10 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.46 ms /   131 runs   (    0.57 ms per token,  1759.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4378.11 ms /   810 tokens (    5.41 ms per token,   185.01 tokens per second)\n",
            "llama_print_timings:        eval time =    5198.43 ms /   130 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    9769.92 ms /   940 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.14 ms /    77 runs   (    0.53 ms per token,  1871.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3466.53 ms /   646 tokens (    5.37 ms per token,   186.35 tokens per second)\n",
            "llama_print_timings:        eval time =    2994.38 ms /    76 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6568.80 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.21 ms /    88 runs   (    0.60 ms per token,  1653.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.49 ms /   463 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3415.61 ms /    87 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5961.39 ms /   550 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.14 ms /   106 runs   (    0.59 ms per token,  1705.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1966.17 ms /   376 tokens (    5.23 ms per token,   191.23 tokens per second)\n",
            "llama_print_timings:        eval time =    4133.08 ms /   106 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    6252.11 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.55 ms /    80 runs   (    0.57 ms per token,  1756.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4290.11 ms /   800 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3147.00 ms /    79 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    7557.05 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.61 ms /    91 runs   (    0.53 ms per token,  1872.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3465.05 ms /   648 tokens (    5.35 ms per token,   187.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3544.34 ms /    90 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    7136.36 ms /   738 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.01 ms /   256 runs   (    0.60 ms per token,  1662.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.99 ms /   464 tokens (    5.21 ms per token,   191.90 tokens per second)\n",
            "llama_print_timings:        eval time =   10059.94 ms /   256 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   12896.50 ms /   720 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.87 ms /    70 runs   (    0.60 ms per token,  1671.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4611.45 ms /   856 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2770.64 ms /    69 runs   (   40.15 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    7496.11 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2666.95 ms /   503 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =     233.17 ms /     6 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2917.81 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.32 ms /    70 runs   (    0.58 ms per token,  1736.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.73 ms /   502 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2703.05 ms /    69 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5433.55 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.12 ms /   256 runs   (    0.62 ms per token,  1619.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.92 ms /   456 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =    9963.54 ms /   255 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12753.34 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.83 ms /    83 runs   (    0.67 ms per token,  1486.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4384.56 ms /   814 tokens (    5.39 ms per token,   185.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3303.80 ms /    82 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    7838.03 ms /   896 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.50 ms /    65 runs   (    0.56 ms per token,  1780.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4610.04 ms /   856 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2559.14 ms /    64 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    7269.79 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.94 ms /    88 runs   (    0.68 ms per token,  1468.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2637.84 ms /   502 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3426.72 ms /    87 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6216.60 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.72 ms /    71 runs   (    0.56 ms per token,  1787.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2326.01 ms /   444 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2742.69 ms /    70 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5165.14 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1850.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.72 ms /   403 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =     229.55 ms /     6 runs   (   38.26 ms per token,    26.14 tokens per second)\n",
            "llama_print_timings:       total time =    2359.67 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.60 ms /   256 runs   (    0.59 ms per token,  1699.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1771.35 ms /   344 tokens (    5.15 ms per token,   194.20 tokens per second)\n",
            "llama_print_timings:        eval time =    9968.75 ms /   256 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =   12142.83 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.61 ms /     7 runs   (    0.52 ms per token,  1937.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1811.46 ms /   350 tokens (    5.18 ms per token,   193.21 tokens per second)\n",
            "llama_print_timings:        eval time =     233.97 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2058.80 ms /   356 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.37 ms /    80 runs   (    0.58 ms per token,  1725.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4745.69 ms /   870 tokens (    5.45 ms per token,   183.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3165.51 ms /    79 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    8031.40 ms /   949 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.94 ms /   256 runs   (    0.59 ms per token,  1684.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3202.42 ms /   602 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
            "llama_print_timings:        eval time =   10098.34 ms /   255 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =   13717.68 ms /   857 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.57 ms /    68 runs   (    0.61 ms per token,  1635.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4901.58 ms /   904 tokens (    5.42 ms per token,   184.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2739.43 ms /    68 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    7752.11 ms /   972 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.36 ms /    65 runs   (    0.53 ms per token,  1891.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4636.57 ms /   850 tokens (    5.45 ms per token,   183.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2557.56 ms /    64 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    7288.00 ms /   914 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2546.24 ms /   486 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =     193.35 ms /     5 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    2754.22 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.92 ms /     9 runs   (    0.55 ms per token,  1829.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1014.77 ms /   199 tokens (    5.10 ms per token,   196.10 tokens per second)\n",
            "llama_print_timings:        eval time =     303.21 ms /     8 runs   (   37.90 ms per token,    26.38 tokens per second)\n",
            "llama_print_timings:       total time =    1330.77 ms /   207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.18 ms /     6 runs   (    0.70 ms per token,  1435.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1698.62 ms /   326 tokens (    5.21 ms per token,   191.92 tokens per second)\n",
            "llama_print_timings:        eval time =     192.49 ms /     5 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    1905.58 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.55 ms /     6 runs   (    0.76 ms per token,  1319.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1665.50 ms /   316 tokens (    5.27 ms per token,   189.73 tokens per second)\n",
            "llama_print_timings:        eval time =     196.43 ms /     5 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    1878.61 ms /   321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      24.57 ms /    48 runs   (    0.51 ms per token,  1954.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4562.99 ms /   842 tokens (    5.42 ms per token,   184.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1872.81 ms /    47 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    6510.20 ms /   889 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.29 ms /    93 runs   (    0.65 ms per token,  1542.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1683.72 ms /   327 tokens (    5.15 ms per token,   194.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3567.67 ms /    92 runs   (   38.78 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    5395.58 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1890.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2791.49 ms /   524 tokens (    5.33 ms per token,   187.71 tokens per second)\n",
            "llama_print_timings:        eval time =     233.41 ms /     6 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    3042.27 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.59 ms /    81 runs   (    0.54 ms per token,  1858.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1981.16 ms /   380 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3111.65 ms /    80 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    5199.79 ms /   460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.77 ms /   107 runs   (    0.68 ms per token,  1470.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.01 ms /   437 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4149.25 ms /   106 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6615.85 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1786.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2334.79 ms /   442 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =     191.84 ms /     5 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2542.25 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.52 ms /    64 runs   (    0.54 ms per token,  1853.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4615.57 ms /   854 tokens (    5.40 ms per token,   185.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2521.80 ms /    63 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7230.76 ms /   917 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.73 ms /     7 runs   (    0.82 ms per token,  1222.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3373.01 ms /   629 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =     237.99 ms /     6 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    3636.21 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.42 ms /   256 runs   (    0.57 ms per token,  1748.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2301.88 ms /   437 tokens (    5.27 ms per token,   189.84 tokens per second)\n",
            "llama_print_timings:        eval time =   10007.27 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12715.38 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.05 ms /    59 runs   (    0.56 ms per token,  1785.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3714.21 ms /   691 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2280.91 ms /    58 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6080.53 ms /   749 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.25 ms /   256 runs   (    0.59 ms per token,  1703.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.02 ms /   444 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =    9994.27 ms /   255 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12733.09 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.42 ms /    79 runs   (    0.56 ms per token,  1778.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2157.39 ms /   410 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3036.31 ms /    78 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5299.50 ms /   488 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.76 ms /   254 runs   (    0.57 ms per token,  1766.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2524.33 ms /   478 tokens (    5.28 ms per token,   189.36 tokens per second)\n",
            "llama_print_timings:        eval time =    9910.07 ms /   253 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12811.59 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.12 ms /     7 runs   (    0.73 ms per token,  1368.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2693.87 ms /   506 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =     238.04 ms /     6 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    2950.87 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.92 ms /   120 runs   (    0.56 ms per token,  1793.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1624.83 ms /   308 tokens (    5.28 ms per token,   189.56 tokens per second)\n",
            "llama_print_timings:        eval time =    4594.56 ms /   119 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    6383.32 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.91 ms /   256 runs   (    0.59 ms per token,  1707.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1983.11 ms /   384 tokens (    5.16 ms per token,   193.64 tokens per second)\n",
            "llama_print_timings:        eval time =    9948.43 ms /   255 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =   12342.75 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.83 ms /    96 runs   (    0.55 ms per token,  1817.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2199.23 ms /   421 tokens (    5.22 ms per token,   191.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3713.22 ms /    95 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6042.25 ms /   516 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.71 ms /    73 runs   (    0.57 ms per token,  1750.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3519.85 ms /   650 tokens (    5.42 ms per token,   184.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2839.38 ms /    72 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6466.22 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.97 ms /    66 runs   (    0.58 ms per token,  1738.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4932.37 ms /   906 tokens (    5.44 ms per token,   183.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2617.15 ms /    65 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    7652.91 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.54 ms /    77 runs   (    0.57 ms per token,  1768.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4423.85 ms /   816 tokens (    5.42 ms per token,   184.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3025.51 ms /    76 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7564.14 ms /   892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.80 ms /   217 runs   (    0.63 ms per token,  1586.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.53 ms /   454 tokens (    5.23 ms per token,   191.36 tokens per second)\n",
            "llama_print_timings:        eval time =    8471.63 ms /   216 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   11200.02 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.16 ms /   110 runs   (    0.57 ms per token,  1769.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2075.25 ms /   400 tokens (    5.19 ms per token,   192.75 tokens per second)\n",
            "llama_print_timings:        eval time =    4283.58 ms /   110 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    6510.87 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.85 ms /   103 runs   (    0.69 ms per token,  1453.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     212.60 ms /    40 tokens (    5.31 ms per token,   188.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3986.49 ms /   102 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4370.39 ms /   142 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.02 ms /   256 runs   (    0.58 ms per token,  1729.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2426.45 ms /   463 tokens (    5.24 ms per token,   190.81 tokens per second)\n",
            "llama_print_timings:        eval time =   10009.81 ms /   255 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12849.23 ms /   718 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.56 ms /    70 runs   (    0.55 ms per token,  1815.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6182.61 ms /  1120 tokens (    5.52 ms per token,   181.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2820.06 ms /    69 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =    9110.71 ms /  1189 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.45 ms /    89 runs   (    0.54 ms per token,  1837.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6496.69 ms /  1168 tokens (    5.56 ms per token,   179.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3616.97 ms /    88 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   10247.68 ms /  1256 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.66 ms /    94 runs   (    0.66 ms per token,  1524.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3835.35 ms /   718 tokens (    5.34 ms per token,   187.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3717.20 ms /    93 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    7715.40 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.81 ms /    87 runs   (    0.55 ms per token,  1819.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6127.92 ms /  1112 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3558.91 ms /    87 runs   (   40.91 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    9817.66 ms /  1199 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.44 ms /    59 runs   (    0.55 ms per token,  1818.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6458.02 ms /  1158 tokens (    5.58 ms per token,   179.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2377.49 ms /    58 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =    8929.45 ms /  1216 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.58 ms /   119 runs   (    0.53 ms per token,  1871.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     185.26 ms /    27 tokens (    6.86 ms per token,   145.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4853.23 ms /   118 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =    5199.67 ms /   145 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     120.29 ms /   219 runs   (    0.55 ms per token,  1820.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6214.11 ms /  1115 tokens (    5.57 ms per token,   179.43 tokens per second)\n",
            "llama_print_timings:        eval time =    8975.11 ms /   218 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =   15539.19 ms /  1333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.10 ms /    98 runs   (    0.57 ms per token,  1747.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     144.49 ms /    24 tokens (    6.02 ms per token,   166.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4024.85 ms /    98 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    4319.95 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.98 ms /    97 runs   (    0.69 ms per token,  1448.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6407.22 ms /  1159 tokens (    5.53 ms per token,   180.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3971.49 ms /    96 runs   (   41.37 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   10557.66 ms /  1255 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.27 ms /   136 runs   (    0.58 ms per token,  1715.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6211.38 ms /  1122 tokens (    5.54 ms per token,   180.64 tokens per second)\n",
            "llama_print_timings:        eval time =    5547.20 ms /   135 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =   11977.21 ms /  1257 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.79 ms /    78 runs   (    0.59 ms per token,  1703.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =      96.03 ms /    16 tokens (    6.00 ms per token,   166.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3198.72 ms /    78 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    3415.39 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.10 ms /    86 runs   (    0.68 ms per token,  1480.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6417.05 ms /  1160 tokens (    5.53 ms per token,   180.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3548.43 ms /    86 runs   (   41.26 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =   10121.87 ms /  1246 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     131.37 ms /   232 runs   (    0.57 ms per token,  1766.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     139.90 ms /    22 tokens (    6.36 ms per token,   157.26 tokens per second)\n",
            "llama_print_timings:        eval time =    9536.43 ms /   231 runs   (   41.28 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =   10032.36 ms /   253 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      81.76 ms /   148 runs   (    0.55 ms per token,  1810.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6207.85 ms /  1120 tokens (    5.54 ms per token,   180.42 tokens per second)\n",
            "llama_print_timings:        eval time =    6028.90 ms /   147 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =   12455.19 ms /  1267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.23 ms /   256 runs   (    0.59 ms per token,  1681.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2732.97 ms /   520 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
            "llama_print_timings:        eval time =   10001.56 ms /   255 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   13138.79 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.98 ms /    66 runs   (    0.70 ms per token,  1435.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2024.77 ms /   387 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2521.11 ms /    65 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    4660.91 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.21 ms /    72 runs   (    0.54 ms per token,  1836.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6238.82 ms /  1123 tokens (    5.56 ms per token,   180.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2906.18 ms /    71 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =    9254.24 ms /  1194 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.13 ms /    78 runs   (    0.53 ms per token,  1896.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7393.76 ms /  1307 tokens (    5.66 ms per token,   176.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3195.45 ms /    77 runs   (   41.50 ms per token,    24.10 tokens per second)\n",
            "llama_print_timings:       total time =   10712.60 ms /  1384 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.51 ms /    69 runs   (    0.59 ms per token,  1703.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2327.62 ms /   444 tokens (    5.24 ms per token,   190.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2658.47 ms /    68 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5084.89 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     134.54 ms /   232 runs   (    0.58 ms per token,  1724.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2014.71 ms /   384 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =    9031.27 ms /   231 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   11400.57 ms /   615 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.27 ms /    75 runs   (    0.70 ms per token,  1434.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2734.83 ms /   517 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2913.82 ms /    74 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5781.65 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.69 ms /    87 runs   (    0.56 ms per token,  1786.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6455.54 ms /  1166 tokens (    5.54 ms per token,   180.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3537.93 ms /    86 runs   (   41.14 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =   10132.63 ms /  1252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.09 ms /    69 runs   (    0.55 ms per token,  1811.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3959.92 ms /   733 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2691.60 ms /    68 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    6756.61 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1720.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2285.68 ms /   440 tokens (    5.19 ms per token,   192.50 tokens per second)\n",
            "llama_print_timings:        eval time =     232.09 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    2538.38 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.30 ms /   129 runs   (    0.68 ms per token,  1477.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2026.88 ms /   386 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    4996.83 ms /   128 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    7252.97 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.93 ms /    96 runs   (    0.57 ms per token,  1747.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     169.98 ms /    32 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3700.02 ms /    95 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    3998.04 ms /   127 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.70 ms /    94 runs   (    0.58 ms per token,  1718.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.71 ms /   451 tokens (    5.26 ms per token,   190.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3645.88 ms /    93 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6151.98 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.82 ms /     7 runs   (    0.97 ms per token,  1026.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2226.10 ms /   421 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =     236.57 ms /     6 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    2483.82 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.04 ms /   105 runs   (    0.53 ms per token,  1873.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5978.21 ms /  1083 tokens (    5.52 ms per token,   181.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4242.32 ms /   104 runs   (   40.79 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =   10372.54 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.24 ms /    92 runs   (    0.62 ms per token,  1607.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2055.40 ms /   387 tokens (    5.31 ms per token,   188.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3544.12 ms /    91 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5747.14 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.59 ms /   256 runs   (    0.60 ms per token,  1655.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.65 ms /   391 tokens (    5.19 ms per token,   192.64 tokens per second)\n",
            "llama_print_timings:        eval time =    9970.44 ms /   255 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12425.02 ms /   646 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      22.26 ms /    42 runs   (    0.53 ms per token,  1886.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1982.24 ms /   382 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.12 ms /    41 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    3626.39 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.84 ms /    77 runs   (    0.62 ms per token,  1609.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3738.85 ms /   699 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3016.64 ms /    76 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6880.51 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1874.05 ms /   359 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =     233.35 ms /     6 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    2121.89 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.65 ms /     6 runs   (    0.61 ms per token,  1642.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.94 ms /   415 tokens (    5.21 ms per token,   192.05 tokens per second)\n",
            "llama_print_timings:        eval time =     193.02 ms /     5 runs   (   38.60 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2368.01 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1822.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1857.33 ms /   360 tokens (    5.16 ms per token,   193.83 tokens per second)\n",
            "llama_print_timings:        eval time =     268.82 ms /     7 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2141.77 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.57 ms /    65 runs   (    0.61 ms per token,  1642.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.71 ms /   508 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2513.98 ms /    64 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5289.18 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.92 ms /    79 runs   (    0.53 ms per token,  1884.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6158.18 ms /  1107 tokens (    5.56 ms per token,   179.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3186.86 ms /    78 runs   (   40.86 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =    9463.17 ms /  1185 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.94 ms /    64 runs   (    0.66 ms per token,  1526.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2676.64 ms /   512 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2509.17 ms /    64 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5292.10 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.13 ms /    67 runs   (    0.52 ms per token,  1907.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3904.03 ms /   725 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2602.13 ms /    66 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6599.76 ms /   791 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.91 ms /   111 runs   (    0.62 ms per token,  1610.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2677.88 ms /   510 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4320.64 ms /   110 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7176.00 ms /   620 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.20 ms /    58 runs   (    0.54 ms per token,  1858.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2269.18 ms /   432 tokens (    5.25 ms per token,   190.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2259.10 ms /    58 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4606.16 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.02 ms /   122 runs   (    0.56 ms per token,  1793.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1725.66 ms /   332 tokens (    5.20 ms per token,   192.39 tokens per second)\n",
            "llama_print_timings:        eval time =    4695.41 ms /   121 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    6586.51 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.04 ms /    54 runs   (    0.69 ms per token,  1457.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2006.39 ms /   380 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2068.55 ms /    53 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4167.44 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.90 ms /    65 runs   (    0.52 ms per token,  1917.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6454.90 ms /  1164 tokens (    5.55 ms per token,   180.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2625.25 ms /    64 runs   (   41.02 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    9175.71 ms /  1228 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.81 ms /    70 runs   (    0.54 ms per token,  1851.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6219.47 ms /  1117 tokens (    5.57 ms per token,   179.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2823.25 ms /    69 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =    9151.34 ms /  1186 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.54 ms /    76 runs   (    0.65 ms per token,  1533.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3834.31 ms /   714 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2995.20 ms /    75 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    6966.17 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.75 ms /   256 runs   (    0.55 ms per token,  1818.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1954.62 ms /   375 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
            "llama_print_timings:        eval time =    9971.85 ms /   255 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =   12308.35 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.58 ms /    58 runs   (    0.53 ms per token,  1896.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5812.54 ms /  1055 tokens (    5.51 ms per token,   181.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2317.09 ms /    57 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8217.23 ms /  1112 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.77 ms /    60 runs   (    0.58 ms per token,  1725.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1941.82 ms /   376 tokens (    5.16 ms per token,   193.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2333.87 ms /    60 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4360.10 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.57 ms /    65 runs   (    0.62 ms per token,  1602.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1580.06 ms /   301 tokens (    5.25 ms per token,   190.50 tokens per second)\n",
            "llama_print_timings:        eval time =    2479.48 ms /    64 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    4160.15 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.94 ms /    14 runs   (    0.57 ms per token,  1763.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1262.54 ms /   242 tokens (    5.22 ms per token,   191.68 tokens per second)\n",
            "llama_print_timings:        eval time =     498.21 ms /    13 runs   (   38.32 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    1781.31 ms /   255 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.31 ms /   256 runs   (    0.61 ms per token,  1627.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2028.28 ms /   390 tokens (    5.20 ms per token,   192.28 tokens per second)\n",
            "llama_print_timings:        eval time =    9958.49 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12414.30 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.95 ms /    70 runs   (    0.54 ms per token,  1844.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2329.53 ms /   444 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2703.45 ms /    69 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5127.16 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.22 ms /   129 runs   (    0.69 ms per token,  1445.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2116.15 ms /   408 tokens (    5.19 ms per token,   192.80 tokens per second)\n",
            "llama_print_timings:        eval time =    4999.53 ms /   128 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    7339.45 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.51 ms /    70 runs   (    0.56 ms per token,  1771.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6511.64 ms /  1176 tokens (    5.54 ms per token,   180.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2842.78 ms /    69 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
            "llama_print_timings:       total time =    9469.96 ms /  1245 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    12 runs   (    0.72 ms per token,  1380.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2227.24 ms /   424 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =     464.48 ms /    12 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2718.78 ms /   436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1840.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2725.35 ms /   516 tokens (    5.28 ms per token,   189.33 tokens per second)\n",
            "llama_print_timings:        eval time =     237.26 ms /     6 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    2979.06 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.30 ms /    86 runs   (    0.64 ms per token,  1555.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6214.46 ms /  1122 tokens (    5.54 ms per token,   180.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3499.28 ms /    85 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    9876.79 ms /  1207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.70 ms /   256 runs   (    0.58 ms per token,  1721.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2169.25 ms /   410 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =    9988.06 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12563.46 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     130.99 ms /   232 runs   (    0.56 ms per token,  1771.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1836.85 ms /   349 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    8982.52 ms /   231 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =   11156.63 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.39 ms /    79 runs   (    0.64 ms per token,  1567.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2223.14 ms /   419 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3033.57 ms /    78 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    5383.85 ms /   497 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._l2_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_cosine_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_AES CORP_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_ip_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.38 ms /    77 runs   (    0.54 ms per token,  1860.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4380.60 ms /   810 tokens (    5.41 ms per token,   184.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3026.86 ms /    76 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7517.73 ms /   886 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.43 ms /    71 runs   (    0.61 ms per token,  1634.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3104.11 ms /   581 tokens (    5.34 ms per token,   187.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2758.81 ms /    70 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =    5974.65 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.61 ms /    91 runs   (    0.53 ms per token,  1872.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4021.31 ms /   752 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3603.21 ms /    91 runs   (   39.60 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    7753.47 ms /   843 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.46 ms /    84 runs   (    0.55 ms per token,  1808.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6131.57 ms /  1104 tokens (    5.55 ms per token,   180.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3430.57 ms /    84 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    9697.20 ms /  1188 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.16 ms /    72 runs   (    0.70 ms per token,  1435.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3981.40 ms /   743 tokens (    5.36 ms per token,   186.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2841.88 ms /    71 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6958.36 ms /   814 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.60 ms /    77 runs   (    0.54 ms per token,  1850.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2782.43 ms /   528 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3018.63 ms /    77 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5913.07 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.25 ms /    84 runs   (    0.63 ms per token,  1577.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4342.15 ms /   807 tokens (    5.38 ms per token,   185.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3339.73 ms /    83 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7830.43 ms /   890 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.47 ms /    74 runs   (    0.56 ms per token,  1784.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4764.70 ms /   874 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2930.23 ms /    73 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7806.88 ms /   947 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.78 ms /   100 runs   (    0.60 ms per token,  1672.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4361.97 ms /   805 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3968.71 ms /    99 runs   (   40.09 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    8494.61 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.04 ms /   128 runs   (    0.56 ms per token,  1776.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.59 ms /   530 tokens (    5.30 ms per token,   188.71 tokens per second)\n",
            "llama_print_timings:        eval time =    4979.05 ms /   127 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7970.06 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     134.88 ms /   243 runs   (    0.56 ms per token,  1801.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3118.11 ms /   584 tokens (    5.34 ms per token,   187.29 tokens per second)\n",
            "llama_print_timings:        eval time =    9567.93 ms /   243 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   13049.63 ms /   827 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.73 ms /    68 runs   (    0.55 ms per token,  1802.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4294.16 ms /   788 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2663.63 ms /    67 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7062.42 ms /   855 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.40 ms /    68 runs   (    0.56 ms per token,  1770.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4020.63 ms /   746 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2653.42 ms /    67 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    6775.37 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.01 ms /   120 runs   (    0.56 ms per token,  1790.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4521.81 ms /   828 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4758.55 ms /   119 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    9459.75 ms /   947 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     155.45 ms /   256 runs   (    0.61 ms per token,  1646.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2589.70 ms /   490 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =   10023.66 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13040.43 ms /   745 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.15 ms /    83 runs   (    0.59 ms per token,  1688.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2549.65 ms /   488 tokens (    5.22 ms per token,   191.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3215.27 ms /    82 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5894.95 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.92 ms /    68 runs   (    0.56 ms per token,  1793.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3864.58 ms /   719 tokens (    5.37 ms per token,   186.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2656.93 ms /    67 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    6620.78 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.76 ms /    86 runs   (    0.68 ms per token,  1463.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4341.39 ms /   808 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3458.66 ms /    86 runs   (   40.22 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7957.07 ms /   894 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.45 ms /   116 runs   (    0.55 ms per token,  1828.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3487.79 ms /   651 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4519.24 ms /   115 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    8176.06 ms /   766 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.48 ms /    66 runs   (    0.64 ms per token,  1553.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4410.30 ms /   814 tokens (    5.42 ms per token,   184.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2613.44 ms /    65 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7140.87 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2814.92 ms /   536 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
            "llama_print_timings:        eval time =     233.29 ms /     6 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    3064.05 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.74 ms /    99 runs   (    0.63 ms per token,  1577.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4019.51 ms /   750 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3921.72 ms /    98 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    8112.41 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.87 ms /    75 runs   (    0.56 ms per token,  1791.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4359.78 ms /   806 tokens (    5.41 ms per token,   184.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2950.44 ms /    74 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7422.84 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.84 ms /    80 runs   (    0.66 ms per token,  1513.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4722.27 ms /   872 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3238.38 ms /    80 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    8106.27 ms /   952 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.03 ms /    64 runs   (    0.56 ms per token,  1776.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4387.11 ms /   811 tokens (    5.41 ms per token,   184.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2509.59 ms /    63 runs   (   39.83 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    6994.59 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.34 ms /    65 runs   (    0.54 ms per token,  1839.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6121.94 ms /  1102 tokens (    5.56 ms per token,   180.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2612.45 ms /    64 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    8836.04 ms /  1166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.51 ms /    78 runs   (    0.57 ms per token,  1752.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2809.29 ms /   532 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3024.62 ms /    77 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5944.00 ms /   609 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.30 ms /    69 runs   (    0.56 ms per token,  1801.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4298.13 ms /   787 tokens (    5.46 ms per token,   183.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.28 ms /    68 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7107.47 ms /   855 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.45 ms /    69 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2072.35 ms /   397 tokens (    5.22 ms per token,   191.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2653.35 ms /    68 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4822.50 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.55 ms /     7 runs   (    0.79 ms per token,  1261.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2637.31 ms /   498 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =     238.25 ms /     6 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    2895.15 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.44 ms /   113 runs   (    0.59 ms per token,  1700.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2014.80 ms /   382 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4368.63 ms /   112 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    6552.28 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.02 ms /    77 runs   (    0.62 ms per token,  1603.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4710.73 ms /   872 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3103.41 ms /    77 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7951.33 ms /   949 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.62 ms /    96 runs   (    0.57 ms per token,  1757.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3543.53 ms /   660 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3731.15 ms /    95 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7416.91 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.15 ms /    91 runs   (    0.60 ms per token,  1680.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2161.72 ms /   412 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3505.12 ms /    90 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    5806.04 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.58 ms /   256 runs   (    0.57 ms per token,  1758.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2888.12 ms /   539 tokens (    5.36 ms per token,   186.63 tokens per second)\n",
            "llama_print_timings:        eval time =   10033.95 ms /   255 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   13328.46 ms /   794 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      10.36 ms /    14 runs   (    0.74 ms per token,  1350.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1624.93 ms /   307 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
            "llama_print_timings:        eval time =     503.02 ms /    13 runs   (   38.69 ms per token,    25.84 tokens per second)\n",
            "llama_print_timings:       total time =    2160.21 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2297.80 ms /   440 tokens (    5.22 ms per token,   191.49 tokens per second)\n",
            "llama_print_timings:        eval time =     268.40 ms /     7 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2581.82 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.55 ms /    81 runs   (    0.61 ms per token,  1634.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5981.68 ms /  1088 tokens (    5.50 ms per token,   181.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3281.18 ms /    80 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    9406.45 ms /  1168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      20.95 ms /    39 runs   (    0.54 ms per token,  1861.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3954.54 ms /   736 tokens (    5.37 ms per token,   186.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.34 ms /    38 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    5527.04 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.13 ms /   113 runs   (    0.66 ms per token,  1504.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6034.33 ms /  1093 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4611.17 ms /   112 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =   10854.19 ms /  1205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.74 ms /    76 runs   (    0.56 ms per token,  1777.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5504.63 ms /  1002 tokens (    5.49 ms per token,   182.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3041.66 ms /    75 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    8661.85 ms /  1077 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.58 ms /    73 runs   (    0.51 ms per token,  1942.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4747.59 ms /   866 tokens (    5.48 ms per token,   182.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2887.42 ms /    72 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    7742.74 ms /   938 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.29 ms /    99 runs   (    0.61 ms per token,  1642.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3030.50 ms /   570 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3864.93 ms /    98 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7052.14 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.58 ms /    67 runs   (    0.59 ms per token,  1692.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3646.87 ms /   680 tokens (    5.36 ms per token,   186.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2636.20 ms /    67 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6385.38 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.94 ms /    60 runs   (    0.60 ms per token,  1669.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4665.51 ms /   861 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2377.26 ms /    59 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    7142.75 ms /   920 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.16 ms /    65 runs   (    0.57 ms per token,  1749.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4053.64 ms /   748 tokens (    5.42 ms per token,   184.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2533.35 ms /    64 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    6690.91 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.17 ms /    83 runs   (    0.66 ms per token,  1504.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4574.26 ms /   847 tokens (    5.40 ms per token,   185.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3306.10 ms /    82 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    8027.33 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.07 ms /    86 runs   (    0.56 ms per token,  1789.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4358.72 ms /   808 tokens (    5.39 ms per token,   185.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3425.30 ms /    86 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7911.86 ms /   894 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.17 ms /   256 runs   (    0.62 ms per token,  1618.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     890.65 ms /   176 tokens (    5.06 ms per token,   197.61 tokens per second)\n",
            "llama_print_timings:        eval time =    9891.49 ms /   256 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
            "llama_print_timings:       total time =   11210.93 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.10 ms /    60 runs   (    0.60 ms per token,  1661.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3701.92 ms /   694 tokens (    5.33 ms per token,   187.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2333.91 ms /    59 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6132.41 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.35 ms /   256 runs   (    0.59 ms per token,  1702.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2052.67 ms /   387 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =    9947.10 ms /   255 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12397.65 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.29 ms /   256 runs   (    0.58 ms per token,  1726.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2048.27 ms /   387 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9943.64 ms /   255 runs   (   38.99 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12389.04 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.24 ms /    66 runs   (    0.72 ms per token,  1397.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     936.24 ms /   184 tokens (    5.09 ms per token,   196.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2530.46 ms /    66 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    3584.68 ms /   250 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1620.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1875.24 ms /   359 tokens (    5.22 ms per token,   191.44 tokens per second)\n",
            "llama_print_timings:        eval time =     234.04 ms /     6 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    2126.50 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.41 ms /     6 runs   (    0.57 ms per token,  1759.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2813.33 ms /   536 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     198.08 ms /     5 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    3026.29 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.32 ms /    76 runs   (    0.54 ms per token,  1839.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3077.43 ms /   582 tokens (    5.29 ms per token,   189.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2946.70 ms /    75 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6132.50 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.65 ms per token,  1527.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2190.35 ms /   414 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =     231.51 ms /     6 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2439.93 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.45 ms /    70 runs   (    0.58 ms per token,  1730.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2088.88 ms /   399 tokens (    5.24 ms per token,   191.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2686.10 ms /    69 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4876.04 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.45 ms /    79 runs   (    0.60 ms per token,  1664.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4381.91 ms /   810 tokens (    5.41 ms per token,   184.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3128.63 ms /    78 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    7640.09 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.42 ms /    69 runs   (    0.64 ms per token,  1553.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     137.53 ms /    23 tokens (    5.98 ms per token,   167.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2726.80 ms /    68 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    2982.14 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.84 ms /    69 runs   (    0.53 ms per token,  1873.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4758.23 ms /   880 tokens (    5.41 ms per token,   184.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2728.11 ms /    68 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    7586.67 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.18 ms /     7 runs   (    0.74 ms per token,  1351.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2562.46 ms /   486 tokens (    5.27 ms per token,   189.66 tokens per second)\n",
            "llama_print_timings:        eval time =     234.65 ms /     6 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    2820.95 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.07 ms /     7 runs   (    0.58 ms per token,  1720.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2362.20 ms /   448 tokens (    5.27 ms per token,   189.65 tokens per second)\n",
            "llama_print_timings:        eval time =     231.94 ms /     6 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
            "llama_print_timings:       total time =    2610.71 ms /   454 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.51 ms /    68 runs   (    0.55 ms per token,  1812.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4756.60 ms /   878 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2685.50 ms /    67 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7543.04 ms /   945 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     101.80 ms /   176 runs   (    0.58 ms per token,  1728.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3763.72 ms /   698 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =    6957.93 ms /   175 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =   10994.34 ms /   873 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_l2_1.json\n",
            "KeyError occurred: 'ip'. Skipping approach 2 for dataframe results_approach_AES CORP_l2_2.json\n",
            "Total score for approach 2 and distance function ip is 0.35714285714285715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(2, 'l2')"
      ],
      "metadata": {
        "id": "vDMuX3Ta3nC3",
        "outputId": "704ddc73-3cf6-4149-bd5a-aa013a5facd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_COCA COLA CO_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.72 ms /   109 runs   (    0.60 ms per token,  1658.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5956.29 ms /  1077 tokens (    5.53 ms per token,   180.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4423.15 ms /   108 runs   (   40.96 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =   10568.34 ms /  1185 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.69 ms /    86 runs   (    0.61 ms per token,  1632.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5029.92 ms /   922 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3440.90 ms /    85 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    8618.36 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.67 ms /    80 runs   (    0.56 ms per token,  1790.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4407.96 ms /   810 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3149.37 ms /    79 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7679.48 ms /   889 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.72 ms /    69 runs   (    0.69 ms per token,  1446.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5045.60 ms /   926 tokens (    5.45 ms per token,   183.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2765.06 ms /    68 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    7943.41 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.64 ms /    88 runs   (    0.56 ms per token,  1772.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3930.77 ms /   736 tokens (    5.34 ms per token,   187.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3444.67 ms /    87 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    7508.61 ms /   823 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.24 ms /    12 runs   (    0.69 ms per token,  1456.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2817.00 ms /   531 tokens (    5.31 ms per token,   188.50 tokens per second)\n",
            "llama_print_timings:        eval time =     430.62 ms /    11 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    3275.36 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.92 ms /    82 runs   (    0.56 ms per token,  1785.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5019.82 ms /   919 tokens (    5.46 ms per token,   183.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3258.12 ms /    81 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8405.25 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.64 ms /    86 runs   (    0.72 ms per token,  1395.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4340.20 ms /   803 tokens (    5.40 ms per token,   185.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3416.31 ms /    85 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7921.65 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.71 ms /    80 runs   (    0.53 ms per token,  1873.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5931.71 ms /  1074 tokens (    5.52 ms per token,   181.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3217.60 ms /    79 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    9270.33 ms /  1153 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.59 ms /    81 runs   (    0.56 ms per token,  1776.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5031.46 ms /   917 tokens (    5.49 ms per token,   182.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3220.58 ms /    80 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8377.20 ms /   997 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      85.43 ms /   136 runs   (    0.63 ms per token,  1591.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5984.69 ms /  1083 tokens (    5.53 ms per token,   180.96 tokens per second)\n",
            "llama_print_timings:        eval time =    5547.99 ms /   135 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   11766.19 ms /  1218 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.20 ms /    91 runs   (    0.64 ms per token,  1563.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4697.86 ms /   866 tokens (    5.42 ms per token,   184.34 tokens per second)\n",
            "llama_print_timings:        eval time =    3622.65 ms /    90 runs   (   40.25 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    8477.34 ms /   956 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.49 ms /    70 runs   (    0.55 ms per token,  1818.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3997.18 ms /   739 tokens (    5.41 ms per token,   184.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2737.05 ms /    69 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6842.50 ms /   808 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.87 ms /   249 runs   (    0.62 ms per token,  1607.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3928.57 ms /   735 tokens (    5.34 ms per token,   187.09 tokens per second)\n",
            "llama_print_timings:        eval time =    9931.95 ms /   248 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =   14284.72 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.37 ms /    79 runs   (    0.66 ms per token,  1508.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5325.10 ms /   972 tokens (    5.48 ms per token,   182.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3173.12 ms /    78 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    8640.01 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.82 ms /   256 runs   (    0.58 ms per token,  1720.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5212.10 ms /   954 tokens (    5.46 ms per token,   183.04 tokens per second)\n",
            "llama_print_timings:        eval time =   10391.74 ms /   255 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =   16039.68 ms /  1209 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      90.11 ms /   150 runs   (    0.60 ms per token,  1664.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1519.03 ms /   296 tokens (    5.13 ms per token,   194.86 tokens per second)\n",
            "llama_print_timings:        eval time =    5790.43 ms /   150 runs   (   38.60 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    7540.07 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.31 ms /    11 runs   (    0.57 ms per token,  1743.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2656.25 ms /   499 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =     392.50 ms /    10 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    3071.42 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.34 ms /    97 runs   (    0.55 ms per token,  1818.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3698.08 ms /   692 tokens (    5.34 ms per token,   187.12 tokens per second)\n",
            "llama_print_timings:        eval time =    3788.16 ms /    96 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7623.70 ms /   788 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.26 ms /    89 runs   (    0.63 ms per token,  1581.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2301.24 ms /   440 tokens (    5.23 ms per token,   191.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3459.47 ms /    89 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    5906.72 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.85 ms /    71 runs   (    0.56 ms per token,  1781.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3973.15 ms /   743 tokens (    5.35 ms per token,   187.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2762.56 ms /    70 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6840.66 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.37 ms /   256 runs   (    0.56 ms per token,  1798.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2504.37 ms /   474 tokens (    5.28 ms per token,   189.27 tokens per second)\n",
            "llama_print_timings:        eval time =    9982.39 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12885.60 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.97 ms /    67 runs   (    0.67 ms per token,  1489.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3985.10 ms /   738 tokens (    5.40 ms per token,   185.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2634.13 ms /    66 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    6740.48 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.04 ms /    84 runs   (    0.55 ms per token,  1824.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1896.46 ms /   364 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3220.06 ms /    83 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
            "llama_print_timings:       total time =    5227.21 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.08 ms /    70 runs   (    0.60 ms per token,  1663.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.68 ms /   397 tokens (    5.21 ms per token,   191.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2683.16 ms /    69 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    4855.67 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.88 ms /   106 runs   (    0.56 ms per token,  1770.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2699.32 ms /   509 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =    4122.32 ms /   105 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6962.01 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.80 ms /   123 runs   (    0.62 ms per token,  1622.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2717.48 ms /   520 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4840.95 ms /   123 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    7742.16 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.53 ms /   256 runs   (    0.57 ms per token,  1759.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2554.02 ms /   483 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =   10025.22 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   12964.63 ms /   738 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1901.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1508.45 ms /   279 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =     233.55 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    1755.88 ms /   285 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     7 runs   (    0.50 ms per token,  1983.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2459.02 ms /   471 tokens (    5.22 ms per token,   191.54 tokens per second)\n",
            "llama_print_timings:        eval time =     231.02 ms /     6 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2703.29 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.20 ms /   250 runs   (    0.59 ms per token,  1698.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.45 ms /   391 tokens (    5.19 ms per token,   192.85 tokens per second)\n",
            "llama_print_timings:        eval time =    9740.75 ms /   249 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12161.29 ms /   640 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.99 ms /   256 runs   (    0.59 ms per token,  1695.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2203.99 ms /   424 tokens (    5.20 ms per token,   192.38 tokens per second)\n",
            "llama_print_timings:        eval time =   10045.92 ms /   256 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12649.51 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.75 ms /    79 runs   (    0.54 ms per token,  1847.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2856.58 ms /   544 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3106.62 ms /    79 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6065.96 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.47 ms /   256 runs   (    0.58 ms per token,  1724.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2367.01 ms /   452 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =    9985.27 ms /   255 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12733.05 ms /   707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.80 ms /    94 runs   (    0.65 ms per token,  1546.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2026.07 ms /   390 tokens (    5.20 ms per token,   192.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3620.47 ms /    93 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5791.59 ms /   483 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.48 ms /    70 runs   (    0.52 ms per token,  1918.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3701.93 ms /   690 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2717.56 ms /    69 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6511.27 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.86 ms /   119 runs   (    0.66 ms per token,  1508.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3969.98 ms /   744 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =    4708.45 ms /   118 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    8869.54 ms /   862 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1840.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2325.40 ms /   445 tokens (    5.23 ms per token,   191.36 tokens per second)\n",
            "llama_print_timings:        eval time =     230.39 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2569.75 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     9 runs   (    0.55 ms per token,  1833.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1348.04 ms /   263 tokens (    5.13 ms per token,   195.10 tokens per second)\n",
            "llama_print_timings:        eval time =     304.50 ms /     8 runs   (   38.06 ms per token,    26.27 tokens per second)\n",
            "llama_print_timings:       total time =    1666.97 ms /   271 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     6 runs   (    0.61 ms per token,  1650.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5886.46 ms /  1066 tokens (    5.52 ms per token,   181.09 tokens per second)\n",
            "llama_print_timings:        eval time =     205.80 ms /     5 runs   (   41.16 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =    6113.80 ms /  1071 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2429.33 ms /   462 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =     232.54 ms /     6 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2677.38 ms /   468 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.60 ms /   256 runs   (    0.62 ms per token,  1614.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2714.78 ms /   515 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =   10066.31 ms /   255 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   13195.54 ms /   770 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.64 ms /   256 runs   (    0.57 ms per token,  1769.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2757.84 ms /   523 tokens (    5.27 ms per token,   189.64 tokens per second)\n",
            "llama_print_timings:        eval time =   10066.21 ms /   255 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =   13217.54 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.62 ms /    66 runs   (    0.54 ms per token,  1852.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3918.07 ms /   731 tokens (    5.36 ms per token,   186.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2553.35 ms /    65 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6559.41 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.16 ms /    71 runs   (    0.72 ms per token,  1387.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2764.34 ms /   526 tokens (    5.26 ms per token,   190.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2748.24 ms /    70 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5633.90 ms /   596 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.52 ms /   109 runs   (    0.55 ms per token,  1831.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4067.47 ms /   760 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4318.51 ms /   109 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    8530.61 ms /   869 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      97.72 ms /   169 runs   (    0.58 ms per token,  1729.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3939.93 ms /   731 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
            "llama_print_timings:        eval time =    6674.31 ms /   168 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =   10855.43 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.14 ms /   100 runs   (    0.63 ms per token,  1583.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4652.43 ms /   861 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3997.62 ms /    99 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    8810.48 ms /   960 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.35 ms /    85 runs   (    0.55 ms per token,  1833.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4790.89 ms /   888 tokens (    5.40 ms per token,   185.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3414.09 ms /    85 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8320.03 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.08 ms /    88 runs   (    0.59 ms per token,  1689.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2692.79 ms /   512 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
            "llama_print_timings:        eval time =    3442.26 ms /    88 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6259.96 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.80 ms /    84 runs   (    0.56 ms per token,  1794.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1256.43 ms /   234 tokens (    5.37 ms per token,   186.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3230.80 ms /    83 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4593.72 ms /   317 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.79 ms /   100 runs   (    0.66 ms per token,  1519.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3472.88 ms /   653 tokens (    5.32 ms per token,   188.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3930.47 ms /    99 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7567.81 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.78 ms /   104 runs   (    0.54 ms per token,  1864.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3871.94 ms /   723 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    4063.58 ms /   103 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    8072.07 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.71 ms /   256 runs   (    0.55 ms per token,  1806.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2513.79 ms /   475 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =    9967.76 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12845.27 ms /   730 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.80 ms /    65 runs   (    0.57 ms per token,  1766.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4093.26 ms /   756 tokens (    5.41 ms per token,   184.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2539.05 ms /    64 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6725.91 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.18 ms /    67 runs   (    0.54 ms per token,  1851.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3244.28 ms /   611 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2590.13 ms /    66 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    5922.57 ms /   677 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.01 ms /    87 runs   (    0.70 ms per token,  1425.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3128.39 ms /   589 tokens (    5.31 ms per token,   188.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3388.71 ms /    86 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6656.78 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.19 ms /    72 runs   (    0.54 ms per token,  1837.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5015.07 ms /   923 tokens (    5.43 ms per token,   184.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2853.49 ms /    71 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7967.03 ms /   994 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.41 ms /    96 runs   (    0.56 ms per token,  1797.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5202.05 ms /   948 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =    3828.21 ms /    95 runs   (   40.30 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    9166.24 ms /  1043 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.02 ms /    68 runs   (    0.54 ms per token,  1837.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2277.72 ms /   436 tokens (    5.22 ms per token,   191.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2612.14 ms /    67 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    4976.98 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.84 ms /   256 runs   (    0.57 ms per token,  1755.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2179.02 ms /   415 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
            "llama_print_timings:        eval time =    9977.72 ms /   255 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12525.51 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.09 ms /   109 runs   (    0.61 ms per token,  1649.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1949.59 ms /   371 tokens (    5.25 ms per token,   190.30 tokens per second)\n",
            "llama_print_timings:        eval time =    4202.51 ms /   108 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    6308.86 ms /   479 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.09 ms /   256 runs   (    0.57 ms per token,  1752.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2628.49 ms /   501 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =   10027.41 ms /   255 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   13047.48 ms /   756 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.91 ms /   103 runs   (    0.54 ms per token,  1842.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2196.81 ms /   421 tokens (    5.22 ms per token,   191.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3968.80 ms /   102 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    6295.86 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.07 ms /   250 runs   (    0.59 ms per token,  1699.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2177.35 ms /   414 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
            "llama_print_timings:        eval time =    9746.28 ms /   249 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12292.77 ms /   663 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     7 runs   (    0.55 ms per token,  1826.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1806.37 ms /   349 tokens (    5.18 ms per token,   193.21 tokens per second)\n",
            "llama_print_timings:        eval time =     233.07 ms /     6 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2051.88 ms /   355 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.84 ms /     7 runs   (    0.69 ms per token,  1447.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1778.47 ms /   340 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
            "llama_print_timings:        eval time =     234.25 ms /     6 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    2027.90 ms /   346 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.49 ms /    70 runs   (    0.55 ms per token,  1818.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4220.03 ms /   778 tokens (    5.42 ms per token,   184.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2733.84 ms /    69 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    7050.12 ms /   847 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.45 ms /    70 runs   (    0.64 ms per token,  1574.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4005.81 ms /   748 tokens (    5.36 ms per token,   186.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2739.65 ms /    69 runs   (   39.71 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6855.75 ms /   817 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AMAZON COM INC_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.35 ms /   116 runs   (    0.53 ms per token,  1890.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5271.48 ms /   965 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4642.26 ms /   115 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =   10067.84 ms /  1080 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.94 ms /    76 runs   (    0.67 ms per token,  1492.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2815.97 ms /   532 tokens (    5.29 ms per token,   188.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2952.53 ms /    75 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5888.38 ms /   607 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.68 ms /   114 runs   (    0.58 ms per token,  1735.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5297.55 ms /   971 tokens (    5.46 ms per token,   183.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4568.56 ms /   113 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =   10030.40 ms /  1084 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.84 ms /    74 runs   (    0.55 ms per token,  1812.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2789.02 ms /   526 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2864.34 ms /    73 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5749.52 ms /   599 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      21.94 ms /    41 runs   (    0.54 ms per token,  1868.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3024.32 ms /   573 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.56 ms /    40 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    4645.81 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.52 ms /    72 runs   (    0.69 ms per token,  1453.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.01 ms /   528 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2825.08 ms /    72 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5709.53 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.59 ms /    75 runs   (    0.54 ms per token,  1847.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     167.17 ms /    26 tokens (    6.43 ms per token,   155.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2908.93 ms /    74 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3167.33 ms /   100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.20 ms /    94 runs   (    0.56 ms per token,  1800.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3023.19 ms /   574 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3650.41 ms /    93 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6799.96 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.44 ms /    79 runs   (    0.65 ms per token,  1535.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5290.84 ms /   968 tokens (    5.47 ms per token,   182.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3211.55 ms /    79 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8639.30 ms /  1047 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     6 runs   (    0.64 ms per token,  1553.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5311.39 ms /   971 tokens (    5.47 ms per token,   182.81 tokens per second)\n",
            "llama_print_timings:        eval time =     201.54 ms /     5 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    5535.07 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.76 ms /    85 runs   (    0.54 ms per token,  1857.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5368.30 ms /   979 tokens (    5.48 ms per token,   182.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3390.31 ms /    84 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    8878.11 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.71 ms /    69 runs   (    0.62 ms per token,  1615.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4894.92 ms /   899 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2739.53 ms /    68 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    7742.81 ms /   967 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     120.96 ms /   207 runs   (    0.58 ms per token,  1711.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2803.46 ms /   534 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
            "llama_print_timings:        eval time =    8126.55 ms /   206 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   11248.91 ms /   740 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     132.11 ms /   256 runs   (    0.52 ms per token,  1937.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3107.64 ms /   581 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =   10030.24 ms /   255 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =   13488.71 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.74 ms /    77 runs   (    0.54 ms per token,  1844.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5381.96 ms /   981 tokens (    5.49 ms per token,   182.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3065.83 ms /    76 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    8556.19 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.99 ms /    76 runs   (    0.75 ms per token,  1333.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4881.37 ms /   901 tokens (    5.42 ms per token,   184.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3038.46 ms /    75 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    8058.84 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.94 ms /    70 runs   (    0.53 ms per token,  1894.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.77 ms /   536 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2713.47 ms /    69 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5613.89 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.45 ms /    76 runs   (    0.70 ms per token,  1421.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5421.32 ms /   986 tokens (    5.50 ms per token,   181.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3076.75 ms /    75 runs   (   41.02 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    8657.61 ms /  1061 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.90 ms /    70 runs   (    0.64 ms per token,  1559.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     139.47 ms /    21 tokens (    6.64 ms per token,   150.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2803.16 ms /    69 runs   (   40.63 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    3048.09 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.63 ms /    79 runs   (    0.55 ms per token,  1810.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4885.14 ms /   903 tokens (    5.41 ms per token,   184.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3133.93 ms /    78 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    8127.45 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.81 ms /   106 runs   (    0.53 ms per token,  1899.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5289.81 ms /   963 tokens (    5.49 ms per token,   182.05 tokens per second)\n",
            "llama_print_timings:        eval time =    4236.57 ms /   105 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    9670.92 ms /  1068 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.96 ms /    98 runs   (    0.72 ms per token,  1381.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5229.87 ms /   960 tokens (    5.45 ms per token,   183.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3996.36 ms /    98 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    9411.29 ms /  1058 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.59 ms /   113 runs   (    0.55 ms per token,  1834.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2817.13 ms /   533 tokens (    5.29 ms per token,   189.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4406.75 ms /   112 runs   (   39.35 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7371.00 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.89 ms /    69 runs   (    0.58 ms per token,  1729.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3102.53 ms /   580 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2663.03 ms /    68 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5865.24 ms /   648 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.25 ms /   256 runs   (    0.61 ms per token,  1638.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1851.15 ms /   359 tokens (    5.16 ms per token,   193.93 tokens per second)\n",
            "llama_print_timings:        eval time =    9962.75 ms /   255 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =   12215.65 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.20 ms /    75 runs   (    0.70 ms per token,  1436.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4892.19 ms /   899 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2996.95 ms /    74 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    8022.28 ms /   973 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.86 ms /    71 runs   (    0.59 ms per token,  1695.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3592.15 ms /   670 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2765.68 ms /    70 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6460.63 ms /   740 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.25 ms /    77 runs   (    0.54 ms per token,  1866.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3246.49 ms /   614 tokens (    5.29 ms per token,   189.13 tokens per second)\n",
            "llama_print_timings:        eval time =    2994.54 ms /    76 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6341.86 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.30 ms /    91 runs   (    0.61 ms per token,  1645.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2904.55 ms /   546 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3542.32 ms /    90 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6587.34 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.69 ms /    67 runs   (    0.50 ms per token,  1988.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3646.92 ms /   683 tokens (    5.34 ms per token,   187.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2598.35 ms /    66 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6330.17 ms /   749 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.40 ms /     6 runs   (    1.07 ms per token,   937.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.70 ms /   464 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =     233.14 ms /     6 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2668.71 ms /   470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.97 ms /    80 runs   (    0.64 ms per token,  1569.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3308.51 ms /   615 tokens (    5.38 ms per token,   185.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3144.74 ms /    79 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6594.29 ms /   694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.59 ms /    70 runs   (    0.51 ms per token,  1966.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2408.16 ms /   458 tokens (    5.26 ms per token,   190.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2694.10 ms /    69 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5187.20 ms /   527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.72 ms /    66 runs   (    0.66 ms per token,  1509.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3209.47 ms /   608 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2566.59 ms /    65 runs   (   39.49 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    5880.42 ms /   673 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.65 ms /   256 runs   (    0.54 ms per token,  1846.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1574.50 ms /   301 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =    9897.27 ms /   255 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =   11828.35 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     162.89 ms /   256 runs   (    0.64 ms per token,  1571.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1342.94 ms /   248 tokens (    5.42 ms per token,   184.67 tokens per second)\n",
            "llama_print_timings:        eval time =   10067.10 ms /   256 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   11814.23 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.74 ms /   102 runs   (    0.60 ms per token,  1679.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2386.26 ms /   456 tokens (    5.23 ms per token,   191.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3936.58 ms /   101 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    6474.15 ms /   557 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1851.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.03 ms /   429 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
            "llama_print_timings:        eval time =     229.44 ms /     6 runs   (   38.24 ms per token,    26.15 tokens per second)\n",
            "llama_print_timings:       total time =    2482.46 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.11 ms /    74 runs   (    0.54 ms per token,  1844.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2720.07 ms /   519 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2861.05 ms /    73 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5676.59 ms /   592 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.90 ms /     6 runs   (    0.48 ms per token,  2069.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5256.40 ms /   954 tokens (    5.51 ms per token,   181.49 tokens per second)\n",
            "llama_print_timings:        eval time =     201.18 ms /     5 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    5477.14 ms /   959 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.21 ms /    11 runs   (    0.56 ms per token,  1771.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.33 ms /   455 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =     388.49 ms /    10 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    2779.75 ms /   465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      90.74 ms /   133 runs   (    0.68 ms per token,  1465.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3237.72 ms /   605 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =    5221.77 ms /   132 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    8682.06 ms /   737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.16 ms /    67 runs   (    0.55 ms per token,  1802.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5208.36 ms /   954 tokens (    5.46 ms per token,   183.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2657.44 ms /    66 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =    7959.57 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.19 ms /    93 runs   (    0.63 ms per token,  1598.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2738.25 ms /   520 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3644.39 ms /    93 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6522.61 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.59 ms /    69 runs   (    0.56 ms per token,  1788.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.86 ms /    22 tokens (    5.81 ms per token,   172.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2670.10 ms /    68 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    2887.28 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.83 ms /     9 runs   (    0.54 ms per token,  1863.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2586.85 ms /   495 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =     315.05 ms /     8 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    2919.54 ms /   503 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     166.60 ms /   256 runs   (    0.65 ms per token,  1536.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.46 ms /   531 tokens (    5.29 ms per token,   189.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10082.15 ms /   255 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =   13350.79 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.91 ms /    71 runs   (    0.67 ms per token,  1481.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3563.90 ms /   668 tokens (    5.34 ms per token,   187.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2781.04 ms /    70 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6475.16 ms /   738 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.98 ms /    69 runs   (    0.56 ms per token,  1770.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2425.53 ms /   462 tokens (    5.25 ms per token,   190.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2661.05 ms /    68 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5188.13 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.41 ms /    64 runs   (    0.57 ms per token,  1757.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3472.99 ms /   654 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2488.61 ms /    63 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6056.63 ms /   717 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     102.17 ms /   158 runs   (    0.65 ms per token,  1546.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3198.28 ms /   598 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
            "llama_print_timings:        eval time =    6223.20 ms /   157 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    9697.25 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.52 ms /    59 runs   (    0.67 ms per token,  1493.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3479.43 ms /   656 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2361.55 ms /    59 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    5951.20 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.89 ms /    63 runs   (    0.55 ms per token,  1805.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2381.51 ms /   451 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2421.57 ms /    62 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4892.11 ms /   513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.87 ms /    12 runs   (    0.57 ms per token,  1745.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1643.60 ms /   319 tokens (    5.15 ms per token,   194.09 tokens per second)\n",
            "llama_print_timings:        eval time =     421.80 ms /    11 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2084.82 ms /   330 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.01 ms /    12 runs   (    0.58 ms per token,  1711.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1455.70 ms /   267 tokens (    5.45 ms per token,   183.42 tokens per second)\n",
            "llama_print_timings:        eval time =     426.77 ms /    11 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    1903.96 ms /   278 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.79 ms /    93 runs   (    0.65 ms per token,  1529.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3086.92 ms /   580 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3631.57 ms /    92 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6874.49 ms /   672 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.63 ms /    72 runs   (    0.56 ms per token,  1772.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.45 ms /   533 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2781.45 ms /    71 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5693.58 ms /   604 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2632.52 ms /   500 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =     235.27 ms /     6 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    2887.53 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.45 ms /   120 runs   (    0.58 ms per token,  1727.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2469.67 ms /   460 tokens (    5.37 ms per token,   186.26 tokens per second)\n",
            "llama_print_timings:        eval time =    4669.06 ms /   119 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7315.96 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.05 ms /   125 runs   (    0.58 ms per token,  1711.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1897.50 ms /   362 tokens (    5.24 ms per token,   190.78 tokens per second)\n",
            "llama_print_timings:        eval time =    4838.73 ms /   124 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    6919.04 ms /   486 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.98 ms /     7 runs   (    0.57 ms per token,  1760.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2489.93 ms /   468 tokens (    5.32 ms per token,   187.96 tokens per second)\n",
            "llama_print_timings:        eval time =     233.32 ms /     6 runs   (   38.89 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    2740.24 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.87 ms /    74 runs   (    0.58 ms per token,  1726.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5400.35 ms /   984 tokens (    5.49 ms per token,   182.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3003.24 ms /    74 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    8524.01 ms /  1058 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.93 ms /    67 runs   (    0.55 ms per token,  1814.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4939.18 ms /   904 tokens (    5.46 ms per token,   183.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2694.24 ms /    67 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7738.30 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2242.07 ms /   432 tokens (    5.19 ms per token,   192.68 tokens per second)\n",
            "llama_print_timings:        eval time =     273.40 ms /     7 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2531.25 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     159.72 ms /   256 runs   (    0.62 ms per token,  1602.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3478.01 ms /   650 tokens (    5.35 ms per token,   186.89 tokens per second)\n",
            "llama_print_timings:        eval time =   10144.89 ms /   255 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =   14058.89 ms /   905 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.69 ms /    97 runs   (    0.77 ms per token,  1298.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3133.74 ms /   591 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3829.91 ms /    96 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7160.05 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PayPal Holdings, Inc._l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.83 ms /    90 runs   (    0.53 ms per token,  1881.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5406.44 ms /   984 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3604.03 ms /    89 runs   (   40.49 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    9141.72 ms /  1073 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.22 ms /    77 runs   (    0.59 ms per token,  1702.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5020.36 ms /   917 tokens (    5.47 ms per token,   182.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3071.64 ms /    76 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    8218.35 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.75 ms /    64 runs   (    0.56 ms per token,  1790.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5415.80 ms /   987 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2558.66 ms /    63 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    8074.28 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.38 ms /    84 runs   (    0.67 ms per token,  1490.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5060.89 ms /   920 tokens (    5.50 ms per token,   181.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3364.27 ms /    83 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    8577.55 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.45 ms /    71 runs   (    0.57 ms per token,  1755.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3081.06 ms /   584 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2790.87 ms /    71 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5984.12 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    69 runs   (    0.53 ms per token,  1896.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5355.50 ms /   976 tokens (    5.49 ms per token,   182.24 tokens per second)\n",
            "llama_print_timings:        eval time =    2791.06 ms /    69 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8251.76 ms /  1045 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.04 ms /    83 runs   (    0.52 ms per token,  1928.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     181.21 ms /    27 tokens (    6.71 ms per token,   149.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3319.86 ms /    82 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    3614.10 ms /   109 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.62 ms /    86 runs   (    0.58 ms per token,  1733.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3065.77 ms /   573 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3343.95 ms /    85 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6538.32 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.77 ms /   108 runs   (    0.60 ms per token,  1667.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5392.49 ms /   978 tokens (    5.51 ms per token,   181.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4357.16 ms /   107 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    9936.90 ms /  1085 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.48 ms /   117 runs   (    0.52 ms per token,  1934.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4950.70 ms /   911 tokens (    5.43 ms per token,   184.01 tokens per second)\n",
            "llama_print_timings:        eval time =    4668.17 ms /   116 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    9786.06 ms /  1027 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.36 ms /    87 runs   (    0.60 ms per token,  1661.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3100.43 ms /   580 tokens (    5.35 ms per token,   187.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3385.08 ms /    86 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6623.25 ms /   666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.27 ms /    75 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3647.03 ms /   685 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2911.03 ms /    74 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6665.70 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.34 ms /   110 runs   (    0.79 ms per token,  1259.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3147.42 ms /   588 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4363.89 ms /   109 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7760.72 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      87.01 ms /   148 runs   (    0.59 ms per token,  1701.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5359.21 ms /   980 tokens (    5.47 ms per token,   182.86 tokens per second)\n",
            "llama_print_timings:        eval time =    5967.40 ms /   147 runs   (   40.59 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =   11569.04 ms /  1127 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.87 ms /    74 runs   (    0.54 ms per token,  1855.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5001.35 ms /   918 tokens (    5.45 ms per token,   183.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2931.92 ms /    73 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8042.88 ms /   991 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     122.68 ms /   178 runs   (    0.69 ms per token,  1450.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3035.31 ms /   576 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =    7023.58 ms /   177 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =   10401.57 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     140.47 ms /   256 runs   (    0.55 ms per token,  1822.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3120.42 ms /   591 tokens (    5.28 ms per token,   189.40 tokens per second)\n",
            "llama_print_timings:        eval time =   10079.70 ms /   255 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   13611.54 ms /   846 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.56 ms /   100 runs   (    0.65 ms per token,  1548.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5357.13 ms /   980 tokens (    5.47 ms per token,   182.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4033.20 ms /    99 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
            "llama_print_timings:       total time =    9570.95 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.00 ms /    79 runs   (    0.62 ms per token,  1612.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3942.37 ms /   735 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3109.04 ms /    78 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7189.37 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     100.21 ms /   159 runs   (    0.63 ms per token,  1586.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3049.77 ms /   576 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
            "llama_print_timings:        eval time =    6260.88 ms /   159 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    9573.27 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.80 ms /    68 runs   (    0.54 ms per token,  1847.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3122.19 ms /   588 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2628.13 ms /    67 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5843.81 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.89 ms /    67 runs   (    0.64 ms per token,  1562.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3053.42 ms /   573 tokens (    5.33 ms per token,   187.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2598.71 ms /    66 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    5764.49 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.50 ms /    80 runs   (    0.54 ms per token,  1839.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     173.68 ms /    32 tokens (    5.43 ms per token,   184.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3097.43 ms /    79 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    3376.02 ms /   111 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.23 ms /   115 runs   (    0.63 ms per token,  1592.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3119.18 ms /   588 tokens (    5.30 ms per token,   188.51 tokens per second)\n",
            "llama_print_timings:        eval time =    4506.89 ms /   114 runs   (   39.53 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    7822.85 ms /   702 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.95 ms /    91 runs   (    0.63 ms per token,  1597.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2158.63 ms /   408 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3524.25 ms /    90 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5833.27 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.19 ms /   256 runs   (    0.56 ms per token,  1800.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3124.99 ms /   592 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =   10089.85 ms /   255 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   13627.55 ms /   847 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.72 ms /   256 runs   (    0.60 ms per token,  1654.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1852.11 ms /   358 tokens (    5.17 ms per token,   193.29 tokens per second)\n",
            "llama_print_timings:        eval time =    9964.49 ms /   255 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12257.68 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1913.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2578.91 ms /   488 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =     274.94 ms /     7 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2871.61 ms /   495 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.74 ms /    83 runs   (    0.62 ms per token,  1604.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2946.09 ms /   559 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3221.56 ms /    82 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6298.96 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.15 ms /    65 runs   (    0.54 ms per token,  1849.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3160.51 ms /   592 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2556.16 ms /    65 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5808.25 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.11 ms /    11 runs   (    0.56 ms per token,  1801.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3167.09 ms /   600 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =     433.30 ms /    11 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3622.28 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.47 ms /   256 runs   (    0.58 ms per token,  1724.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3120.51 ms /   586 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
            "llama_print_timings:        eval time =   10077.17 ms /   255 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   13606.71 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     106.85 ms /   166 runs   (    0.64 ms per token,  1553.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3193.76 ms /   594 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =    6542.35 ms /   165 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =   10023.87 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.30 ms /   256 runs   (    0.56 ms per token,  1774.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3073.91 ms /   581 tokens (    5.29 ms per token,   189.01 tokens per second)\n",
            "llama_print_timings:        eval time =   10088.82 ms /   255 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   13584.33 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1716.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.43 ms /   568 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
            "llama_print_timings:        eval time =     237.00 ms /     6 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    3239.72 ms /   574 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.20 ms /     7 runs   (    0.60 ms per token,  1665.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1815.84 ms /   352 tokens (    5.16 ms per token,   193.85 tokens per second)\n",
            "llama_print_timings:        eval time =     231.65 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2062.05 ms /   358 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.73 ms /    64 runs   (    0.71 ms per token,  1399.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1227.23 ms /   240 tokens (    5.11 ms per token,   195.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2439.84 ms /    63 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    3781.56 ms /   303 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.40 ms /    80 runs   (    0.56 ms per token,  1801.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3616.83 ms /   669 tokens (    5.41 ms per token,   184.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3118.75 ms /    79 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6858.16 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.67 ms /    11 runs   (    0.52 ms per token,  1939.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3074.90 ms /   579 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =     393.06 ms /    10 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3489.38 ms /   589 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.30 ms /    11 runs   (    0.57 ms per token,  1744.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     129.97 ms /    24 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =     394.95 ms /    10 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =     541.31 ms /    34 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.98 ms /    66 runs   (    0.56 ms per token,  1784.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3647.11 ms /   674 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2552.29 ms /    65 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    6299.50 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.26 ms /   256 runs   (    0.54 ms per token,  1838.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3080.79 ms /   581 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =   10077.69 ms /   255 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   13570.23 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.47 ms /     9 runs   (    0.50 ms per token,  2012.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5352.80 ms /   973 tokens (    5.50 ms per token,   181.77 tokens per second)\n",
            "llama_print_timings:        eval time =     324.58 ms /     8 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    5706.53 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.47 ms /   256 runs   (    0.54 ms per token,  1848.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3088.02 ms /   582 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =   10049.27 ms /   255 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13529.67 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.44 ms /   256 runs   (    0.59 ms per token,  1690.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2115.75 ms /   402 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    9958.57 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12481.48 ms /   657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.84 ms /    77 runs   (    0.71 ms per token,  1404.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3978.22 ms /   736 tokens (    5.41 ms per token,   185.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3097.89 ms /    77 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7236.89 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.53 ms /   116 runs   (    0.56 ms per token,  1797.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3131.29 ms /   590 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4502.26 ms /   115 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    7797.86 ms /   705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.41 ms /   256 runs   (    0.59 ms per token,  1690.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2460.88 ms /   469 tokens (    5.25 ms per token,   190.58 tokens per second)\n",
            "llama_print_timings:        eval time =    9997.95 ms /   255 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12874.84 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.46 ms /    11 runs   (    0.59 ms per token,  1702.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3032.16 ms /   576 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
            "llama_print_timings:        eval time =     431.91 ms /    11 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3488.07 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.11 ms /    11 runs   (    0.65 ms per token,  1547.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2098.05 ms /   397 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =     392.83 ms /    10 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2515.61 ms /   407 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.23 ms /   103 runs   (    0.58 ms per token,  1710.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3133.83 ms /   579 tokens (    5.41 ms per token,   184.76 tokens per second)\n",
            "llama_print_timings:        eval time =    4009.70 ms /   102 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7308.50 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.17 ms /    12 runs   (    0.51 ms per token,  1945.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2415.22 ms /   460 tokens (    5.25 ms per token,   190.46 tokens per second)\n",
            "llama_print_timings:        eval time =     428.93 ms /    11 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2865.25 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.01 ms /     7 runs   (    0.72 ms per token,  1396.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1904.73 ms /   365 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =     237.60 ms /     6 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    2158.95 ms /   371 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.72 ms /   115 runs   (    0.56 ms per token,  1776.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3212.77 ms /   599 tokens (    5.36 ms per token,   186.44 tokens per second)\n",
            "llama_print_timings:        eval time =    4472.84 ms /   114 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    7854.07 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.92 ms /   107 runs   (    0.58 ms per token,  1727.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     174.40 ms /    32 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =    4159.97 ms /   106 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    4483.85 ms /   138 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.34 ms /    68 runs   (    0.59 ms per token,  1685.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5400.97 ms /   984 tokens (    5.49 ms per token,   182.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2717.79 ms /    67 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    8237.82 ms /  1051 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     101.23 ms /   160 runs   (    0.63 ms per token,  1580.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2270.85 ms /   426 tokens (    5.33 ms per token,   187.60 tokens per second)\n",
            "llama_print_timings:        eval time =    6234.11 ms /   159 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    8777.19 ms /   585 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.84 ms /   256 runs   (    0.60 ms per token,  1664.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2247.67 ms /   429 tokens (    5.24 ms per token,   190.86 tokens per second)\n",
            "llama_print_timings:        eval time =    9997.19 ms /   255 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12673.03 ms /   684 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.25 ms /   159 runs   (    0.56 ms per token,  1781.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1873.42 ms /   357 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =    6142.79 ms /   158 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    8242.13 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.39 ms /     7 runs   (    0.77 ms per token,  1298.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2687.34 ms /   512 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     282.52 ms /     7 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    2990.17 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.23 ms /   236 runs   (    0.60 ms per token,  1659.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3134.11 ms /   579 tokens (    5.41 ms per token,   184.74 tokens per second)\n",
            "llama_print_timings:        eval time =    9274.29 ms /   235 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   12796.96 ms /   814 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.32 ms /   118 runs   (    0.66 ms per token,  1506.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3129.53 ms /   590 tokens (    5.30 ms per token,   188.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4623.59 ms /   117 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    7955.94 ms /   707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.75 ms /    76 runs   (    0.55 ms per token,  1820.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1855.23 ms /   356 tokens (    5.21 ms per token,   191.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2910.38 ms /    75 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4868.80 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.79 ms /    78 runs   (    0.66 ms per token,  1505.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4628.46 ms /   852 tokens (    5.43 ms per token,   184.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3103.00 ms /    77 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7868.87 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     165.62 ms /   256 runs   (    0.65 ms per token,  1545.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3193.73 ms /   599 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =   10086.15 ms /   255 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   13737.49 ms /   854 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_GENERAL MILLS INC_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.94 ms /   256 runs   (    0.59 ms per token,  1696.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3841.11 ms /   719 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =   10180.95 ms /   255 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =   14448.03 ms /   974 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.02 ms /    66 runs   (    0.73 ms per token,  1374.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5501.78 ms /  1008 tokens (    5.46 ms per token,   183.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2709.08 ms /    66 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    8345.13 ms /  1074 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.93 ms /    92 runs   (    0.59 ms per token,  1705.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3685.28 ms /   680 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3589.08 ms /    91 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    7415.76 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.38 ms /   108 runs   (    0.51 ms per token,  1950.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2859.84 ms /   542 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =    4204.30 ms /   107 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    7217.64 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.80 ms /   142 runs   (    0.52 ms per token,  1924.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4880.99 ms /   896 tokens (    5.45 ms per token,   183.57 tokens per second)\n",
            "llama_print_timings:        eval time =    5678.01 ms /   141 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =   10764.27 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.09 ms /     6 runs   (    0.52 ms per token,  1941.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5781.66 ms /  1048 tokens (    5.52 ms per token,   181.26 tokens per second)\n",
            "llama_print_timings:        eval time =     245.44 ms /     6 runs   (   40.91 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    6052.48 ms /  1054 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.02 ms /    80 runs   (    0.56 ms per token,  1776.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3605.19 ms /   672 tokens (    5.36 ms per token,   186.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3142.72 ms /    80 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6865.19 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.90 ms /   104 runs   (    0.63 ms per token,  1578.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2813.13 ms /   535 tokens (    5.26 ms per token,   190.18 tokens per second)\n",
            "llama_print_timings:        eval time =    4045.55 ms /   103 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7031.86 ms /   638 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.07 ms /    95 runs   (    0.55 ms per token,  1824.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     170.42 ms /    28 tokens (    6.09 ms per token,   164.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3681.85 ms /    94 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3980.75 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.25 ms /    82 runs   (    0.75 ms per token,  1338.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4837.69 ms /   890 tokens (    5.44 ms per token,   183.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3291.94 ms /    81 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    8290.30 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.26 ms /   121 runs   (    0.65 ms per token,  1546.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3881.45 ms /   724 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4781.69 ms /   120 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    8878.71 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.14 ms /     6 runs   (    0.52 ms per token,  1913.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5560.79 ms /  1006 tokens (    5.53 ms per token,   180.91 tokens per second)\n",
            "llama_print_timings:        eval time =     201.34 ms /     5 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    5788.47 ms /  1011 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.81 ms /   114 runs   (    0.62 ms per token,  1610.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5265.68 ms /   966 tokens (    5.45 ms per token,   183.45 tokens per second)\n",
            "llama_print_timings:        eval time =    4579.93 ms /   113 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   10034.08 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.64 ms /   118 runs   (    0.55 ms per token,  1825.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5529.61 ms /  1002 tokens (    5.52 ms per token,   181.21 tokens per second)\n",
            "llama_print_timings:        eval time =    4744.19 ms /   117 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =   10454.61 ms /  1119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      85.31 ms /   141 runs   (    0.61 ms per token,  1652.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5356.48 ms /   970 tokens (    5.52 ms per token,   181.09 tokens per second)\n",
            "llama_print_timings:        eval time =    5697.03 ms /   140 runs   (   40.69 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =   11295.59 ms /  1110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.38 ms /    79 runs   (    0.60 ms per token,  1667.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2811.39 ms /   536 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3098.76 ms /    79 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6032.93 ms /   615 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.72 ms /    67 runs   (    0.56 ms per token,  1776.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4698.19 ms /   862 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2643.72 ms /    66 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    7446.60 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     143.43 ms /   226 runs   (    0.63 ms per token,  1575.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5988.06 ms /  1085 tokens (    5.52 ms per token,   181.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9271.12 ms /   225 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
            "llama_print_timings:       total time =   15672.96 ms /  1310 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.73 ms /    80 runs   (    0.61 ms per token,  1641.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4583.92 ms /   842 tokens (    5.44 ms per token,   183.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3174.99 ms /    79 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7888.95 ms /   921 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.68 ms /    59 runs   (    0.55 ms per token,  1805.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3432.51 ms /   648 tokens (    5.30 ms per token,   188.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2284.61 ms /    58 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5802.48 ms /   706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.18 ms /    75 runs   (    0.62 ms per token,  1624.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3854.96 ms /   720 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2990.29 ms /    75 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    6969.42 ms /   795 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.75 ms /   112 runs   (    0.68 ms per token,  1478.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5925.40 ms /  1077 tokens (    5.50 ms per token,   181.76 tokens per second)\n",
            "llama_print_timings:        eval time =    4590.33 ms /   111 runs   (   41.35 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =   10731.32 ms /  1188 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.58 ms /   111 runs   (    0.56 ms per token,  1773.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4833.03 ms /   886 tokens (    5.45 ms per token,   183.32 tokens per second)\n",
            "llama_print_timings:        eval time =    4423.78 ms /   110 runs   (   40.22 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    9425.46 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.42 ms /    63 runs   (    0.55 ms per token,  1830.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     223.29 ms /    35 tokens (    6.38 ms per token,   156.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2488.32 ms /    62 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    2795.84 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.13 ms /    10 runs   (    0.81 ms per token,  1230.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2887.96 ms /   539 tokens (    5.36 ms per token,   186.64 tokens per second)\n",
            "llama_print_timings:        eval time =     353.92 ms /     9 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    3269.60 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.92 ms /    78 runs   (    0.56 ms per token,  1775.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3756.28 ms /   703 tokens (    5.34 ms per token,   187.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3033.57 ms /    77 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6983.60 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.05 ms /    74 runs   (    0.69 ms per token,  1449.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5526.95 ms /  1006 tokens (    5.49 ms per token,   182.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3006.18 ms /    73 runs   (   41.18 ms per token,    24.28 tokens per second)\n",
            "llama_print_timings:       total time =    8690.23 ms /  1079 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.76 ms /     7 runs   (    0.54 ms per token,  1863.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2476.40 ms /   466 tokens (    5.31 ms per token,   188.18 tokens per second)\n",
            "llama_print_timings:        eval time =     232.89 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2726.35 ms /   472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.75 ms /     7 runs   (    0.54 ms per token,  1868.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.30 ms /   468 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
            "llama_print_timings:        eval time =     232.50 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2705.54 ms /   474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      95.03 ms /   153 runs   (    0.62 ms per token,  1610.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3836.27 ms /   719 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
            "llama_print_timings:        eval time =    6073.00 ms /   152 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =   10167.52 ms /   871 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3741.22 ms /   698 tokens (    5.36 ms per token,   186.57 tokens per second)\n",
            "llama_print_timings:        eval time =     199.72 ms /     5 runs   (   39.95 ms per token,    25.03 tokens per second)\n",
            "llama_print_timings:       total time =    3957.84 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.36 ms /    89 runs   (    0.64 ms per token,  1551.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4857.81 ms /   892 tokens (    5.45 ms per token,   183.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3559.22 ms /    88 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8570.42 ms /   980 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.83 ms /    71 runs   (    0.66 ms per token,  1516.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     183.30 ms /    31 tokens (    5.91 ms per token,   169.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2841.24 ms /    70 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    3148.28 ms /   101 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.83 ms /    70 runs   (    0.55 ms per token,  1802.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.25 ms /   341 tokens (    5.19 ms per token,   192.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2678.96 ms /    69 runs   (   38.83 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    4544.11 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.51 ms /    68 runs   (    0.55 ms per token,  1812.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4604.44 ms /   844 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2676.06 ms /    67 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    7388.47 ms /   911 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.63 ms /     9 runs   (    0.51 ms per token,  1944.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4752.11 ms /   879 tokens (    5.41 ms per token,   184.97 tokens per second)\n",
            "llama_print_timings:        eval time =     320.94 ms /     8 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    5095.87 ms /   887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.36 ms /    68 runs   (    0.64 ms per token,  1568.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2432.05 ms /   458 tokens (    5.31 ms per token,   188.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2607.71 ms /    67 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5158.18 ms /   525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.20 ms /    70 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1264.58 ms /   245 tokens (    5.16 ms per token,   193.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2642.13 ms /    69 runs   (   38.29 ms per token,    26.12 tokens per second)\n",
            "llama_print_timings:       total time =    4001.07 ms /   314 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.65 ms /    52 runs   (    0.69 ms per token,  1458.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5311.41 ms /   968 tokens (    5.49 ms per token,   182.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2129.16 ms /    52 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =    7544.32 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      28.85 ms /    54 runs   (    0.53 ms per token,  1871.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4859.38 ms /   893 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
            "llama_print_timings:        eval time =    2127.96 ms /    53 runs   (   40.15 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7071.74 ms /   946 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.30 ms /    11 runs   (    0.57 ms per token,  1745.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2548.26 ms /   488 tokens (    5.22 ms per token,   191.50 tokens per second)\n",
            "llama_print_timings:        eval time =     393.44 ms /    10 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    2962.41 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.72 ms /    83 runs   (    0.56 ms per token,  1776.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3871.10 ms /   714 tokens (    5.42 ms per token,   184.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3246.04 ms /    82 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    7243.41 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.05 ms /   256 runs   (    0.62 ms per token,  1619.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.85 ms /   563 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10115.62 ms /   255 runs   (   39.67 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =   13579.36 ms /   818 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.77 ms /   256 runs   (    0.57 ms per token,  1744.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2707.34 ms /   510 tokens (    5.31 ms per token,   188.38 tokens per second)\n",
            "llama_print_timings:        eval time =   10073.95 ms /   255 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   13196.47 ms /   765 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.77 ms /    65 runs   (    0.54 ms per token,  1869.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2767.92 ms /   528 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2515.92 ms /    64 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5374.24 ms /   592 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.00 ms /    80 runs   (    0.56 ms per token,  1777.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4790.75 ms /   880 tokens (    5.44 ms per token,   183.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3172.72 ms /    79 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8087.72 ms /   959 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.01 ms /    72 runs   (    0.64 ms per token,  1564.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4141.57 ms /   766 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2831.76 ms /    71 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7093.27 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.98 ms /    96 runs   (    0.55 ms per token,  1811.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5833.04 ms /  1055 tokens (    5.53 ms per token,   180.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3864.45 ms /    95 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    9842.73 ms /  1150 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.43 ms /   112 runs   (    0.65 ms per token,  1546.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4111.77 ms /   766 tokens (    5.37 ms per token,   186.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4442.54 ms /   111 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    8748.65 ms /   877 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.64 ms /   117 runs   (    0.60 ms per token,  1680.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3750.77 ms /   704 tokens (    5.33 ms per token,   187.69 tokens per second)\n",
            "llama_print_timings:        eval time =    4634.94 ms /   117 runs   (   39.61 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    8567.23 ms /   821 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.65 ms /    82 runs   (    0.68 ms per token,  1473.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3582.95 ms /   664 tokens (    5.40 ms per token,   185.32 tokens per second)\n",
            "llama_print_timings:        eval time =    3264.27 ms /    82 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7001.63 ms /   746 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.96 ms /    68 runs   (    0.56 ms per token,  1791.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2968.23 ms /   558 tokens (    5.32 ms per token,   187.99 tokens per second)\n",
            "llama_print_timings:        eval time =    2630.29 ms /    67 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5694.35 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.11 ms /    14 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1599.93 ms /   312 tokens (    5.13 ms per token,   195.01 tokens per second)\n",
            "llama_print_timings:        eval time =     504.54 ms /    13 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2126.63 ms /   325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.48 ms /    68 runs   (    0.73 ms per token,  1374.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     835.44 ms /   160 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2595.70 ms /    67 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    3550.18 ms /   227 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.85 ms /    12 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2591.99 ms /   490 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =     432.82 ms /    11 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3047.36 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.76 ms /    12 runs   (    0.56 ms per token,  1775.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2814.39 ms /   536 tokens (    5.25 ms per token,   190.45 tokens per second)\n",
            "llama_print_timings:        eval time =     434.04 ms /    11 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3271.42 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.24 ms /    82 runs   (    0.78 ms per token,  1276.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5565.16 ms /  1010 tokens (    5.51 ms per token,   181.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3348.24 ms /    81 runs   (   41.34 ms per token,    24.19 tokens per second)\n",
            "llama_print_timings:       total time =    9100.08 ms /  1091 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.01 ms /    92 runs   (    0.54 ms per token,  1839.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4872.86 ms /   891 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3655.08 ms /    91 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8663.78 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     102.48 ms /   184 runs   (    0.56 ms per token,  1795.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3922.85 ms /   727 tokens (    5.40 ms per token,   185.32 tokens per second)\n",
            "llama_print_timings:        eval time =    7272.75 ms /   183 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =   11466.17 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1778.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1684.43 ms /   324 tokens (    5.20 ms per token,   192.35 tokens per second)\n",
            "llama_print_timings:        eval time =     230.94 ms /     6 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    1928.51 ms /   330 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     7 runs   (    0.60 ms per token,  1659.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     204.86 ms /    34 tokens (    6.03 ms per token,   165.97 tokens per second)\n",
            "llama_print_timings:        eval time =     228.32 ms /     6 runs   (   38.05 ms per token,    26.28 tokens per second)\n",
            "llama_print_timings:       total time =     444.59 ms /    40 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.20 ms /     7 runs   (    0.74 ms per token,  1347.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     919.27 ms /   172 tokens (    5.34 ms per token,   187.11 tokens per second)\n",
            "llama_print_timings:        eval time =     233.72 ms /     6 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    1169.47 ms /   178 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.72 ms /    79 runs   (    0.69 ms per token,  1443.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3687.93 ms /   683 tokens (    5.40 ms per token,   185.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3122.96 ms /    78 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6961.43 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.83 ms /    76 runs   (    0.58 ms per token,  1734.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3070.61 ms /   576 tokens (    5.33 ms per token,   187.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2938.91 ms /    75 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6123.74 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.12 ms /     7 runs   (    0.73 ms per token,  1366.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2445.03 ms /   464 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =     274.35 ms /     7 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    2741.31 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     7 runs   (    0.58 ms per token,  1714.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2675.31 ms /   506 tokens (    5.29 ms per token,   189.14 tokens per second)\n",
            "llama_print_timings:        eval time =     234.85 ms /     6 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2929.19 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.92 ms /    68 runs   (    0.57 ms per token,  1747.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4701.57 ms /   870 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2685.36 ms /    67 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7489.38 ms /   937 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Walmart Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Walmart Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Walmart Inc._l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.81 ms /    87 runs   (    0.55 ms per token,  1819.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5971.26 ms /  1080 tokens (    5.53 ms per token,   180.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3507.98 ms /    86 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    9613.93 ms /  1166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.24 ms /    67 runs   (    0.57 ms per token,  1751.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5839.55 ms /  1046 tokens (    5.58 ms per token,   179.12 tokens per second)\n",
            "llama_print_timings:        eval time =    2699.94 ms /    66 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =    8656.09 ms /  1112 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.42 ms /   256 runs   (    0.61 ms per token,  1636.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2944.75 ms /   558 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =   10063.11 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13440.95 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.94 ms /   108 runs   (    0.56 ms per token,  1801.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3472.27 ms /   651 tokens (    5.33 ms per token,   187.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4221.59 ms /   107 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    7845.61 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.26 ms /    73 runs   (    0.70 ms per token,  1424.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3765.78 ms /   685 tokens (    5.50 ms per token,   181.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2908.24 ms /    72 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    6830.33 ms /   757 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.95 ms /    68 runs   (    0.56 ms per token,  1791.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2207.93 ms /   423 tokens (    5.22 ms per token,   191.58 tokens per second)\n",
            "llama_print_timings:        eval time =    2609.68 ms /    67 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4911.91 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      99.80 ms /   155 runs   (    0.64 ms per token,  1553.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.41 ms /   471 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =    6021.75 ms /   154 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    8742.00 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.10 ms /   256 runs   (    0.61 ms per token,  1639.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.60 ms /   430 tokens (    5.22 ms per token,   191.49 tokens per second)\n",
            "llama_print_timings:        eval time =   10007.36 ms /   255 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =   12697.13 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.73 ms /     6 runs   (    0.79 ms per token,  1267.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5732.29 ms /  1040 tokens (    5.51 ms per token,   181.43 tokens per second)\n",
            "llama_print_timings:        eval time =     248.81 ms /     6 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =    6011.19 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.92 ms /    87 runs   (    0.70 ms per token,  1428.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2948.92 ms /   556 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3401.85 ms /    86 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6513.05 ms /   642 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.98 ms /    99 runs   (    0.55 ms per token,  1834.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3617.88 ms /   676 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3864.28 ms /    98 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7622.38 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.64 ms /    99 runs   (    0.61 ms per token,  1632.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3717.77 ms /   694 tokens (    5.36 ms per token,   186.67 tokens per second)\n",
            "llama_print_timings:        eval time =    3890.98 ms /    98 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7769.31 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.19 ms /    89 runs   (    0.54 ms per token,  1847.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =      87.38 ms /    16 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3506.49 ms /    89 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    3718.94 ms /   105 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     100.47 ms /   131 runs   (    0.77 ms per token,  1303.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2240.32 ms /   428 tokens (    5.23 ms per token,   191.04 tokens per second)\n",
            "llama_print_timings:        eval time =    5116.14 ms /   130 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    7622.14 ms /   558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.27 ms /   111 runs   (    0.53 ms per token,  1872.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5621.01 ms /  1018 tokens (    5.52 ms per token,   181.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4468.79 ms /   110 runs   (   40.63 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =   10255.46 ms /  1128 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.28 ms /   162 runs   (    0.55 ms per token,  1814.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5776.67 ms /  1042 tokens (    5.54 ms per token,   180.38 tokens per second)\n",
            "llama_print_timings:        eval time =    6563.10 ms /   161 runs   (   40.76 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =   12587.18 ms /  1203 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.21 ms /     6 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3356.81 ms /   631 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
            "llama_print_timings:        eval time =     196.56 ms /     5 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    3573.73 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.00 ms /    66 runs   (    0.53 ms per token,  1885.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6074.89 ms /  1083 tokens (    5.61 ms per token,   178.27 tokens per second)\n",
            "llama_print_timings:        eval time =    2648.78 ms /    65 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    8831.90 ms /  1148 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.42 ms /    88 runs   (    0.65 ms per token,  1532.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5784.54 ms /  1048 tokens (    5.52 ms per token,   181.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3615.07 ms /    88 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =    9557.67 ms /  1136 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.04 ms /   256 runs   (    0.59 ms per token,  1694.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4290.28 ms /   794 tokens (    5.40 ms per token,   185.07 tokens per second)\n",
            "llama_print_timings:        eval time =   10256.22 ms /   255 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =   14992.75 ms /  1049 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.62 ms /    76 runs   (    0.56 ms per token,  1783.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3738.07 ms /   695 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
            "llama_print_timings:        eval time =    2949.64 ms /    75 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    6802.10 ms /   770 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.05 ms /    75 runs   (    0.59 ms per token,  1702.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3004.06 ms /   552 tokens (    5.44 ms per token,   183.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2967.81 ms /    75 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    6087.45 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.21 ms /    81 runs   (    0.56 ms per token,  1791.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2967.88 ms /   551 tokens (    5.39 ms per token,   185.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3159.95 ms /    80 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6242.11 ms /   631 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.66 ms /    69 runs   (    0.60 ms per token,  1656.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3548.11 ms /   660 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2689.66 ms /    68 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6350.52 ms /   728 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.82 ms /    69 runs   (    0.62 ms per token,  1611.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3703.14 ms /   693 tokens (    5.34 ms per token,   187.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2713.51 ms /    68 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    6532.93 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.01 ms /    76 runs   (    0.67 ms per token,  1489.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2932.72 ms /   551 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2957.15 ms /    75 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6023.41 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.19 ms /    76 runs   (    0.56 ms per token,  1801.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3251.54 ms /   612 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2949.89 ms /    75 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6308.09 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     7 runs   (    0.55 ms per token,  1821.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.34 ms /   398 tokens (    5.20 ms per token,   192.33 tokens per second)\n",
            "llama_print_timings:        eval time =     230.39 ms /     6 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
            "llama_print_timings:       total time =    2313.80 ms /   404 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.01 ms /   155 runs   (    0.57 ms per token,  1741.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2847.31 ms /   536 tokens (    5.31 ms per token,   188.25 tokens per second)\n",
            "llama_print_timings:        eval time =    6093.29 ms /   155 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    9175.65 ms /   691 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1921.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.77 ms /   460 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =     235.62 ms /     6 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2664.04 ms /   466 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.05 ms /    68 runs   (    0.74 ms per token,  1358.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2550.44 ms /   483 tokens (    5.28 ms per token,   189.38 tokens per second)\n",
            "llama_print_timings:        eval time =    2638.73 ms /    67 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5328.43 ms /   550 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.22 ms /    78 runs   (    0.59 ms per token,  1687.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2812.89 ms /   526 tokens (    5.35 ms per token,   187.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3020.32 ms /    77 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5951.05 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.20 ms /    63 runs   (    0.54 ms per token,  1842.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2502.20 ms /   478 tokens (    5.23 ms per token,   191.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2434.90 ms /    62 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5025.09 ms /   540 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.07 ms /    66 runs   (    0.68 ms per token,  1464.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1824.82 ms /   342 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2545.04 ms /    65 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4488.26 ms /   407 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1776.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1940.98 ms /   373 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =     194.93 ms /     5 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    2149.69 ms /   378 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.36 ms /     6 runs   (    0.56 ms per token,  1784.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.84 ms /   462 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =     193.60 ms /     5 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2625.57 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1836.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2416.68 ms /   458 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =     231.22 ms /     6 runs   (   38.54 ms per token,    25.95 tokens per second)\n",
            "llama_print_timings:       total time =    2662.74 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.58 ms /    82 runs   (    0.71 ms per token,  1399.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2728.31 ms /   514 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3195.43 ms /    81 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6070.71 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     162.98 ms /   256 runs   (    0.64 ms per token,  1570.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2350.04 ms /   448 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =   10013.71 ms /   255 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   12824.25 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.88 ms /    11 runs   (    0.53 ms per token,  1869.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2729.98 ms /   519 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
            "llama_print_timings:        eval time =     396.78 ms /    10 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    3148.49 ms /   529 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.23 ms /   111 runs   (    0.56 ms per token,  1783.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3297.92 ms /   621 tokens (    5.31 ms per token,   188.30 tokens per second)\n",
            "llama_print_timings:        eval time =    4331.43 ms /   110 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    7795.18 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.55 ms /   256 runs   (    0.60 ms per token,  1667.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2757.67 ms /   519 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
            "llama_print_timings:        eval time =   10057.30 ms /   255 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13272.07 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.74 ms /    69 runs   (    0.53 ms per token,  1877.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3337.17 ms /   622 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =    2670.47 ms /    68 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6106.52 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.79 ms /    85 runs   (    0.61 ms per token,  1641.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4527.03 ms /   839 tokens (    5.40 ms per token,   185.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3376.21 ms /    84 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    8047.79 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.17 ms /    72 runs   (    0.53 ms per token,  1886.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5244.32 ms /   960 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2906.18 ms /    72 runs   (   40.36 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8263.01 ms /  1032 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.75 ms /     7 runs   (    0.68 ms per token,  1474.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4259.32 ms /   792 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =     241.68 ms /     6 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    4523.97 ms /   798 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.77 ms /    78 runs   (    0.66 ms per token,  1506.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3761.17 ms /   692 tokens (    5.44 ms per token,   183.99 tokens per second)\n",
            "llama_print_timings:        eval time =    3059.25 ms /    77 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6967.23 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.72 ms /    70 runs   (    0.57 ms per token,  1762.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3654.45 ms /   684 tokens (    5.34 ms per token,   187.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2720.94 ms /    69 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6478.83 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.52 ms /    66 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3835.84 ms /   712 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2575.09 ms /    65 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
            "llama_print_timings:       total time =    6515.93 ms /   777 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.96 ms /    14 runs   (    0.57 ms per token,  1758.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2550.43 ms /   488 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =     510.36 ms /    13 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    3085.52 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.38 ms /    56 runs   (    0.63 ms per token,  1582.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3655.49 ms /   686 tokens (    5.33 ms per token,   187.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2189.10 ms /    55 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    5937.07 ms /   741 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     159.03 ms /   256 runs   (    0.62 ms per token,  1609.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2005.81 ms /   378 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =    9947.12 ms /   255 runs   (   39.01 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =   12385.83 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      10.76 ms /    12 runs   (    0.90 ms per token,  1115.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     601.94 ms /   112 tokens (    5.37 ms per token,   186.07 tokens per second)\n",
            "llama_print_timings:        eval time =     434.38 ms /    11 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    1067.95 ms /   123 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     109.25 ms /   206 runs   (    0.53 ms per token,  1885.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2976.53 ms /   555 tokens (    5.36 ms per token,   186.46 tokens per second)\n",
            "llama_print_timings:        eval time =    8037.77 ms /   205 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   11309.04 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.34 ms /     9 runs   (    0.70 ms per token,  1418.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2616.02 ms /   494 tokens (    5.30 ms per token,   188.84 tokens per second)\n",
            "llama_print_timings:        eval time =     316.19 ms /     8 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    2954.00 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.06 ms /   256 runs   (    0.61 ms per token,  1629.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1957.52 ms /   373 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9963.01 ms /   255 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   12364.27 ms /   628 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    14 runs   (    0.67 ms per token,  1496.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1074.90 ms /   205 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
            "llama_print_timings:        eval time =     503.91 ms /    13 runs   (   38.76 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    1604.70 ms /   218 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.43 ms /   256 runs   (    0.62 ms per token,  1615.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3129.53 ms /   589 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =   10059.10 ms /   255 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13624.88 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.68 ms /    88 runs   (    0.56 ms per token,  1771.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.77 ms /   467 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3409.76 ms /    87 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5997.54 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.70 ms /    55 runs   (    0.74 ms per token,  1351.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5187.36 ms /   952 tokens (    5.45 ms per token,   183.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2205.35 ms /    54 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    7513.82 ms /  1006 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.40 ms /    90 runs   (    0.56 ms per token,  1785.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3856.34 ms /   706 tokens (    5.46 ms per token,   183.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3512.76 ms /    89 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7505.37 ms /   795 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.97 ms /     7 runs   (    0.57 ms per token,  1765.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.21 ms /   429 tokens (    5.23 ms per token,   191.16 tokens per second)\n",
            "llama_print_timings:        eval time =     231.64 ms /     6 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
            "llama_print_timings:       total time =    2492.84 ms /   435 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.32 ms /    82 runs   (    0.72 ms per token,  1382.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2902.73 ms /   552 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3237.36 ms /    82 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6289.15 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_PEPSICO INC_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.48 ms /   256 runs   (    0.60 ms per token,  1668.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2898.82 ms /   549 tokens (    5.28 ms per token,   189.39 tokens per second)\n",
            "llama_print_timings:        eval time =   10058.49 ms /   255 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13393.98 ms /   804 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.37 ms /   113 runs   (    0.53 ms per token,  1903.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3291.60 ms /   604 tokens (    5.45 ms per token,   183.50 tokens per second)\n",
            "llama_print_timings:        eval time =    4397.28 ms /   112 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    7849.86 ms /   716 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.31 ms /    90 runs   (    0.68 ms per token,  1467.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4434.98 ms /   818 tokens (    5.42 ms per token,   184.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3584.24 ms /    89 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    8182.67 ms /   907 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.98 ms /   136 runs   (    0.55 ms per token,  1813.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3033.08 ms /   576 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =    5303.49 ms /   135 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    8525.74 ms /   711 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.13 ms /    75 runs   (    0.64 ms per token,  1558.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4108.65 ms /   756 tokens (    5.43 ms per token,   184.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2957.53 ms /    74 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    7198.67 ms /   830 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     146.04 ms /   256 runs   (    0.57 ms per token,  1752.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5381.95 ms /   984 tokens (    5.47 ms per token,   182.83 tokens per second)\n",
            "llama_print_timings:        eval time =   10455.97 ms /   256 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =   16263.25 ms /  1240 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.97 ms /    67 runs   (    0.54 ms per token,  1862.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     180.81 ms /    28 tokens (    6.46 ms per token,   154.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2668.25 ms /    66 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    2937.22 ms /    94 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.52 ms /    90 runs   (    0.55 ms per token,  1817.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5215.94 ms /   946 tokens (    5.51 ms per token,   181.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3592.03 ms /    89 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    8940.66 ms /  1035 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.54 ms /   133 runs   (    0.60 ms per token,  1672.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5445.53 ms /   986 tokens (    5.52 ms per token,   181.07 tokens per second)\n",
            "llama_print_timings:        eval time =    5382.06 ms /   132 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =   11066.43 ms /  1118 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.62 ms /   121 runs   (    0.58 ms per token,  1737.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5126.84 ms /   944 tokens (    5.43 ms per token,   184.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4868.83 ms /   120 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =   10197.10 ms /  1064 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.34 ms /     6 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5466.89 ms /   995 tokens (    5.49 ms per token,   182.00 tokens per second)\n",
            "llama_print_timings:        eval time =     202.84 ms /     5 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    5691.47 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.33 ms /   117 runs   (    0.69 ms per token,  1456.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5172.24 ms /   952 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4788.73 ms /   117 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   10200.95 ms /  1069 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.19 ms /   107 runs   (    0.54 ms per token,  1838.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5425.85 ms /   988 tokens (    5.49 ms per token,   182.09 tokens per second)\n",
            "llama_print_timings:        eval time =    4293.66 ms /   106 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    9879.46 ms /  1094 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     132.41 ms /   242 runs   (    0.55 ms per token,  1827.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5212.13 ms /   946 tokens (    5.51 ms per token,   181.50 tokens per second)\n",
            "llama_print_timings:        eval time =    9798.07 ms /   241 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   15406.10 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     114.39 ms /   190 runs   (    0.60 ms per token,  1661.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4147.10 ms /   764 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
            "llama_print_timings:        eval time =    7570.39 ms /   189 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =   12036.87 ms /   953 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.56 ms /    82 runs   (    0.52 ms per token,  1926.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4507.78 ms /   828 tokens (    5.44 ms per token,   183.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3229.64 ms /    81 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7856.02 ms /   909 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.36 ms /    57 runs   (    0.69 ms per token,  1448.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5085.18 ms /   936 tokens (    5.43 ms per token,   184.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2317.76 ms /    57 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    7513.68 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      94.27 ms /   143 runs   (    0.66 ms per token,  1516.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4860.30 ms /   895 tokens (    5.43 ms per token,   184.15 tokens per second)\n",
            "llama_print_timings:        eval time =    5755.48 ms /   142 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   10885.01 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.69 ms /    73 runs   (    0.53 ms per token,  1886.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4520.53 ms /   830 tokens (    5.45 ms per token,   183.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2874.28 ms /    72 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    7503.17 ms /   902 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.89 ms /    90 runs   (    0.64 ms per token,  1554.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4386.15 ms /   815 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =    3576.42 ms /    89 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    8119.87 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.50 ms /    78 runs   (    0.56 ms per token,  1793.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4721.98 ms /   871 tokens (    5.42 ms per token,   184.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3086.35 ms /    77 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7927.71 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.85 ms /    75 runs   (    0.88 ms per token,  1138.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4459.90 ms /   822 tokens (    5.43 ms per token,   184.31 tokens per second)\n",
            "llama_print_timings:        eval time =    3000.20 ms /    74 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    7630.86 ms /   896 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.97 ms /    68 runs   (    0.56 ms per token,  1790.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4221.36 ms /   778 tokens (    5.43 ms per token,   184.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2660.15 ms /    67 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6984.19 ms /   845 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.02 ms /    68 runs   (    0.68 ms per token,  1477.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4707.61 ms /   871 tokens (    5.40 ms per token,   185.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2712.67 ms /    67 runs   (   40.49 ms per token,    24.70 tokens per second)\n",
            "llama_print_timings:       total time =    7550.16 ms /   938 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.08 ms /    79 runs   (    0.56 ms per token,  1792.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2900.18 ms /   552 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
            "llama_print_timings:        eval time =    3052.04 ms /    78 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6064.28 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.51 ms /   203 runs   (    0.69 ms per token,  1455.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1768.35 ms /   344 tokens (    5.14 ms per token,   194.53 tokens per second)\n",
            "llama_print_timings:        eval time =    7946.95 ms /   203 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   10107.66 ms /   547 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.80 ms /     7 runs   (    0.54 ms per token,  1842.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2473.37 ms /   472 tokens (    5.24 ms per token,   190.83 tokens per second)\n",
            "llama_print_timings:        eval time =     229.84 ms /     6 runs   (   38.31 ms per token,    26.10 tokens per second)\n",
            "llama_print_timings:       total time =    2718.93 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.82 ms /     7 runs   (    0.55 ms per token,  1834.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2010.13 ms /   382 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =     233.62 ms /     6 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2258.80 ms /   388 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.91 ms /   100 runs   (    0.66 ms per token,  1517.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3704.32 ms /   694 tokens (    5.34 ms per token,   187.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3950.70 ms /    99 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    7828.54 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.52 ms /    81 runs   (    0.51 ms per token,  1950.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2061.02 ms /   371 tokens (    5.56 ms per token,   180.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3157.43 ms /    80 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    5326.69 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.91 ms /   106 runs   (    0.70 ms per token,  1434.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3295.54 ms /   622 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4168.32 ms /   105 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7652.25 ms /   727 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.22 ms /   131 runs   (    0.60 ms per token,  1674.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3117.90 ms /   582 tokens (    5.36 ms per token,   186.66 tokens per second)\n",
            "llama_print_timings:        eval time =    5123.01 ms /   130 runs   (   39.41 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    8446.67 ms /   712 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.68 ms /   107 runs   (    0.58 ms per token,  1734.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3083.52 ms /   575 tokens (    5.36 ms per token,   186.48 tokens per second)\n",
            "llama_print_timings:        eval time =    4175.27 ms /   106 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    7420.92 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.24 ms /    91 runs   (    0.53 ms per token,  1886.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3054.87 ms /   575 tokens (    5.31 ms per token,   188.22 tokens per second)\n",
            "llama_print_timings:        eval time =    3540.37 ms /    90 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6720.21 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.72 ms /    66 runs   (    0.63 ms per token,  1582.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2315.68 ms /   440 tokens (    5.26 ms per token,   190.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2575.54 ms /    66 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    4996.87 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.29 ms /    11 runs   (    0.57 ms per token,  1747.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2990.56 ms /   568 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =     427.22 ms /    11 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3442.27 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.09 ms /    72 runs   (    0.70 ms per token,  1437.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3455.30 ms /   642 tokens (    5.38 ms per token,   185.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2818.71 ms /    71 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    6413.21 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.41 ms /    77 runs   (    0.55 ms per token,  1815.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2527.64 ms /   478 tokens (    5.29 ms per token,   189.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2978.89 ms /    76 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5620.25 ms /   554 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.27 ms /    64 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2896.68 ms /   549 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2468.01 ms /    63 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5455.47 ms /   612 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.77 ms /    77 runs   (    0.57 ms per token,  1758.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3685.96 ms /   683 tokens (    5.40 ms per token,   185.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2993.58 ms /    76 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6799.04 ms /   759 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.62 ms /    90 runs   (    0.55 ms per token,  1813.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3612.89 ms /   680 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3510.07 ms /    89 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7251.21 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     161.56 ms /   256 runs   (    0.63 ms per token,  1584.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2541.55 ms /   479 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =   10023.30 ms /   255 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =   13013.15 ms /   734 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.80 ms /    70 runs   (    0.61 ms per token,  1635.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4362.02 ms /   803 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2761.43 ms /    69 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    7244.23 ms /   872 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.79 ms /    92 runs   (    0.58 ms per token,  1710.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5037.51 ms /   927 tokens (    5.43 ms per token,   184.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3669.43 ms /    91 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    8852.20 ms /  1018 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.12 ms /    70 runs   (    0.66 ms per token,  1517.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     138.28 ms /    22 tokens (    6.29 ms per token,   159.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2806.50 ms /    69 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    3073.47 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.15 ms /    76 runs   (    0.65 ms per token,  1546.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3448.72 ms /   645 tokens (    5.35 ms per token,   187.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2970.17 ms /    75 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    6549.21 ms /   720 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      63.79 ms /    92 runs   (    0.69 ms per token,  1442.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2987.99 ms /   565 tokens (    5.29 ms per token,   189.09 tokens per second)\n",
            "llama_print_timings:        eval time =    3599.97 ms /    91 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6754.40 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.84 ms /    67 runs   (    0.55 ms per token,  1818.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4428.23 ms /   824 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2670.63 ms /    67 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7196.60 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.48 ms /     7 runs   (    0.78 ms per token,  1277.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2993.66 ms /   565 tokens (    5.30 ms per token,   188.73 tokens per second)\n",
            "llama_print_timings:        eval time =     238.19 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    3254.82 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.82 ms /    76 runs   (    0.58 ms per token,  1734.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2008.43 ms /   384 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
            "llama_print_timings:        eval time =    2921.80 ms /    75 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5043.95 ms /   459 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     159.08 ms /   256 runs   (    0.62 ms per token,  1609.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2719.85 ms /   516 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =   10085.74 ms /   255 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =   13281.16 ms /   771 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.41 ms /   256 runs   (    0.60 ms per token,  1679.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   10065.53 ms /   256 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =   10505.61 ms /   256 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.01 ms /    92 runs   (    0.58 ms per token,  1735.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3644.07 ms /   678 tokens (    5.37 ms per token,   186.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3594.31 ms /    91 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7375.83 ms /   769 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      98.64 ms /   123 runs   (    0.80 ms per token,  1246.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3116.62 ms /   587 tokens (    5.31 ms per token,   188.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4846.00 ms /   122 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    8218.00 ms /   709 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.93 ms /    72 runs   (    0.54 ms per token,  1849.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2981.99 ms /   556 tokens (    5.36 ms per token,   186.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2790.79 ms /    71 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5876.53 ms /   627 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.72 ms /    12 runs   (    0.56 ms per token,  1784.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.69 ms /   421 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =     428.45 ms /    11 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    2650.01 ms /   432 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.83 ms /   109 runs   (    0.62 ms per token,  1607.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1810.99 ms /   352 tokens (    5.14 ms per token,   194.37 tokens per second)\n",
            "llama_print_timings:        eval time =    4229.69 ms /   109 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    6220.47 ms /   461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2771.63 ms /   524 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =     233.52 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    3021.61 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.83 ms /    12 runs   (    0.57 ms per token,  1756.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2942.65 ms /   555 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
            "llama_print_timings:        eval time =     427.18 ms /    11 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    3392.69 ms /   566 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.29 ms /    83 runs   (    0.69 ms per token,  1448.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4430.14 ms /   818 tokens (    5.42 ms per token,   184.64 tokens per second)\n",
            "llama_print_timings:        eval time =    3318.10 ms /    82 runs   (   40.46 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    7910.79 ms /   900 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.52 ms /    67 runs   (    0.57 ms per token,  1739.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.55 ms /   432 tokens (    5.30 ms per token,   188.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.77 ms /    66 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    4972.95 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.14 ms /   138 runs   (    0.58 ms per token,  1722.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1267.02 ms /   239 tokens (    5.30 ms per token,   188.63 tokens per second)\n",
            "llama_print_timings:        eval time =    5363.91 ms /   137 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6832.41 ms /   376 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.06 ms /    64 runs   (    0.55 ms per token,  1825.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5162.48 ms /   944 tokens (    5.47 ms per token,   182.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2581.05 ms /    64 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =    7841.70 ms /  1008 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.73 ms /    11 runs   (    0.61 ms per token,  1633.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2288.05 ms /   440 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
            "llama_print_timings:        eval time =     429.28 ms /    11 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2738.23 ms /   451 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Kraft Heinz Co_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      78.11 ms /   125 runs   (    0.62 ms per token,  1600.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5024.67 ms /   917 tokens (    5.48 ms per token,   182.50 tokens per second)\n",
            "llama_print_timings:        eval time =    5035.88 ms /   124 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =   10287.43 ms /  1041 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.53 ms /   145 runs   (    0.53 ms per token,  1870.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     181.64 ms /    30 tokens (    6.05 ms per token,   165.16 tokens per second)\n",
            "llama_print_timings:        eval time =    5821.15 ms /   144 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    6215.17 ms /   174 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.60 ms /   110 runs   (    0.52 ms per token,  1909.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6099.29 ms /  1098 tokens (    5.55 ms per token,   180.02 tokens per second)\n",
            "llama_print_timings:        eval time =    4453.24 ms /   109 runs   (   40.86 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =   10715.02 ms /  1207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.10 ms /   103 runs   (    0.55 ms per token,  1803.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4982.13 ms /   911 tokens (    5.47 ms per token,   182.85 tokens per second)\n",
            "llama_print_timings:        eval time =    4101.16 ms /   102 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    9235.20 ms /  1013 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.42 ms /    68 runs   (    0.68 ms per token,  1465.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2384.90 ms /   452 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2620.01 ms /    67 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5123.57 ms /   519 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.02 ms /   125 runs   (    0.53 ms per token,  1893.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5018.19 ms /   914 tokens (    5.49 ms per token,   182.14 tokens per second)\n",
            "llama_print_timings:        eval time =    4989.97 ms /   124 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =   10188.29 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.70 ms /    75 runs   (    0.54 ms per token,  1842.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     136.61 ms /    23 tokens (    5.94 ms per token,   168.36 tokens per second)\n",
            "llama_print_timings:        eval time =    2972.09 ms /    74 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    3212.06 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1847.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7286.65 ms /  1296 tokens (    5.62 ms per token,   177.86 tokens per second)\n",
            "llama_print_timings:        eval time =     205.07 ms /     5 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =    7518.31 ms /  1301 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      92.64 ms /   121 runs   (    0.77 ms per token,  1306.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6027.36 ms /  1096 tokens (    5.50 ms per token,   181.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4974.97 ms /   120 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   11270.00 ms /  1216 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.34 ms /   128 runs   (    0.55 ms per token,  1819.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5004.23 ms /   914 tokens (    5.48 ms per token,   182.65 tokens per second)\n",
            "llama_print_timings:        eval time =    5118.08 ms /   127 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =   10313.88 ms /  1041 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.50 ms /   110 runs   (    0.55 ms per token,  1818.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5454.89 ms /   992 tokens (    5.50 ms per token,   181.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4462.88 ms /   110 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =   10087.47 ms /  1102 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.12 ms /    91 runs   (    0.65 ms per token,  1539.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5479.65 ms /  1000 tokens (    5.48 ms per token,   182.49 tokens per second)\n",
            "llama_print_timings:        eval time =    3692.82 ms /    90 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    9349.25 ms /  1090 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.56 ms /    59 runs   (    0.55 ms per token,  1812.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5384.33 ms /   980 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2347.19 ms /    58 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    7823.22 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.36 ms /    81 runs   (    0.56 ms per token,  1785.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6545.99 ms /  1171 tokens (    5.59 ms per token,   178.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3287.83 ms /    80 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =    9964.57 ms /  1251 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.70 ms /    67 runs   (    0.52 ms per token,  1930.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     189.31 ms /    32 tokens (    5.92 ms per token,   169.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2752.74 ms /    67 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =    3029.23 ms /    99 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.64 ms /    76 runs   (    0.67 ms per token,  1500.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6450.77 ms /  1158 tokens (    5.57 ms per token,   179.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3100.92 ms /    75 runs   (   41.35 ms per token,    24.19 tokens per second)\n",
            "llama_print_timings:       total time =    9700.30 ms /  1233 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.13 ms /    73 runs   (    0.58 ms per token,  1732.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7291.18 ms /  1293 tokens (    5.64 ms per token,   177.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2986.36 ms /    72 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =   10400.17 ms /  1365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.05 ms /    68 runs   (    0.60 ms per token,  1656.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2371.22 ms /   454 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2621.53 ms /    67 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    5093.11 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.23 ms /    70 runs   (    0.55 ms per token,  1830.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6060.88 ms /  1090 tokens (    5.56 ms per token,   179.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2813.53 ms /    69 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =    8982.15 ms /  1159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.14 ms /    72 runs   (    0.81 ms per token,  1238.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4990.37 ms /   918 tokens (    5.44 ms per token,   183.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2892.88 ms /    71 runs   (   40.74 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    8033.84 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.82 ms /    59 runs   (    0.52 ms per token,  1914.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5497.56 ms /   999 tokens (    5.50 ms per token,   181.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2347.69 ms /    58 runs   (   40.48 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    7938.06 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.08 ms /    85 runs   (    0.64 ms per token,  1571.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2374.36 ms /   455 tokens (    5.22 ms per token,   191.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3290.93 ms /    84 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5797.07 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.32 ms /    86 runs   (    0.55 ms per token,  1817.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2847.55 ms /   534 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3343.85 ms /    85 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6310.34 ms /   619 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.12 ms /    67 runs   (    0.54 ms per token,  1854.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2372.85 ms /   456 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2586.02 ms /    66 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5048.41 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.94 ms /    88 runs   (    0.74 ms per token,  1355.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3924.77 ms /   723 tokens (    5.43 ms per token,   184.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3492.53 ms /    87 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    7609.12 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.85 ms /   102 runs   (    0.54 ms per token,  1859.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3208.34 ms /   603 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3959.24 ms /   101 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7308.35 ms /   704 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.81 ms /    72 runs   (    0.73 ms per token,  1363.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.75 ms /   460 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =    2782.84 ms /    71 runs   (   39.19 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5328.91 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.23 ms /    73 runs   (    0.52 ms per token,  1909.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3840.87 ms /   714 tokens (    5.38 ms per token,   185.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2842.40 ms /    72 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6786.02 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      69.43 ms /    96 runs   (    0.72 ms per token,  1382.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2367.86 ms /   450 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3714.11 ms /    95 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6252.64 ms /   545 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.34 ms /     6 runs   (    0.72 ms per token,  1380.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2026.99 ms /   384 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =     196.87 ms /     5 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    2243.24 ms /   389 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.70 ms /    79 runs   (    0.62 ms per token,  1622.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     127.72 ms /    20 tokens (    6.39 ms per token,   156.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3041.97 ms /    78 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3285.41 ms /    98 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.13 ms /    99 runs   (    0.67 ms per token,  1496.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7155.64 ms /  1279 tokens (    5.59 ms per token,   178.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4077.99 ms /    98 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
            "llama_print_timings:       total time =   11411.77 ms /  1377 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.00 ms /    11 runs   (    0.55 ms per token,  1833.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3078.43 ms /   584 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =     393.83 ms /    10 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3493.55 ms /   594 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.30 ms /    66 runs   (    0.61 ms per token,  1637.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6375.35 ms /  1146 tokens (    5.56 ms per token,   179.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2681.25 ms /    65 runs   (   41.25 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =    9170.88 ms /  1211 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.22 ms /    88 runs   (    0.65 ms per token,  1538.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7187.82 ms /  1280 tokens (    5.62 ms per token,   178.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3666.24 ms /    88 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
            "llama_print_timings:       total time =   11021.66 ms /  1368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.95 ms /    96 runs   (    0.54 ms per token,  1847.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4949.99 ms /   906 tokens (    5.46 ms per token,   183.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3819.61 ms /    95 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    8910.56 ms /  1001 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.04 ms /    66 runs   (    0.67 ms per token,  1498.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3854.66 ms /   714 tokens (    5.40 ms per token,   185.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2589.44 ms /    65 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    6558.09 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.78 ms /    97 runs   (    0.61 ms per token,  1650.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2333.61 ms /   448 tokens (    5.21 ms per token,   191.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3770.60 ms /    96 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6253.62 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.33 ms /    69 runs   (    0.57 ms per token,  1754.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5509.82 ms /   994 tokens (    5.54 ms per token,   180.41 tokens per second)\n",
            "llama_print_timings:        eval time =    2755.71 ms /    68 runs   (   40.53 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =    8384.33 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.46 ms /    64 runs   (    0.60 ms per token,  1664.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6022.56 ms /  1093 tokens (    5.51 ms per token,   181.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.23 ms /    63 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =    8707.40 ms /  1156 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.82 ms /    69 runs   (    0.56 ms per token,  1777.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3058.74 ms /   571 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2673.71 ms /    68 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5831.79 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.44 ms /    94 runs   (    0.56 ms per token,  1792.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1764.35 ms /   340 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
            "llama_print_timings:        eval time =    3597.72 ms /    93 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    5490.05 ms /   433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.15 ms /    58 runs   (    0.80 ms per token,  1256.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4244.88 ms /   784 tokens (    5.41 ms per token,   184.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2302.17 ms /    57 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    6677.63 ms /   841 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.18 ms /    72 runs   (    0.56 ms per token,  1791.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2345.16 ms /   443 tokens (    5.29 ms per token,   188.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2767.70 ms /    71 runs   (   38.98 ms per token,    25.65 tokens per second)\n",
            "llama_print_timings:       total time =    5216.43 ms /   514 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.65 ms /    66 runs   (    0.56 ms per token,  1800.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =      84.74 ms /    16 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2578.69 ms /    66 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2748.58 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.43 ms /    73 runs   (    0.62 ms per token,  1606.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4006.85 ms /   744 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2862.26 ms /    72 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6989.77 ms /   816 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.96 ms /    72 runs   (    0.50 ms per token,  2002.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4195.63 ms /   784 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2858.03 ms /    72 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7153.31 ms /   856 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.42 ms /   141 runs   (    0.53 ms per token,  1869.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7311.21 ms /  1293 tokens (    5.65 ms per token,   176.85 tokens per second)\n",
            "llama_print_timings:        eval time =    5817.49 ms /   140 runs   (   41.55 ms per token,    24.07 tokens per second)\n",
            "llama_print_timings:       total time =   13346.02 ms /  1433 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.07 ms /    59 runs   (    0.54 ms per token,  1839.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6063.96 ms /  1093 tokens (    5.55 ms per token,   180.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2361.72 ms /    58 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    8520.12 ms /  1151 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.24 ms /    92 runs   (    0.59 ms per token,  1696.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2544.77 ms /   482 tokens (    5.28 ms per token,   189.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3560.00 ms /    91 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6243.06 ms /   573 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.97 ms /   119 runs   (    0.60 ms per token,  1653.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2317.05 ms /   437 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =    4614.75 ms /   118 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    7116.88 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.21 ms /    91 runs   (    0.58 ms per token,  1710.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3841.30 ms /   712 tokens (    5.40 ms per token,   185.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3571.30 ms /    90 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    7561.18 ms /   802 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1846.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2655.39 ms /   504 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =     271.74 ms /     7 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2944.47 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.04 ms /    70 runs   (    0.54 ms per token,  1839.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6027.85 ms /  1096 tokens (    5.50 ms per token,   181.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2857.01 ms /    70 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    8992.14 ms /  1166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.87 ms /    87 runs   (    0.53 ms per token,  1896.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6554.06 ms /  1175 tokens (    5.58 ms per token,   179.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3534.84 ms /    86 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   10219.32 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.61 ms /    66 runs   (    0.80 ms per token,  1254.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2398.75 ms /   456 tokens (    5.26 ms per token,   190.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2567.24 ms /    65 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    5092.02 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1861.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2841.97 ms /   534 tokens (    5.32 ms per token,   187.90 tokens per second)\n",
            "llama_print_timings:        eval time =     195.45 ms /     5 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3055.35 ms /   539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1854.39 ms /   360 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
            "llama_print_timings:        eval time =     270.19 ms /     7 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2138.63 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1769.70 ms /   342 tokens (    5.17 ms per token,   193.25 tokens per second)\n",
            "llama_print_timings:        eval time =     233.42 ms /     6 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    2016.70 ms /   348 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Amcor plc_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Amcor plc_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Amcor plc_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.44 ms /   104 runs   (    0.59 ms per token,  1692.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2941.22 ms /   558 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =    4066.98 ms /   103 runs   (   39.49 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    7173.17 ms /   661 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.14 ms /   104 runs   (    0.59 ms per token,  1700.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    4084.42 ms /   104 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    4239.23 ms /   104 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.46 ms /    82 runs   (    0.54 ms per token,  1844.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3075.51 ms /   580 tokens (    5.30 ms per token,   188.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3182.36 ms /    81 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6371.70 ms /   661 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.20 ms /    78 runs   (    0.77 ms per token,  1295.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3021.74 ms /   562 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =    3058.60 ms /    77 runs   (   39.72 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6245.34 ms /   639 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.53 ms /    71 runs   (    0.54 ms per token,  1842.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3767.70 ms /   704 tokens (    5.35 ms per token,   186.85 tokens per second)\n",
            "llama_print_timings:        eval time =    2767.94 ms /    70 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    6644.43 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.58 ms /    80 runs   (    0.58 ms per token,  1717.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4675.74 ms /   864 tokens (    5.41 ms per token,   184.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3184.00 ms /    79 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7991.77 ms /   943 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.58 ms /   141 runs   (    0.54 ms per token,  1865.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3031.50 ms /   573 tokens (    5.29 ms per token,   189.02 tokens per second)\n",
            "llama_print_timings:        eval time =    5497.63 ms /   140 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    8726.96 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.72 ms /   122 runs   (    0.66 ms per token,  1511.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2981.47 ms /   555 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
            "llama_print_timings:        eval time =    4775.51 ms /   121 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7970.71 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      98.78 ms /   159 runs   (    0.62 ms per token,  1609.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3386.59 ms /   639 tokens (    5.30 ms per token,   188.69 tokens per second)\n",
            "llama_print_timings:        eval time =    6271.11 ms /   158 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    9923.37 ms /   797 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.00 ms /   110 runs   (    0.53 ms per token,  1896.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3385.97 ms /   635 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
            "llama_print_timings:        eval time =    4284.87 ms /   109 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7823.38 ms /   744 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.29 ms /    54 runs   (    0.54 ms per token,  1843.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5403.83 ms /   983 tokens (    5.50 ms per token,   181.91 tokens per second)\n",
            "llama_print_timings:        eval time =    2143.91 ms /    53 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    7631.30 ms /  1036 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.75 ms /   135 runs   (    0.60 ms per token,  1671.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2746.42 ms /   520 tokens (    5.28 ms per token,   189.34 tokens per second)\n",
            "llama_print_timings:        eval time =    5310.07 ms /   135 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    8272.21 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5108.37 ms /   936 tokens (    5.46 ms per token,   183.23 tokens per second)\n",
            "llama_print_timings:        eval time =     239.38 ms /     6 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5369.50 ms /   942 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.24 ms /    95 runs   (    0.61 ms per token,  1631.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4644.64 ms /   852 tokens (    5.45 ms per token,   183.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3802.05 ms /    94 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8607.50 ms /   946 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.41 ms /   148 runs   (    0.56 ms per token,  1795.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3353.90 ms /   627 tokens (    5.35 ms per token,   186.95 tokens per second)\n",
            "llama_print_timings:        eval time =    5774.75 ms /   147 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    9339.83 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.67 ms /    75 runs   (    0.60 ms per token,  1679.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4693.83 ms /   854 tokens (    5.50 ms per token,   181.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2983.04 ms /    74 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    7801.66 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.69 ms /    75 runs   (    0.54 ms per token,  1843.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3001.58 ms /    75 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    3101.81 ms /    75 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.19 ms /    97 runs   (    0.58 ms per token,  1726.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2368.62 ms /   450 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3764.90 ms /    96 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    6272.50 ms /   546 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.31 ms /   105 runs   (    0.54 ms per token,  1864.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2885.25 ms /   544 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
            "llama_print_timings:        eval time =    4126.73 ms /   105 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7160.36 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.21 ms /    58 runs   (    0.78 ms per token,  1282.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5738.28 ms /  1042 tokens (    5.51 ms per token,   181.59 tokens per second)\n",
            "llama_print_timings:        eval time =    2352.68 ms /    57 runs   (   41.28 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =    8220.06 ms /  1099 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.24 ms /    72 runs   (    0.57 ms per token,  1745.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4492.96 ms /   821 tokens (    5.47 ms per token,   182.73 tokens per second)\n",
            "llama_print_timings:        eval time =    2837.86 ms /    71 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    7453.25 ms /   892 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.62 ms /   256 runs   (    0.58 ms per token,  1722.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2328.31 ms /   443 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
            "llama_print_timings:        eval time =    9979.26 ms /   255 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12714.89 ms /   698 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     164.43 ms /   256 runs   (    0.64 ms per token,  1556.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2499.71 ms /   474 tokens (    5.27 ms per token,   189.62 tokens per second)\n",
            "llama_print_timings:        eval time =   10090.58 ms /   255 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =   13063.42 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.09 ms /    78 runs   (    0.54 ms per token,  1853.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2941.19 ms /   559 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3015.83 ms /    77 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    6061.65 ms /   636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.12 ms /    78 runs   (    0.63 ms per token,  1587.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    3076.51 ms /    78 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    3198.65 ms /    78 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.14 ms /    93 runs   (    0.57 ms per token,  1750.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2432.91 ms /   459 tokens (    5.30 ms per token,   188.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3598.34 ms /    92 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    6163.77 ms /   551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.73 ms /   103 runs   (    0.60 ms per token,  1668.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2413.26 ms /   460 tokens (    5.25 ms per token,   190.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3998.14 ms /   102 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6570.73 ms /   562 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.06 ms /   256 runs   (    0.60 ms per token,  1661.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2448.46 ms /   460 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
            "llama_print_timings:        eval time =    9992.32 ms /   255 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   12872.74 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.41 ms /   105 runs   (    0.57 ms per token,  1767.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2446.15 ms /   461 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =    4077.10 ms /   104 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6670.42 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.12 ms /    95 runs   (    0.56 ms per token,  1788.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1985.90 ms /   383 tokens (    5.19 ms per token,   192.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3653.82 ms /    94 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    5770.31 ms /   477 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.49 ms /   132 runs   (    0.61 ms per token,  1639.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2357.29 ms /   448 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =    5116.14 ms /   131 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    7676.27 ms /   579 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     132.73 ms /   190 runs   (    0.70 ms per token,  1431.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2423.34 ms /   462 tokens (    5.25 ms per token,   190.65 tokens per second)\n",
            "llama_print_timings:        eval time =    7410.25 ms /   189 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   10184.97 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.08 ms /   224 runs   (    0.60 ms per token,  1658.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2378.72 ms /   451 tokens (    5.27 ms per token,   189.60 tokens per second)\n",
            "llama_print_timings:        eval time =    8762.54 ms /   223 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   11506.48 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.66 ms /    70 runs   (    0.54 ms per token,  1858.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4398.74 ms /   812 tokens (    5.42 ms per token,   184.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2754.09 ms /    69 runs   (   39.91 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    7256.81 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.70 ms /    11 runs   (    0.61 ms per token,  1642.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2992.44 ms /   567 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
            "llama_print_timings:        eval time =     390.36 ms /    10 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3408.04 ms /   577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.94 ms /    43 runs   (    0.98 ms per token,  1025.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2420.69 ms /   454 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1650.97 ms /    42 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    4169.08 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.09 ms /   256 runs   (    0.56 ms per token,  1801.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2160.25 ms /   403 tokens (    5.36 ms per token,   186.55 tokens per second)\n",
            "llama_print_timings:        eval time =    9978.04 ms /   255 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12521.74 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.97 ms /    67 runs   (    0.60 ms per token,  1676.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1794.35 ms /   340 tokens (    5.28 ms per token,   189.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2563.13 ms /    66 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    4460.38 ms /   406 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.95 ms /    67 runs   (    0.57 ms per token,  1765.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2594.90 ms /    67 runs   (   38.73 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2682.59 ms /    67 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      27.62 ms /    43 runs   (    0.64 ms per token,  1556.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5651.82 ms /  1028 tokens (    5.50 ms per token,   181.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1719.45 ms /    42 runs   (   40.94 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =    7456.76 ms /  1070 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.36 ms /     6 runs   (    0.73 ms per token,  1375.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3636.11 ms /   671 tokens (    5.42 ms per token,   184.54 tokens per second)\n",
            "llama_print_timings:        eval time =     197.14 ms /     5 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    3856.13 ms /   676 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.79 ms /    89 runs   (    0.55 ms per token,  1824.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4530.73 ms /   835 tokens (    5.43 ms per token,   184.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3522.84 ms /    88 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    8184.18 ms /   923 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.71 ms /   102 runs   (    0.55 ms per token,  1830.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4429.22 ms /   814 tokens (    5.44 ms per token,   183.78 tokens per second)\n",
            "llama_print_timings:        eval time =    4032.36 ms /   101 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    8610.20 ms /   915 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     172.17 ms /   256 runs   (    0.67 ms per token,  1486.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2992.47 ms /   565 tokens (    5.30 ms per token,   188.81 tokens per second)\n",
            "llama_print_timings:        eval time =   10114.09 ms /   255 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =   13596.25 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.13 ms /    81 runs   (    0.67 ms per token,  1496.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4343.89 ms /   808 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3257.47 ms /    81 runs   (   40.22 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7745.53 ms /   889 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.77 ms /   127 runs   (    0.57 ms per token,  1769.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2384.10 ms /   452 tokens (    5.27 ms per token,   189.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4922.90 ms /   126 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    7487.70 ms /   578 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.98 ms /    90 runs   (    0.64 ms per token,  1552.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2900.39 ms /   548 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3517.54 ms /    89 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6577.57 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.03 ms /    92 runs   (    0.64 ms per token,  1558.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2904.36 ms /   552 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3589.79 ms /    91 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6646.71 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.87 ms /    53 runs   (    0.73 ms per token,  1363.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2918.22 ms /   552 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2085.79 ms /    53 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5102.64 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.00 ms /    66 runs   (    0.55 ms per token,  1833.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4036.37 ms /   748 tokens (    5.40 ms per token,   185.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2572.87 ms /    65 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    6705.32 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.65 ms /    75 runs   (    0.65 ms per token,  1541.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4339.79 ms /   807 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2975.09 ms /    74 runs   (   40.20 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7451.11 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    66 runs   (    0.55 ms per token,  1814.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4489.44 ms /   828 tokens (    5.42 ms per token,   184.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2588.98 ms /    65 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7179.77 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.50 ms /    44 runs   (    0.83 ms per token,  1205.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5266.28 ms /   957 tokens (    5.50 ms per token,   181.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1761.52 ms /    43 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =    7132.83 ms /  1000 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.06 ms /   256 runs   (    0.54 ms per token,  1840.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2391.67 ms /   456 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =   10033.95 ms /   256 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =   12818.30 ms /   712 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.94 ms /   256 runs   (    0.57 ms per token,  1766.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2485.39 ms /   469 tokens (    5.30 ms per token,   188.70 tokens per second)\n",
            "llama_print_timings:        eval time =    9974.77 ms /   255 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =   12855.70 ms /   724 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.28 ms /    69 runs   (    0.66 ms per token,  1523.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3967.49 ms /   725 tokens (    5.47 ms per token,   182.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2719.11 ms /    68 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    6816.54 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.47 ms /    69 runs   (    0.54 ms per token,  1841.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    2721.85 ms /    69 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    2812.38 ms /    69 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.98 ms /    12 runs   (    0.58 ms per token,  1719.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2199.74 ms /   423 tokens (    5.20 ms per token,   192.30 tokens per second)\n",
            "llama_print_timings:        eval time =     423.25 ms /    11 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2648.82 ms /   434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      79.59 ms /   119 runs   (    0.67 ms per token,  1495.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2112.19 ms /   404 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4608.11 ms /   118 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    6923.13 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.94 ms /   414 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
            "llama_print_timings:        eval time =     230.60 ms /     6 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    2402.20 ms /   420 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1777.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2334.71 ms /   447 tokens (    5.22 ms per token,   191.46 tokens per second)\n",
            "llama_print_timings:        eval time =     232.42 ms /     6 runs   (   38.74 ms per token,    25.82 tokens per second)\n",
            "llama_print_timings:       total time =    2582.24 ms /   453 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.89 ms /    73 runs   (    0.74 ms per token,  1354.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4020.28 ms /   752 tokens (    5.35 ms per token,   187.05 tokens per second)\n",
            "llama_print_timings:        eval time =    2933.81 ms /    73 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7097.55 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     160.59 ms /   256 runs   (    0.63 ms per token,  1594.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2330.23 ms /   440 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =   10025.15 ms /   256 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12793.40 ms /   696 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1508.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2054.09 ms /   390 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =     234.76 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2308.15 ms /   396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      98.01 ms /   173 runs   (    0.57 ms per token,  1765.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2458.90 ms /   469 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =    6722.75 ms /   172 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    9429.32 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.22 ms /    12 runs   (    0.69 ms per token,  1459.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2787.11 ms /   523 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
            "llama_print_timings:        eval time =     435.15 ms /    11 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    3249.62 ms /   534 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Square, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Square, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Square, Inc._l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.70 ms /    96 runs   (    0.53 ms per token,  1893.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5833.27 ms /  1054 tokens (    5.53 ms per token,   180.69 tokens per second)\n",
            "llama_print_timings:        eval time =    3863.89 ms /    95 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    9840.09 ms /  1149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.66 ms /    99 runs   (    0.52 ms per token,  1916.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5726.94 ms /  1036 tokens (    5.53 ms per token,   180.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3980.43 ms /    98 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    9854.34 ms /  1134 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.28 ms /   256 runs   (    0.58 ms per token,  1714.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2986.65 ms /   564 tokens (    5.30 ms per token,   188.84 tokens per second)\n",
            "llama_print_timings:        eval time =   10064.50 ms /   255 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13481.28 ms /   819 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.98 ms /    83 runs   (    0.65 ms per token,  1537.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3114.37 ms /   583 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3238.37 ms /    82 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6495.61 ms /   665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.64 ms /    73 runs   (    0.53 ms per token,  1889.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5752.14 ms /  1047 tokens (    5.49 ms per token,   182.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2925.57 ms /    72 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    8790.09 ms /  1119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.52 ms /    64 runs   (    0.79 ms per token,  1266.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2243.34 ms /   427 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2463.64 ms /    63 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4839.25 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.38 ms /    68 runs   (    0.68 ms per token,  1466.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4265.16 ms /   792 tokens (    5.39 ms per token,   185.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2694.62 ms /    67 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    7087.49 ms /   859 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.45 ms /    85 runs   (    0.69 ms per token,  1454.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4166.41 ms /   776 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3380.87 ms /    84 runs   (   40.25 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7706.89 ms /   860 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.39 ms /    71 runs   (    0.55 ms per token,  1802.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3610.45 ms /   680 tokens (    5.31 ms per token,   188.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2781.81 ms /    71 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6495.36 ms /   751 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.84 ms /   126 runs   (    0.60 ms per token,  1661.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4959.45 ms /   912 tokens (    5.44 ms per token,   183.89 tokens per second)\n",
            "llama_print_timings:        eval time =    5088.73 ms /   126 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   10251.41 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.47 ms /    90 runs   (    0.73 ms per token,  1374.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6305.82 ms /  1140 tokens (    5.53 ms per token,   180.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3682.68 ms /    89 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   10181.79 ms /  1229 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.08 ms /    77 runs   (    0.53 ms per token,  1874.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5077.42 ms /   922 tokens (    5.51 ms per token,   181.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3056.95 ms /    76 runs   (   40.22 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8253.12 ms /   998 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.85 ms /    82 runs   (    0.61 ms per token,  1645.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3890.71 ms /   722 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3225.01 ms /    81 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7253.25 ms /   803 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.68 ms /   118 runs   (    0.55 ms per token,  1824.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3649.33 ms /   683 tokens (    5.34 ms per token,   187.16 tokens per second)\n",
            "llama_print_timings:        eval time =    4617.82 ms /   117 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    8429.96 ms /   800 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.43 ms /    88 runs   (    0.58 ms per token,  1710.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5040.35 ms /   920 tokens (    5.48 ms per token,   182.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3517.83 ms /    87 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8704.30 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.39 ms /   132 runs   (    0.59 ms per token,  1705.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6265.09 ms /  1133 tokens (    5.53 ms per token,   180.84 tokens per second)\n",
            "llama_print_timings:        eval time =    5388.12 ms /   131 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =   11852.02 ms /  1264 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.31 ms /    72 runs   (    0.56 ms per token,  1786.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2241.75 ms /   432 tokens (    5.19 ms per token,   192.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2798.21 ms /    72 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    5132.63 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.41 ms /    55 runs   (    0.84 ms per token,  1185.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3917.06 ms /   725 tokens (    5.40 ms per token,   185.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2164.82 ms /    54 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    6190.37 ms /   779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      83.95 ms /   161 runs   (    0.52 ms per token,  1917.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3003.08 ms /   566 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =    6280.97 ms /   160 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    9496.09 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.97 ms /    70 runs   (    0.56 ms per token,  1796.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3914.77 ms /   726 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =    2722.75 ms /    69 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6734.25 ms /   795 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.07 ms /    66 runs   (    0.55 ms per token,  1829.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3654.12 ms /   687 tokens (    5.32 ms per token,   188.01 tokens per second)\n",
            "llama_print_timings:        eval time =    2564.16 ms /    65 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6307.16 ms /   752 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.89 ms /    73 runs   (    0.68 ms per token,  1463.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     131.43 ms /    24 tokens (    5.48 ms per token,   182.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2898.97 ms /    73 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    3143.09 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.24 ms /    67 runs   (    0.53 ms per token,  1901.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5835.17 ms /  1050 tokens (    5.56 ms per token,   179.94 tokens per second)\n",
            "llama_print_timings:        eval time =    2679.70 ms /    66 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    8612.21 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1804.86 ms /   346 tokens (    5.22 ms per token,   191.70 tokens per second)\n",
            "llama_print_timings:        eval time =     232.33 ms /     6 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
            "llama_print_timings:       total time =    2050.41 ms /   352 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.76 ms /    99 runs   (    0.62 ms per token,  1602.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2394.44 ms /   455 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =    3829.70 ms /    98 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    6368.87 ms /   553 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.15 ms /    83 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4241.57 ms /   790 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3257.54 ms /    82 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    7608.40 ms /   872 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.93 ms /   256 runs   (    0.57 ms per token,  1766.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1923.97 ms /   368 tokens (    5.23 ms per token,   191.27 tokens per second)\n",
            "llama_print_timings:        eval time =    9952.33 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12246.42 ms /   623 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.69 ms /   236 runs   (    0.57 ms per token,  1739.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3840.12 ms /   711 tokens (    5.40 ms per token,   185.15 tokens per second)\n",
            "llama_print_timings:        eval time =    9336.59 ms /   235 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =   13518.62 ms /   946 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.58 ms /    91 runs   (    0.58 ms per token,  1730.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4257.80 ms /   791 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3581.77 ms /    90 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    7972.57 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      84.35 ms /   134 runs   (    0.63 ms per token,  1588.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1516.18 ms /   295 tokens (    5.14 ms per token,   194.57 tokens per second)\n",
            "llama_print_timings:        eval time =    5143.25 ms /   133 runs   (   38.67 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    6867.18 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.65 ms /    77 runs   (    0.63 ms per token,  1582.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2041.88 ms /   388 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2957.12 ms /    76 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    5112.30 ms /   464 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.36 ms /    66 runs   (    0.54 ms per token,  1866.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3832.49 ms /   715 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2557.57 ms /    65 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    6478.47 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      25.16 ms /    49 runs   (    0.51 ms per token,  1947.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     128.24 ms /    20 tokens (    6.41 ms per token,   155.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1886.66 ms /    48 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2075.05 ms /    68 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      30.89 ms /    59 runs   (    0.52 ms per token,  1910.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4235.54 ms /   784 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2344.45 ms /    59 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    6661.32 ms /   843 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.90 ms /   115 runs   (    0.57 ms per token,  1745.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3379.12 ms /   636 tokens (    5.31 ms per token,   188.21 tokens per second)\n",
            "llama_print_timings:        eval time =    4502.78 ms /   114 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    8044.10 ms /   750 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.76 ms /   256 runs   (    0.60 ms per token,  1664.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3057.10 ms /   574 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
            "llama_print_timings:        eval time =   10075.11 ms /   255 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =   13538.87 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.01 ms /    77 runs   (    0.55 ms per token,  1833.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2351.34 ms /   446 tokens (    5.27 ms per token,   189.68 tokens per second)\n",
            "llama_print_timings:        eval time =    2976.30 ms /    76 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    5426.42 ms /   522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.56 ms /    78 runs   (    0.65 ms per token,  1542.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5309.45 ms /   973 tokens (    5.46 ms per token,   183.26 tokens per second)\n",
            "llama_print_timings:        eval time =    3131.86 ms /    77 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    8569.24 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      75.51 ms /   122 runs   (    0.62 ms per token,  1615.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4523.64 ms /   835 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4872.58 ms /   121 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    9601.33 ms /   956 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       9.91 ms /    14 runs   (    0.71 ms per token,  1412.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1599.36 ms /   309 tokens (    5.18 ms per token,   193.20 tokens per second)\n",
            "llama_print_timings:        eval time =     503.64 ms /    13 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2128.72 ms /   322 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.11 ms /     9 runs   (    0.68 ms per token,  1473.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2098.77 ms /   400 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =     314.24 ms /     8 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    2432.91 ms /   408 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.77 ms /    12 runs   (    0.56 ms per token,  1772.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2289.59 ms /   438 tokens (    5.23 ms per token,   191.30 tokens per second)\n",
            "llama_print_timings:        eval time =     424.48 ms /    11 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
            "llama_print_timings:       total time =    2734.71 ms /   449 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     105.30 ms /   196 runs   (    0.54 ms per token,  1861.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     126.45 ms /    19 tokens (    6.66 ms per token,   150.26 tokens per second)\n",
            "llama_print_timings:        eval time =    7618.85 ms /   195 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    8004.01 ms /   214 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.73 ms /    74 runs   (    0.52 ms per token,  1910.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5013.89 ms /   917 tokens (    5.47 ms per token,   182.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2926.00 ms /    73 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    8039.58 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.64 ms /    70 runs   (    0.77 ms per token,  1305.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3875.03 ms /   724 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2762.42 ms /    69 runs   (   40.04 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6763.28 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     138.69 ms /   256 runs   (    0.54 ms per token,  1845.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2291.84 ms /   432 tokens (    5.31 ms per token,   188.49 tokens per second)\n",
            "llama_print_timings:        eval time =   10022.84 ms /   256 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   12666.06 ms /   688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.17 ms /   256 runs   (    0.54 ms per token,  1839.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2833.17 ms /   536 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =   10051.31 ms /   256 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =   13237.97 ms /   792 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     100.91 ms /   141 runs   (    0.72 ms per token,  1397.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2259.08 ms /   430 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
            "llama_print_timings:        eval time =    5495.90 ms /   140 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    7993.31 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.43 ms /   236 runs   (    0.59 ms per token,  1692.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2195.84 ms /   421 tokens (    5.22 ms per token,   191.73 tokens per second)\n",
            "llama_print_timings:        eval time =    9207.43 ms /   235 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =   11763.66 ms /   656 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.96 ms /    60 runs   (    0.53 ms per token,  1877.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3161.27 ms /   600 tokens (    5.27 ms per token,   189.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2352.72 ms /    60 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    5592.47 ms /   660 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     162.62 ms /   256 runs   (    0.64 ms per token,  1574.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2543.33 ms /   488 tokens (    5.21 ms per token,   191.87 tokens per second)\n",
            "llama_print_timings:        eval time =   10036.50 ms /   255 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =   13005.91 ms /   743 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.20 ms /    82 runs   (    0.60 ms per token,  1666.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3468.20 ms /   654 tokens (    5.30 ms per token,   188.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3198.12 ms /    81 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    6787.83 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.44 ms /    78 runs   (    0.53 ms per token,  1882.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5698.05 ms /  1036 tokens (    5.50 ms per token,   181.82 tokens per second)\n",
            "llama_print_timings:        eval time =    3122.04 ms /    77 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    8931.09 ms /  1113 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.27 ms /    68 runs   (    0.59 ms per token,  1688.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5806.37 ms /  1054 tokens (    5.51 ms per token,   181.52 tokens per second)\n",
            "llama_print_timings:        eval time =    2733.24 ms /    67 runs   (   40.79 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    8649.18 ms /  1121 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      25.01 ms /    45 runs   (    0.56 ms per token,  1799.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2706.77 ms /   512 tokens (    5.29 ms per token,   189.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1726.66 ms /    44 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    4496.95 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     149.44 ms /   256 runs   (    0.58 ms per token,  1713.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2632.01 ms /   500 tokens (    5.26 ms per token,   189.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9987.50 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12998.10 ms /   755 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.54 ms /    56 runs   (    0.71 ms per token,  1416.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3789.99 ms /   712 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2236.53 ms /    56 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    6122.41 ms /   768 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1804.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2674.32 ms /   506 tokens (    5.29 ms per token,   189.21 tokens per second)\n",
            "llama_print_timings:        eval time =     236.89 ms /     6 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
            "llama_print_timings:       total time =    2929.81 ms /   512 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.43 ms /    69 runs   (    0.64 ms per token,  1553.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3897.43 ms /   728 tokens (    5.35 ms per token,   186.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2706.97 ms /    68 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    6713.18 ms /   796 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.61 ms /   121 runs   (    0.54 ms per token,  1844.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4282.07 ms /   792 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4770.31 ms /   120 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    9212.19 ms /   912 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.31 ms /   102 runs   (    0.56 ms per token,  1779.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1936.13 ms /   370 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3913.93 ms /   101 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    5988.29 ms /   471 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2403.51 ms /   456 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =     232.79 ms /     6 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    2653.33 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      60.20 ms /   109 runs   (    0.55 ms per token,  1810.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2105.14 ms /   402 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4198.74 ms /   108 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    6441.30 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_3M CO_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_3M CO_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_3M CO_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.32 ms /    87 runs   (    0.72 ms per token,  1396.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2785.29 ms /   528 tokens (    5.28 ms per token,   189.57 tokens per second)\n",
            "llama_print_timings:        eval time =    3411.11 ms /    86 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    6359.08 ms /   614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.44 ms /    90 runs   (    0.54 ms per token,  1857.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3309.42 ms /   624 tokens (    5.30 ms per token,   188.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3543.49 ms /    90 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6970.03 ms /   714 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.74 ms /   112 runs   (    0.63 ms per token,  1583.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2799.45 ms /   532 tokens (    5.26 ms per token,   190.04 tokens per second)\n",
            "llama_print_timings:        eval time =    4366.43 ms /   111 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    7340.23 ms /   643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.69 ms /     9 runs   (    0.52 ms per token,  1917.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2629.28 ms /   499 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =     313.97 ms /     8 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    2959.82 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.21 ms /    74 runs   (    0.53 ms per token,  1887.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2758.18 ms /   522 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2867.11 ms /    73 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    5719.15 ms /   595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.30 ms /    73 runs   (    0.73 ms per token,  1369.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1945.97 ms /   376 tokens (    5.18 ms per token,   193.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2819.42 ms /    72 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    4898.70 ms /   448 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     139.05 ms /   256 runs   (    0.54 ms per token,  1841.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2861.61 ms /   536 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
            "llama_print_timings:        eval time =   10018.30 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   13236.46 ms /   791 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.06 ms /    95 runs   (    0.57 ms per token,  1757.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2176.95 ms /   415 tokens (    5.25 ms per token,   190.63 tokens per second)\n",
            "llama_print_timings:        eval time =    3667.17 ms /    94 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
            "llama_print_timings:       total time =    5972.02 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.53 ms /    83 runs   (    0.54 ms per token,  1863.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3606.58 ms /   680 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3269.47 ms /    83 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    6985.56 ms /   763 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.03 ms /   111 runs   (    0.66 ms per token,  1519.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3030.55 ms /   564 tokens (    5.37 ms per token,   186.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4356.48 ms /   110 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7567.88 ms /   674 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.98 ms /   109 runs   (    0.51 ms per token,  1947.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3742.06 ms /   703 tokens (    5.32 ms per token,   187.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4266.03 ms /   108 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    8147.06 ms /   811 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.32 ms /    95 runs   (    0.57 ms per token,  1748.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2889.04 ms /   543 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3698.30 ms /    94 runs   (   39.34 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6717.26 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.38 ms /    77 runs   (    0.56 ms per token,  1774.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4012.27 ms /   749 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3005.63 ms /    76 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    7123.89 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.85 ms /   256 runs   (    0.58 ms per token,  1731.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2184.25 ms /   412 tokens (    5.30 ms per token,   188.62 tokens per second)\n",
            "llama_print_timings:        eval time =    9981.63 ms /   255 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   12550.54 ms /   667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      96.53 ms /   159 runs   (    0.61 ms per token,  1647.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3040.11 ms /   571 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =    6203.82 ms /   158 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    9477.71 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     112.09 ms /   153 runs   (    0.73 ms per token,  1364.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2849.15 ms /   538 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =    6004.03 ms /   152 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    9135.86 ms /   690 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1650.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2174.80 ms /   416 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
            "llama_print_timings:        eval time =     268.68 ms /     7 runs   (   38.38 ms per token,    26.05 tokens per second)\n",
            "llama_print_timings:       total time =    2458.26 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     122.03 ms /   206 runs   (    0.59 ms per token,  1688.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.16 ms /   536 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
            "llama_print_timings:        eval time =    8115.67 ms /   206 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   11238.92 ms /   742 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.00 ms /    94 runs   (    0.54 ms per token,  1843.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1481.25 ms /   279 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3636.19 ms /    93 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5235.89 ms /   372 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.29 ms /    93 runs   (    0.58 ms per token,  1712.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1985.67 ms /   383 tokens (    5.18 ms per token,   192.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3579.58 ms /    92 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    5688.21 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.46 ms /    74 runs   (    0.72 ms per token,  1384.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1380.70 ms /   264 tokens (    5.23 ms per token,   191.21 tokens per second)\n",
            "llama_print_timings:        eval time =    2841.55 ms /    73 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4348.01 ms /   337 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.96 ms /    62 runs   (    0.55 ms per token,  1825.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2280.01 ms /   432 tokens (    5.28 ms per token,   189.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2375.87 ms /    61 runs   (   38.95 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    4735.88 ms /   493 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.03 ms /   100 runs   (    0.56 ms per token,  1784.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1559.61 ms /   303 tokens (    5.15 ms per token,   194.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3817.54 ms /    99 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    5505.49 ms /   402 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      80.74 ms /   120 runs   (    0.67 ms per token,  1486.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1513.49 ms /   290 tokens (    5.22 ms per token,   191.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4613.53 ms /   119 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    6315.41 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.46 ms /    65 runs   (    0.53 ms per token,  1886.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2369.12 ms /   451 tokens (    5.25 ms per token,   190.37 tokens per second)\n",
            "llama_print_timings:        eval time =    2501.56 ms /    64 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    4953.01 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.23 ms /    12 runs   (    0.52 ms per token,  1925.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2593.22 ms /   495 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     432.96 ms /    11 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    3047.00 ms /   506 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.62 ms /    64 runs   (    0.70 ms per token,  1434.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2491.33 ms /   472 tokens (    5.28 ms per token,   189.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2517.12 ms /    64 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5125.27 ms /   536 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     144.88 ms /   256 runs   (    0.57 ms per token,  1767.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     169.60 ms /    27 tokens (    6.28 ms per token,   159.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9988.02 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   10523.60 ms /   282 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.80 ms /   103 runs   (    0.57 ms per token,  1751.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3462.44 ms /   647 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4029.34 ms /   102 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    7638.77 ms /   749 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.08 ms /   143 runs   (    0.62 ms per token,  1605.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2244.66 ms /   428 tokens (    5.24 ms per token,   190.67 tokens per second)\n",
            "llama_print_timings:        eval time =    5566.20 ms /   142 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    8035.68 ms /   570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      72.23 ms /    90 runs   (    0.80 ms per token,  1246.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1427.36 ms /   272 tokens (    5.25 ms per token,   190.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3497.13 ms /    90 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    5108.37 ms /   362 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1790.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2417.48 ms /   461 tokens (    5.24 ms per token,   190.69 tokens per second)\n",
            "llama_print_timings:        eval time =     232.49 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2665.29 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.88 ms /    81 runs   (    0.58 ms per token,  1727.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1309.52 ms /   255 tokens (    5.14 ms per token,   194.73 tokens per second)\n",
            "llama_print_timings:        eval time =    3074.42 ms /    80 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
            "llama_print_timings:       total time =    4493.56 ms /   335 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.62 ms /    72 runs   (    0.55 ms per token,  1817.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4141.76 ms /   766 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =    2826.14 ms /    71 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    7081.57 ms /   837 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      31.34 ms /    58 runs   (    0.54 ms per token,  1850.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2245.04 ms /   428 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
            "llama_print_timings:        eval time =    2216.81 ms /    57 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
            "llama_print_timings:       total time =    4541.27 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2635.28 ms /   504 tokens (    5.23 ms per token,   191.25 tokens per second)\n",
            "llama_print_timings:        eval time =     236.14 ms /     6 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    2885.78 ms /   510 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     6 runs   (    0.80 ms per token,  1250.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2754.30 ms /   516 tokens (    5.34 ms per token,   187.34 tokens per second)\n",
            "llama_print_timings:        eval time =     199.66 ms /     5 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    2972.94 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.80 ms /     7 runs   (    0.69 ms per token,  1457.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2465.90 ms /   461 tokens (    5.35 ms per token,   186.95 tokens per second)\n",
            "llama_print_timings:        eval time =     237.10 ms /     6 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    2726.04 ms /   467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.48 ms /   118 runs   (    0.55 ms per token,  1802.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3180.32 ms /   596 tokens (    5.34 ms per token,   187.40 tokens per second)\n",
            "llama_print_timings:        eval time =    4586.33 ms /   117 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7935.79 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.49 ms /   256 runs   (    0.60 ms per token,  1667.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2203.16 ms /   420 tokens (    5.25 ms per token,   190.64 tokens per second)\n",
            "llama_print_timings:        eval time =    9953.54 ms /   255 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =   12577.04 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.50 ms /    70 runs   (    0.69 ms per token,  1443.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.13 ms /   536 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2721.23 ms /    69 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    5664.76 ms /   605 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.88 ms /     7 runs   (    0.70 ms per token,  1435.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2321.65 ms /   435 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =     239.32 ms /     6 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    2582.44 ms /   441 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     153.39 ms /   256 runs   (    0.60 ms per token,  1668.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     427.05 ms /    76 tokens (    5.62 ms per token,   177.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9983.43 ms /   255 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =   10837.93 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1813.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2568.35 ms /   484 tokens (    5.31 ms per token,   188.45 tokens per second)\n",
            "llama_print_timings:        eval time =     232.89 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2820.79 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.15 ms /    71 runs   (    0.54 ms per token,  1860.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2457.68 ms /   467 tokens (    5.26 ms per token,   190.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2741.51 ms /    70 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5296.43 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     167.22 ms /   256 runs   (    0.65 ms per token,  1530.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2076.80 ms /   394 tokens (    5.27 ms per token,   189.71 tokens per second)\n",
            "llama_print_timings:        eval time =   10005.27 ms /   255 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =   12553.90 ms /   649 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.15 ms /    80 runs   (    0.59 ms per token,  1696.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1559.38 ms /   304 tokens (    5.13 ms per token,   194.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3094.35 ms /    80 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    4770.29 ms /   384 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     135.30 ms /   256 runs   (    0.53 ms per token,  1892.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2731.31 ms /   508 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =   10019.23 ms /   255 runs   (   39.29 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =   13131.28 ms /   763 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.32 ms /     7 runs   (    0.62 ms per token,  1621.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2624.89 ms /   495 tokens (    5.30 ms per token,   188.58 tokens per second)\n",
            "llama_print_timings:        eval time =     233.51 ms /     6 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    2878.79 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.85 ms /    12 runs   (    0.57 ms per token,  1750.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2863.80 ms /   544 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
            "llama_print_timings:        eval time =     470.12 ms /    12 runs   (   39.18 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3358.11 ms /   556 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.10 ms /     6 runs   (    0.68 ms per token,  1463.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1701.04 ms /   328 tokens (    5.19 ms per token,   192.82 tokens per second)\n",
            "llama_print_timings:        eval time =     232.10 ms /     6 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
            "llama_print_timings:       total time =    1948.35 ms /   334 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      23.60 ms /    42 runs   (    0.56 ms per token,  1779.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2451.05 ms /   464 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1600.34 ms /    41 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    4114.95 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       8.07 ms /    11 runs   (    0.73 ms per token,  1363.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2130.35 ms /   408 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
            "llama_print_timings:        eval time =     389.40 ms /    10 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    2549.64 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.33 ms /    66 runs   (    0.57 ms per token,  1767.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2274.23 ms /   431 tokens (    5.28 ms per token,   189.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2531.22 ms /    65 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
            "llama_print_timings:       total time =    4902.44 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.17 ms /    75 runs   (    0.58 ms per token,  1737.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2332.91 ms /   443 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2893.35 ms /    74 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    5331.18 ms /   517 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     152.89 ms /   256 runs   (    0.60 ms per token,  1674.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1992.61 ms /   378 tokens (    5.27 ms per token,   189.70 tokens per second)\n",
            "llama_print_timings:        eval time =    9956.38 ms /   255 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12372.08 ms /   633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     154.62 ms /   256 runs   (    0.60 ms per token,  1655.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1966.27 ms /   370 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =    9957.19 ms /   255 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12341.08 ms /   625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     103.43 ms /   166 runs   (    0.62 ms per token,  1605.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2726.64 ms /   520 tokens (    5.24 ms per token,   190.71 tokens per second)\n",
            "llama_print_timings:        eval time =    6493.18 ms /   165 runs   (   39.35 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    9494.85 ms /   685 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.72 ms /    82 runs   (    0.58 ms per token,  1718.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2202.11 ms /   419 tokens (    5.26 ms per token,   190.27 tokens per second)\n",
            "llama_print_timings:        eval time =    3163.07 ms /    81 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =    5479.75 ms /   500 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.61 ms /    65 runs   (    0.78 ms per token,  1284.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4672.81 ms /   853 tokens (    5.48 ms per token,   182.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2604.04 ms /    64 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
            "llama_print_timings:       total time =    7411.31 ms /   917 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      61.67 ms /   112 runs   (    0.55 ms per token,  1816.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3638.66 ms /   663 tokens (    5.49 ms per token,   182.21 tokens per second)\n",
            "llama_print_timings:        eval time =    4435.68 ms /   111 runs   (   39.96 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    8235.39 ms /   774 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.36 ms /     6 runs   (    0.73 ms per token,  1375.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2818.08 ms /   536 tokens (    5.26 ms per token,   190.20 tokens per second)\n",
            "llama_print_timings:        eval time =     236.81 ms /     6 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    3072.75 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.57 ms /    75 runs   (    0.63 ms per token,  1576.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2192.30 ms /   416 tokens (    5.27 ms per token,   189.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2892.24 ms /    74 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5201.64 ms /   490 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      73.62 ms /   131 runs   (    0.56 ms per token,  1779.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     212.43 ms /    36 tokens (    5.90 ms per token,   169.47 tokens per second)\n",
            "llama_print_timings:        eval time =    5087.52 ms /   130 runs   (   39.13 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    5481.84 ms /   166 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_MICROSOFT CORP_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      88.39 ms /   131 runs   (    0.67 ms per token,  1482.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3507.21 ms /   655 tokens (    5.35 ms per token,   186.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5221.70 ms /   130 runs   (   40.17 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8976.91 ms /   785 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1930.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2637.41 ms /   502 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
            "llama_print_timings:        eval time =     236.82 ms /     6 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    2890.13 ms /   508 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2377.66 ms /   456 tokens (    5.21 ms per token,   191.78 tokens per second)\n",
            "llama_print_timings:        eval time =     273.42 ms /     7 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    2667.55 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1749.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2597.26 ms /   496 tokens (    5.24 ms per token,   190.97 tokens per second)\n",
            "llama_print_timings:        eval time =     234.78 ms /     6 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2848.72 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.06 ms /    65 runs   (    0.66 ms per token,  1509.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2352.87 ms /   447 tokens (    5.26 ms per token,   189.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2502.49 ms /    64 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    4965.85 ms /   511 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.81 ms /    84 runs   (    0.57 ms per token,  1756.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2633.99 ms /   501 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3249.54 ms /    83 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    6005.91 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.92 ms /   118 runs   (    0.74 ms per token,  1357.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2332.96 ms /   448 tokens (    5.21 ms per token,   192.03 tokens per second)\n",
            "llama_print_timings:        eval time =    4604.64 ms /   117 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    7165.16 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.66 ms /   164 runs   (    0.53 ms per token,  1892.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4112.06 ms /   760 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =    6535.09 ms /   164 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =   10886.95 ms /   924 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.66 ms /     7 runs   (    0.67 ms per token,  1500.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2702.70 ms /   509 tokens (    5.31 ms per token,   188.33 tokens per second)\n",
            "llama_print_timings:        eval time =     235.89 ms /     6 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    2958.21 ms /   515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.69 ms /     7 runs   (    0.53 ms per token,  1895.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2616.37 ms /   495 tokens (    5.29 ms per token,   189.19 tokens per second)\n",
            "llama_print_timings:        eval time =     232.93 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2865.49 ms /   501 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      25.73 ms /    46 runs   (    0.56 ms per token,  1787.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =      85.55 ms /    16 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1792.11 ms /    46 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    1941.10 ms /    62 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.96 ms /    82 runs   (    0.55 ms per token,  1823.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2722.72 ms /   516 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3169.35 ms /    81 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6006.87 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     179.95 ms /   256 runs   (    0.70 ms per token,  1422.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1447.58 ms /   277 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =    9937.65 ms /   255 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =   11874.16 ms /   532 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.38 ms /   103 runs   (    0.64 ms per token,  1551.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2375.89 ms /   456 tokens (    5.21 ms per token,   191.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4037.49 ms /   103 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6588.21 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      58.44 ms /   106 runs   (    0.55 ms per token,  1813.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1957.22 ms /   376 tokens (    5.21 ms per token,   192.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4124.44 ms /   106 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    6226.53 ms /   482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.99 ms /    77 runs   (    0.73 ms per token,  1375.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5463.67 ms /   995 tokens (    5.49 ms per token,   182.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3125.45 ms /    76 runs   (   41.12 ms per token,    24.32 tokens per second)\n",
            "llama_print_timings:       total time =    8745.11 ms /  1071 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.24 ms /    85 runs   (    0.56 ms per token,  1799.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2714.67 ms /   512 tokens (    5.30 ms per token,   188.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3331.73 ms /    85 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6170.97 ms /   597 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.48 ms /    12 runs   (    0.54 ms per token,  1852.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2461.49 ms /   469 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =     430.31 ms /    11 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    2913.76 ms /   480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.36 ms /    67 runs   (    0.57 ms per token,  1746.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5019.06 ms /   917 tokens (    5.47 ms per token,   182.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2658.08 ms /    66 runs   (   40.27 ms per token,    24.83 tokens per second)\n",
            "llama_print_timings:       total time =    7785.90 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.77 ms /    66 runs   (    0.54 ms per token,  1844.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4572.52 ms /   845 tokens (    5.41 ms per token,   184.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2601.64 ms /    65 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7273.88 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.54 ms /    70 runs   (    0.81 ms per token,  1238.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2668.22 ms /   502 tokens (    5.32 ms per token,   188.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2737.68 ms /    69 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    5546.17 ms /   571 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      32.29 ms /    60 runs   (    0.54 ms per token,  1857.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3184.05 ms /   600 tokens (    5.31 ms per token,   188.44 tokens per second)\n",
            "llama_print_timings:        eval time =    2313.27 ms /    59 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5584.63 ms /   659 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.58 ms /    59 runs   (    0.67 ms per token,  1490.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3566.20 ms /   671 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
            "llama_print_timings:        eval time =    2310.64 ms /    58 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    5982.19 ms /   729 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.19 ms /    80 runs   (    0.56 ms per token,  1770.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3487.82 ms /   652 tokens (    5.35 ms per token,   186.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3099.97 ms /    79 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6708.77 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.17 ms /     7 runs   (    0.60 ms per token,  1679.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2638.18 ms /   503 tokens (    5.24 ms per token,   190.66 tokens per second)\n",
            "llama_print_timings:        eval time =     232.90 ms /     6 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    2889.01 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.16 ms /     6 runs   (    0.69 ms per token,  1443.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2132.33 ms /   405 tokens (    5.27 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =     195.19 ms /     5 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    2343.72 ms /   410 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.90 ms /     7 runs   (    0.70 ms per token,  1428.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2140.88 ms /   403 tokens (    5.31 ms per token,   188.24 tokens per second)\n",
            "llama_print_timings:        eval time =     234.43 ms /     6 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    2395.49 ms /   409 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.50 ms /     7 runs   (    0.79 ms per token,  1273.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1837.05 ms /   350 tokens (    5.25 ms per token,   190.52 tokens per second)\n",
            "llama_print_timings:        eval time =     232.48 ms /     6 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
            "llama_print_timings:       total time =    2088.81 ms /   356 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.05 ms /   120 runs   (    0.57 ms per token,  1763.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2936.39 ms /   551 tokens (    5.33 ms per token,   187.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4653.90 ms /   119 runs   (   39.11 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    7762.61 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     142.80 ms /   256 runs   (    0.56 ms per token,  1792.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3246.68 ms /   602 tokens (    5.39 ms per token,   185.42 tokens per second)\n",
            "llama_print_timings:        eval time =   10061.85 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13694.31 ms /   857 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.59 ms /    71 runs   (    0.57 ms per token,  1748.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2846.06 ms /   530 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    2735.16 ms /    70 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    5690.72 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.50 ms /     6 runs   (    0.75 ms per token,  1332.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1953.80 ms /   370 tokens (    5.28 ms per token,   189.37 tokens per second)\n",
            "llama_print_timings:        eval time =     193.77 ms /     5 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
            "llama_print_timings:       total time =    2164.28 ms /   375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1822.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2580.00 ms /   486 tokens (    5.31 ms per token,   188.37 tokens per second)\n",
            "llama_print_timings:        eval time =     195.71 ms /     5 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    2794.49 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.42 ms /     6 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1687.85 ms /   326 tokens (    5.18 ms per token,   193.15 tokens per second)\n",
            "llama_print_timings:        eval time =     194.23 ms /     5 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    1896.42 ms /   331 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.09 ms /     6 runs   (    0.68 ms per token,  1466.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1652.99 ms /   316 tokens (    5.23 ms per token,   191.17 tokens per second)\n",
            "llama_print_timings:        eval time =     192.82 ms /     5 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
            "llama_print_timings:       total time =    1859.93 ms /   321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.48 ms /    65 runs   (    0.55 ms per token,  1832.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2844.10 ms /   536 tokens (    5.31 ms per token,   188.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2551.55 ms /    65 runs   (   39.25 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    5488.68 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     141.68 ms /   256 runs   (    0.55 ms per token,  1806.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2810.51 ms /   531 tokens (    5.29 ms per token,   188.93 tokens per second)\n",
            "llama_print_timings:        eval time =   10069.46 ms /   255 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =   13296.47 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.31 ms /    93 runs   (    0.70 ms per token,  1424.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1689.53 ms /   326 tokens (    5.18 ms per token,   192.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3570.05 ms /    92 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    5419.55 ms /   418 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     128.78 ms /   225 runs   (    0.57 ms per token,  1747.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3337.21 ms /   624 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
            "llama_print_timings:        eval time =    8894.77 ms /   225 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =   12575.48 ms /   849 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.64 ms /     7 runs   (    0.66 ms per token,  1508.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2774.93 ms /   524 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =     240.07 ms /     6 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    3033.70 ms /   530 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.44 ms /    54 runs   (    0.55 ms per token,  1834.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4880.51 ms /   893 tokens (    5.47 ms per token,   182.97 tokens per second)\n",
            "llama_print_timings:        eval time =    2130.39 ms /    53 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    7096.04 ms /   946 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.92 ms /    65 runs   (    0.69 ms per token,  1446.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4574.78 ms /   844 tokens (    5.42 ms per token,   184.49 tokens per second)\n",
            "llama_print_timings:        eval time =    2598.83 ms /    64 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    7297.10 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.62 ms /    69 runs   (    0.53 ms per token,  1883.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4952.40 ms /   904 tokens (    5.48 ms per token,   182.54 tokens per second)\n",
            "llama_print_timings:        eval time =    2735.90 ms /    68 runs   (   40.23 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7792.64 ms /   972 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      41.54 ms /    64 runs   (    0.65 ms per token,  1540.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4573.80 ms /   843 tokens (    5.43 ms per token,   184.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2542.24 ms /    63 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    7235.22 ms /   906 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.58 ms /     7 runs   (    0.66 ms per token,  1526.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3364.84 ms /   629 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =     233.82 ms /     6 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    3620.18 ms /   635 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     168.50 ms /   256 runs   (    0.66 ms per token,  1519.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2286.81 ms /   437 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
            "llama_print_timings:        eval time =   10056.78 ms /   255 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   12837.18 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.98 ms /    11 runs   (    0.54 ms per token,  1841.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2835.68 ms /   534 tokens (    5.31 ms per token,   188.31 tokens per second)\n",
            "llama_print_timings:        eval time =     389.97 ms /    10 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3248.76 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1783.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1897.45 ms /   363 tokens (    5.23 ms per token,   191.31 tokens per second)\n",
            "llama_print_timings:        eval time =     191.84 ms /     5 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
            "llama_print_timings:       total time =    2101.24 ms /   368 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.67 ms /    12 runs   (    0.56 ms per token,  1797.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2812.38 ms /   536 tokens (    5.25 ms per token,   190.59 tokens per second)\n",
            "llama_print_timings:        eval time =     465.76 ms /    12 runs   (   38.81 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    3300.71 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.52 ms /   254 runs   (    0.60 ms per token,  1676.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2505.80 ms /   478 tokens (    5.24 ms per token,   190.76 tokens per second)\n",
            "llama_print_timings:        eval time =    9920.29 ms /   253 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =   12833.22 ms /   731 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.71 ms /     7 runs   (    0.67 ms per token,  1487.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2637.10 ms /   503 tokens (    5.24 ms per token,   190.74 tokens per second)\n",
            "llama_print_timings:        eval time =     238.19 ms /     6 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    2893.56 ms /   509 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.22 ms /    64 runs   (    0.86 ms per token,  1159.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3537.06 ms /   656 tokens (    5.39 ms per token,   185.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2526.07 ms /    63 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    6203.36 ms /   719 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      65.98 ms /   120 runs   (    0.55 ms per token,  1818.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.16 ms /   309 tokens (    5.18 ms per token,   192.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4602.35 ms /   119 runs   (   38.68 ms per token,    25.86 tokens per second)\n",
            "llama_print_timings:       total time =    6366.85 ms /   428 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.79 ms /    12 runs   (    0.57 ms per token,  1768.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2419.37 ms /   464 tokens (    5.21 ms per token,   191.79 tokens per second)\n",
            "llama_print_timings:        eval time =     465.95 ms /    12 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
            "llama_print_timings:       total time =    2907.66 ms /   476 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.95 ms /     7 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2748.46 ms /   517 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
            "llama_print_timings:        eval time =     240.76 ms /     6 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    3010.04 ms /   523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.40 ms /    72 runs   (    0.55 ms per token,  1827.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5000.30 ms /   919 tokens (    5.44 ms per token,   183.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2854.69 ms /    71 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7962.84 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     145.25 ms /   217 runs   (    0.67 ms per token,  1494.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2375.93 ms /   454 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
            "llama_print_timings:        eval time =    8520.10 ms /   216 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   11317.13 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.93 ms /    12 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2942.29 ms /   556 tokens (    5.29 ms per token,   188.97 tokens per second)\n",
            "llama_print_timings:        eval time =     429.80 ms /    11 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =    3396.06 ms /   567 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.17 ms /   256 runs   (    0.61 ms per token,  1639.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1726.40 ms /   332 tokens (    5.20 ms per token,   192.31 tokens per second)\n",
            "llama_print_timings:        eval time =    9911.07 ms /   255 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =   12054.00 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_Ulta Beauty, Inc._l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      23.75 ms /    37 runs   (    0.64 ms per token,  1557.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6036.59 ms /  1094 tokens (    5.52 ms per token,   181.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.70 ms /    36 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =    7600.85 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.96 ms /    94 runs   (    0.64 ms per token,  1567.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3071.80 ms /   570 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3652.44 ms /    93 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6870.86 ms /   663 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.22 ms /    89 runs   (    0.67 ms per token,  1503.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6455.16 ms /  1168 tokens (    5.53 ms per token,   180.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3690.41 ms /    89 runs   (   41.47 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   10312.34 ms /  1257 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     102.57 ms /   176 runs   (    0.58 ms per token,  1715.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6026.86 ms /  1095 tokens (    5.50 ms per token,   181.69 tokens per second)\n",
            "llama_print_timings:        eval time =    7221.47 ms /   175 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =   13549.57 ms /  1270 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.88 ms /    64 runs   (    0.59 ms per token,  1689.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2023.79 ms /   381 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2460.61 ms /    63 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    4578.02 ms /   444 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.76 ms /    68 runs   (    0.54 ms per token,  1849.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2985.83 ms /   563 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2632.99 ms /    67 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    5710.39 ms /   630 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.35 ms /   119 runs   (    0.52 ms per token,  1908.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6483.44 ms /  1162 tokens (    5.58 ms per token,   179.23 tokens per second)\n",
            "llama_print_timings:        eval time =    4848.22 ms /   118 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =   11503.13 ms /  1280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     132.31 ms /   219 runs   (    0.60 ms per token,  1655.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6214.00 ms /  1115 tokens (    5.57 ms per token,   179.43 tokens per second)\n",
            "llama_print_timings:        eval time =    8997.52 ms /   218 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =   15589.75 ms /  1333 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.60 ms /    98 runs   (    0.53 ms per token,  1899.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     140.96 ms /    24 tokens (    5.87 ms per token,   170.27 tokens per second)\n",
            "llama_print_timings:        eval time =    4010.45 ms /    98 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =    4282.61 ms /   122 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.84 ms /    11 runs   (    0.62 ms per token,  1608.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3067.74 ms /   573 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
            "llama_print_timings:        eval time =     395.56 ms /    10 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    3489.47 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      85.70 ms /   136 runs   (    0.63 ms per token,  1586.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6211.50 ms /  1123 tokens (    5.53 ms per token,   180.79 tokens per second)\n",
            "llama_print_timings:        eval time =    5569.55 ms /   135 runs   (   41.26 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =   12036.27 ms /  1258 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.99 ms /   110 runs   (    0.57 ms per token,  1746.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3045.66 ms /   566 tokens (    5.38 ms per token,   185.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4279.52 ms /   109 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
            "llama_print_timings:       total time =    7484.73 ms /   675 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.39 ms /    77 runs   (    0.71 ms per token,  1415.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6025.79 ms /  1090 tokens (    5.53 ms per token,   180.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3131.38 ms /    76 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
            "llama_print_timings:       total time =    9308.76 ms /  1166 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     158.22 ms /   229 runs   (    0.69 ms per token,  1447.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6456.90 ms /  1165 tokens (    5.54 ms per token,   180.43 tokens per second)\n",
            "llama_print_timings:        eval time =    9481.57 ms /   228 runs   (   41.59 ms per token,    24.05 tokens per second)\n",
            "llama_print_timings:       total time =   16418.50 ms /  1393 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      89.50 ms /   148 runs   (    0.60 ms per token,  1653.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6169.44 ms /  1120 tokens (    5.51 ms per token,   181.54 tokens per second)\n",
            "llama_print_timings:        eval time =    6049.18 ms /   147 runs   (   41.15 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =   12473.97 ms /  1267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     170.31 ms /   256 runs   (    0.67 ms per token,  1503.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2724.66 ms /   520 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10039.39 ms /   255 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =   13235.10 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.51 ms /    66 runs   (    0.60 ms per token,  1670.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2068.68 ms /   387 tokens (    5.35 ms per token,   187.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2533.41 ms /    65 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
            "llama_print_timings:       total time =    4711.30 ms /   452 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.12 ms /   100 runs   (    0.54 ms per token,  1847.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3607.92 ms /   676 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =    3890.81 ms /    99 runs   (   39.30 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7638.38 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.59 ms /    86 runs   (    0.57 ms per token,  1769.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3191.88 ms /   596 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
            "llama_print_timings:        eval time =    3341.68 ms /    85 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6660.38 ms /   681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      54.88 ms /    95 runs   (    0.58 ms per token,  1731.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3028.74 ms /   570 tokens (    5.31 ms per token,   188.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3694.02 ms /    94 runs   (   39.30 ms per token,    25.45 tokens per second)\n",
            "llama_print_timings:       total time =    6863.50 ms /   664 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     147.59 ms /   232 runs   (    0.64 ms per token,  1571.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2023.84 ms /   384 tokens (    5.27 ms per token,   189.74 tokens per second)\n",
            "llama_print_timings:        eval time =    9042.02 ms /   231 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =   11463.42 ms /   615 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.51 ms /    82 runs   (    0.60 ms per token,  1656.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2895.94 ms /   550 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3196.89 ms /    81 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    6224.56 ms /   631 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.16 ms /    87 runs   (    0.53 ms per token,  1884.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6477.56 ms /  1166 tokens (    5.56 ms per token,   180.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3527.92 ms /    86 runs   (   41.02 ms per token,    24.38 tokens per second)\n",
            "llama_print_timings:       total time =   10144.51 ms /  1252 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      68.55 ms /    87 runs   (    0.79 ms per token,  1269.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2271.21 ms /   432 tokens (    5.26 ms per token,   190.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3368.86 ms /    86 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5823.49 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.77 ms /     7 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2313.74 ms /   440 tokens (    5.26 ms per token,   190.17 tokens per second)\n",
            "llama_print_timings:        eval time =     233.20 ms /     6 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
            "llama_print_timings:       total time =    2563.07 ms /   446 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.50 ms /    96 runs   (    0.56 ms per token,  1794.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2029.48 ms /   390 tokens (    5.20 ms per token,   192.17 tokens per second)\n",
            "llama_print_timings:        eval time =    3701.18 ms /    95 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5861.89 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.06 ms /    94 runs   (    0.75 ms per token,  1341.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2373.00 ms /   451 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3632.37 ms /    93 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    6175.66 ms /   544 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1933.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2201.95 ms /   421 tokens (    5.23 ms per token,   191.19 tokens per second)\n",
            "llama_print_timings:        eval time =     229.49 ms /     6 runs   (   38.25 ms per token,    26.15 tokens per second)\n",
            "llama_print_timings:       total time =    2447.08 ms /   427 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      74.26 ms /   105 runs   (    0.71 ms per token,  1413.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5973.77 ms /  1083 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =    4282.16 ms /   104 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =   10477.85 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.15 ms /    92 runs   (    0.61 ms per token,  1638.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2070.01 ms /   387 tokens (    5.35 ms per token,   186.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3558.51 ms /    91 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    5773.83 ms /   478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     159.61 ms /   256 runs   (    0.62 ms per token,  1603.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2073.16 ms /   400 tokens (    5.18 ms per token,   192.94 tokens per second)\n",
            "llama_print_timings:        eval time =    9967.80 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   12472.63 ms /   655 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.61 ms /   115 runs   (    0.54 ms per token,  1836.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2681.08 ms /   512 tokens (    5.24 ms per token,   190.97 tokens per second)\n",
            "llama_print_timings:        eval time =    4470.77 ms /   114 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
            "llama_print_timings:       total time =    7315.83 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      29.97 ms /    42 runs   (    0.71 ms per token,  1401.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2018.13 ms /   382 tokens (    5.28 ms per token,   189.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.71 ms /    41 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3713.61 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     7 runs   (    0.73 ms per token,  1372.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1907.90 ms /   359 tokens (    5.31 ms per token,   188.17 tokens per second)\n",
            "llama_print_timings:        eval time =     231.28 ms /     6 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
            "llama_print_timings:       total time =    2159.96 ms /   365 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2165.82 ms /   416 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
            "llama_print_timings:        eval time =     269.38 ms /     7 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
            "llama_print_timings:       total time =    2451.38 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1858.98 ms /   360 tokens (    5.16 ms per token,   193.65 tokens per second)\n",
            "llama_print_timings:        eval time =     268.34 ms /     7 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
            "llama_print_timings:       total time =    2141.22 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       2.83 ms /     6 runs   (    0.47 ms per token,  2120.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3834.79 ms /   714 tokens (    5.37 ms per token,   186.19 tokens per second)\n",
            "llama_print_timings:        eval time =     198.18 ms /     5 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    4052.94 ms /   719 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.22 ms /     6 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2211.03 ms /   418 tokens (    5.29 ms per token,   189.05 tokens per second)\n",
            "llama_print_timings:        eval time =     192.55 ms /     5 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
            "llama_print_timings:       total time =    2419.09 ms /   423 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.16 ms /    64 runs   (    0.53 ms per token,  1873.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2717.27 ms /   512 tokens (    5.31 ms per token,   188.42 tokens per second)\n",
            "llama_print_timings:        eval time =    2507.53 ms /    64 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    5314.77 ms /   576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.87 ms /    86 runs   (    0.56 ms per token,  1796.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1944.18 ms /   376 tokens (    5.17 ms per token,   193.40 tokens per second)\n",
            "llama_print_timings:        eval time =    3347.53 ms /    86 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    5409.75 ms /   462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.09 ms /    67 runs   (    0.73 ms per token,  1364.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2319.21 ms /   440 tokens (    5.27 ms per token,   189.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2637.12 ms /    67 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    5085.74 ms /   507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.18 ms /    69 runs   (    0.55 ms per token,  1807.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2838.72 ms /   530 tokens (    5.36 ms per token,   186.70 tokens per second)\n",
            "llama_print_timings:        eval time =    2667.95 ms /    68 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    5607.52 ms /   598 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.30 ms /    64 runs   (    0.55 ms per token,  1813.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2898.53 ms /   548 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2467.71 ms /    63 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5455.53 ms /   611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.32 ms /    65 runs   (    0.53 ms per token,  1894.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6501.55 ms /  1164 tokens (    5.59 ms per token,   179.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2629.15 ms /    64 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =    9233.57 ms /  1228 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.41 ms /    76 runs   (    0.69 ms per token,  1450.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3839.25 ms /   714 tokens (    5.38 ms per token,   185.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3009.73 ms /    75 runs   (   40.13 ms per token,    24.92 tokens per second)\n",
            "llama_print_timings:       total time =    6996.99 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     151.26 ms /   256 runs   (    0.59 ms per token,  1692.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1943.07 ms /   366 tokens (    5.31 ms per token,   188.36 tokens per second)\n",
            "llama_print_timings:        eval time =    9955.28 ms /   255 runs   (   39.04 ms per token,    25.61 tokens per second)\n",
            "llama_print_timings:       total time =   12316.20 ms /   621 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     156.17 ms /   256 runs   (    0.61 ms per token,  1639.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1733.43 ms /   332 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
            "llama_print_timings:        eval time =    9922.58 ms /   255 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =   12068.40 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      50.36 ms /    65 runs   (    0.77 ms per token,  1290.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1686.70 ms /   328 tokens (    5.14 ms per token,   194.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2491.11 ms /    64 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
            "llama_print_timings:       total time =    4304.84 ms /   392 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     157.88 ms /   256 runs   (    0.62 ms per token,  1621.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     429.58 ms /    77 tokens (    5.58 ms per token,   179.25 tokens per second)\n",
            "llama_print_timings:        eval time =    9968.78 ms /   255 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =   10824.04 ms /   332 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.91 ms /     7 runs   (    0.56 ms per token,  1788.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2631.01 ms /   498 tokens (    5.28 ms per token,   189.28 tokens per second)\n",
            "llama_print_timings:        eval time =     236.38 ms /     6 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    2883.08 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.28 ms /    99 runs   (    0.58 ms per token,  1728.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3063.91 ms /   570 tokens (    5.38 ms per token,   186.04 tokens per second)\n",
            "llama_print_timings:        eval time =    3841.65 ms /    98 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    7051.76 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     175.07 ms /   256 runs   (    0.68 ms per token,  1462.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2027.47 ms /   390 tokens (    5.20 ms per token,   192.36 tokens per second)\n",
            "llama_print_timings:        eval time =   10043.08 ms /   255 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   12573.23 ms /   645 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      76.62 ms /   133 runs   (    0.58 ms per token,  1735.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2896.27 ms /   550 tokens (    5.27 ms per token,   189.90 tokens per second)\n",
            "llama_print_timings:        eval time =    5168.65 ms /   132 runs   (   39.16 ms per token,    25.54 tokens per second)\n",
            "llama_print_timings:       total time =    8258.18 ms /   682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.06 ms /    70 runs   (    0.52 ms per token,  1941.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6545.32 ms /  1176 tokens (    5.57 ms per token,   179.67 tokens per second)\n",
            "llama_print_timings:        eval time =    2833.37 ms /    69 runs   (   41.06 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =    9487.25 ms /  1245 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      62.51 ms /   100 runs   (    0.63 ms per token,  1599.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2200.48 ms /   422 tokens (    5.21 ms per token,   191.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3889.11 ms /    99 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    6251.96 ms /   521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      82.00 ms /   124 runs   (    0.66 ms per token,  1512.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2234.01 ms /   419 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =    4817.21 ms /   123 runs   (   39.16 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    7253.87 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.75 ms /    75 runs   (    0.57 ms per token,  1754.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2903.11 ms /   552 tokens (    5.26 ms per token,   190.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2901.37 ms /    74 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    5914.03 ms /   626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.13 ms /    86 runs   (    0.55 ms per token,  1824.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6249.54 ms /  1122 tokens (    5.57 ms per token,   179.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3476.63 ms /    85 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =    9858.55 ms /  1207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     6 runs   (    0.58 ms per token,  1735.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2069.32 ms /   397 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
            "llama_print_timings:        eval time =     192.94 ms /     5 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
            "llama_print_timings:       total time =    2276.65 ms /   402 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     170.00 ms /   232 runs   (    0.73 ms per token,  1364.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1813.58 ms /   349 tokens (    5.20 ms per token,   192.44 tokens per second)\n",
            "llama_print_timings:        eval time =    9027.02 ms /   231 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
            "llama_print_timings:       total time =   11295.33 ms /   580 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_cosine_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_AES CORP_cosine_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_ip_1.json\n",
            "KeyError occurred: 'l2'. Skipping approach 2 for dataframe results_approach_AES CORP_ip_2.json\n",
            "KeyError occurred: 'question_name'. Skipping approach 2 for dataframe results_approach_AES CORP_l2_1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     126.48 ms /   220 runs   (    0.57 ms per token,  1739.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4477.00 ms /   831 tokens (    5.39 ms per token,   185.62 tokens per second)\n",
            "llama_print_timings:        eval time =    8824.29 ms /   219 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =   13661.29 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      38.42 ms /    71 runs   (    0.54 ms per token,  1847.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3073.12 ms /   581 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =    2751.91 ms /    70 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5923.13 ms /   651 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.28 ms /    65 runs   (    0.70 ms per token,  1435.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4605.77 ms /   835 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =    2584.06 ms /    64 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    7327.11 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      48.73 ms /    91 runs   (    0.54 ms per token,  1867.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4017.38 ms /   752 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =    3607.14 ms /    91 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    7752.83 ms /   843 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.44 ms /    71 runs   (    0.56 ms per token,  1800.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4463.60 ms /   824 tokens (    5.42 ms per token,   184.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2829.56 ms /    71 runs   (   39.85 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =    7399.88 ms /   895 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.67 ms /    84 runs   (    0.52 ms per token,  1923.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3033.46 ms /   575 tokens (    5.28 ms per token,   189.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3257.94 ms /    83 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    6413.74 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      49.05 ms /    84 runs   (    0.58 ms per token,  1712.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4408.49 ms /   807 tokens (    5.46 ms per token,   183.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3322.61 ms /    83 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7875.71 ms /   890 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.55 ms /    74 runs   (    0.53 ms per token,  1871.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4742.69 ms /   874 tokens (    5.43 ms per token,   184.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2920.29 ms /    73 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    7769.04 ms /   947 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.31 ms /   101 runs   (    0.53 ms per token,  1894.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4509.88 ms /   826 tokens (    5.46 ms per token,   183.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3983.59 ms /   100 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    8638.12 ms /   926 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      70.42 ms /   100 runs   (    0.70 ms per token,  1420.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4338.64 ms /   805 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3991.13 ms /    99 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
            "llama_print_timings:       total time =    8527.83 ms /   904 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     136.54 ms /   243 runs   (    0.56 ms per token,  1779.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3119.89 ms /   584 tokens (    5.34 ms per token,   187.19 tokens per second)\n",
            "llama_print_timings:        eval time =    9569.13 ms /   243 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =   13071.58 ms /   827 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.34 ms /    68 runs   (    0.53 ms per token,  1870.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4286.27 ms /   788 tokens (    5.44 ms per token,   183.84 tokens per second)\n",
            "llama_print_timings:        eval time =    2660.05 ms /    67 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    7045.57 ms /   855 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.43 ms /    68 runs   (    0.70 ms per token,  1433.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4009.11 ms /   746 tokens (    5.37 ms per token,   186.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2685.80 ms /    67 runs   (   40.09 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    6822.46 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.77 ms /     6 runs   (    0.96 ms per token,  1039.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2865.93 ms /   536 tokens (    5.35 ms per token,   187.02 tokens per second)\n",
            "llama_print_timings:        eval time =     238.40 ms /     6 runs   (   39.73 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    3130.20 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.23 ms /    88 runs   (    0.59 ms per token,  1684.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3101.91 ms /   583 tokens (    5.32 ms per token,   187.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3411.05 ms /    87 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    6646.62 ms /   670 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      44.60 ms /    68 runs   (    0.66 ms per token,  1524.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3834.39 ms /   719 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2666.37 ms /    67 runs   (   39.80 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    6621.80 ms /   786 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.62 ms /    69 runs   (    0.55 ms per token,  1834.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2091.88 ms /   395 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2642.20 ms /    68 runs   (   38.86 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    4827.28 ms /   463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.85 ms /     7 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2808.02 ms /   536 tokens (    5.24 ms per token,   190.88 tokens per second)\n",
            "llama_print_timings:        eval time =     237.28 ms /     6 runs   (   39.55 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    3061.34 ms /   542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      66.35 ms /    99 runs   (    0.67 ms per token,  1492.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4041.36 ms /   750 tokens (    5.39 ms per token,   185.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3957.01 ms /    98 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8187.10 ms /   848 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      40.85 ms /    75 runs   (    0.54 ms per token,  1835.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4343.60 ms /   806 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =    2941.79 ms /    74 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7394.74 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      47.57 ms /    74 runs   (    0.64 ms per token,  1555.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5385.68 ms /   984 tokens (    5.47 ms per token,   182.71 tokens per second)\n",
            "llama_print_timings:        eval time =    2967.42 ms /    73 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =    8482.74 ms /  1057 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      34.96 ms /    64 runs   (    0.55 ms per token,  1830.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4375.67 ms /   811 tokens (    5.40 ms per token,   185.34 tokens per second)\n",
            "llama_print_timings:        eval time =    2506.24 ms /    63 runs   (   39.78 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    6973.47 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      45.02 ms /    66 runs   (    0.68 ms per token,  1466.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3171.59 ms /   592 tokens (    5.36 ms per token,   186.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2624.91 ms /    66 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
            "llama_print_timings:       total time =    5929.02 ms /   658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.12 ms /    12 runs   (    0.59 ms per token,  1686.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2822.30 ms /   536 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
            "llama_print_timings:        eval time =     472.36 ms /    12 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    3319.34 ms /   548 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      39.78 ms /    72 runs   (    0.55 ms per token,  1810.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2807.26 ms /   530 tokens (    5.30 ms per token,   188.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2773.70 ms /    71 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    5682.22 ms /   601 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.02 ms /     7 runs   (    0.72 ms per token,  1394.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1642.76 ms /   317 tokens (    5.18 ms per token,   192.97 tokens per second)\n",
            "llama_print_timings:        eval time =     235.44 ms /     6 runs   (   39.24 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    1895.26 ms /   323 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      55.12 ms /    96 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2884.80 ms /   539 tokens (    5.35 ms per token,   186.84 tokens per second)\n",
            "llama_print_timings:        eval time =    3726.90 ms /    95 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    6756.04 ms /   634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      67.21 ms /   113 runs   (    0.59 ms per token,  1681.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1983.96 ms /   382 tokens (    5.19 ms per token,   192.54 tokens per second)\n",
            "llama_print_timings:        eval time =    4354.64 ms /   112 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
            "llama_print_timings:       total time =    6508.31 ms /   494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      51.15 ms /    93 runs   (    0.55 ms per token,  1818.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4824.01 ms /   879 tokens (    5.49 ms per token,   182.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3694.41 ms /    92 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8668.38 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      37.89 ms /    69 runs   (    0.55 ms per token,  1820.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2854.58 ms /   542 tokens (    5.27 ms per token,   189.87 tokens per second)\n",
            "llama_print_timings:        eval time =    2672.95 ms /    68 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    5623.02 ms /   610 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.92 ms /    91 runs   (    0.64 ms per token,  1571.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2169.63 ms /   412 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3506.48 ms /    90 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
            "llama_print_timings:       total time =    5822.49 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.47 ms /    64 runs   (    0.57 ms per token,  1755.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1988.51 ms /   384 tokens (    5.18 ms per token,   193.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2445.56 ms /    63 runs   (   38.82 ms per token,    25.76 tokens per second)\n",
            "llama_print_timings:       total time =    4523.57 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       7.87 ms /    14 runs   (    0.56 ms per token,  1778.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1600.17 ms /   307 tokens (    5.21 ms per token,   191.85 tokens per second)\n",
            "llama_print_timings:        eval time =     498.51 ms /    13 runs   (   38.35 ms per token,    26.08 tokens per second)\n",
            "llama_print_timings:       total time =    2120.76 ms /   320 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.00 ms /     7 runs   (    0.71 ms per token,  1399.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2311.63 ms /   440 tokens (    5.25 ms per token,   190.34 tokens per second)\n",
            "llama_print_timings:        eval time =     277.21 ms /     7 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    2608.82 ms /   447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.05 ms /    81 runs   (    0.53 ms per token,  1881.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6059.94 ms /  1088 tokens (    5.57 ms per token,   179.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3263.54 ms /    80 runs   (   40.79 ms per token,    24.51 tokens per second)\n",
            "llama_print_timings:       total time =    9449.15 ms /  1168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      46.79 ms /    68 runs   (    0.69 ms per token,  1453.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4423.92 ms /   818 tokens (    5.41 ms per token,   184.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2693.98 ms /    67 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =    7240.69 ms /   885 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      64.13 ms /   113 runs   (    0.57 ms per token,  1762.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6050.90 ms /  1093 tokens (    5.54 ms per token,   180.63 tokens per second)\n",
            "llama_print_timings:        eval time =    4584.84 ms /   112 runs   (   40.94 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   10815.27 ms /  1205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      59.57 ms /    99 runs   (    0.60 ms per token,  1661.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4230.55 ms /   776 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3927.46 ms /    98 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    8330.06 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     150.82 ms /   256 runs   (    0.59 ms per token,  1697.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2770.91 ms /   528 tokens (    5.25 ms per token,   190.55 tokens per second)\n",
            "llama_print_timings:        eval time =   10089.20 ms /   256 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13286.04 ms /   784 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      57.80 ms /    99 runs   (    0.58 ms per token,  1712.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3030.65 ms /   570 tokens (    5.32 ms per token,   188.08 tokens per second)\n",
            "llama_print_timings:        eval time =    3851.93 ms /    98 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7034.21 ms /   668 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      56.70 ms /    81 runs   (    0.70 ms per token,  1428.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3349.76 ms /   619 tokens (    5.41 ms per token,   184.79 tokens per second)\n",
            "llama_print_timings:        eval time =    3165.81 ms /    80 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    6663.18 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.59 ms /    67 runs   (    0.55 ms per token,  1831.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3612.67 ms /   680 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2642.89 ms /    67 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6352.25 ms /   747 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.40 ms /    65 runs   (    0.65 ms per token,  1532.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4045.64 ms /   748 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2562.12 ms /    64 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    6727.27 ms /   812 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.83 ms /    96 runs   (    0.56 ms per token,  1783.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4479.72 ms /   830 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3805.60 ms /    95 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    8428.71 ms /   925 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.59 ms /     6 runs   (    0.93 ms per token,  1073.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2672.92 ms /   500 tokens (    5.35 ms per token,   187.06 tokens per second)\n",
            "llama_print_timings:        eval time =     199.94 ms /     5 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    2896.73 ms /   505 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      71.48 ms /   132 runs   (    0.54 ms per token,  1846.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2877.91 ms /   532 tokens (    5.41 ms per token,   184.86 tokens per second)\n",
            "llama_print_timings:        eval time =    5141.94 ms /   131 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
            "llama_print_timings:       total time =    8225.56 ms /   663 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      86.54 ms /   134 runs   (    0.65 ms per token,  1548.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3436.16 ms /   647 tokens (    5.31 ms per token,   188.29 tokens per second)\n",
            "llama_print_timings:        eval time =    5273.40 ms /   133 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    8946.60 ms /   780 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      77.08 ms /   135 runs   (    0.57 ms per token,  1751.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2947.73 ms /   558 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
            "llama_print_timings:        eval time =    5250.07 ms /   134 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    8392.00 ms /   692 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      53.36 ms /    68 runs   (    0.78 ms per token,  1274.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2147.34 ms /   408 tokens (    5.26 ms per token,   190.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2626.84 ms /    67 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
            "llama_print_timings:       total time =    4915.58 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      33.04 ms /    64 runs   (    0.52 ms per token,  1936.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4698.29 ms /   864 tokens (    5.44 ms per token,   183.90 tokens per second)\n",
            "llama_print_timings:        eval time =    2560.87 ms /    64 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    7354.75 ms /   928 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       6.74 ms /    12 runs   (    0.56 ms per token,  1779.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2502.54 ms /   480 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
            "llama_print_timings:        eval time =     426.49 ms /    11 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
            "llama_print_timings:       total time =    2950.72 ms /   491 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       4.13 ms /     6 runs   (    0.69 ms per token,  1453.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2824.35 ms /   536 tokens (    5.27 ms per token,   189.78 tokens per second)\n",
            "llama_print_timings:        eval time =     198.18 ms /     5 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    3040.58 ms /   541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      36.55 ms /    68 runs   (    0.54 ms per token,  1860.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4507.01 ms /   832 tokens (    5.42 ms per token,   184.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2672.30 ms /    67 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    7277.63 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     172.79 ms /   256 runs   (    0.67 ms per token,  1481.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1987.46 ms /   382 tokens (    5.20 ms per token,   192.21 tokens per second)\n",
            "llama_print_timings:        eval time =    9989.05 ms /   255 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =   12458.23 ms /   637 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       3.88 ms /     7 runs   (    0.55 ms per token,  1805.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2156.00 ms /   413 tokens (    5.22 ms per token,   191.56 tokens per second)\n",
            "llama_print_timings:        eval time =     230.99 ms /     6 runs   (   38.50 ms per token,    25.98 tokens per second)\n",
            "llama_print_timings:       total time =    2401.71 ms /   419 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      52.20 ms /    79 runs   (    0.66 ms per token,  1513.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4380.87 ms /   810 tokens (    5.41 ms per token,   184.89 tokens per second)\n",
            "llama_print_timings:        eval time =    3126.49 ms /    78 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7651.68 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      43.00 ms /    69 runs   (    0.62 ms per token,  1604.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     135.27 ms /    23 tokens (    5.88 ms per token,   170.03 tokens per second)\n",
            "llama_print_timings:        eval time =    2717.73 ms /    68 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    2959.14 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      42.19 ms /    69 runs   (    0.61 ms per token,  1635.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4754.49 ms /   880 tokens (    5.40 ms per token,   185.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2748.67 ms /    68 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =    7621.86 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =       5.32 ms /     7 runs   (    0.76 ms per token,  1315.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2610.98 ms /   486 tokens (    5.37 ms per token,   186.14 tokens per second)\n",
            "llama_print_timings:        eval time =     242.01 ms /     6 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =    2877.09 ms /   492 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =      35.69 ms /    67 runs   (    0.53 ms per token,  1877.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2054.88 ms /   389 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
            "llama_print_timings:        eval time =    2560.84 ms /    66 runs   (   38.80 ms per token,    25.77 tokens per second)\n",
            "llama_print_timings:       total time =    4708.19 ms /   455 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     148.44 ms /   256 runs   (    0.58 ms per token,  1724.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3385.62 ms /   636 tokens (    5.32 ms per token,   187.85 tokens per second)\n",
            "llama_print_timings:        eval time =   10119.91 ms /   255 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =   13931.66 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     424.96 ms\n",
            "llama_print_timings:      sample time =     127.70 ms /   158 runs   (    0.81 ms per token,  1237.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4798.41 ms /   884 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
            "llama_print_timings:        eval time =    6411.64 ms /   157 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =   11562.32 ms /  1041 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total score for approach 2 and distance function l2 is 0.3688029020556227\n"
          ]
        }
      ]
    }
  ]
}