{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJvYflKIpZb+V4aM/2VBKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winterForestStump/thesis/blob/main/retrieval/Retrievals_reranked_l2_evaluation_phi3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  LLAMA_CUBLAS is deprecated and will be removed in the future. Use LLAMA_CUDA instead"
      ],
      "metadata": {
        "id": "fEYgSV_fPq26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqMqPVKIzJy0",
        "outputId": "0f84f369-0614-47d4-c783-ee3a335a389a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.77.tar.gz (50.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting scikit-build-core[pyproject]>=0.9.2\n",
            "    Downloading scikit_build_core-0.9.5-py3-none-any.whl (152 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.1/152.1 kB 4.6 MB/s eta 0:00:00\n",
            "  Collecting exceptiongroup>=1.0 (from scikit-build-core[pyproject]>=0.9.2)\n",
            "    Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
            "  Collecting packaging>=21.3 (from scikit-build-core[pyproject]>=0.9.2)\n",
            "    Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 7.3 MB/s eta 0:00:00\n",
            "  Collecting pathspec>=0.10.1 (from scikit-build-core[pyproject]>=0.9.2)\n",
            "    Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "  Collecting tomli>=1.2.2 (from scikit-build-core[pyproject]>=0.9.2)\n",
            "    Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Installing collected packages: tomli, pathspec, packaging, exceptiongroup, scikit-build-core\n",
            "  ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "  langchain-core 0.2.4 requires packaging<24.0,>=23.2, but you have packaging 24.0 which is incompatible.\n",
            "  Successfully installed exceptiongroup-1.2.1 packaging-24.0 pathspec-0.12.1 scikit-build-core-0.9.5 tomli-2.0.1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  Could not determine CMake version via --version, got '' 'Traceback (most recent call last):\\n  File \"/usr/local/bin/cmake\", line 5, in <module>\\n    from cmake import cmake\\nModuleNotFoundError: No module named \\'cmake\\'\\n'\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command pip subprocess to install backend dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting ninja>=1.5\n",
            "    Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 8.1 MB/s eta 0:00:00\n",
            "  Collecting cmake>=3.21\n",
            "    Downloading cmake-3.29.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.7/26.7 MB 56.3 MB/s eta 0:00:00\n",
            "  Installing collected packages: ninja, cmake\n",
            "    Creating /tmp/pip-build-env-inrvy29x/normal/local/bin\n",
            "    changing mode of /tmp/pip-build-env-inrvy29x/normal/local/bin/ninja to 755\n",
            "    changing mode of /tmp/pip-build-env-inrvy29x/normal/local/bin/cmake to 755\n",
            "    changing mode of /tmp/pip-build-env-inrvy29x/normal/local/bin/cpack to 755\n",
            "    changing mode of /tmp/pip-build-env-inrvy29x/normal/local/bin/ctest to 755\n",
            "  Successfully installed cmake-3.29.3 ninja-1.11.1.1\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  *** scikit-build-core 0.9.5 using CMake 3.29.3 (metadata_wheel)\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
            "  *** scikit-build-core 0.9.5 using CMake 3.29.3 (wheel)\n",
            "  *** Configuring CMake...\n",
            "  loading initial cache file /tmp/tmp0l68icjl/build/CMakeInit.txt\n",
            "  -- The C compiler identification is GNU 11.4.0\n",
            "  -- The CXX compiler identification is GNU 11.4.0\n",
            "  -- Detecting C compiler ABI info\n",
            "  -- Detecting C compiler ABI info - done\n",
            "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
            "  -- Detecting C compile features\n",
            "  -- Detecting C compile features - done\n",
            "  -- Detecting CXX compiler ABI info\n",
            "  -- Detecting CXX compiler ABI info - done\n",
            "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "  -- Detecting CXX compile features\n",
            "  -- Detecting CXX compile features - done\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "  -- Found Threads: TRUE\n",
            "  -- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "  -- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "  -- Found OpenMP: TRUE (found version \"4.5\")\n",
            "  -- OpenMP found\n",
            "  CMake Warning at vendor/llama.cpp/CMakeLists.txt:401 (message):\n",
            "    LLAMA_CUBLAS is deprecated and will be removed in the future.\n",
            "\n",
            "    Use LLAMA_CUDA instead\n",
            "\n",
            "\n",
            "  -- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.2.140\")\n",
            "  -- CUDA found\n",
            "  -- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "  -- Detecting CUDA compiler ABI info\n",
            "  -- Detecting CUDA compiler ABI info - done\n",
            "  -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "  -- Detecting CUDA compile features\n",
            "  -- Detecting CUDA compile features - done\n",
            "  -- Using CUDA architectures: 52;61;70\n",
            "  -- CUDA host compiler is GNU 11.4.0\n",
            "\n",
            "  -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with LLAMA_CCACHE=OFF\n",
            "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "  -- x86 detected\n",
            "  CMake Warning (dev) at CMakeLists.txt:26 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  CMake Warning (dev) at CMakeLists.txt:35 (install):\n",
            "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
            "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\n",
            "  -- Configuring done (5.6s)\n",
            "  -- Generating done (0.0s)\n",
            "  -- Build files have been written to: /tmp/tmp0l68icjl/build\n",
            "  *** Building project with Ninja...\n",
            "  Change Dir: '/tmp/tmp0l68icjl/build'\n",
            "\n",
            "  Run Build Command(s): /tmp/pip-build-env-inrvy29x/normal/local/lib/python3.10/dist-packages/ninja/data/bin/ninja -v\n",
            "  [1/71] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-alloc.c\n",
            "  [2/71] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-backend.c\n",
            "  [3/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/acc.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o\n",
            "  [4/71] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-quants.c\n",
            "  [5/71] /usr/bin/cc -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml.c\n",
            "  [6/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/arange.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o\n",
            "  [7/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/argsort.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o\n",
            "  [8/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/clamp.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o\n",
            "  [9/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/concat.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o\n",
            "  [10/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/binbcast.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o\n",
            "  [11/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/diagmask.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o\n",
            "  [12/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/convert.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o\n",
            "  [13/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/cpy.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o\n",
            "  [14/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/dmmv.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o\n",
            "  [15/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/fattn-tile-f16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o\n",
            "  [16/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/fattn.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o\n",
            "  [17/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/getrows.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o\n",
            "  [18/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/fattn-tile-f32.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o\n",
            "  [19/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/im2col.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o\n",
            "  [20/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/norm.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o\n",
            "  [21/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/pad.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o\n",
            "  [22/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/pool2d.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o\n",
            "  [23/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/mmq.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o\n",
            "  [24/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/quantize.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o\n",
            "  [25/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/scale.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o\n",
            "  [26/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/rope.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o\n",
            "  [27/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/sumrows.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o\n",
            "  [28/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/softmax.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o\n",
            "  [29/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/tsembd.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o\n",
            "  [30/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/unary.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o\n",
            "  [31/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/upscale.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o\n",
            "  [32/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o\n",
            "  [33/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o\n",
            "  [34/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o\n",
            "  [35/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o\n",
            "  [36/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/mmvq.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o\n",
            "  [37/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o\n",
            "  [38/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o\n",
            "  [39/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o\n",
            "  [40/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o\n",
            "  [41/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o\n",
            "  [42/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o\n",
            "  [43/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o\n",
            "  [44/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o\n",
            "  [45/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o\n",
            "  [46/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o\n",
            "  [47/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/sgemm.cpp.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/sgemm.cpp.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/sgemm.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/sgemm.cpp\n",
            "  [48/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o\n",
            "  [49/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/unicode.cpp\n",
            "  [50/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/unicode-data.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/unicode-data.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/unicode-data.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/unicode-data.cpp\n",
            "  [51/71] cd /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp && /tmp/pip-build-env-inrvy29x/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -DMSVC= -DCMAKE_C_COMPILER_VERSION=11.4.0 -DCMAKE_C_COMPILER_ID=GNU -DCMAKE_VS_PLATFORM_NAME= -DCMAKE_C_COMPILER=/usr/bin/cc -P /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/../scripts/gen-build-info-cpp.cmake\n",
            "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "  [52/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600  -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/build-info.cpp\n",
            "  [53/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/common.cpp\n",
            "  [54/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -fopenmp -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/llama.cpp\n",
            "  [55/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/sampling.cpp\n",
            "  [56/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/console.cpp\n",
            "  [57/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/grammar-parser.cpp\n",
            "  [58/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/train.cpp\n",
            "  [59/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/ngram-cache.cpp\n",
            "  [60/71] /usr/bin/c++ -DGGML_USE_CUBLAS -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -fopenmp -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/llava.cpp\n",
            "  [61/71] /usr/bin/c++ -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/json-schema-to-grammar.cpp\n",
            "  [62/71] /usr/bin/c++ -DGGML_USE_CUBLAS -DGGML_USE_CUDA -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/common/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/llava-cli.cpp\n",
            "  [63/71] /usr/bin/c++ -DGGML_USE_CUBLAS -DGGML_USE_CUDA -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -fPIC -Wno-cast-qual -fopenmp -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/examples/llava/clip.cpp\n",
            "  [64/71] : && /tmp/pip-build-env-inrvy29x/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/examples/llava/libllava_static.a && /usr/bin/ar qc vendor/llama.cpp/examples/llava/libllava_static.a  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o && /usr/bin/ranlib vendor/llama.cpp/examples/llava/libllava_static.a && :\n",
            "  [65/71] /usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_CUDA_USE_GRAPHS -DGGML_SCHED_MAX_COPIES=4 -DGGML_USE_CUDA -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/. -isystem /usr/local/cuda/targets/x86_64-linux/include -O3 -DNDEBUG -std=c++11 \"--generate-code=arch=compute_52,code=[compute_52,sm_52]\" \"--generate-code=arch=compute_61,code=[compute_61,sm_61]\" \"--generate-code=arch=compute_70,code=[compute_70,sm_70]\" -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o.d -x cu -c /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/vendor/llama.cpp/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o\n",
            "  [66/71] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libggml_shared.so -o vendor/llama.cpp/libggml_shared.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/sgemm.cpp.o -L/usr/local/cuda/targets/x86_64-linux/lib -Wl,-rpath,/usr/local/cuda-12.2/targets/x86_64-linux/lib:  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so  /usr/lib/gcc/x86_64-linux-gnu/11/libgomp.so  /usr/lib/x86_64-linux-gnu/libpthread.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  -ldl  /usr/lib/x86_64-linux-gnu/librt.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl && :\n",
            "  [67/71] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllama.so -o vendor/llama.cpp/libllama.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/sgemm.cpp.o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o vendor/llama.cpp/CMakeFiles/llama.dir/unicode-data.cpp.o -L/usr/local/cuda/targets/x86_64-linux/lib -Wl,-rpath,/usr/local/cuda-12.2/targets/x86_64-linux/lib:  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so  /usr/lib/gcc/x86_64-linux-gnu/11/libgomp.so  /usr/lib/x86_64-linux-gnu/libpthread.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  -ldl  /usr/lib/x86_64-linux-gnu/librt.a  -lcudadevrt  -lcudart_static  -lrt  -lpthread  -ldl && :\n",
            "  [68/71] : && /tmp/pip-build-env-inrvy29x/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/libggml_static.a && /usr/bin/ar qc vendor/llama.cpp/libggml_static.a  vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/sgemm.cpp.o && /usr/bin/ranlib vendor/llama.cpp/libggml_static.a && :\n",
            "  [69/71] : && /tmp/pip-build-env-inrvy29x/normal/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/common/libcommon.a && /usr/bin/ar qc vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/json-schema-to-grammar.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/ngram-cache.cpp.o && /usr/bin/ranlib vendor/llama.cpp/common/libcommon.a && :\n",
            "  [70/71] : && /usr/bin/c++ -O3 -DNDEBUG  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -o vendor/llama.cpp/examples/llava/llava-cli  -Wl,-rpath,/tmp/tmp0l68icjl/build/vendor/llama.cpp:/usr/local/cuda-12.2/targets/x86_64-linux/lib:  vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/libllama.so  /usr/lib/gcc/x86_64-linux-gnu/11/libgomp.so  /usr/lib/x86_64-linux-gnu/libpthread.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so  -ldl  /usr/lib/x86_64-linux-gnu/librt.a && :\n",
            "  [71/71] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllava.so -o vendor/llama.cpp/examples/llava/libllava.so vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o vendor/llama.cpp/CMakeFiles/ggml.dir/sgemm.cpp.o  -Wl,-rpath,/tmp/tmp0l68icjl/build/vendor/llama.cpp:/usr/local/cuda-12.2/targets/x86_64-linux/lib:  vendor/llama.cpp/libllama.so  /usr/lib/gcc/x86_64-linux-gnu/11/libgomp.so  /usr/lib/x86_64-linux-gnu/libpthread.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublas.so  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libculibos.a  /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcublasLt.so  /usr/local/cuda/targets/x86_64-linux/lib/stubs/libcuda.so  -ldl  /usr/lib/x86_64-linux-gnu/librt.a && :\n",
            "\n",
            "  *** Installing project into wheel...\n",
            "  -- Install configuration: \"Release\"\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/lib/libggml_shared.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmp0l68icjl/wheel/platlib/lib/libggml_shared.so\" to \"\"\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/lib/cmake/Llama/LlamaConfig.cmake\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/lib/cmake/Llama/LlamaConfigVersion.cmake\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/include/ggml.h\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/include/ggml-alloc.h\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/include/ggml-backend.h\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/include/ggml-cuda.h\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/lib/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmp0l68icjl/wheel/platlib/lib/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/include/llama.h\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/bin/convert-hf-to-gguf.py\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/lib/pkgconfig/llama.pc\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmp0l68icjl/wheel/platlib/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/llama_cpp/libllama.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/llama_cpp/libllama.so\" to \"\"\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/lib/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmp0l68icjl/wheel/platlib/lib/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/bin/llava-cli\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmp0l68icjl/wheel/platlib/bin/llava-cli\" to \"\"\n",
            "  -- Installing: /tmp/tmp0l68icjl/wheel/platlib/llama_cpp/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/tmp0l68icjl/wheel/platlib/llama_cpp/libllava.so\" to \"\"\n",
            "  -- Installing: /tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/llama_cpp/libllava.so\n",
            "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-ugos2hgi/llama-cpp-python_496c779e2ffe493ea31811c49b5bfdf7/llama_cpp/libllava.so\" to \"\"\n",
            "  *** Making wheel...\n",
            "  *** Created llama_cpp_python-0.2.77-cp310-cp310-linux_x86_64.whl...\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.77-cp310-cp310-linux_x86_64.whl size=132151889 sha256=2dd72104d091bb66f518df411a8277e0ef1bb84117599e04c35e12a387928a8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/55/a1/6d6c2ef6fed3ef054b4170d8bcd05a09e6dc971db7fad955ff\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.77\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --verbose"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download microsoft/Phi-3-mini-4k-instruct-gguf Phi-3-mini-4k-instruct-fp16.gguf --local-dir ./models --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "XBCZobiVzKeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25962b3d-9741-450c-847d-f5e3592d0a46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:132: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "Downloading 'Phi-3-mini-4k-instruct-fp16.gguf' to 'models/.huggingface/download/Phi-3-mini-4k-instruct-fp16.gguf.5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3.incomplete'\n",
            "Phi-3-mini-4k-instruct-fp16.gguf: 100% 7.64G/7.64G [00:58<00:00, 131MB/s]\n",
            "Download complete. Moving file to models/Phi-3-mini-4k-instruct-fp16.gguf\n",
            "models/Phi-3-mini-4k-instruct-fp16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MCqrdCON0gMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f38db4-1d23-4e91-fba8-fd32585ee1b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-community --quiet"
      ],
      "metadata": {
        "id": "0B4eLZEi3ZND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb7d935-539c-41fa-d459-250a961a5b85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.4/310.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from json import JSONDecodeError\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "vdNwMqueoQF5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP = 0\n",
        "N_CTX = 4096\n",
        "N_GPU_L = -1\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/models/Phi-3-mini-4k-instruct-fp16.gguf\",\n",
        "    temperature=TEMP,\n",
        "    n_ctx=N_CTX,\n",
        "    n_gpu_layers = N_GPU_L,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "2RRPjbl3zOj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90aab290-3910-495d-a93e-1840aab4aa88"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 23 key-value pairs and 195 tensors from /content/models/Phi-3-mini-4k-instruct-fp16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi3\n",
            "llama_model_loader: - kv   2:                        phi3.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                      phi3.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   4:                   phi3.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   5:                           phi3.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi3.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi3.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi3.rope.dimension_count u32              = 96\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32064]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32064]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 32000\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  130 tensors\n",
            "llm_load_vocab: special tokens cache size = 323\n",
            "llm_load_vocab: token to piece cache size = 0.1687 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = phi3\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32064\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 3072\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 96\n",
            "llm_load_print_meta: n_embd_head_k    = 96\n",
            "llm_load_print_meta: n_embd_head_v    = 96\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
            "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 8192\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 3B\n",
            "llm_load_print_meta: model ftype      = F16\n",
            "llm_load_print_meta: model params     = 3.82 B\n",
            "llm_load_print_meta: model size       = 7.12 GiB (16.00 BPW) \n",
            "llm_load_print_meta: general.name     = Phi3\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   187.88 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  7100.64 MiB\n",
            "....................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1536.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1536.00 MiB, K (f16):  768.00 MiB, V (f16):  768.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =    18.75 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.88 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1286\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\\n' + message['content'] + '<|end|>' + '\\n' + '<|assistant|>' + '\\n'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\\n'}}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.eos_token_id': '32000', 'tokenizer.ggml.bos_token_id': '1', 'general.architecture': 'phi3', 'phi3.context_length': '4096', 'phi3.attention.head_count_kv': '32', 'general.name': 'Phi3', 'tokenizer.ggml.pre': 'default', 'phi3.embedding_length': '3072', 'tokenizer.ggml.unknown_token_id': '0', 'phi3.feed_forward_length': '8192', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.block_count': '32', 'phi3.attention.head_count': '32', 'phi3.rope.dimension_count': '96', 'tokenizer.ggml.model': 'llama', 'general.file_type': '1'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') %}{{'<|user|>' + '\n",
            "' + message['content'] + '<|end|>' + '\n",
            "' + '<|assistant|>' + '\n",
            "'}}{% elif (message['role'] == 'assistant') %}{{message['content'] + '<|end|>' + '\n",
            "'}}{% endif %}{% endfor %}\n",
            "Using chat eos_token: <|endoftext|>\n",
            "Using chat bos_token: <s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Retrieval Grader for approach 1\n",
        "\n",
        "prompt_1 = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    <|assistant|> You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question, grade it as relevant.\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. <|end|>\n",
        "    <|user|> Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: {question} <|end|>\n",
        "    <|assistant|>\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader_1 = prompt_1 | llm | JsonOutputParser()"
      ],
      "metadata": {
        "id": "B0cVnmRczRED"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Thesis/retrievals/reranked/'\n",
        "\n",
        "dataframes = []\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.json'):\n",
        "        approach_name = file_name\n",
        "        dataframes.append(approach_name)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZJdMhlofa0M8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_results():\n",
        "  results_list = []\n",
        "\n",
        "  for i in range(len(dataframes)):\n",
        "\n",
        "    approach = pd.read_json(os.path.join(folder_path + dataframes[i]))\n",
        "    try:\n",
        "      for j in range(len(approach)):\n",
        "        question = approach['question'][j]\n",
        "        list_of_lists = approach['context'][j]\n",
        "        doc_txt = [inner_list[1] for inner_list in list_of_lists if len(inner_list)>1]\n",
        "        if not doc_txt:\n",
        "          continue\n",
        "        try:\n",
        "          answer = retrieval_grader_1.invoke({\"question\": question, \"document\": [doc_txt]})\n",
        "          results_list.append(pd.DataFrame({\"question\": question, \"answer\": [answer], \"document\": [doc_txt]}))\n",
        "        except JSONDecodeError as e:\n",
        "          print(f\"JSONDecodeError occurred for question: {question}. Skipping...\")\n",
        "          continue\n",
        "        except OutputParserException as e:\n",
        "          print(f\"OutputParserException occurred for question: {question}. Skipping...\")\n",
        "          continue\n",
        "    except KeyError as e:\n",
        "      print(f\"KeyError occurred: {e}. Skipping approach for dataframe {dataframes[i]}\")\n",
        "      continue\n",
        "\n",
        "\n",
        "  if results_list:\n",
        "    results = pd.concat(results_list, ignore_index=True)\n",
        "    results.to_json(f'/content/drive/MyDrive/Thesis/evaluation/eval_reranked.json')\n",
        "    score = 0\n",
        "    for i in range(len(results)):\n",
        "      if (results['answer'][i] is not None) and (results['answer'][i]['score'] == 'yes'):\n",
        "        score += 1\n",
        "    total_score = score/len(results)\n",
        "    print(f'Total score is {total_score}')\n",
        "  else:\n",
        "    print(f\"No results to concatenate\")"
      ],
      "metadata": {
        "id": "ucfAHsBia0JX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results()"
      ],
      "metadata": {
        "id": "EHHf1hr-3XM6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8d807ed-a0b7-4631-c9b3-5f1982890456"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      68.83 ms /   120 runs   (    0.57 ms per token,  1743.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =    4768.47 ms /   120 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
            "llama_print_timings:       total time =    4926.60 ms /   120 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      38.06 ms /    67 runs   (    0.57 ms per token,  1760.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8678.85 ms /  1549 tokens (    5.60 ms per token,   178.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2704.11 ms /    66 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
            "llama_print_timings:       total time =   11507.25 ms /  1615 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     108.83 ms /   210 runs   (    0.52 ms per token,  1929.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5829.35 ms /  1075 tokens (    5.42 ms per token,   184.41 tokens per second)\n",
            "llama_print_timings:        eval time =    8331.92 ms /   209 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =   14429.50 ms /  1284 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.49 ms /    83 runs   (    0.58 ms per token,  1711.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4466.91 ms /   839 tokens (    5.32 ms per token,   187.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3227.13 ms /    82 runs   (   39.36 ms per token,    25.41 tokens per second)\n",
            "llama_print_timings:       total time =    7811.25 ms /   921 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.70 ms /     6 runs   (    0.62 ms per token,  1619.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6538.14 ms /  1199 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
            "llama_print_timings:        eval time =     201.80 ms /     5 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =    6765.04 ms /  1204 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     140.69 ms /   256 runs   (    0.55 ms per token,  1819.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12452.32 ms /  2115 tokens (    5.89 ms per token,   169.85 tokens per second)\n",
            "llama_print_timings:        eval time =   11369.36 ms /   255 runs   (   44.59 ms per token,    22.43 tokens per second)\n",
            "llama_print_timings:       total time =   24210.08 ms /  2370 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     143.66 ms /   256 runs   (    0.56 ms per token,  1782.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4581.83 ms /   842 tokens (    5.44 ms per token,   183.77 tokens per second)\n",
            "llama_print_timings:        eval time =   10297.47 ms /   255 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =   15222.82 ms /  1097 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.89 ms /    80 runs   (    0.57 ms per token,  1743.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4836.50 ms /   885 tokens (    5.46 ms per token,   182.98 tokens per second)\n",
            "llama_print_timings:        eval time =    3167.76 ms /    79 runs   (   40.10 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    8106.83 ms /   964 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.70 ms /   104 runs   (    0.64 ms per token,  1559.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6500.09 ms /  1171 tokens (    5.55 ms per token,   180.15 tokens per second)\n",
            "llama_print_timings:        eval time =    4239.71 ms /   103 runs   (   41.16 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =   10895.24 ms /  1274 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      58.58 ms /    86 runs   (    0.68 ms per token,  1468.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7632.46 ms /  1362 tokens (    5.60 ms per token,   178.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3550.49 ms /    85 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   11328.85 ms /  1447 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      22.44 ms /    41 runs   (    0.55 ms per token,  1826.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7572.65 ms /  1360 tokens (    5.57 ms per token,   179.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1692.16 ms /    41 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =    9325.97 ms /  1401 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's current ratio and quick ratio and how do these ratios compare to industry averages?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      56.20 ms /   100 runs   (    0.56 ms per token,  1779.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3981.43 ms /   739 tokens (    5.39 ms per token,   185.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3909.24 ms /    99 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    8011.61 ms /   838 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      33.03 ms /    54 runs   (    0.61 ms per token,  1634.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4170.80 ms /   781 tokens (    5.34 ms per token,   187.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2094.76 ms /    53 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    6355.15 ms /   834 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      37.96 ms /    68 runs   (    0.56 ms per token,  1791.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4711.40 ms /   868 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
            "llama_print_timings:        eval time =    2663.83 ms /    67 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7465.82 ms /   935 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      77.25 ms /   112 runs   (    0.69 ms per token,  1449.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5097.10 ms /   939 tokens (    5.43 ms per token,   184.22 tokens per second)\n",
            "llama_print_timings:        eval time =    4490.73 ms /   111 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    9769.75 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      75.41 ms /   123 runs   (    0.61 ms per token,  1631.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4926.89 ms /   912 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
            "llama_print_timings:        eval time =    4915.11 ms /   122 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =   10026.32 ms /  1034 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      75.69 ms /   135 runs   (    0.56 ms per token,  1783.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4946.73 ms /   912 tokens (    5.42 ms per token,   184.36 tokens per second)\n",
            "llama_print_timings:        eval time =    5380.98 ms /   134 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =   10503.16 ms /  1046 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      44.34 ms /    83 runs   (    0.53 ms per token,  1871.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5670.28 ms /  1032 tokens (    5.49 ms per token,   182.00 tokens per second)\n",
            "llama_print_timings:        eval time =    3318.40 ms /    82 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    9095.73 ms /  1114 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      55.23 ms /    83 runs   (    0.67 ms per token,  1502.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4274.35 ms /   799 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3267.30 ms /    82 runs   (   39.85 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    7667.88 ms /   881 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.16 ms /    89 runs   (    0.56 ms per token,  1774.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2674.99 ms /   508 tokens (    5.27 ms per token,   189.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3447.66 ms /    88 runs   (   39.18 ms per token,    25.52 tokens per second)\n",
            "llama_print_timings:       total time =    6230.22 ms /   596 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      41.09 ms /    68 runs   (    0.60 ms per token,  1654.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2880.75 ms /   546 tokens (    5.28 ms per token,   189.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2634.49 ms /    67 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    5607.97 ms /   613 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       4.91 ms /     9 runs   (    0.55 ms per token,  1834.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4758.31 ms /   878 tokens (    5.42 ms per token,   184.52 tokens per second)\n",
            "llama_print_timings:        eval time =     318.03 ms /     8 runs   (   39.75 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    5098.04 ms /   886 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      61.00 ms /    92 runs   (    0.66 ms per token,  1508.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6280.73 ms /  1142 tokens (    5.50 ms per token,   181.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3739.98 ms /    91 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   10165.00 ms /  1233 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.03 ms /    95 runs   (    0.56 ms per token,  1791.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4046.27 ms /   755 tokens (    5.36 ms per token,   186.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3714.64 ms /    94 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    7876.80 ms /   849 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      56.86 ms /   103 runs   (    0.55 ms per token,  1811.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7619.44 ms /  1354 tokens (    5.63 ms per token,   177.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4231.22 ms /   102 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =   11986.85 ms /  1456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      80.94 ms /   136 runs   (    0.60 ms per token,  1680.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6256.91 ms /  1131 tokens (    5.53 ms per token,   180.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5515.51 ms /   135 runs   (   40.86 ms per token,    24.48 tokens per second)\n",
            "llama_print_timings:       total time =   11952.88 ms /  1266 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.48 ms /     6 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3237.97 ms /   616 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =     234.00 ms /     6 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
            "llama_print_timings:       total time =    3486.32 ms /   622 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     149.96 ms /   256 runs   (    0.59 ms per token,  1707.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3840.96 ms /   720 tokens (    5.33 ms per token,   187.45 tokens per second)\n",
            "llama_print_timings:        eval time =   10112.70 ms /   255 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =   14298.40 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How is the company's corporate culture described?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      78.93 ms /   142 runs   (    0.56 ms per token,  1798.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4539.96 ms /   835 tokens (    5.44 ms per token,   183.92 tokens per second)\n",
            "llama_print_timings:        eval time =    5604.29 ms /   141 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =   10322.53 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      76.92 ms /   132 runs   (    0.58 ms per token,  1716.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8194.33 ms /  1440 tokens (    5.69 ms per token,   175.73 tokens per second)\n",
            "llama_print_timings:        eval time =    5518.11 ms /   132 runs   (   41.80 ms per token,    23.92 tokens per second)\n",
            "llama_print_timings:       total time =   13898.68 ms /  1572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      77.43 ms /   125 runs   (    0.62 ms per token,  1614.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5202.98 ms /   954 tokens (    5.45 ms per token,   183.36 tokens per second)\n",
            "llama_print_timings:        eval time =    5011.51 ms /   124 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
            "llama_print_timings:       total time =   10388.95 ms /  1078 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      76.60 ms /   119 runs   (    0.64 ms per token,  1553.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3772.41 ms /   708 tokens (    5.33 ms per token,   187.68 tokens per second)\n",
            "llama_print_timings:        eval time =    4671.06 ms /   118 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    8607.24 ms /   826 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      49.86 ms /    91 runs   (    0.55 ms per token,  1825.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6987.10 ms /  1255 tokens (    5.57 ms per token,   179.62 tokens per second)\n",
            "llama_print_timings:        eval time =    3705.03 ms /    90 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
            "llama_print_timings:       total time =   10815.06 ms /  1345 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      77.20 ms /   125 runs   (    0.62 ms per token,  1619.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3943.79 ms /   733 tokens (    5.38 ms per token,   185.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4891.61 ms /   124 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    8995.73 ms /   857 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     121.03 ms /   182 runs   (    0.67 ms per token,  1503.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4359.87 ms /   811 tokens (    5.38 ms per token,   186.01 tokens per second)\n",
            "llama_print_timings:        eval time =    7253.97 ms /   181 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =   11889.48 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     130.29 ms /   211 runs   (    0.62 ms per token,  1619.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4914.85 ms /   906 tokens (    5.42 ms per token,   184.34 tokens per second)\n",
            "llama_print_timings:        eval time =    8474.80 ms /   210 runs   (   40.36 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =   13693.24 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      84.76 ms /   148 runs   (    0.57 ms per token,  1746.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8983.73 ms /  1573 tokens (    5.71 ms per token,   175.09 tokens per second)\n",
            "llama_print_timings:        eval time =    6211.44 ms /   147 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
            "llama_print_timings:       total time =   15396.76 ms /  1720 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      55.68 ms /    84 runs   (    0.66 ms per token,  1508.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5205.09 ms /   954 tokens (    5.46 ms per token,   183.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3356.78 ms /    83 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    8687.14 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       6.49 ms /    12 runs   (    0.54 ms per token,  1849.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7699.17 ms /  1376 tokens (    5.60 ms per token,   178.72 tokens per second)\n",
            "llama_print_timings:        eval time =     457.11 ms /    11 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =    8185.29 ms /  1387 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.42 ms /    89 runs   (    0.54 ms per token,  1838.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6029.91 ms /  1090 tokens (    5.53 ms per token,   180.77 tokens per second)\n",
            "llama_print_timings:        eval time =    3573.47 ms /    88 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
            "llama_print_timings:       total time =    9715.78 ms /  1178 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      71.87 ms /   133 runs   (    0.54 ms per token,  1850.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7986.26 ms /  1416 tokens (    5.64 ms per token,   177.30 tokens per second)\n",
            "llama_print_timings:        eval time =    5551.69 ms /   133 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
            "llama_print_timings:       total time =   13708.14 ms /  1549 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     136.10 ms /   256 runs   (    0.53 ms per token,  1881.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12353.24 ms /  2088 tokens (    5.92 ms per token,   169.02 tokens per second)\n",
            "llama_print_timings:        eval time =   11313.23 ms /   256 runs   (   44.19 ms per token,    22.63 tokens per second)\n",
            "llama_print_timings:       total time =   24035.51 ms /  2344 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      46.39 ms /    81 runs   (    0.57 ms per token,  1746.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3683.73 ms /   696 tokens (    5.29 ms per token,   188.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3205.51 ms /    81 runs   (   39.57 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    6989.74 ms /   777 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.20 ms /    82 runs   (    0.58 ms per token,  1737.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4809.29 ms /   886 tokens (    5.43 ms per token,   184.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3240.25 ms /    81 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    8156.71 ms /   967 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      89.12 ms /   147 runs   (    0.61 ms per token,  1649.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13727.50 ms /  2287 tokens (    6.00 ms per token,   166.60 tokens per second)\n",
            "llama_print_timings:        eval time =    6898.43 ms /   146 runs   (   47.25 ms per token,    21.16 tokens per second)\n",
            "llama_print_timings:       total time =   20882.37 ms /  2433 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      52.32 ms /    83 runs   (    0.63 ms per token,  1586.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7752.94 ms /  1382 tokens (    5.61 ms per token,   178.25 tokens per second)\n",
            "llama_print_timings:        eval time =    3420.56 ms /    82 runs   (   41.71 ms per token,    23.97 tokens per second)\n",
            "llama_print_timings:       total time =   11310.20 ms /  1464 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's current ratio and quick ratio and how do these ratios compare to industry averages?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      40.22 ms /    71 runs   (    0.57 ms per token,  1765.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3893.38 ms /   728 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2792.59 ms /    71 runs   (   39.33 ms per token,    25.42 tokens per second)\n",
            "llama_print_timings:       total time =    6793.19 ms /   799 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      72.93 ms /   115 runs   (    0.63 ms per token,  1576.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5541.45 ms /  1016 tokens (    5.45 ms per token,   183.35 tokens per second)\n",
            "llama_print_timings:        eval time =    4641.36 ms /   114 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =   10372.61 ms /  1130 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.65 ms /    74 runs   (    0.66 ms per token,  1521.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6956.94 ms /  1252 tokens (    5.56 ms per token,   179.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3028.28 ms /    73 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
            "llama_print_timings:       total time =   10103.71 ms /  1325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      72.44 ms /   130 runs   (    0.56 ms per token,  1794.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4281.88 ms /   798 tokens (    5.37 ms per token,   186.37 tokens per second)\n",
            "llama_print_timings:        eval time =    5113.50 ms /   129 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    9550.14 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      64.52 ms /   115 runs   (    0.56 ms per token,  1782.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4628.49 ms /   854 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =    4540.93 ms /   114 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    9315.03 ms /   968 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.21 ms /   106 runs   (    0.65 ms per token,  1531.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6054.29 ms /  1103 tokens (    5.49 ms per token,   182.18 tokens per second)\n",
            "llama_print_timings:        eval time =    4298.06 ms /   105 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   10515.21 ms /  1208 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      42.03 ms /    74 runs   (    0.57 ms per token,  1760.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4267.67 ms /   797 tokens (    5.35 ms per token,   186.75 tokens per second)\n",
            "llama_print_timings:        eval time =    2883.29 ms /    73 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    7240.27 ms /   870 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     159.82 ms /   256 runs   (    0.62 ms per token,  1601.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3100.87 ms /   581 tokens (    5.34 ms per token,   187.37 tokens per second)\n",
            "llama_print_timings:        eval time =   10064.17 ms /   255 runs   (   39.47 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13539.16 ms /   836 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any ongoing legal proceedings against the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      56.18 ms /    95 runs   (    0.59 ms per token,  1691.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2910.72 ms /   547 tokens (    5.32 ms per token,   187.93 tokens per second)\n",
            "llama_print_timings:        eval time =    3678.74 ms /    94 runs   (   39.14 ms per token,    25.55 tokens per second)\n",
            "llama_print_timings:       total time =    6719.69 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      56.11 ms /    87 runs   (    0.64 ms per token,  1550.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4281.90 ms /   800 tokens (    5.35 ms per token,   186.83 tokens per second)\n",
            "llama_print_timings:        eval time =    3469.19 ms /    87 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7882.58 ms /   887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     152.87 ms /   256 runs   (    0.60 ms per token,  1674.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4399.32 ms /   816 tokens (    5.39 ms per token,   185.48 tokens per second)\n",
            "llama_print_timings:        eval time =   10266.77 ms /   256 runs   (   40.10 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   15091.74 ms /  1072 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      59.01 ms /   104 runs   (    0.57 ms per token,  1762.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4694.06 ms /   866 tokens (    5.42 ms per token,   184.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4121.27 ms /   103 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    8968.06 ms /   969 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.90 ms /    68 runs   (    0.70 ms per token,  1419.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3581.88 ms /   672 tokens (    5.33 ms per token,   187.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2689.82 ms /    68 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    6387.15 ms /   740 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      77.65 ms /   122 runs   (    0.64 ms per token,  1571.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6013.19 ms /  1091 tokens (    5.51 ms per token,   181.43 tokens per second)\n",
            "llama_print_timings:        eval time =    4953.70 ms /   121 runs   (   40.94 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   11178.45 ms /  1212 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      64.35 ms /   101 runs   (    0.64 ms per token,  1569.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7037.38 ms /  1264 tokens (    5.57 ms per token,   179.61 tokens per second)\n",
            "llama_print_timings:        eval time =    4127.93 ms /   100 runs   (   41.28 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =   11333.91 ms /  1364 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.79 ms /    93 runs   (    0.58 ms per token,  1728.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4850.58 ms /   890 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3679.27 ms /    92 runs   (   39.99 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    8660.03 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     148.29 ms /   256 runs   (    0.58 ms per token,  1726.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3815.93 ms /   716 tokens (    5.33 ms per token,   187.63 tokens per second)\n",
            "llama_print_timings:        eval time =   10146.33 ms /   255 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =   14353.83 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How is the company's corporate culture described?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       8.49 ms /    12 runs   (    0.71 ms per token,  1413.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3385.23 ms /   636 tokens (    5.32 ms per token,   187.87 tokens per second)\n",
            "llama_print_timings:        eval time =     431.46 ms /    11 runs   (   39.22 ms per token,    25.49 tokens per second)\n",
            "llama_print_timings:       total time =    3842.39 ms /   647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     142.19 ms /   256 runs   (    0.56 ms per token,  1800.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9592.76 ms /  1667 tokens (    5.75 ms per token,   173.78 tokens per second)\n",
            "llama_print_timings:        eval time =   10903.39 ms /   255 runs   (   42.76 ms per token,    23.39 tokens per second)\n",
            "llama_print_timings:       total time =   20875.13 ms /  1922 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      79.48 ms /   121 runs   (    0.66 ms per token,  1522.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4585.58 ms /   850 tokens (    5.39 ms per token,   185.36 tokens per second)\n",
            "llama_print_timings:        eval time =    4812.96 ms /   120 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    9586.74 ms /   970 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      86.55 ms /   151 runs   (    0.57 ms per token,  1744.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3592.78 ms /   679 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
            "llama_print_timings:        eval time =    5931.15 ms /   150 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    9724.20 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     147.76 ms /   256 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8163.47 ms /  1443 tokens (    5.66 ms per token,   176.76 tokens per second)\n",
            "llama_print_timings:        eval time =   10725.77 ms /   255 runs   (   42.06 ms per token,    23.77 tokens per second)\n",
            "llama_print_timings:       total time =   19266.77 ms /  1698 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.59 ms /    97 runs   (    0.69 ms per token,  1456.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4131.40 ms /   770 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3819.90 ms /    96 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    8099.61 ms /   866 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.67 ms /   123 runs   (    0.57 ms per token,  1765.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4596.10 ms /   853 tokens (    5.39 ms per token,   185.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4860.34 ms /   122 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    9608.00 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      51.68 ms /   100 runs   (    0.52 ms per token,  1935.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6807.30 ms /  1222 tokens (    5.57 ms per token,   179.51 tokens per second)\n",
            "llama_print_timings:        eval time =    4063.64 ms /    99 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =   10992.85 ms /  1321 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      44.24 ms /    80 runs   (    0.55 ms per token,  1808.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8788.22 ms /  1540 tokens (    5.71 ms per token,   175.23 tokens per second)\n",
            "llama_print_timings:        eval time =    3318.36 ms /    79 runs   (   42.00 ms per token,    23.81 tokens per second)\n",
            "llama_print_timings:       total time =   12215.41 ms /  1619 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.97 ms /    77 runs   (    0.60 ms per token,  1675.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6350.43 ms /  1152 tokens (    5.51 ms per token,   181.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3157.48 ms /    77 runs   (   41.01 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    9620.08 ms /  1229 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      90.09 ms /   158 runs   (    0.57 ms per token,  1753.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6281.75 ms /  1144 tokens (    5.49 ms per token,   182.11 tokens per second)\n",
            "llama_print_timings:        eval time =    6447.43 ms /   157 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
            "llama_print_timings:       total time =   12954.83 ms /  1301 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      61.50 ms /   102 runs   (    0.60 ms per token,  1658.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6663.86 ms /  1204 tokens (    5.53 ms per token,   180.68 tokens per second)\n",
            "llama_print_timings:        eval time =    4162.62 ms /   101 runs   (   41.21 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =   10981.54 ms /  1305 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      98.98 ms /   173 runs   (    0.57 ms per token,  1747.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6177.27 ms /  1019 tokens (    6.06 ms per token,   164.96 tokens per second)\n",
            "llama_print_timings:        eval time =    7348.90 ms /   172 runs   (   42.73 ms per token,    23.40 tokens per second)\n",
            "llama_print_timings:       total time =   13790.31 ms /  1191 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      80.85 ms /   124 runs   (    0.65 ms per token,  1533.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8959.47 ms /  1576 tokens (    5.68 ms per token,   175.90 tokens per second)\n",
            "llama_print_timings:        eval time =    5212.47 ms /   123 runs   (   42.38 ms per token,    23.60 tokens per second)\n",
            "llama_print_timings:       total time =   14370.00 ms /  1699 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     106.96 ms /   168 runs   (    0.64 ms per token,  1570.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7740.73 ms /  1378 tokens (    5.62 ms per token,   178.02 tokens per second)\n",
            "llama_print_timings:        eval time =    6987.91 ms /   167 runs   (   41.84 ms per token,    23.90 tokens per second)\n",
            "llama_print_timings:       total time =   14991.20 ms /  1545 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cash flow generated from operations and are there any notable trends or fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      75.12 ms /   118 runs   (    0.64 ms per token,  1570.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5280.28 ms /   967 tokens (    5.46 ms per token,   183.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4735.21 ms /   117 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =   10196.62 ms /  1084 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      82.21 ms /   135 runs   (    0.61 ms per token,  1642.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7019.19 ms /  1260 tokens (    5.57 ms per token,   179.51 tokens per second)\n",
            "llama_print_timings:        eval time =    5544.63 ms /   134 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   12765.12 ms /  1394 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.08 ms /    84 runs   (    0.56 ms per token,  1784.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7659.55 ms /  1368 tokens (    5.60 ms per token,   178.60 tokens per second)\n",
            "llama_print_timings:        eval time =    3446.58 ms /    83 runs   (   41.53 ms per token,    24.08 tokens per second)\n",
            "llama_print_timings:       total time =   11222.23 ms /  1451 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's current ratio and quick ratio and how do these ratios compare to industry averages?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      40.69 ms /    74 runs   (    0.55 ms per token,  1818.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7053.63 ms /  1264 tokens (    5.58 ms per token,   179.20 tokens per second)\n",
            "llama_print_timings:        eval time =    3004.53 ms /    73 runs   (   41.16 ms per token,    24.30 tokens per second)\n",
            "llama_print_timings:       total time =   10156.14 ms /  1337 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.58 ms /    80 runs   (    0.63 ms per token,  1581.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5024.14 ms /   924 tokens (    5.44 ms per token,   183.91 tokens per second)\n",
            "llama_print_timings:        eval time =    3174.18 ms /    79 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =    8310.71 ms /  1003 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      28.80 ms /    53 runs   (    0.54 ms per token,  1840.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2669.43 ms /   511 tokens (    5.22 ms per token,   191.43 tokens per second)\n",
            "llama_print_timings:        eval time =    2023.25 ms /    52 runs   (   38.91 ms per token,    25.70 tokens per second)\n",
            "llama_print_timings:       total time =    4753.91 ms /   563 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      63.70 ms /    92 runs   (    0.69 ms per token,  1444.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2665.86 ms /   512 tokens (    5.21 ms per token,   192.06 tokens per second)\n",
            "llama_print_timings:        eval time =    3556.82 ms /    91 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    6362.61 ms /   603 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.58 ms /     6 runs   (    0.60 ms per token,  1673.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3684.34 ms /   693 tokens (    5.32 ms per token,   188.09 tokens per second)\n",
            "llama_print_timings:        eval time =     196.95 ms /     5 runs   (   39.39 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    3897.20 ms /   698 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.95 ms /    61 runs   (    0.65 ms per token,  1527.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4497.55 ms /   838 tokens (    5.37 ms per token,   186.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2401.22 ms /    60 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    6987.89 ms /   898 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      36.07 ms /    65 runs   (    0.55 ms per token,  1802.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3806.28 ms /   711 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2519.59 ms /    64 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
            "llama_print_timings:       total time =    6405.97 ms /   775 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.59 ms /     6 runs   (    0.60 ms per token,  1671.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3728.33 ms /   704 tokens (    5.30 ms per token,   188.82 tokens per second)\n",
            "llama_print_timings:        eval time =     234.99 ms /     6 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    3979.39 ms /   710 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     145.64 ms /   256 runs   (    0.57 ms per token,  1757.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3298.50 ms /   624 tokens (    5.29 ms per token,   189.18 tokens per second)\n",
            "llama_print_timings:        eval time =   10091.70 ms /   256 runs   (   39.42 ms per token,    25.37 tokens per second)\n",
            "llama_print_timings:       total time =   13727.18 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     147.16 ms /   256 runs   (    0.57 ms per token,  1739.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6659.65 ms /  1196 tokens (    5.57 ms per token,   179.59 tokens per second)\n",
            "llama_print_timings:        eval time =   10531.52 ms /   255 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
            "llama_print_timings:       total time =   17567.77 ms /  1451 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      51.39 ms /    88 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7497.44 ms /  1342 tokens (    5.59 ms per token,   178.99 tokens per second)\n",
            "llama_print_timings:        eval time =    3615.16 ms /    87 runs   (   41.55 ms per token,    24.07 tokens per second)\n",
            "llama_print_timings:       total time =   11243.10 ms /  1429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      64.41 ms /   119 runs   (    0.54 ms per token,  1847.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6173.53 ms /  1118 tokens (    5.52 ms per token,   181.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4809.03 ms /   118 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =   11131.77 ms /  1236 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      37.17 ms /    69 runs   (    0.54 ms per token,  1856.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4629.44 ms /   853 tokens (    5.43 ms per token,   184.26 tokens per second)\n",
            "llama_print_timings:        eval time =    2709.13 ms /    68 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =    7425.36 ms /   921 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      57.48 ms /    93 runs   (    0.62 ms per token,  1617.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5192.16 ms /   958 tokens (    5.42 ms per token,   184.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3715.40 ms /    92 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    9039.91 ms /  1050 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1900.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5340.75 ms /   978 tokens (    5.46 ms per token,   183.12 tokens per second)\n",
            "llama_print_timings:        eval time =     198.80 ms /     5 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    5557.94 ms /   983 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     104.06 ms /   159 runs   (    0.65 ms per token,  1527.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3768.10 ms /   708 tokens (    5.32 ms per token,   187.89 tokens per second)\n",
            "llama_print_timings:        eval time =    6274.75 ms /   158 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =   10270.01 ms /   866 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.39 ms /     6 runs   (    0.57 ms per token,  1769.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3908.42 ms /   734 tokens (    5.32 ms per token,   187.80 tokens per second)\n",
            "llama_print_timings:        eval time =     197.62 ms /     5 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    4121.82 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      73.41 ms /   103 runs   (    0.71 ms per token,  1403.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2667.47 ms /   512 tokens (    5.21 ms per token,   191.94 tokens per second)\n",
            "llama_print_timings:        eval time =    4029.13 ms /   103 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
            "llama_print_timings:       total time =    6847.42 ms /   615 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.03 ms /   105 runs   (    0.63 ms per token,  1590.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8711.00 ms /  1536 tokens (    5.67 ms per token,   176.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4442.98 ms /   105 runs   (   42.31 ms per token,    23.63 tokens per second)\n",
            "llama_print_timings:       total time =   13316.29 ms /  1641 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.11 ms /    69 runs   (    0.57 ms per token,  1764.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3956.31 ms /   742 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2681.98 ms /    68 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6730.32 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      56.70 ms /    83 runs   (    0.68 ms per token,  1463.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3958.03 ms /   741 tokens (    5.34 ms per token,   187.21 tokens per second)\n",
            "llama_print_timings:        eval time =    3260.78 ms /    82 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    7344.67 ms /   823 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     156.78 ms /   256 runs   (    0.61 ms per token,  1632.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8391.67 ms /  1483 tokens (    5.66 ms per token,   176.72 tokens per second)\n",
            "llama_print_timings:        eval time =   10755.96 ms /   255 runs   (   42.18 ms per token,    23.71 tokens per second)\n",
            "llama_print_timings:       total time =   19526.45 ms /  1738 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     152.18 ms /   256 runs   (    0.59 ms per token,  1682.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3820.25 ms /   716 tokens (    5.34 ms per token,   187.42 tokens per second)\n",
            "llama_print_timings:        eval time =   10133.19 ms /   255 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =   14300.83 ms /   971 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How does the company leverage technology for its operations and are there ongoing technological advancements?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      60.22 ms /   102 runs   (    0.59 ms per token,  1693.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4709.29 ms /   867 tokens (    5.43 ms per token,   184.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4032.85 ms /   101 runs   (   39.93 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    8876.67 ms /   968 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      44.96 ms /    64 runs   (    0.70 ms per token,  1423.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7509.08 ms /  1344 tokens (    5.59 ms per token,   178.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2673.65 ms /    64 runs   (   41.78 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   10293.44 ms /  1408 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the total revenue generated by the company and how has the revenue changed over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     144.69 ms /   256 runs   (    0.57 ms per token,  1769.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12125.12 ms /  2056 tokens (    5.90 ms per token,   169.57 tokens per second)\n",
            "llama_print_timings:        eval time =   11198.89 ms /   255 runs   (   43.92 ms per token,    22.77 tokens per second)\n",
            "llama_print_timings:       total time =   23729.70 ms /  2311 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5468.17 ms /   996 tokens (    5.49 ms per token,   182.14 tokens per second)\n",
            "llama_print_timings:        eval time =     200.79 ms /     5 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    5689.91 ms /  1001 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     137.25 ms /   256 runs   (    0.54 ms per token,  1865.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10739.25 ms /  1846 tokens (    5.82 ms per token,   171.89 tokens per second)\n",
            "llama_print_timings:        eval time =   11024.47 ms /   255 runs   (   43.23 ms per token,    23.13 tokens per second)\n",
            "llama_print_timings:       total time =   22125.82 ms /  2101 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     145.68 ms /   256 runs   (    0.57 ms per token,  1757.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5067.56 ms /   932 tokens (    5.44 ms per token,   183.92 tokens per second)\n",
            "llama_print_timings:        eval time =   10316.00 ms /   255 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =   15746.60 ms /  1187 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's operating income and how does it compare to the previous years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      92.91 ms /   149 runs   (    0.62 ms per token,  1603.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5368.05 ms /   927 tokens (    5.79 ms per token,   172.69 tokens per second)\n",
            "llama_print_timings:        eval time =    6177.82 ms /   148 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
            "llama_print_timings:       total time =   11763.38 ms /  1075 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     135.41 ms /   256 runs   (    0.53 ms per token,  1890.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12267.26 ms /  2074 tokens (    5.91 ms per token,   169.07 tokens per second)\n",
            "llama_print_timings:        eval time =   11190.98 ms /   255 runs   (   43.89 ms per token,    22.79 tokens per second)\n",
            "llama_print_timings:       total time =   23814.87 ms /  2329 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     124.19 ms /   210 runs   (    0.59 ms per token,  1690.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10177.85 ms /  1760 tokens (    5.78 ms per token,   172.92 tokens per second)\n",
            "llama_print_timings:        eval time =    8977.44 ms /   209 runs   (   42.95 ms per token,    23.28 tokens per second)\n",
            "llama_print_timings:       total time =   19476.86 ms /  1969 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cash flow generated from operations and are there any notable trends or fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     147.77 ms /   256 runs   (    0.58 ms per token,  1732.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12015.77 ms /  2036 tokens (    5.90 ms per token,   169.44 tokens per second)\n",
            "llama_print_timings:        eval time =   11169.56 ms /   255 runs   (   43.80 ms per token,    22.83 tokens per second)\n",
            "llama_print_timings:       total time =   23579.25 ms /  2291 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much has the company invested in capital expenditures and are there any significant projects underway?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      86.31 ms /   146 runs   (    0.59 ms per token,  1691.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11193.84 ms /  1920 tokens (    5.83 ms per token,   171.52 tokens per second)\n",
            "llama_print_timings:        eval time =    6289.71 ms /   145 runs   (   43.38 ms per token,    23.05 tokens per second)\n",
            "llama_print_timings:       total time =   17699.20 ms /  2065 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     141.56 ms /   256 runs   (    0.55 ms per token,  1808.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13217.17 ms /  2214 tokens (    5.97 ms per token,   167.51 tokens per second)\n",
            "llama_print_timings:        eval time =   11861.37 ms /   255 runs   (   46.52 ms per token,    21.50 tokens per second)\n",
            "llama_print_timings:       total time =   25474.10 ms /  2469 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's current ratio and quick ratio and how do these ratios compare to industry averages?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     128.97 ms /   235 runs   (    0.55 ms per token,  1822.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10684.44 ms /  1839 tokens (    5.81 ms per token,   172.12 tokens per second)\n",
            "llama_print_timings:        eval time =   10103.65 ms /   234 runs   (   43.18 ms per token,    23.16 tokens per second)\n",
            "llama_print_timings:       total time =   21135.48 ms /  2073 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much inventory does the company hold and are there any signs of inventory management issues?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     142.42 ms /   256 runs   (    0.56 ms per token,  1797.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =   15441.54 ms /  2522 tokens (    6.12 ms per token,   163.33 tokens per second)\n",
            "llama_print_timings:        eval time =   12641.88 ms /   255 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
            "llama_print_timings:       total time =   28530.57 ms /  2777 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      44.05 ms /    64 runs   (    0.69 ms per token,  1452.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8399.63 ms /  1485 tokens (    5.66 ms per token,   176.79 tokens per second)\n",
            "llama_print_timings:        eval time =    2646.52 ms /    63 runs   (   42.01 ms per token,    23.80 tokens per second)\n",
            "llama_print_timings:       total time =   11161.60 ms /  1548 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's market share in its industry and how has it changed over the years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      60.65 ms /   109 runs   (    0.56 ms per token,  1797.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4481.72 ms /   828 tokens (    5.41 ms per token,   184.75 tokens per second)\n",
            "llama_print_timings:        eval time =    4292.63 ms /   108 runs   (   39.75 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    8927.05 ms /   936 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       4.37 ms /     6 runs   (    0.73 ms per token,  1372.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5324.09 ms /   976 tokens (    5.46 ms per token,   183.32 tokens per second)\n",
            "llama_print_timings:        eval time =     243.39 ms /     6 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:       total time =    5592.77 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      37.93 ms /    67 runs   (    0.57 ms per token,  1766.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5064.77 ms /   930 tokens (    5.45 ms per token,   183.62 tokens per second)\n",
            "llama_print_timings:        eval time =    2641.65 ms /    66 runs   (   40.02 ms per token,    24.98 tokens per second)\n",
            "llama_print_timings:       total time =    7798.94 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      68.23 ms /   119 runs   (    0.57 ms per token,  1744.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6478.90 ms /  1166 tokens (    5.56 ms per token,   179.97 tokens per second)\n",
            "llama_print_timings:        eval time =    4831.44 ms /   118 runs   (   40.94 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =   11484.56 ms /  1284 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      31.89 ms /    57 runs   (    0.56 ms per token,  1787.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7950.05 ms /  1404 tokens (    5.66 ms per token,   176.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2328.08 ms /    56 runs   (   41.57 ms per token,    24.05 tokens per second)\n",
            "llama_print_timings:       total time =   10368.54 ms /  1460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      36.81 ms /    64 runs   (    0.58 ms per token,  1738.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4129.08 ms /   766 tokens (    5.39 ms per token,   185.51 tokens per second)\n",
            "llama_print_timings:        eval time =    2488.43 ms /    63 runs   (   39.50 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6713.78 ms /   829 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     140.41 ms /   256 runs   (    0.55 ms per token,  1823.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13151.78 ms /  2200 tokens (    5.98 ms per token,   167.28 tokens per second)\n",
            "llama_print_timings:        eval time =   11810.24 ms /   255 runs   (   46.31 ms per token,    21.59 tokens per second)\n",
            "llama_print_timings:       total time =   25398.90 ms /  2455 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.92 ms /    80 runs   (    0.57 ms per token,  1742.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8351.92 ms /  1470 tokens (    5.68 ms per token,   176.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3306.76 ms /    79 runs   (   41.86 ms per token,    23.89 tokens per second)\n",
            "llama_print_timings:       total time =   11785.27 ms /  1549 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any tax-related risks or benefits for the company mentioned?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      86.68 ms /   155 runs   (    0.56 ms per token,  1788.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6078.22 ms /  1099 tokens (    5.53 ms per token,   180.81 tokens per second)\n",
            "llama_print_timings:        eval time =    6287.44 ms /   154 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =   12588.35 ms /  1253 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      74.22 ms /   137 runs   (    0.54 ms per token,  1845.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7605.13 ms /  1350 tokens (    5.63 ms per token,   177.51 tokens per second)\n",
            "llama_print_timings:        eval time =    5650.31 ms /   136 runs   (   41.55 ms per token,    24.07 tokens per second)\n",
            "llama_print_timings:       total time =   13439.51 ms /  1486 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      42.16 ms /    75 runs   (    0.56 ms per token,  1778.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6856.22 ms /  1228 tokens (    5.58 ms per token,   179.11 tokens per second)\n",
            "llama_print_timings:        eval time =    3044.25 ms /    74 runs   (   41.14 ms per token,    24.31 tokens per second)\n",
            "llama_print_timings:       total time =   10008.13 ms /  1302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     111.57 ms /   187 runs   (    0.60 ms per token,  1676.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8614.55 ms /  1514 tokens (    5.69 ms per token,   175.75 tokens per second)\n",
            "llama_print_timings:        eval time =    7844.80 ms /   186 runs   (   42.18 ms per token,    23.71 tokens per second)\n",
            "llama_print_timings:       total time =   16743.67 ms /  1700 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      78.59 ms /   112 runs   (    0.70 ms per token,  1425.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3194.85 ms /   603 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =    4377.46 ms /   111 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7751.46 ms /   714 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.76 ms /   256 runs   (    0.57 ms per token,  1744.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3907.61 ms /   732 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =   10139.62 ms /   255 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =   14414.83 ms /   987 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How is the company's corporate culture described?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     150.68 ms /   256 runs   (    0.59 ms per token,  1698.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4823.73 ms /   895 tokens (    5.39 ms per token,   185.54 tokens per second)\n",
            "llama_print_timings:        eval time =   10293.33 ms /   255 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =   15497.73 ms /  1150 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How does the company address Environmental, Social, and Governance (ESG) concerns and are there any sustainability initiatives in place?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     145.17 ms /   256 runs   (    0.57 ms per token,  1763.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12066.67 ms /  2042 tokens (    5.91 ms per token,   169.23 tokens per second)\n",
            "llama_print_timings:        eval time =   11167.90 ms /   255 runs   (   43.80 ms per token,    22.83 tokens per second)\n",
            "llama_print_timings:       total time =   23627.23 ms /  2297 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     152.73 ms /   256 runs   (    0.60 ms per token,  1676.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2929.93 ms /   559 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
            "llama_print_timings:        eval time =   10056.99 ms /   255 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13345.70 ms /   814 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How does the company manage currency risk and are there impacts on financials due to currency fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      58.91 ms /    99 runs   (    0.60 ms per token,  1680.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6181.69 ms /  1127 tokens (    5.49 ms per token,   182.31 tokens per second)\n",
            "llama_print_timings:        eval time =    4005.50 ms /    98 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
            "llama_print_timings:       total time =   10324.54 ms /  1225 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     135.16 ms /   256 runs   (    0.53 ms per token,  1894.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12777.40 ms /  2152 tokens (    5.94 ms per token,   168.42 tokens per second)\n",
            "llama_print_timings:        eval time =   11552.19 ms /   255 runs   (   45.30 ms per token,    22.07 tokens per second)\n",
            "llama_print_timings:       total time =   24722.60 ms /  2407 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     134.60 ms /   236 runs   (    0.57 ms per token,  1753.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4175.55 ms /   773 tokens (    5.40 ms per token,   185.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9350.76 ms /   235 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =   13863.73 ms /  1008 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.67 ms /    78 runs   (    0.56 ms per token,  1786.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4167.01 ms /   774 tokens (    5.38 ms per token,   185.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3036.85 ms /    77 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    7309.64 ms /   851 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      60.02 ms /   105 runs   (    0.57 ms per token,  1749.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7679.18 ms /  1367 tokens (    5.62 ms per token,   178.01 tokens per second)\n",
            "llama_print_timings:        eval time =    4330.64 ms /   104 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
            "llama_print_timings:       total time =   12165.68 ms /  1471 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the total revenue generated by the company and how has the revenue changed over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      58.13 ms /    93 runs   (    0.63 ms per token,  1599.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8783.66 ms /  1544 tokens (    5.69 ms per token,   175.78 tokens per second)\n",
            "llama_print_timings:        eval time =    3917.89 ms /    93 runs   (   42.13 ms per token,    23.74 tokens per second)\n",
            "llama_print_timings:       total time =   12852.04 ms /  1637 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      92.86 ms /   152 runs   (    0.61 ms per token,  1636.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5521.93 ms /  1013 tokens (    5.45 ms per token,   183.45 tokens per second)\n",
            "llama_print_timings:        eval time =    6148.56 ms /   151 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =   11905.56 ms /  1164 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      82.99 ms /   130 runs   (    0.64 ms per token,  1566.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5284.08 ms /   971 tokens (    5.44 ms per token,   183.76 tokens per second)\n",
            "llama_print_timings:        eval time =    5226.84 ms /   129 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =   10718.03 ms /  1100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      51.73 ms /    82 runs   (    0.63 ms per token,  1585.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9009.99 ms /  1572 tokens (    5.73 ms per token,   174.47 tokens per second)\n",
            "llama_print_timings:        eval time =    3431.73 ms /    81 runs   (   42.37 ms per token,    23.60 tokens per second)\n",
            "llama_print_timings:       total time =   12593.55 ms /  1653 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.79 ms /    79 runs   (    0.55 ms per token,  1803.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5690.69 ms /  1040 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
            "llama_print_timings:        eval time =    3197.13 ms /    79 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    8999.45 ms /  1119 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     138.49 ms /   256 runs   (    0.54 ms per token,  1848.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =   15777.86 ms /  2571 tokens (    6.14 ms per token,   162.95 tokens per second)\n",
            "llama_print_timings:        eval time =   12690.26 ms /   255 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
            "llama_print_timings:       total time =   28883.21 ms /  2826 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      63.77 ms /   117 runs   (    0.55 ms per token,  1834.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5146.47 ms /   944 tokens (    5.45 ms per token,   183.43 tokens per second)\n",
            "llama_print_timings:        eval time =    4661.50 ms /   116 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    9961.70 ms /  1060 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      55.89 ms /    97 runs   (    0.58 ms per token,  1735.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6366.32 ms /  1146 tokens (    5.56 ms per token,   180.01 tokens per second)\n",
            "llama_print_timings:        eval time =    3920.55 ms /    96 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =   10423.38 ms /  1242 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      95.92 ms /   172 runs   (    0.56 ms per token,  1793.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7769.10 ms /  1380 tokens (    5.63 ms per token,   177.63 tokens per second)\n",
            "llama_print_timings:        eval time =    7138.31 ms /   171 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
            "llama_print_timings:       total time =   15150.44 ms /  1551 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      42.38 ms /    71 runs   (    0.60 ms per token,  1675.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6543.80 ms /  1178 tokens (    5.56 ms per token,   180.02 tokens per second)\n",
            "llama_print_timings:        eval time =    2868.51 ms /    70 runs   (   40.98 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =    9518.69 ms /  1248 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     155.97 ms /   256 runs   (    0.61 ms per token,  1641.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5104.58 ms /   944 tokens (    5.41 ms per token,   184.93 tokens per second)\n",
            "llama_print_timings:        eval time =   10371.84 ms /   256 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =   15861.96 ms /  1200 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.61 ms /    71 runs   (    0.67 ms per token,  1491.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6490.86 ms /  1173 tokens (    5.53 ms per token,   180.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2884.89 ms /    70 runs   (   41.21 ms per token,    24.26 tokens per second)\n",
            "llama_print_timings:       total time =    9497.86 ms /  1243 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      37.12 ms /    66 runs   (    0.56 ms per token,  1778.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4585.24 ms /   851 tokens (    5.39 ms per token,   185.60 tokens per second)\n",
            "llama_print_timings:        eval time =    2581.18 ms /    65 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7248.56 ms /   916 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      61.65 ms /   104 runs   (    0.59 ms per token,  1687.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4541.02 ms /   836 tokens (    5.43 ms per token,   184.10 tokens per second)\n",
            "llama_print_timings:        eval time =    4110.11 ms /   103 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    8786.65 ms /   939 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.53 ms /     6 runs   (    0.59 ms per token,  1699.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4539.82 ms /   844 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
            "llama_print_timings:        eval time =     197.69 ms /     5 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
            "llama_print_timings:       total time =    4754.06 ms /   849 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      52.39 ms /    92 runs   (    0.57 ms per token,  1756.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4584.26 ms /   846 tokens (    5.42 ms per token,   184.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3607.35 ms /    91 runs   (   39.64 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    8303.54 ms /   937 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      32.25 ms /    55 runs   (    0.59 ms per token,  1705.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4591.48 ms /   854 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
            "llama_print_timings:        eval time =    2152.79 ms /    54 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    6818.77 ms /   908 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      36.55 ms /    67 runs   (    0.55 ms per token,  1833.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4716.39 ms /   868 tokens (    5.43 ms per token,   184.04 tokens per second)\n",
            "llama_print_timings:        eval time =    2628.91 ms /    66 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    7431.08 ms /   934 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      92.42 ms /   140 runs   (    0.66 ms per token,  1514.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3285.04 ms /   621 tokens (    5.29 ms per token,   189.04 tokens per second)\n",
            "llama_print_timings:        eval time =    5494.82 ms /   139 runs   (   39.53 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    8988.81 ms /   760 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      74.19 ms /   118 runs   (    0.63 ms per token,  1590.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7847.18 ms /  1398 tokens (    5.61 ms per token,   178.15 tokens per second)\n",
            "llama_print_timings:        eval time =    4903.52 ms /   117 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
            "llama_print_timings:       total time =   12947.10 ms /  1515 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      74.42 ms /   120 runs   (    0.62 ms per token,  1612.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6389.99 ms /  1159 tokens (    5.51 ms per token,   181.38 tokens per second)\n",
            "llama_print_timings:        eval time =    4883.70 ms /   119 runs   (   41.04 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =   11453.22 ms /  1278 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      94.36 ms /   165 runs   (    0.57 ms per token,  1748.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4620.38 ms /   853 tokens (    5.42 ms per token,   184.62 tokens per second)\n",
            "llama_print_timings:        eval time =    6555.48 ms /   164 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =   11396.92 ms /  1017 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      96.90 ms /   166 runs   (    0.58 ms per token,  1713.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6302.33 ms /  1136 tokens (    5.55 ms per token,   180.25 tokens per second)\n",
            "llama_print_timings:        eval time =    6794.54 ms /   166 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   13339.94 ms /  1302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.20 ms /   113 runs   (    0.59 ms per token,  1707.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9979.10 ms /  1725 tokens (    5.78 ms per token,   172.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4791.41 ms /   112 runs   (   42.78 ms per token,    23.38 tokens per second)\n",
            "llama_print_timings:       total time =   14966.69 ms /  1837 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's dividend history and how sustainable are the dividend payouts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     103.57 ms /   162 runs   (    0.64 ms per token,  1564.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7999.79 ms /  1415 tokens (    5.65 ms per token,   176.88 tokens per second)\n",
            "llama_print_timings:        eval time =    6755.87 ms /   161 runs   (   41.96 ms per token,    23.83 tokens per second)\n",
            "llama_print_timings:       total time =   15058.97 ms /  1576 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.88 ms /   125 runs   (    0.56 ms per token,  1788.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5030.52 ms /   928 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
            "llama_print_timings:        eval time =    5025.65 ms /   125 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =   10235.82 ms /  1053 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.53 ms /    68 runs   (    0.58 ms per token,  1720.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6811.80 ms /  1218 tokens (    5.59 ms per token,   178.81 tokens per second)\n",
            "llama_print_timings:        eval time =    2749.26 ms /    67 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
            "llama_print_timings:       total time =    9667.45 ms /  1285 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.82 ms /    88 runs   (    0.61 ms per token,  1635.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5649.23 ms /  1029 tokens (    5.49 ms per token,   182.15 tokens per second)\n",
            "llama_print_timings:        eval time =    3534.87 ms /    87 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    9325.45 ms /  1116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      84.31 ms /   105 runs   (    0.80 ms per token,  1245.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7601.94 ms /  1350 tokens (    5.63 ms per token,   177.59 tokens per second)\n",
            "llama_print_timings:        eval time =    4367.67 ms /   104 runs   (   42.00 ms per token,    23.81 tokens per second)\n",
            "llama_print_timings:       total time =   12192.37 ms /  1454 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      54.44 ms /    97 runs   (    0.56 ms per token,  1781.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3333.97 ms /   626 tokens (    5.33 ms per token,   187.76 tokens per second)\n",
            "llama_print_timings:        eval time =    3770.89 ms /    96 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7235.96 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      61.85 ms /    99 runs   (    0.62 ms per token,  1600.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4305.56 ms /   795 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3894.44 ms /    98 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    8347.26 ms /   893 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      46.27 ms /    79 runs   (    0.59 ms per token,  1707.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3374.96 ms /   637 tokens (    5.30 ms per token,   188.74 tokens per second)\n",
            "llama_print_timings:        eval time =    3066.23 ms /    78 runs   (   39.31 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    6549.28 ms /   715 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     150.06 ms /   256 runs   (    0.59 ms per token,  1706.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7704.31 ms /  1365 tokens (    5.64 ms per token,   177.17 tokens per second)\n",
            "llama_print_timings:        eval time =   10671.99 ms /   255 runs   (   41.85 ms per token,    23.89 tokens per second)\n",
            "llama_print_timings:       total time =   18802.13 ms /  1620 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How does the company leverage technology for its operations and are there ongoing technological advancements?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      73.39 ms /   115 runs   (    0.64 ms per token,  1566.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5425.90 ms /   994 tokens (    5.46 ms per token,   183.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4623.41 ms /   114 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =   10236.36 ms /  1108 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.68 ms /     6 runs   (    0.61 ms per token,  1630.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5537.04 ms /  1010 tokens (    5.48 ms per token,   182.41 tokens per second)\n",
            "llama_print_timings:        eval time =     200.01 ms /     5 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    5760.58 ms /  1015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.45 ms /    69 runs   (    0.57 ms per token,  1749.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8132.60 ms /  1440 tokens (    5.65 ms per token,   177.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2881.24 ms /    69 runs   (   41.76 ms per token,    23.95 tokens per second)\n",
            "llama_print_timings:       total time =   11117.54 ms /  1509 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.50 ms /    62 runs   (    0.64 ms per token,  1569.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6093.09 ms /  1110 tokens (    5.49 ms per token,   182.17 tokens per second)\n",
            "llama_print_timings:        eval time =    2489.93 ms /    61 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
            "llama_print_timings:       total time =    8682.13 ms /  1171 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     143.98 ms /   256 runs   (    0.56 ms per token,  1777.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9531.56 ms /  1659 tokens (    5.75 ms per token,   174.05 tokens per second)\n",
            "llama_print_timings:        eval time =   10886.41 ms /   255 runs   (   42.69 ms per token,    23.42 tokens per second)\n",
            "llama_print_timings:       total time =   20806.52 ms /  1914 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's major operating expenses and how have these expenses changed over time?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.18 ms /   256 runs   (    0.57 ms per token,  1751.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5484.03 ms /  1003 tokens (    5.47 ms per token,   182.89 tokens per second)\n",
            "llama_print_timings:        eval time =   10366.14 ms /   255 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   16224.18 ms /  1258 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's operating income and how does it compare to the previous years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      74.48 ms /   137 runs   (    0.54 ms per token,  1839.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8846.24 ms /  1548 tokens (    5.71 ms per token,   174.99 tokens per second)\n",
            "llama_print_timings:        eval time =    5726.40 ms /   136 runs   (   42.11 ms per token,    23.75 tokens per second)\n",
            "llama_print_timings:       total time =   14769.94 ms /  1684 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.50 ms /   106 runs   (    0.66 ms per token,  1525.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11500.98 ms /  1960 tokens (    5.87 ms per token,   170.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4619.18 ms /   106 runs   (   43.58 ms per token,    22.95 tokens per second)\n",
            "llama_print_timings:       total time =   16303.75 ms /  2066 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1776.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5522.22 ms /  1010 tokens (    5.47 ms per token,   182.90 tokens per second)\n",
            "llama_print_timings:        eval time =     199.53 ms /     5 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5742.17 ms /  1015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      61.87 ms /    96 runs   (    0.64 ms per token,  1551.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5324.45 ms /   911 tokens (    5.84 ms per token,   171.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3976.57 ms /    95 runs   (   41.86 ms per token,    23.89 tokens per second)\n",
            "llama_print_timings:       total time =    9459.57 ms /  1006 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much has the company invested in capital expenditures and are there any significant projects underway?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      94.68 ms /   166 runs   (    0.57 ms per token,  1753.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7157.67 ms /  1284 tokens (    5.57 ms per token,   179.39 tokens per second)\n",
            "llama_print_timings:        eval time =    6857.75 ms /   165 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =   14253.88 ms /  1449 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      57.32 ms /    89 runs   (    0.64 ms per token,  1552.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4322.72 ms /   808 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
            "llama_print_timings:        eval time =    3511.00 ms /    88 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    7965.08 ms /   896 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     142.10 ms /   256 runs   (    0.56 ms per token,  1801.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11015.17 ms /  1886 tokens (    5.84 ms per token,   171.22 tokens per second)\n",
            "llama_print_timings:        eval time =   11066.61 ms /   255 runs   (   43.40 ms per token,    23.04 tokens per second)\n",
            "llama_print_timings:       total time =   22458.26 ms /  2141 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much inventory does the company hold and are there any signs of inventory management issues?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      52.30 ms /    95 runs   (    0.55 ms per token,  1816.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7145.75 ms /  1279 tokens (    5.59 ms per token,   178.99 tokens per second)\n",
            "llama_print_timings:        eval time =    3871.88 ms /    94 runs   (   41.19 ms per token,    24.28 tokens per second)\n",
            "llama_print_timings:       total time =   11142.40 ms /  1373 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      57.09 ms /    85 runs   (    0.67 ms per token,  1488.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5531.90 ms /  1016 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3415.97 ms /    84 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
            "llama_print_timings:       total time =    9085.88 ms /  1100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     115.66 ms /   190 runs   (    0.61 ms per token,  1642.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4724.28 ms /   880 tokens (    5.37 ms per token,   186.27 tokens per second)\n",
            "llama_print_timings:        eval time =    7639.60 ms /   190 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
            "llama_print_timings:       total time =   12640.35 ms /  1070 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     158.62 ms /   256 runs   (    0.62 ms per token,  1613.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3727.94 ms /   700 tokens (    5.33 ms per token,   187.77 tokens per second)\n",
            "llama_print_timings:        eval time =   10098.08 ms /   255 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =   14206.46 ms /   955 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's key risks mentioned in the 10-K and how does the company plan to mitigate these risks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      60.30 ms /   102 runs   (    0.59 ms per token,  1691.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5064.26 ms /   936 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =    4100.03 ms /   102 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    9305.97 ms /  1038 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      57.64 ms /   102 runs   (    0.57 ms per token,  1769.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2418.25 ms /   430 tokens (    5.62 ms per token,   177.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4027.32 ms /   101 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    6577.18 ms /   531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     152.77 ms /   256 runs   (    0.60 ms per token,  1675.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4441.61 ms /   823 tokens (    5.40 ms per token,   185.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10215.17 ms /   255 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =   15029.23 ms /  1078 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any ongoing legal proceedings against the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.87 ms /   100 runs   (    0.70 ms per token,  1431.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4002.02 ms /   750 tokens (    5.34 ms per token,   187.41 tokens per second)\n",
            "llama_print_timings:        eval time =    3954.14 ms /    99 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    8127.70 ms /   849 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     150.87 ms /   256 runs   (    0.59 ms per token,  1696.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3416.54 ms /   646 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =   10097.40 ms /   255 runs   (   39.60 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =   13902.33 ms /   901 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     155.26 ms /   256 runs   (    0.61 ms per token,  1648.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3101.98 ms /   587 tokens (    5.28 ms per token,   189.23 tokens per second)\n",
            "llama_print_timings:        eval time =   10062.72 ms /   255 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =   13546.81 ms /   842 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any tax-related risks or benefits for the company mentioned?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      28.29 ms /    52 runs   (    0.54 ms per token,  1837.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4546.94 ms /   847 tokens (    5.37 ms per token,   186.28 tokens per second)\n",
            "llama_print_timings:        eval time =    2027.52 ms /    51 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    6642.15 ms /   898 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      84.01 ms /   149 runs   (    0.56 ms per token,  1773.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4436.84 ms /   818 tokens (    5.42 ms per token,   184.37 tokens per second)\n",
            "llama_print_timings:        eval time =    5900.66 ms /   148 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =   10530.89 ms /   966 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      49.00 ms /    88 runs   (    0.56 ms per token,  1795.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7435.17 ms /  1324 tokens (    5.62 ms per token,   178.07 tokens per second)\n",
            "llama_print_timings:        eval time =    3606.40 ms /    87 runs   (   41.45 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   11169.13 ms /  1411 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     124.47 ms /   211 runs   (    0.59 ms per token,  1695.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5386.09 ms /   911 tokens (    5.91 ms per token,   169.14 tokens per second)\n",
            "llama_print_timings:        eval time =    8870.08 ms /   210 runs   (   42.24 ms per token,    23.68 tokens per second)\n",
            "llama_print_timings:       total time =   14577.47 ms /  1121 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Has the company engaged in any share buyback programs and if yes what is the rationale behind such actions?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      51.27 ms /    80 runs   (    0.64 ms per token,  1560.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7027.30 ms /  1264 tokens (    5.56 ms per token,   179.87 tokens per second)\n",
            "llama_print_timings:        eval time =    3316.47 ms /    80 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   10474.30 ms /  1344 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      56.43 ms /    99 runs   (    0.57 ms per token,  1754.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3062.28 ms /   582 tokens (    5.26 ms per token,   190.05 tokens per second)\n",
            "llama_print_timings:        eval time =    3849.11 ms /    98 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7030.16 ms /   680 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     144.48 ms /   256 runs   (    0.56 ms per token,  1771.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4502.46 ms /   832 tokens (    5.41 ms per token,   184.79 tokens per second)\n",
            "llama_print_timings:        eval time =   10254.51 ms /   256 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =   15109.48 ms /  1088 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.22 ms /   256 runs   (    0.57 ms per token,  1750.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10853.44 ms /  1864 tokens (    5.82 ms per token,   171.74 tokens per second)\n",
            "llama_print_timings:        eval time =   11101.58 ms /   256 runs   (   43.37 ms per token,    23.06 tokens per second)\n",
            "llama_print_timings:       total time =   22347.40 ms /  2120 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      94.56 ms /   149 runs   (    0.63 ms per token,  1575.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3913.27 ms /   731 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =    5869.84 ms /   148 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    9991.54 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      62.91 ms /    95 runs   (    0.66 ms per token,  1510.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4819.65 ms /   893 tokens (    5.40 ms per token,   185.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3775.30 ms /    94 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =    8739.81 ms /   987 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     115.94 ms /   194 runs   (    0.60 ms per token,  1673.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9327.15 ms /  1628 tokens (    5.73 ms per token,   174.54 tokens per second)\n",
            "llama_print_timings:        eval time =    8219.56 ms /   193 runs   (   42.59 ms per token,    23.48 tokens per second)\n",
            "llama_print_timings:       total time =   17845.93 ms /  1821 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      58.08 ms /    91 runs   (    0.64 ms per token,  1566.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4452.15 ms /   826 tokens (    5.39 ms per token,   185.53 tokens per second)\n",
            "llama_print_timings:        eval time =    3581.40 ms /    90 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =    8165.71 ms /   916 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     116.62 ms /   201 runs   (    0.58 ms per token,  1723.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5125.71 ms /   940 tokens (    5.45 ms per token,   183.39 tokens per second)\n",
            "llama_print_timings:        eval time =    8068.34 ms /   200 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
            "llama_print_timings:       total time =   13479.17 ms /  1140 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     128.15 ms /   219 runs   (    0.59 ms per token,  1709.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5920.41 ms /  1077 tokens (    5.50 ms per token,   181.91 tokens per second)\n",
            "llama_print_timings:        eval time =    8914.49 ms /   218 runs   (   40.89 ms per token,    24.45 tokens per second)\n",
            "llama_print_timings:       total time =   15170.01 ms /  1295 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     138.01 ms /   256 runs   (    0.54 ms per token,  1854.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12891.85 ms /  2165 tokens (    5.95 ms per token,   167.94 tokens per second)\n",
            "llama_print_timings:        eval time =   11597.54 ms /   255 runs   (   45.48 ms per token,    21.99 tokens per second)\n",
            "llama_print_timings:       total time =   24887.49 ms /  2420 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.88 ms /    84 runs   (    0.57 ms per token,  1754.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6536.74 ms /  1184 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
            "llama_print_timings:        eval time =    3429.79 ms /    84 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =   10080.66 ms /  1268 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.16 ms /    88 runs   (    0.55 ms per token,  1827.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7339.40 ms /  1309 tokens (    5.61 ms per token,   178.35 tokens per second)\n",
            "llama_print_timings:        eval time =    3587.00 ms /    87 runs   (   41.23 ms per token,    24.25 tokens per second)\n",
            "llama_print_timings:       total time =   11054.53 ms /  1396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      62.72 ms /    92 runs   (    0.68 ms per token,  1466.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3749.02 ms /   662 tokens (    5.66 ms per token,   176.58 tokens per second)\n",
            "llama_print_timings:        eval time =    3720.28 ms /    91 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =    7627.62 ms /   753 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     6 runs   (    0.64 ms per token,  1562.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     140.91 ms /    24 tokens (    5.87 ms per token,   170.32 tokens per second)\n",
            "llama_print_timings:        eval time =     203.18 ms /     5 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =     356.74 ms /    29 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      78.18 ms /   125 runs   (    0.63 ms per token,  1598.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10161.23 ms /  1756 tokens (    5.79 ms per token,   172.81 tokens per second)\n",
            "llama_print_timings:        eval time =    5302.14 ms /   124 runs   (   42.76 ms per token,    23.39 tokens per second)\n",
            "llama_print_timings:       total time =   15687.65 ms /  1880 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      46.10 ms /    81 runs   (    0.57 ms per token,  1756.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9105.26 ms /  1596 tokens (    5.71 ms per token,   175.28 tokens per second)\n",
            "llama_print_timings:        eval time =    3368.78 ms /    80 runs   (   42.11 ms per token,    23.75 tokens per second)\n",
            "llama_print_timings:       total time =   12596.07 ms /  1676 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cash flow generated from operations and are there any notable trends or fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.44 ms /   256 runs   (    0.57 ms per token,  1748.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9489.99 ms /  1654 tokens (    5.74 ms per token,   174.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10895.27 ms /   255 runs   (   42.73 ms per token,    23.40 tokens per second)\n",
            "llama_print_timings:       total time =   20817.28 ms /  1909 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much has the company invested in capital expenditures and are there any significant projects underway?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     139.66 ms /   256 runs   (    0.55 ms per token,  1832.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =   15665.05 ms /  2552 tokens (    6.14 ms per token,   162.91 tokens per second)\n",
            "llama_print_timings:        eval time =   12692.61 ms /   255 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
            "llama_print_timings:       total time =   28771.77 ms /  2807 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.32 ms /    78 runs   (    0.65 ms per token,  1550.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8692.31 ms /  1533 tokens (    5.67 ms per token,   176.36 tokens per second)\n",
            "llama_print_timings:        eval time =    3249.89 ms /    77 runs   (   42.21 ms per token,    23.69 tokens per second)\n",
            "llama_print_timings:       total time =   12075.00 ms /  1610 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's current ratio and quick ratio and how do these ratios compare to industry averages?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     140.54 ms /   256 runs   (    0.55 ms per token,  1821.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13209.93 ms /  2211 tokens (    5.97 ms per token,   167.37 tokens per second)\n",
            "llama_print_timings:        eval time =   11829.52 ms /   255 runs   (   46.39 ms per token,    21.56 tokens per second)\n",
            "llama_print_timings:       total time =   25465.45 ms /  2466 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much inventory does the company hold and are there any signs of inventory management issues?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      44.77 ms /    79 runs   (    0.57 ms per token,  1764.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8333.69 ms /  1467 tokens (    5.68 ms per token,   176.03 tokens per second)\n",
            "llama_print_timings:        eval time =    3262.35 ms /    78 runs   (   41.82 ms per token,    23.91 tokens per second)\n",
            "llama_print_timings:       total time =   11730.94 ms /  1545 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.84 ms /    74 runs   (    0.59 ms per token,  1687.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4369.54 ms /   806 tokens (    5.42 ms per token,   184.46 tokens per second)\n",
            "llama_print_timings:        eval time =    2896.68 ms /    73 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    7377.93 ms /   879 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.15 ms /   107 runs   (    0.65 ms per token,  1547.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4318.70 ms /   807 tokens (    5.35 ms per token,   186.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4233.18 ms /   106 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    8713.30 ms /   913 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1837.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5075.91 ms /   931 tokens (    5.45 ms per token,   183.42 tokens per second)\n",
            "llama_print_timings:        eval time =     200.45 ms /     5 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    5298.82 ms /   936 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      98.10 ms /   153 runs   (    0.64 ms per token,  1559.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5915.93 ms /  1080 tokens (    5.48 ms per token,   182.56 tokens per second)\n",
            "llama_print_timings:        eval time =    6263.71 ms /   153 runs   (   40.94 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   12419.34 ms /  1233 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      63.39 ms /    90 runs   (    0.70 ms per token,  1419.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5859.58 ms /  1072 tokens (    5.47 ms per token,   182.95 tokens per second)\n",
            "llama_print_timings:        eval time =    3649.73 ms /    89 runs   (   41.01 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    9671.83 ms /  1161 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       6.35 ms /    11 runs   (    0.58 ms per token,  1732.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2890.48 ms /   549 tokens (    5.26 ms per token,   189.93 tokens per second)\n",
            "llama_print_timings:        eval time =     391.04 ms /    10 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
            "llama_print_timings:       total time =    3301.83 ms /   559 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.89 ms /   117 runs   (    0.60 ms per token,  1673.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2580.89 ms /   490 tokens (    5.27 ms per token,   189.86 tokens per second)\n",
            "llama_print_timings:        eval time =    4532.04 ms /   116 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
            "llama_print_timings:       total time =    7265.15 ms /   606 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     117.70 ms /   199 runs   (    0.59 ms per token,  1690.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9925.13 ms /  1720 tokens (    5.77 ms per token,   173.30 tokens per second)\n",
            "llama_print_timings:        eval time =    8493.29 ms /   198 runs   (   42.90 ms per token,    23.31 tokens per second)\n",
            "llama_print_timings:       total time =   18758.60 ms /  1918 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      90.39 ms /   139 runs   (    0.65 ms per token,  1537.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7519.75 ms /  1344 tokens (    5.60 ms per token,   178.73 tokens per second)\n",
            "llama_print_timings:        eval time =    5763.97 ms /   138 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   13517.65 ms /  1482 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.56 ms /    69 runs   (    0.70 ms per token,  1420.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8728.33 ms /  1536 tokens (    5.68 ms per token,   175.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2911.39 ms /    69 runs   (   42.19 ms per token,    23.70 tokens per second)\n",
            "llama_print_timings:       total time =   11760.29 ms /  1605 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much is spent on research and development by the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.71 ms /   113 runs   (    0.59 ms per token,  1693.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4004.31 ms /   752 tokens (    5.32 ms per token,   187.80 tokens per second)\n",
            "llama_print_timings:        eval time =    4416.78 ms /   112 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    8565.36 ms /   864 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.80 ms /    99 runs   (    0.54 ms per token,  1840.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6655.58 ms /  1196 tokens (    5.56 ms per token,   179.70 tokens per second)\n",
            "llama_print_timings:        eval time =    4015.74 ms /    98 runs   (   40.98 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =   10800.47 ms /  1294 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      71.81 ms /   125 runs   (    0.57 ms per token,  1740.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7296.00 ms /  1304 tokens (    5.60 ms per token,   178.73 tokens per second)\n",
            "llama_print_timings:        eval time =    5171.61 ms /   125 runs   (   41.37 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   12637.61 ms /  1429 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      85.55 ms /   147 runs   (    0.58 ms per token,  1718.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5845.40 ms /  1061 tokens (    5.51 ms per token,   181.51 tokens per second)\n",
            "llama_print_timings:        eval time =    5932.70 ms /   146 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =   11978.55 ms /  1207 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     169.94 ms /   256 runs   (    0.66 ms per token,  1506.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3821.91 ms /   720 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
            "llama_print_timings:        eval time =   10215.76 ms /   256 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =   14458.92 ms /   976 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     152.05 ms /   256 runs   (    0.59 ms per token,  1683.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4890.11 ms /   902 tokens (    5.42 ms per token,   184.45 tokens per second)\n",
            "llama_print_timings:        eval time =   10281.90 ms /   255 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =   15540.24 ms /  1157 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     149.35 ms /   256 runs   (    0.58 ms per token,  1714.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10119.51 ms /  1749 tokens (    5.79 ms per token,   172.83 tokens per second)\n",
            "llama_print_timings:        eval time =   10972.46 ms /   255 runs   (   43.03 ms per token,    23.24 tokens per second)\n",
            "llama_print_timings:       total time =   21487.44 ms /  2004 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     163.80 ms /   256 runs   (    0.64 ms per token,  1562.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3866.14 ms /   727 tokens (    5.32 ms per token,   188.04 tokens per second)\n",
            "llama_print_timings:        eval time =   10152.67 ms /   255 runs   (   39.81 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =   14397.51 ms /   982 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.11 ms /    77 runs   (    0.69 ms per token,  1449.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5206.25 ms /   960 tokens (    5.42 ms per token,   184.39 tokens per second)\n",
            "llama_print_timings:        eval time =    3116.57 ms /    77 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =    8445.23 ms /  1037 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     103.06 ms /   172 runs   (    0.60 ms per token,  1668.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7053.53 ms /  1268 tokens (    5.56 ms per token,   179.77 tokens per second)\n",
            "llama_print_timings:        eval time =    7090.74 ms /   171 runs   (   41.47 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   14394.31 ms /  1439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     159.66 ms /   256 runs   (    0.62 ms per token,  1603.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4037.15 ms /   754 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
            "llama_print_timings:        eval time =   10176.26 ms /   255 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =   14599.95 ms /  1009 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      80.51 ms /   124 runs   (    0.65 ms per token,  1540.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3728.96 ms /   702 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    4878.37 ms /   123 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
            "llama_print_timings:       total time =    8804.25 ms /   825 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      23.41 ms /    44 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4119.48 ms /   763 tokens (    5.40 ms per token,   185.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1693.54 ms /    43 runs   (   39.38 ms per token,    25.39 tokens per second)\n",
            "llama_print_timings:       total time =    5873.33 ms /   806 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     156.35 ms /   256 runs   (    0.61 ms per token,  1637.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3950.34 ms /   738 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
            "llama_print_timings:        eval time =   10160.44 ms /   255 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
            "llama_print_timings:       total time =   14490.95 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     139.55 ms /   256 runs   (    0.55 ms per token,  1834.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9928.45 ms /  1720 tokens (    5.77 ms per token,   173.24 tokens per second)\n",
            "llama_print_timings:        eval time =   10947.84 ms /   255 runs   (   42.93 ms per token,    23.29 tokens per second)\n",
            "llama_print_timings:       total time =   21257.56 ms /  1975 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's gross profit margin, and how has it evolved?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      70.68 ms /   114 runs   (    0.62 ms per token,  1612.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8495.83 ms /  1501 tokens (    5.66 ms per token,   176.67 tokens per second)\n",
            "llama_print_timings:        eval time =    4772.75 ms /   113 runs   (   42.24 ms per token,    23.68 tokens per second)\n",
            "llama_print_timings:       total time =   13449.50 ms /  1614 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      86.91 ms /   142 runs   (    0.61 ms per token,  1633.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7008.11 ms /  1264 tokens (    5.54 ms per token,   180.36 tokens per second)\n",
            "llama_print_timings:        eval time =    5886.01 ms /   142 runs   (   41.45 ms per token,    24.12 tokens per second)\n",
            "llama_print_timings:       total time =   13110.94 ms /  1406 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's operating income and how does it compare to the previous years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     137.55 ms /   256 runs   (    0.54 ms per token,  1861.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11468.74 ms /  1960 tokens (    5.85 ms per token,   170.90 tokens per second)\n",
            "llama_print_timings:        eval time =   11114.33 ms /   255 runs   (   43.59 ms per token,    22.94 tokens per second)\n",
            "llama_print_timings:       total time =   22938.77 ms /  2215 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      82.35 ms /   134 runs   (    0.61 ms per token,  1627.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9189.47 ms /  1604 tokens (    5.73 ms per token,   174.55 tokens per second)\n",
            "llama_print_timings:        eval time =    5642.02 ms /   133 runs   (   42.42 ms per token,    23.57 tokens per second)\n",
            "llama_print_timings:       total time =   15030.82 ms /  1737 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      41.98 ms /    72 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8719.92 ms /  1533 tokens (    5.69 ms per token,   175.80 tokens per second)\n",
            "llama_print_timings:        eval time =    2985.65 ms /    71 runs   (   42.05 ms per token,    23.78 tokens per second)\n",
            "llama_print_timings:       total time =   11807.89 ms /  1604 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cash flow generated from operations and are there any notable trends or fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      34.00 ms /    60 runs   (    0.57 ms per token,  1764.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7207.89 ms /  1288 tokens (    5.60 ms per token,   178.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2435.14 ms /    59 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
            "llama_print_timings:       total time =    9736.58 ms /  1347 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much has the company invested in capital expenditures and are there any significant projects underway?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     140.33 ms /   256 runs   (    0.55 ms per token,  1824.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9711.90 ms /  1688 tokens (    5.75 ms per token,   173.81 tokens per second)\n",
            "llama_print_timings:        eval time =   10963.24 ms /   256 runs   (   42.83 ms per token,    23.35 tokens per second)\n",
            "llama_print_timings:       total time =   21054.67 ms /  1944 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      57.23 ms /    86 runs   (    0.67 ms per token,  1502.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6858.01 ms /  1234 tokens (    5.56 ms per token,   179.94 tokens per second)\n",
            "llama_print_timings:        eval time =    3509.23 ms /    85 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
            "llama_print_timings:       total time =   10496.43 ms /  1319 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      52.81 ms /    92 runs   (    0.57 ms per token,  1741.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4979.28 ms /   916 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
            "llama_print_timings:        eval time =    3647.69 ms /    91 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    8742.44 ms /  1007 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      49.15 ms /    73 runs   (    0.67 ms per token,  1485.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3470.10 ms /   654 tokens (    5.31 ms per token,   188.47 tokens per second)\n",
            "llama_print_timings:        eval time =    2845.02 ms /    72 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6426.62 ms /   726 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     155.52 ms /   256 runs   (    0.61 ms per token,  1646.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4128.25 ms /   766 tokens (    5.39 ms per token,   185.55 tokens per second)\n",
            "llama_print_timings:        eval time =   10181.26 ms /   255 runs   (   39.93 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =   14686.15 ms /  1021 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     155.19 ms /   256 runs   (    0.61 ms per token,  1649.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2476.33 ms /   444 tokens (    5.58 ms per token,   179.30 tokens per second)\n",
            "llama_print_timings:        eval time =   10228.69 ms /   255 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =   13068.79 ms /   699 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Who are the company's main competitors and how does the company differentiate itself?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     153.99 ms /   256 runs   (    0.60 ms per token,  1662.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4217.23 ms /   786 tokens (    5.37 ms per token,   186.38 tokens per second)\n",
            "llama_print_timings:        eval time =   10191.56 ms /   255 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =   14784.57 ms /  1041 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's key risks mentioned in the 10-K and how does the company plan to mitigate these risks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.73 ms /    69 runs   (    0.69 ms per token,  1445.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6709.62 ms /  1214 tokens (    5.53 ms per token,   180.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2810.06 ms /    68 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
            "llama_print_timings:       total time =    9635.61 ms /  1282 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.27 ms /   112 runs   (    0.59 ms per token,  1690.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7347.30 ms /  1315 tokens (    5.59 ms per token,   178.98 tokens per second)\n",
            "llama_print_timings:        eval time =    4607.59 ms /   111 runs   (   41.51 ms per token,    24.09 tokens per second)\n",
            "llama_print_timings:       total time =   12109.66 ms /  1426 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      61.02 ms /   111 runs   (    0.55 ms per token,  1819.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5819.99 ms /  1063 tokens (    5.48 ms per token,   182.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4458.02 ms /   110 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =   10414.29 ms /  1173 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     145.83 ms /   256 runs   (    0.57 ms per token,  1755.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3494.66 ms /   655 tokens (    5.34 ms per token,   187.43 tokens per second)\n",
            "llama_print_timings:        eval time =   10053.37 ms /   255 runs   (   39.42 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =   13874.37 ms /   910 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     121.89 ms /   211 runs   (    0.58 ms per token,  1731.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7630.83 ms /  1357 tokens (    5.62 ms per token,   177.83 tokens per second)\n",
            "llama_print_timings:        eval time =    8772.00 ms /   210 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   16718.38 ms /  1567 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     157.82 ms /   256 runs   (    0.62 ms per token,  1622.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4824.40 ms /   896 tokens (    5.38 ms per token,   185.72 tokens per second)\n",
            "llama_print_timings:        eval time =   10315.34 ms /   256 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =   15511.87 ms /  1152 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any tax-related risks or benefits for the company mentioned?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      78.34 ms /   128 runs   (    0.61 ms per token,  1633.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6904.86 ms /  1243 tokens (    5.55 ms per token,   180.02 tokens per second)\n",
            "llama_print_timings:        eval time =    5255.57 ms /   127 runs   (   41.38 ms per token,    24.16 tokens per second)\n",
            "llama_print_timings:       total time =   12351.70 ms /  1370 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.22 ms /    69 runs   (    0.63 ms per token,  1596.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4003.86 ms /   752 tokens (    5.32 ms per token,   187.82 tokens per second)\n",
            "llama_print_timings:        eval time =    2694.69 ms /    68 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
            "llama_print_timings:       total time =    6800.69 ms /   820 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.13 ms /    90 runs   (    0.56 ms per token,  1795.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5845.03 ms /  1063 tokens (    5.50 ms per token,   181.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3605.01 ms /    89 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =    9571.90 ms /  1152 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      85.03 ms /   135 runs   (    0.63 ms per token,  1587.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6386.22 ms /  1157 tokens (    5.52 ms per token,   181.17 tokens per second)\n",
            "llama_print_timings:        eval time =    5506.54 ms /   134 runs   (   41.09 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =   12092.51 ms /  1291 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      62.07 ms /   108 runs   (    0.57 ms per token,  1739.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3067.74 ms /   580 tokens (    5.29 ms per token,   189.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4203.49 ms /   107 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
            "llama_print_timings:       total time =    7426.64 ms /   687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      35.41 ms /    64 runs   (    0.55 ms per token,  1807.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4446.56 ms /   822 tokens (    5.41 ms per token,   184.86 tokens per second)\n",
            "llama_print_timings:        eval time =    2497.83 ms /    63 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
            "llama_print_timings:       total time =    7037.39 ms /   885 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      75.73 ms /   112 runs   (    0.68 ms per token,  1479.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4053.80 ms /   759 tokens (    5.34 ms per token,   187.23 tokens per second)\n",
            "llama_print_timings:        eval time =    4433.69 ms /   111 runs   (   39.94 ms per token,    25.04 tokens per second)\n",
            "llama_print_timings:       total time =    8655.84 ms /   870 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     148.73 ms /   256 runs   (    0.58 ms per token,  1721.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4091.38 ms /   768 tokens (    5.33 ms per token,   187.71 tokens per second)\n",
            "llama_print_timings:        eval time =   10163.41 ms /   255 runs   (   39.86 ms per token,    25.09 tokens per second)\n",
            "llama_print_timings:       total time =   14617.53 ms /  1023 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      40.51 ms /    72 runs   (    0.56 ms per token,  1777.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3861.42 ms /   722 tokens (    5.35 ms per token,   186.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2803.99 ms /    71 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
            "llama_print_timings:       total time =    6749.43 ms /   793 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      77.95 ms /   120 runs   (    0.65 ms per token,  1539.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2855.12 ms /   544 tokens (    5.25 ms per token,   190.53 tokens per second)\n",
            "llama_print_timings:        eval time =    4717.84 ms /   120 runs   (   39.32 ms per token,    25.44 tokens per second)\n",
            "llama_print_timings:       total time =    7735.00 ms /   664 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      97.61 ms /   151 runs   (    0.65 ms per token,  1546.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4641.09 ms /   864 tokens (    5.37 ms per token,   186.16 tokens per second)\n",
            "llama_print_timings:        eval time =    6078.62 ms /   151 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
            "llama_print_timings:       total time =   10963.37 ms /  1015 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.46 ms /     6 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4048.49 ms /   760 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
            "llama_print_timings:        eval time =     197.75 ms /     5 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    4262.01 ms /   765 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      64.45 ms /   100 runs   (    0.64 ms per token,  1551.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3502.31 ms /   659 tokens (    5.31 ms per token,   188.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3916.45 ms /    99 runs   (   39.56 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    7558.33 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      80.19 ms /   147 runs   (    0.55 ms per token,  1833.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5973.42 ms /  1088 tokens (    5.49 ms per token,   182.14 tokens per second)\n",
            "llama_print_timings:        eval time =    5990.60 ms /   147 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =   12154.19 ms /  1235 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     145.31 ms /   256 runs   (    0.57 ms per token,  1761.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16494.00 ms /  2672 tokens (    6.17 ms per token,   162.00 tokens per second)\n",
            "llama_print_timings:        eval time =   12842.52 ms /   255 runs   (   50.36 ms per token,    19.86 tokens per second)\n",
            "llama_print_timings:       total time =   29799.65 ms /  2927 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      54.47 ms /    95 runs   (    0.57 ms per token,  1744.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4219.28 ms /   781 tokens (    5.40 ms per token,   185.10 tokens per second)\n",
            "llama_print_timings:        eval time =    3714.76 ms /    94 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
            "llama_print_timings:       total time =    8060.14 ms /   875 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     147.96 ms /   256 runs   (    0.58 ms per token,  1730.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3341.10 ms /   629 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =   10060.09 ms /   255 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =   13750.32 ms /   884 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's major operating expenses and how have these expenses changed over time?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     141.88 ms /   256 runs   (    0.55 ms per token,  1804.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =   14900.44 ms /  2456 tokens (    6.07 ms per token,   164.83 tokens per second)\n",
            "llama_print_timings:        eval time =   12557.58 ms /   255 runs   (   49.25 ms per token,    20.31 tokens per second)\n",
            "llama_print_timings:       total time =   27837.67 ms /  2711 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's operating income and how does it compare to the previous years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      83.79 ms /   148 runs   (    0.57 ms per token,  1766.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2784.11 ms /   453 tokens (    6.15 ms per token,   162.71 tokens per second)\n",
            "llama_print_timings:        eval time =    6161.15 ms /   147 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
            "llama_print_timings:       total time =    9129.96 ms /   600 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     143.77 ms /   256 runs   (    0.56 ms per token,  1780.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7408.53 ms /  1157 tokens (    6.40 ms per token,   156.17 tokens per second)\n",
            "llama_print_timings:        eval time =   11587.80 ms /   255 runs   (   45.44 ms per token,    22.01 tokens per second)\n",
            "llama_print_timings:       total time =   19379.60 ms /  1412 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.40 ms /    85 runs   (    0.57 ms per token,  1756.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4658.97 ms /   864 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3343.39 ms /    84 runs   (   39.80 ms per token,    25.12 tokens per second)\n",
            "llama_print_timings:       total time =    8121.87 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      46.95 ms /    71 runs   (    0.66 ms per token,  1512.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4795.03 ms /   887 tokens (    5.41 ms per token,   184.98 tokens per second)\n",
            "llama_print_timings:        eval time =    2816.45 ms /    70 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    7724.71 ms /   957 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      75.73 ms /   120 runs   (    0.63 ms per token,  1584.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6233.68 ms /  1131 tokens (    5.51 ms per token,   181.43 tokens per second)\n",
            "llama_print_timings:        eval time =    4873.34 ms /   119 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =   11291.06 ms /  1250 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      67.45 ms /    99 runs   (    0.68 ms per token,  1467.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9944.13 ms /  1728 tokens (    5.75 ms per token,   173.77 tokens per second)\n",
            "llama_print_timings:        eval time =    4242.56 ms /    99 runs   (   42.85 ms per token,    23.33 tokens per second)\n",
            "llama_print_timings:       total time =   14357.18 ms /  1827 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's current ratio and quick ratio and how do these ratios compare to industry averages?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.19 ms /   118 runs   (    0.56 ms per token,  1782.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4178.80 ms /   782 tokens (    5.34 ms per token,   187.13 tokens per second)\n",
            "llama_print_timings:        eval time =    4630.59 ms /   117 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
            "llama_print_timings:       total time =    8946.49 ms /   899 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     139.87 ms /   256 runs   (    0.55 ms per token,  1830.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4901.06 ms /   902 tokens (    5.43 ms per token,   184.04 tokens per second)\n",
            "llama_print_timings:        eval time =   10258.15 ms /   255 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =   15495.07 ms /  1157 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.13 ms /    82 runs   (    0.55 ms per token,  1816.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5396.11 ms /   991 tokens (    5.45 ms per token,   183.65 tokens per second)\n",
            "llama_print_timings:        eval time =    3258.77 ms /    81 runs   (   40.23 ms per token,    24.86 tokens per second)\n",
            "llama_print_timings:       total time =    8755.75 ms /  1072 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     149.74 ms /   256 runs   (    0.58 ms per token,  1709.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4140.49 ms /   771 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
            "llama_print_timings:        eval time =   10171.37 ms /   255 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =   14659.20 ms /  1026 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Who are the company's main competitors and how does the company differentiate itself?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      68.62 ms /   117 runs   (    0.59 ms per token,  1705.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4064.64 ms /   758 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4591.36 ms /   116 runs   (   39.58 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    8806.68 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      96.10 ms /   164 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8317.48 ms /  1472 tokens (    5.65 ms per token,   176.98 tokens per second)\n",
            "llama_print_timings:        eval time =    6886.62 ms /   164 runs   (   41.99 ms per token,    23.81 tokens per second)\n",
            "llama_print_timings:       total time =   15426.52 ms /  1636 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      56.12 ms /    83 runs   (    0.68 ms per token,  1479.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4691.36 ms /   866 tokens (    5.42 ms per token,   184.59 tokens per second)\n",
            "llama_print_timings:        eval time =    3295.43 ms /    82 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    8110.76 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      29.77 ms /    52 runs   (    0.57 ms per token,  1746.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4082.25 ms /   762 tokens (    5.36 ms per token,   186.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2011.27 ms /    51 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
            "llama_print_timings:       total time =    6159.08 ms /   813 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      44.63 ms /    64 runs   (    0.70 ms per token,  1434.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2497.87 ms /   440 tokens (    5.68 ms per token,   176.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2608.12 ms /    64 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =    5205.98 ms /   504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     142.50 ms /   256 runs   (    0.56 ms per token,  1796.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11203.31 ms /  1920 tokens (    5.84 ms per token,   171.38 tokens per second)\n",
            "llama_print_timings:        eval time =   11089.63 ms /   255 runs   (   43.49 ms per token,    22.99 tokens per second)\n",
            "llama_print_timings:       total time =   22659.22 ms /  2175 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       6.29 ms /    11 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5184.21 ms /   950 tokens (    5.46 ms per token,   183.25 tokens per second)\n",
            "llama_print_timings:        eval time =     399.67 ms /    10 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
            "llama_print_timings:       total time =    5609.08 ms /   960 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     139.13 ms /   256 runs   (    0.54 ms per token,  1840.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10563.83 ms /  1822 tokens (    5.80 ms per token,   172.48 tokens per second)\n",
            "llama_print_timings:        eval time =   11012.62 ms /   255 runs   (   43.19 ms per token,    23.16 tokens per second)\n",
            "llama_print_timings:       total time =   21928.59 ms /  2077 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much is spent on research and development by the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.61 ms /    69 runs   (    0.69 ms per token,  1449.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2736.05 ms /   519 tokens (    5.27 ms per token,   189.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2663.88 ms /    68 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
            "llama_print_timings:       total time =    5496.48 ms /   587 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      46.97 ms /    80 runs   (    0.59 ms per token,  1703.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6087.66 ms /  1106 tokens (    5.50 ms per token,   181.68 tokens per second)\n",
            "llama_print_timings:        eval time =    3220.71 ms /    79 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
            "llama_print_timings:       total time =    9416.10 ms /  1185 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      38.55 ms /    70 runs   (    0.55 ms per token,  1815.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5461.79 ms /   992 tokens (    5.51 ms per token,   181.63 tokens per second)\n",
            "llama_print_timings:        eval time =    2820.76 ms /    70 runs   (   40.30 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    8374.86 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      49.10 ms /    70 runs   (    0.70 ms per token,  1425.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5150.24 ms /   951 tokens (    5.42 ms per token,   184.65 tokens per second)\n",
            "llama_print_timings:        eval time =    2803.41 ms /    69 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
            "llama_print_timings:       total time =    8069.70 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     153.32 ms /   256 runs   (    0.60 ms per token,  1669.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4408.15 ms /   818 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =   10200.47 ms /   255 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =   15061.94 ms /  1073 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How is the company's corporate culture described?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      70.69 ms /   112 runs   (    0.63 ms per token,  1584.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5574.27 ms /  1020 tokens (    5.46 ms per token,   182.98 tokens per second)\n",
            "llama_print_timings:        eval time =    4512.80 ms /   111 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   10267.53 ms /  1131 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      68.32 ms /   113 runs   (    0.60 ms per token,  1654.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7969.04 ms /  1411 tokens (    5.65 ms per token,   177.06 tokens per second)\n",
            "llama_print_timings:        eval time =    4678.53 ms /   112 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   12813.06 ms /  1523 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      99.65 ms /   167 runs   (    0.60 ms per token,  1675.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5504.98 ms /  1004 tokens (    5.48 ms per token,   182.38 tokens per second)\n",
            "llama_print_timings:        eval time =    6718.84 ms /   166 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =   12457.09 ms /  1170 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.80 ms /   119 runs   (    0.56 ms per token,  1781.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4493.96 ms /   830 tokens (    5.41 ms per token,   184.69 tokens per second)\n",
            "llama_print_timings:        eval time =    4689.78 ms /   118 runs   (   39.74 ms per token,    25.16 tokens per second)\n",
            "llama_print_timings:       total time =    9334.79 ms /   948 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      70.76 ms /   121 runs   (    0.58 ms per token,  1709.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5788.86 ms /  1054 tokens (    5.49 ms per token,   182.07 tokens per second)\n",
            "llama_print_timings:        eval time =    4873.35 ms /   120 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =   10825.12 ms /  1174 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      65.70 ms /   105 runs   (    0.63 ms per token,  1598.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3105.72 ms /   592 tokens (    5.25 ms per token,   190.62 tokens per second)\n",
            "llama_print_timings:        eval time =    4128.82 ms /   105 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
            "llama_print_timings:       total time =    7379.36 ms /   697 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      64.31 ms /   114 runs   (    0.56 ms per token,  1772.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4481.32 ms /   827 tokens (    5.42 ms per token,   184.54 tokens per second)\n",
            "llama_print_timings:        eval time =    4487.97 ms /   113 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    9114.15 ms /   940 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      75.98 ms /   142 runs   (    0.54 ms per token,  1868.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6573.14 ms /  1184 tokens (    5.55 ms per token,   180.13 tokens per second)\n",
            "llama_print_timings:        eval time =    5787.36 ms /   141 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =   12555.88 ms /  1325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      67.39 ms /   103 runs   (    0.65 ms per token,  1528.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4522.40 ms /   834 tokens (    5.42 ms per token,   184.42 tokens per second)\n",
            "llama_print_timings:        eval time =    4086.41 ms /   102 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    8778.77 ms /   936 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.68 ms /    69 runs   (    0.71 ms per token,  1417.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6980.34 ms /  1256 tokens (    5.56 ms per token,   179.93 tokens per second)\n",
            "llama_print_timings:        eval time =    2866.77 ms /    69 runs   (   41.55 ms per token,    24.07 tokens per second)\n",
            "llama_print_timings:       total time =    9989.47 ms /  1325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      38.25 ms /    67 runs   (    0.57 ms per token,  1751.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6892.89 ms /  1236 tokens (    5.58 ms per token,   179.32 tokens per second)\n",
            "llama_print_timings:        eval time =    2711.30 ms /    66 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =    9711.31 ms /  1302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      83.19 ms /   156 runs   (    0.53 ms per token,  1875.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7841.02 ms /  1386 tokens (    5.66 ms per token,   176.76 tokens per second)\n",
            "llama_print_timings:        eval time =    6461.67 ms /   155 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
            "llama_print_timings:       total time =   14530.38 ms /  1541 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's operating income and how does it compare to the previous years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     151.25 ms /   256 runs   (    0.59 ms per token,  1692.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7452.93 ms /  1324 tokens (    5.63 ms per token,   177.65 tokens per second)\n",
            "llama_print_timings:        eval time =   10650.15 ms /   255 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
            "llama_print_timings:       total time =   18544.37 ms /  1579 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      51.34 ms /    66 runs   (    0.78 ms per token,  1285.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8017.68 ms /  1424 tokens (    5.63 ms per token,   177.61 tokens per second)\n",
            "llama_print_timings:        eval time =    2781.87 ms /    66 runs   (   42.15 ms per token,    23.73 tokens per second)\n",
            "llama_print_timings:       total time =   10943.60 ms /  1490 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's earnings per share and how does it compare to industry benchmarks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      99.98 ms /   162 runs   (    0.62 ms per token,  1620.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6061.99 ms /  1100 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
            "llama_print_timings:        eval time =    6586.90 ms /   161 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =   12914.90 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     130.05 ms /   221 runs   (    0.59 ms per token,  1699.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8165.09 ms /  1447 tokens (    5.64 ms per token,   177.22 tokens per second)\n",
            "llama_print_timings:        eval time =    9258.86 ms /   220 runs   (   42.09 ms per token,    23.76 tokens per second)\n",
            "llama_print_timings:       total time =   17786.48 ms /  1667 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     150.08 ms /   256 runs   (    0.59 ms per token,  1705.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5717.29 ms /  1045 tokens (    5.47 ms per token,   182.78 tokens per second)\n",
            "llama_print_timings:        eval time =   10423.46 ms /   255 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
            "llama_print_timings:       total time =   16542.57 ms /  1300 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.27 ms /    69 runs   (    0.57 ms per token,  1757.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6153.26 ms /  1112 tokens (    5.53 ms per token,   180.72 tokens per second)\n",
            "llama_print_timings:        eval time =    2769.28 ms /    68 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
            "llama_print_timings:       total time =    9030.51 ms /  1180 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     121.58 ms /   203 runs   (    0.60 ms per token,  1669.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8522.80 ms /  1504 tokens (    5.67 ms per token,   176.47 tokens per second)\n",
            "llama_print_timings:        eval time =    8567.18 ms /   203 runs   (   42.20 ms per token,    23.70 tokens per second)\n",
            "llama_print_timings:       total time =   17403.46 ms /  1707 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How much inventory does the company hold and are there any signs of inventory management issues?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.68 ms /    86 runs   (    0.62 ms per token,  1602.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4757.43 ms /   880 tokens (    5.41 ms per token,   184.97 tokens per second)\n",
            "llama_print_timings:        eval time =    3412.19 ms /    85 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
            "llama_print_timings:       total time =    8299.79 ms /   965 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.77 ms /   244 runs   (    0.60 ms per token,  1662.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9228.31 ms /  1616 tokens (    5.71 ms per token,   175.11 tokens per second)\n",
            "llama_print_timings:        eval time =   10341.36 ms /   243 runs   (   42.56 ms per token,    23.50 tokens per second)\n",
            "llama_print_timings:       total time =   19968.22 ms /  1859 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's market share in its industry and how has it changed over the years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.24 ms /    64 runs   (    0.68 ms per token,  1479.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2583.73 ms /   455 tokens (    5.68 ms per token,   176.10 tokens per second)\n",
            "llama_print_timings:        eval time =    2554.65 ms /    63 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    5244.95 ms /   518 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.31 ms /     6 runs   (    0.55 ms per token,  1813.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3380.58 ms /   636 tokens (    5.32 ms per token,   188.13 tokens per second)\n",
            "llama_print_timings:        eval time =     194.25 ms /     5 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
            "llama_print_timings:       total time =    3592.71 ms /   641 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      84.67 ms /   136 runs   (    0.62 ms per token,  1606.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6592.81 ms /  1190 tokens (    5.54 ms per token,   180.50 tokens per second)\n",
            "llama_print_timings:        eval time =    5567.91 ms /   135 runs   (   41.24 ms per token,    24.25 tokens per second)\n",
            "llama_print_timings:       total time =   12382.56 ms /  1325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     157.47 ms /   256 runs   (    0.62 ms per token,  1625.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3559.43 ms /   672 tokens (    5.30 ms per token,   188.79 tokens per second)\n",
            "llama_print_timings:        eval time =   10125.36 ms /   255 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =   14080.76 ms /   927 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: How does the company's management view the company performance?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.49 ms /     6 runs   (    0.58 ms per token,  1719.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4142.26 ms /   773 tokens (    5.36 ms per token,   186.61 tokens per second)\n",
            "llama_print_timings:        eval time =     197.96 ms /     5 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    4357.13 ms /   778 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      71.85 ms /   123 runs   (    0.58 ms per token,  1711.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4223.45 ms /   781 tokens (    5.41 ms per token,   184.92 tokens per second)\n",
            "llama_print_timings:        eval time =    4840.82 ms /   122 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
            "llama_print_timings:       total time =    9231.68 ms /   903 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.28 ms /     6 runs   (    0.55 ms per token,  1830.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4923.28 ms /   911 tokens (    5.40 ms per token,   185.04 tokens per second)\n",
            "llama_print_timings:        eval time =     199.94 ms /     5 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =    5141.67 ms /   916 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       8.02 ms /    11 runs   (    0.73 ms per token,  1371.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3057.41 ms /   574 tokens (    5.33 ms per token,   187.74 tokens per second)\n",
            "llama_print_timings:        eval time =     390.33 ms /    10 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
            "llama_print_timings:       total time =    3475.06 ms /   584 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      65.74 ms /   119 runs   (    0.55 ms per token,  1810.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4597.00 ms /   856 tokens (    5.37 ms per token,   186.21 tokens per second)\n",
            "llama_print_timings:        eval time =    4749.28 ms /   119 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    9501.85 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.48 ms /    72 runs   (    0.60 ms per token,  1655.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2636.40 ms /   466 tokens (    5.66 ms per token,   176.76 tokens per second)\n",
            "llama_print_timings:        eval time =    2832.91 ms /    71 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
            "llama_print_timings:       total time =    5564.55 ms /   537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      41.99 ms /    74 runs   (    0.57 ms per token,  1762.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4368.72 ms /   816 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2930.87 ms /    74 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    7396.91 ms /   890 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.86 ms /    78 runs   (    0.59 ms per token,  1700.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4842.88 ms /   884 tokens (    5.48 ms per token,   182.54 tokens per second)\n",
            "llama_print_timings:        eval time =    3086.22 ms /    77 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    8032.83 ms /   961 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      54.06 ms /    90 runs   (    0.60 ms per token,  1664.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3594.69 ms /   674 tokens (    5.33 ms per token,   187.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3516.89 ms /    89 runs   (   39.52 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    7238.30 ms /   763 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      41.06 ms /    71 runs   (    0.58 ms per token,  1729.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4311.60 ms /   798 tokens (    5.40 ms per token,   185.08 tokens per second)\n",
            "llama_print_timings:        eval time =    2779.58 ms /    70 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
            "llama_print_timings:       total time =    7193.26 ms /   868 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.83 ms /    73 runs   (    0.66 ms per token,  1526.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5675.79 ms /  1038 tokens (    5.47 ms per token,   182.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2940.51 ms /    72 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
            "llama_print_timings:       total time =    8742.23 ms /  1110 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     159.45 ms /   256 runs   (    0.62 ms per token,  1605.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9006.32 ms /  1579 tokens (    5.70 ms per token,   175.32 tokens per second)\n",
            "llama_print_timings:        eval time =   10829.91 ms /   255 runs   (   42.47 ms per token,    23.55 tokens per second)\n",
            "llama_print_timings:       total time =   20243.33 ms /  1834 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      76.62 ms /   131 runs   (    0.58 ms per token,  1709.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5085.61 ms /   930 tokens (    5.47 ms per token,   182.87 tokens per second)\n",
            "llama_print_timings:        eval time =    5220.31 ms /   130 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
            "llama_print_timings:       total time =   10473.66 ms /  1060 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.94 ms /    81 runs   (    0.63 ms per token,  1590.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4409.23 ms /   822 tokens (    5.36 ms per token,   186.43 tokens per second)\n",
            "llama_print_timings:        eval time =    3203.51 ms /    80 runs   (   40.04 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    7736.37 ms /   902 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     116.57 ms /   186 runs   (    0.63 ms per token,  1595.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5812.95 ms /  1058 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
            "llama_print_timings:        eval time =    7544.88 ms /   185 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
            "llama_print_timings:       total time =   13637.06 ms /  1243 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      48.95 ms /    93 runs   (    0.53 ms per token,  1899.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4006.03 ms /   752 tokens (    5.33 ms per token,   187.72 tokens per second)\n",
            "llama_print_timings:        eval time =    3629.54 ms /    92 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    7749.29 ms /   844 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.93 ms /    90 runs   (    0.60 ms per token,  1668.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4942.55 ms /   907 tokens (    5.45 ms per token,   183.51 tokens per second)\n",
            "llama_print_timings:        eval time =    3564.32 ms /    89 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    8630.84 ms /   996 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      82.58 ms /   131 runs   (    0.63 ms per token,  1586.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6615.79 ms /  1195 tokens (    5.54 ms per token,   180.63 tokens per second)\n",
            "llama_print_timings:        eval time =    5363.66 ms /   130 runs   (   41.26 ms per token,    24.24 tokens per second)\n",
            "llama_print_timings:       total time =   12177.61 ms /  1325 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     141.81 ms /   256 runs   (    0.55 ms per token,  1805.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12508.31 ms /  2112 tokens (    5.92 ms per token,   168.85 tokens per second)\n",
            "llama_print_timings:        eval time =   11368.46 ms /   255 runs   (   44.58 ms per token,    22.43 tokens per second)\n",
            "llama_print_timings:       total time =   24266.91 ms /  2367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.34 ms /    70 runs   (    0.56 ms per token,  1779.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6819.40 ms /  1226 tokens (    5.56 ms per token,   179.78 tokens per second)\n",
            "llama_print_timings:        eval time =    2828.96 ms /    69 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    9743.04 ms /  1295 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       6.93 ms /    12 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6765.70 ms /  1212 tokens (    5.58 ms per token,   179.14 tokens per second)\n",
            "llama_print_timings:        eval time =     451.50 ms /    11 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
            "llama_print_timings:       total time =    7251.71 ms /  1223 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1791.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5569.95 ms /  1021 tokens (    5.46 ms per token,   183.31 tokens per second)\n",
            "llama_print_timings:        eval time =     202.91 ms /     5 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    5792.68 ms /  1026 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     142.31 ms /   237 runs   (    0.60 ms per token,  1665.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9243.40 ms /  1610 tokens (    5.74 ms per token,   174.18 tokens per second)\n",
            "llama_print_timings:        eval time =   10035.89 ms /   236 runs   (   42.52 ms per token,    23.52 tokens per second)\n",
            "llama_print_timings:       total time =   19642.47 ms /  1846 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      98.47 ms /   185 runs   (    0.53 ms per token,  1878.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12230.16 ms /  2069 tokens (    5.91 ms per token,   169.17 tokens per second)\n",
            "llama_print_timings:        eval time =    8044.48 ms /   184 runs   (   43.72 ms per token,    22.87 tokens per second)\n",
            "llama_print_timings:       total time =   20525.31 ms /  2253 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     149.99 ms /   256 runs   (    0.59 ms per token,  1706.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5280.33 ms /   968 tokens (    5.45 ms per token,   183.32 tokens per second)\n",
            "llama_print_timings:        eval time =   10373.10 ms /   256 runs   (   40.52 ms per token,    24.68 tokens per second)\n",
            "llama_print_timings:       total time =   16016.89 ms /  1224 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cash flow generated from operations and are there any notable trends or fluctuations?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.97 ms /    87 runs   (    0.59 ms per token,  1706.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4148.91 ms /   774 tokens (    5.36 ms per token,   186.56 tokens per second)\n",
            "llama_print_timings:        eval time =    3401.26 ms /    86 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
            "llama_print_timings:       total time =    7662.14 ms /   860 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      64.62 ms /   117 runs   (    0.55 ms per token,  1810.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10056.07 ms /  1739 tokens (    5.78 ms per token,   172.93 tokens per second)\n",
            "llama_print_timings:        eval time =    4942.04 ms /   116 runs   (   42.60 ms per token,    23.47 tokens per second)\n",
            "llama_print_timings:       total time =   15159.51 ms /  1855 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's total outstanding debt, how is the debt structured, and what are the interest rates?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.54 ms /   256 runs   (    0.57 ms per token,  1746.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11534.14 ms /  1966 tokens (    5.87 ms per token,   170.45 tokens per second)\n",
            "llama_print_timings:        eval time =   11122.71 ms /   255 runs   (   43.62 ms per token,    22.93 tokens per second)\n",
            "llama_print_timings:       total time =   23070.39 ms /  2221 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's current ratio and quick ratio and how do these ratios compare to industry averages?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.19 ms /   122 runs   (    0.57 ms per token,  1763.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    8532.45 ms /  1503 tokens (    5.68 ms per token,   176.15 tokens per second)\n",
            "llama_print_timings:        eval time =    5071.88 ms /   121 runs   (   41.92 ms per token,    23.86 tokens per second)\n",
            "llama_print_timings:       total time =   13766.38 ms /  1624 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.68 ms /   256 runs   (    0.57 ms per token,  1745.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =   14316.29 ms /  2371 tokens (    6.04 ms per token,   165.62 tokens per second)\n",
            "llama_print_timings:        eval time =   12465.12 ms /   255 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
            "llama_print_timings:       total time =   27185.68 ms /  2626 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      44.23 ms /    65 runs   (    0.68 ms per token,  1469.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5020.71 ms /   928 tokens (    5.41 ms per token,   184.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2585.70 ms /    64 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
            "llama_print_timings:       total time =    7711.25 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      90.39 ms /   160 runs   (    0.56 ms per token,  1770.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4406.91 ms /   822 tokens (    5.36 ms per token,   186.53 tokens per second)\n",
            "llama_print_timings:        eval time =    6341.22 ms /   159 runs   (   39.88 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =   10969.91 ms /   981 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     150.74 ms /   256 runs   (    0.59 ms per token,  1698.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4340.73 ms /   804 tokens (    5.40 ms per token,   185.22 tokens per second)\n",
            "llama_print_timings:        eval time =   10194.33 ms /   255 runs   (   39.98 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =   14912.96 ms /  1059 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's key risks mentioned in the 10-K and how does the company plan to mitigate these risks?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     151.65 ms /   256 runs   (    0.59 ms per token,  1688.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6186.81 ms /  1126 tokens (    5.49 ms per token,   182.00 tokens per second)\n",
            "llama_print_timings:        eval time =   10476.03 ms /   255 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
            "llama_print_timings:       total time =   17037.98 ms /  1381 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.28 ms /    69 runs   (    0.66 ms per token,  1523.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5568.94 ms /  1024 tokens (    5.44 ms per token,   183.88 tokens per second)\n",
            "llama_print_timings:        eval time =    2808.16 ms /    69 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
            "llama_print_timings:       total time =    8488.80 ms /  1093 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      41.18 ms /    72 runs   (    0.57 ms per token,  1748.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3918.22 ms /   734 tokens (    5.34 ms per token,   187.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2797.47 ms /    71 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =    6802.58 ms /   805 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      53.20 ms /    77 runs   (    0.69 ms per token,  1447.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4269.67 ms /   798 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
            "llama_print_timings:        eval time =    3040.96 ms /    76 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    7432.08 ms /   874 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      36.38 ms /    68 runs   (    0.54 ms per token,  1869.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6715.80 ms /  1216 tokens (    5.52 ms per token,   181.07 tokens per second)\n",
            "llama_print_timings:        eval time =    2746.66 ms /    67 runs   (   40.99 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =    9553.68 ms /  1283 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     6 runs   (    0.58 ms per token,  1713.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3808.29 ms /   708 tokens (    5.38 ms per token,   185.91 tokens per second)\n",
            "llama_print_timings:        eval time =     200.07 ms /     5 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =    4025.03 ms /   713 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      31.17 ms /    55 runs   (    0.57 ms per token,  1764.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5062.45 ms /   935 tokens (    5.41 ms per token,   184.69 tokens per second)\n",
            "llama_print_timings:        eval time =    2164.40 ms /    54 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7306.78 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      63.11 ms /   110 runs   (    0.57 ms per token,  1743.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4627.03 ms /   856 tokens (    5.41 ms per token,   185.00 tokens per second)\n",
            "llama_print_timings:        eval time =    4360.61 ms /   109 runs   (   40.01 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    9128.04 ms /   965 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      74.59 ms /   122 runs   (    0.61 ms per token,  1635.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7561.28 ms /  1351 tokens (    5.60 ms per token,   178.67 tokens per second)\n",
            "llama_print_timings:        eval time =    5042.74 ms /   121 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
            "llama_print_timings:       total time =   12797.46 ms /  1472 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      73.08 ms /   112 runs   (    0.65 ms per token,  1532.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7213.27 ms /  1290 tokens (    5.59 ms per token,   178.84 tokens per second)\n",
            "llama_print_timings:        eval time =    4612.60 ms /   111 runs   (   41.55 ms per token,    24.06 tokens per second)\n",
            "llama_print_timings:       total time =   12004.43 ms /  1401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      46.37 ms /    81 runs   (    0.57 ms per token,  1746.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4917.53 ms /   909 tokens (    5.41 ms per token,   184.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3206.92 ms /    80 runs   (   40.09 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    8233.31 ms /   989 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      42.87 ms /    77 runs   (    0.56 ms per token,  1796.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3817.24 ms /   712 tokens (    5.36 ms per token,   186.52 tokens per second)\n",
            "llama_print_timings:        eval time =    3041.71 ms /    77 runs   (   39.50 ms per token,    25.31 tokens per second)\n",
            "llama_print_timings:       total time =    6953.56 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      81.74 ms /   121 runs   (    0.68 ms per token,  1480.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5057.22 ms /   933 tokens (    5.42 ms per token,   184.49 tokens per second)\n",
            "llama_print_timings:        eval time =    4855.70 ms /   120 runs   (   40.46 ms per token,    24.71 tokens per second)\n",
            "llama_print_timings:       total time =   10115.25 ms /  1053 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     110.31 ms /   182 runs   (    0.61 ms per token,  1649.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9666.34 ms /  1686 tokens (    5.73 ms per token,   174.42 tokens per second)\n",
            "llama_print_timings:        eval time =    7731.02 ms /   181 runs   (   42.71 ms per token,    23.41 tokens per second)\n",
            "llama_print_timings:       total time =   17659.17 ms /  1867 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      62.87 ms /    85 runs   (    0.74 ms per token,  1352.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4822.22 ms /   893 tokens (    5.40 ms per token,   185.18 tokens per second)\n",
            "llama_print_timings:        eval time =    3390.66 ms /    84 runs   (   40.36 ms per token,    24.77 tokens per second)\n",
            "llama_print_timings:       total time =    8349.29 ms /   977 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      92.26 ms /   153 runs   (    0.60 ms per token,  1658.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5098.75 ms /   943 tokens (    5.41 ms per token,   184.95 tokens per second)\n",
            "llama_print_timings:        eval time =    6129.97 ms /   152 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
            "llama_print_timings:       total time =   11437.13 ms /  1095 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     140.77 ms /   256 runs   (    0.55 ms per token,  1818.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =   12383.40 ms /  2092 tokens (    5.92 ms per token,   168.94 tokens per second)\n",
            "llama_print_timings:        eval time =   11274.39 ms /   255 runs   (   44.21 ms per token,    22.62 tokens per second)\n",
            "llama_print_timings:       total time =   24039.66 ms /  2347 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      65.74 ms /   114 runs   (    0.58 ms per token,  1734.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3617.16 ms /   674 tokens (    5.37 ms per token,   186.33 tokens per second)\n",
            "llama_print_timings:        eval time =    4457.44 ms /   113 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    8211.71 ms /   787 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      85.13 ms /   132 runs   (    0.64 ms per token,  1550.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5056.34 ms /   930 tokens (    5.44 ms per token,   183.93 tokens per second)\n",
            "llama_print_timings:        eval time =    5298.23 ms /   131 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =   10561.52 ms /  1061 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      49.27 ms /    73 runs   (    0.67 ms per token,  1481.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7753.62 ms /  1384 tokens (    5.60 ms per token,   178.50 tokens per second)\n",
            "llama_print_timings:        eval time =    3016.53 ms /    72 runs   (   41.90 ms per token,    23.87 tokens per second)\n",
            "llama_print_timings:       total time =   10900.15 ms /  1456 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the total revenue generated by the company and how has the revenue changed over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     153.97 ms /   256 runs   (    0.60 ms per token,  1662.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6778.83 ms /  1091 tokens (    6.21 ms per token,   160.94 tokens per second)\n",
            "llama_print_timings:        eval time =   11075.22 ms /   255 runs   (   43.43 ms per token,    23.02 tokens per second)\n",
            "llama_print_timings:       total time =   18253.11 ms /  1346 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.98 ms /    80 runs   (    0.60 ms per token,  1667.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3668.08 ms /   610 tokens (    6.01 ms per token,   166.30 tokens per second)\n",
            "llama_print_timings:        eval time =    3306.94 ms /    79 runs   (   41.86 ms per token,    23.89 tokens per second)\n",
            "llama_print_timings:       total time =    7090.36 ms /   689 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's gross profit margin, and how has it evolved?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     143.43 ms /   256 runs   (    0.56 ms per token,  1784.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =   10106.18 ms /  1752 tokens (    5.77 ms per token,   173.36 tokens per second)\n",
            "llama_print_timings:        eval time =   11010.99 ms /   256 runs   (   43.01 ms per token,    23.25 tokens per second)\n",
            "llama_print_timings:       total time =   21514.75 ms /  2008 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     146.72 ms /   256 runs   (    0.57 ms per token,  1744.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =   13567.80 ms /  2264 tokens (    5.99 ms per token,   166.87 tokens per second)\n",
            "llama_print_timings:        eval time =   12112.85 ms /   255 runs   (   47.50 ms per token,    21.05 tokens per second)\n",
            "llama_print_timings:       total time =   26082.66 ms /  2519 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's operating income and how does it compare to the previous years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.27 ms /    86 runs   (    0.58 ms per token,  1710.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7788.29 ms /  1382 tokens (    5.64 ms per token,   177.45 tokens per second)\n",
            "llama_print_timings:        eval time =    3533.79 ms /    85 runs   (   41.57 ms per token,    24.05 tokens per second)\n",
            "llama_print_timings:       total time =   11457.87 ms /  1467 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's net income for the current fiscal year and how has net income trended over the past few years?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      70.55 ms /   104 runs   (    0.68 ms per token,  1474.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6002.92 ms /  1096 tokens (    5.48 ms per token,   182.58 tokens per second)\n",
            "llama_print_timings:        eval time =    4223.81 ms /   103 runs   (   41.01 ms per token,    24.39 tokens per second)\n",
            "llama_print_timings:       total time =   10403.83 ms /  1199 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.77 ms /    68 runs   (    0.58 ms per token,  1709.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5619.04 ms /  1032 tokens (    5.44 ms per token,   183.66 tokens per second)\n",
            "llama_print_timings:        eval time =    2746.78 ms /    68 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    8458.07 ms /  1100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      69.04 ms /   127 runs   (    0.54 ms per token,  1839.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5986.75 ms /  1082 tokens (    5.53 ms per token,   180.73 tokens per second)\n",
            "llama_print_timings:        eval time =    5122.36 ms /   126 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
            "llama_print_timings:       total time =   11273.61 ms /  1208 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.49 ms /    79 runs   (    0.55 ms per token,  1816.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5937.83 ms /  1080 tokens (    5.50 ms per token,   181.88 tokens per second)\n",
            "llama_print_timings:        eval time =    3203.15 ms /    79 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
            "llama_print_timings:       total time =    9244.77 ms /  1159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      42.18 ms /    73 runs   (    0.58 ms per token,  1730.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9128.74 ms /  1594 tokens (    5.73 ms per token,   174.61 tokens per second)\n",
            "llama_print_timings:        eval time =    3041.61 ms /    72 runs   (   42.24 ms per token,    23.67 tokens per second)\n",
            "llama_print_timings:       total time =   12277.86 ms /  1666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     114.61 ms /   187 runs   (    0.61 ms per token,  1631.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4959.23 ms /   914 tokens (    5.43 ms per token,   184.30 tokens per second)\n",
            "llama_print_timings:        eval time =    7505.65 ms /   186 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
            "llama_print_timings:       total time =   12738.81 ms /  1100 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.39 ms /    58 runs   (    0.68 ms per token,  1472.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7709.48 ms /  1376 tokens (    5.60 ms per token,   178.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2430.70 ms /    58 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
            "llama_print_timings:       total time =   10246.94 ms /  1434 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's accounts receivable turnover and are there any concerns regarding receivables aging?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.13 ms /    85 runs   (    0.55 ms per token,  1803.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4330.32 ms /   803 tokens (    5.39 ms per token,   185.44 tokens per second)\n",
            "llama_print_timings:        eval time =    3314.33 ms /    84 runs   (   39.46 ms per token,    25.34 tokens per second)\n",
            "llama_print_timings:       total time =    7750.94 ms /   887 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     144.03 ms /   256 runs   (    0.56 ms per token,  1777.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4327.41 ms /   807 tokens (    5.36 ms per token,   186.49 tokens per second)\n",
            "llama_print_timings:        eval time =   10201.80 ms /   255 runs   (   40.01 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =   14861.66 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Who are the company's main competitors and how does the company differentiate itself?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     6 runs   (    0.54 ms per token,  1839.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5284.59 ms /   964 tokens (    5.48 ms per token,   182.42 tokens per second)\n",
            "llama_print_timings:        eval time =     199.43 ms /     5 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
            "llama_print_timings:       total time =    5503.48 ms /   969 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      40.31 ms /    72 runs   (    0.56 ms per token,  1785.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5712.06 ms /  1047 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =    2872.09 ms /    71 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
            "llama_print_timings:       total time =    8675.55 ms /  1118 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      39.68 ms /    70 runs   (    0.57 ms per token,  1764.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4720.14 ms /   871 tokens (    5.42 ms per token,   184.53 tokens per second)\n",
            "llama_print_timings:        eval time =    2751.73 ms /    69 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
            "llama_print_timings:       total time =    7561.57 ms /   940 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       4.60 ms /     7 runs   (    0.66 ms per token,  1520.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6485.83 ms /  1176 tokens (    5.52 ms per token,   181.32 tokens per second)\n",
            "llama_print_timings:        eval time =     291.01 ms /     7 runs   (   41.57 ms per token,    24.05 tokens per second)\n",
            "llama_print_timings:       total time =    6803.18 ms /  1183 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: Are there any ongoing legal proceedings against the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.84 ms /   121 runs   (    0.55 ms per token,  1810.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3686.51 ms /   685 tokens (    5.38 ms per token,   185.81 tokens per second)\n",
            "llama_print_timings:        eval time =    4733.08 ms /   120 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    8574.16 ms /   805 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     121.13 ms /   224 runs   (    0.54 ms per token,  1849.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9802.62 ms /  1698 tokens (    5.77 ms per token,   173.22 tokens per second)\n",
            "llama_print_timings:        eval time =    9539.60 ms /   223 runs   (   42.78 ms per token,    23.38 tokens per second)\n",
            "llama_print_timings:       total time =   19670.68 ms /  1921 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the effective tax rate for the company?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5446.88 ms /   997 tokens (    5.46 ms per token,   183.04 tokens per second)\n",
            "llama_print_timings:        eval time =     200.47 ms /     5 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
            "llama_print_timings:       total time =    5666.84 ms /  1002 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      66.59 ms /   103 runs   (    0.65 ms per token,  1546.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5956.76 ms /  1088 tokens (    5.47 ms per token,   182.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4177.16 ms /   102 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
            "llama_print_timings:       total time =   10293.60 ms /  1190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.90 ms /    78 runs   (    0.59 ms per token,  1699.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6524.82 ms /  1184 tokens (    5.51 ms per token,   181.46 tokens per second)\n",
            "llama_print_timings:        eval time =    3205.46 ms /    78 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
            "llama_print_timings:       total time =    9844.61 ms /  1262 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      50.12 ms /    83 runs   (    0.60 ms per token,  1655.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9893.56 ms /  1717 tokens (    5.76 ms per token,   173.55 tokens per second)\n",
            "llama_print_timings:        eval time =    3503.03 ms /    82 runs   (   42.72 ms per token,    23.41 tokens per second)\n",
            "llama_print_timings:       total time =   13528.29 ms /  1799 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's dividend history and how sustainable are the dividend payouts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.40 ms /     6 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5773.87 ms /  1056 tokens (    5.47 ms per token,   182.89 tokens per second)\n",
            "llama_print_timings:        eval time =     242.32 ms /     6 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
            "llama_print_timings:       total time =    6044.15 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      83.39 ms /   123 runs   (    0.68 ms per token,  1475.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4862.89 ms /   898 tokens (    5.42 ms per token,   184.66 tokens per second)\n",
            "llama_print_timings:        eval time =    4915.77 ms /   122 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    9962.78 ms /  1020 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      67.47 ms /   121 runs   (    0.56 ms per token,  1793.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4130.78 ms /   771 tokens (    5.36 ms per token,   186.65 tokens per second)\n",
            "llama_print_timings:        eval time =    4752.84 ms /   120 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
            "llama_print_timings:       total time =    9031.48 ms /   891 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       5.10 ms /     7 runs   (    0.73 ms per token,  1373.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2834.79 ms /   536 tokens (    5.29 ms per token,   189.08 tokens per second)\n",
            "llama_print_timings:        eval time =     273.60 ms /     7 runs   (   39.09 ms per token,    25.58 tokens per second)\n",
            "llama_print_timings:       total time =    3125.94 ms /   543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     161.19 ms /   256 runs   (    0.63 ms per token,  1588.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4317.16 ms /   807 tokens (    5.35 ms per token,   186.93 tokens per second)\n",
            "llama_print_timings:        eval time =   10218.90 ms /   255 runs   (   40.07 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =   14909.72 ms /  1062 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     152.23 ms /   256 runs   (    0.59 ms per token,  1681.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3912.53 ms /   736 tokens (    5.32 ms per token,   188.11 tokens per second)\n",
            "llama_print_timings:        eval time =   10196.72 ms /   256 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =   14465.04 ms /   992 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     116.02 ms /   188 runs   (    0.62 ms per token,  1620.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4723.24 ms /   876 tokens (    5.39 ms per token,   185.47 tokens per second)\n",
            "llama_print_timings:        eval time =    7533.94 ms /   187 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =   12532.94 ms /  1063 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     126.29 ms /   215 runs   (    0.59 ms per token,  1702.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9111.96 ms /  1595 tokens (    5.71 ms per token,   175.04 tokens per second)\n",
            "llama_print_timings:        eval time =    9084.08 ms /   214 runs   (   42.45 ms per token,    23.56 tokens per second)\n",
            "llama_print_timings:       total time =   18496.92 ms /  1809 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What are the company's pension obligations and contributions and is there a pension fund surplus or deficit?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     124.72 ms /   203 runs   (    0.61 ms per token,  1627.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3203.22 ms /   604 tokens (    5.30 ms per token,   188.56 tokens per second)\n",
            "llama_print_timings:        eval time =    7958.66 ms /   202 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
            "llama_print_timings:       total time =   11431.77 ms /   806 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      81.61 ms /   127 runs   (    0.64 ms per token,  1556.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4501.39 ms /   839 tokens (    5.37 ms per token,   186.39 tokens per second)\n",
            "llama_print_timings:        eval time =    5046.42 ms /   126 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
            "llama_print_timings:       total time =    9725.40 ms /   965 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      75.80 ms /   130 runs   (    0.58 ms per token,  1715.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5662.66 ms /  1039 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =    5256.48 ms /   129 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
            "llama_print_timings:       total time =   11104.62 ms /  1168 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     162.30 ms /   256 runs   (    0.63 ms per token,  1577.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9004.21 ms /  1583 tokens (    5.69 ms per token,   175.81 tokens per second)\n",
            "llama_print_timings:        eval time =   10843.27 ms /   255 runs   (   42.52 ms per token,    23.52 tokens per second)\n",
            "llama_print_timings:       total time =   20262.86 ms /  1838 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's cost of goods sold (COGS) and how does the COGS compare to the total revenue?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      43.59 ms /    64 runs   (    0.68 ms per token,  1468.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4426.42 ms /   824 tokens (    5.37 ms per token,   186.15 tokens per second)\n",
            "llama_print_timings:        eval time =    2565.01 ms /    64 runs   (   40.08 ms per token,    24.95 tokens per second)\n",
            "llama_print_timings:       total time =    7097.72 ms /   888 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      47.32 ms /    83 runs   (    0.57 ms per token,  1753.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5993.49 ms /  1096 tokens (    5.47 ms per token,   182.86 tokens per second)\n",
            "llama_print_timings:        eval time =    3330.21 ms /    82 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =    9438.33 ms /  1178 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      65.07 ms /   122 runs   (    0.53 ms per token,  1874.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6565.18 ms /  1178 tokens (    5.57 ms per token,   179.43 tokens per second)\n",
            "llama_print_timings:        eval time =    4959.03 ms /   121 runs   (   40.98 ms per token,    24.40 tokens per second)\n",
            "llama_print_timings:       total time =   11709.65 ms /  1299 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      81.22 ms /   150 runs   (    0.54 ms per token,  1846.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7349.18 ms /  1311 tokens (    5.61 ms per token,   178.39 tokens per second)\n",
            "llama_print_timings:        eval time =    6165.46 ms /   149 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
            "llama_print_timings:       total time =   13716.62 ms /  1460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      57.68 ms /   102 runs   (    0.57 ms per token,  1768.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5840.21 ms /  1063 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
            "llama_print_timings:        eval time =    4090.29 ms /   101 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
            "llama_print_timings:       total time =   10062.36 ms /  1164 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      77.47 ms /   118 runs   (    0.66 ms per token,  1523.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4770.01 ms /   882 tokens (    5.41 ms per token,   184.91 tokens per second)\n",
            "llama_print_timings:        eval time =    4702.22 ms /   117 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
            "llama_print_timings:       total time =    9645.54 ms /   999 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      45.81 ms /    67 runs   (    0.68 ms per token,  1462.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7583.99 ms /  1360 tokens (    5.58 ms per token,   179.33 tokens per second)\n",
            "llama_print_timings:        eval time =    2758.71 ms /    66 runs   (   41.80 ms per token,    23.92 tokens per second)\n",
            "llama_print_timings:       total time =   10459.59 ms /  1426 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      78.82 ms /   140 runs   (    0.56 ms per token,  1776.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5196.35 ms /   954 tokens (    5.45 ms per token,   183.59 tokens per second)\n",
            "llama_print_timings:        eval time =    5584.74 ms /   139 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
            "llama_print_timings:       total time =   10955.89 ms /  1093 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      42.54 ms /    78 runs   (    0.55 ms per token,  1833.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6655.03 ms /  1199 tokens (    5.55 ms per token,   180.16 tokens per second)\n",
            "llama_print_timings:        eval time =    3150.98 ms /    77 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
            "llama_print_timings:       total time =    9904.62 ms /  1276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      52.18 ms /    73 runs   (    0.71 ms per token,  1399.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2983.99 ms /   511 tokens (    5.84 ms per token,   171.25 tokens per second)\n",
            "llama_print_timings:        eval time =    2977.10 ms /    72 runs   (   41.35 ms per token,    24.18 tokens per second)\n",
            "llama_print_timings:       total time =    6078.86 ms /   583 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      49.03 ms /    87 runs   (    0.56 ms per token,  1774.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4779.23 ms /   888 tokens (    5.38 ms per token,   185.80 tokens per second)\n",
            "llama_print_timings:        eval time =    3472.64 ms /    87 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    8369.43 ms /   975 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      58.16 ms /   108 runs   (    0.54 ms per token,  1856.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6649.71 ms /  1195 tokens (    5.56 ms per token,   179.71 tokens per second)\n",
            "llama_print_timings:        eval time =    4379.34 ms /   107 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
            "llama_print_timings:       total time =   11176.69 ms /  1302 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      37.93 ms /    63 runs   (    0.60 ms per token,  1661.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2366.50 ms /   423 tokens (    5.59 ms per token,   178.74 tokens per second)\n",
            "llama_print_timings:        eval time =    2483.68 ms /    62 runs   (   40.06 ms per token,    24.96 tokens per second)\n",
            "llama_print_timings:       total time =    4937.66 ms /   485 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     126.13 ms /   214 runs   (    0.59 ms per token,  1696.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4527.96 ms /   839 tokens (    5.40 ms per token,   185.29 tokens per second)\n",
            "llama_print_timings:        eval time =    8524.22 ms /   213 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =   13377.29 ms /  1052 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     150.55 ms /   256 runs   (    0.59 ms per token,  1700.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3990.01 ms /   738 tokens (    5.41 ms per token,   184.96 tokens per second)\n",
            "llama_print_timings:        eval time =   10146.84 ms /   255 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
            "llama_print_timings:       total time =   14543.41 ms /   993 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      35.19 ms /    64 runs   (    0.55 ms per token,  1818.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5038.85 ms /   927 tokens (    5.44 ms per token,   183.97 tokens per second)\n",
            "llama_print_timings:        eval time =    2527.43 ms /    63 runs   (   40.12 ms per token,    24.93 tokens per second)\n",
            "llama_print_timings:       total time =    7656.33 ms /   990 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      68.03 ms /   104 runs   (    0.65 ms per token,  1528.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4195.07 ms /   782 tokens (    5.36 ms per token,   186.41 tokens per second)\n",
            "llama_print_timings:        eval time =    4112.01 ms /   103 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
            "llama_print_timings:       total time =    8470.18 ms /   885 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      61.72 ms /   109 runs   (    0.57 ms per token,  1765.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4409.33 ms /   821 tokens (    5.37 ms per token,   186.20 tokens per second)\n",
            "llama_print_timings:        eval time =    4301.16 ms /   108 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
            "llama_print_timings:       total time =    8866.41 ms /   929 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    6283.16 ms /  1136 tokens (    5.53 ms per token,   180.80 tokens per second)\n",
            "llama_print_timings:        eval time =     202.91 ms /     5 runs   (   40.58 ms per token,    24.64 tokens per second)\n",
            "llama_print_timings:       total time =    6511.90 ms /  1141 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1846.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5619.11 ms /  1028 tokens (    5.47 ms per token,   182.95 tokens per second)\n",
            "llama_print_timings:        eval time =     202.70 ms /     5 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
            "llama_print_timings:       total time =    5843.58 ms /  1033 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      68.60 ms /   122 runs   (    0.56 ms per token,  1778.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4857.44 ms /   895 tokens (    5.43 ms per token,   184.25 tokens per second)\n",
            "llama_print_timings:        eval time =    4839.08 ms /   121 runs   (   39.99 ms per token,    25.00 tokens per second)\n",
            "llama_print_timings:       total time =    9857.86 ms /  1016 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      42.13 ms /    64 runs   (    0.66 ms per token,  1519.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4921.61 ms /   906 tokens (    5.43 ms per token,   184.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2538.61 ms /    63 runs   (   40.30 ms per token,    24.82 tokens per second)\n",
            "llama_print_timings:       total time =    7561.53 ms /   969 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     103.57 ms /   162 runs   (    0.64 ms per token,  1564.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5608.37 ms /  1029 tokens (    5.45 ms per token,   183.48 tokens per second)\n",
            "llama_print_timings:        eval time =    6540.19 ms /   161 runs   (   40.62 ms per token,    24.62 tokens per second)\n",
            "llama_print_timings:       total time =   12386.59 ms /  1190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      52.49 ms /    90 runs   (    0.58 ms per token,  1714.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     140.04 ms /    24 tokens (    5.83 ms per token,   171.38 tokens per second)\n",
            "llama_print_timings:        eval time =    3638.77 ms /    90 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
            "llama_print_timings:       total time =    3886.05 ms /   114 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      49.41 ms /    75 runs   (    0.66 ms per token,  1517.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7056.03 ms /  1269 tokens (    5.56 ms per token,   179.85 tokens per second)\n",
            "llama_print_timings:        eval time =    3067.06 ms /    74 runs   (   41.45 ms per token,    24.13 tokens per second)\n",
            "llama_print_timings:       total time =   10250.06 ms /  1343 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     154.14 ms /   256 runs   (    0.60 ms per token,  1660.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4403.36 ms /   819 tokens (    5.38 ms per token,   185.99 tokens per second)\n",
            "llama_print_timings:        eval time =   10196.81 ms /   255 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
            "llama_print_timings:       total time =   14964.43 ms /  1074 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      36.41 ms /    64 runs   (    0.57 ms per token,  1757.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3944.15 ms /   738 tokens (    5.34 ms per token,   187.11 tokens per second)\n",
            "llama_print_timings:        eval time =    2485.16 ms /    63 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6509.70 ms /   801 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =     151.90 ms /   256 runs   (    0.59 ms per token,  1685.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9075.51 ms /  1591 tokens (    5.70 ms per token,   175.31 tokens per second)\n",
            "llama_print_timings:        eval time =   10829.13 ms /   255 runs   (   42.47 ms per token,    23.55 tokens per second)\n",
            "llama_print_timings:       total time =   20290.37 ms /  1846 tokens\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutputParserException occurred for question: What is the company's geographic breakdown of revenue and are there any notable trends or shifts?. Skipping...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      73.69 ms /   123 runs   (    0.60 ms per token,  1669.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3635.78 ms /   687 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =    4830.58 ms /   122 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
            "llama_print_timings:       total time =    8627.59 ms /   809 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      18.07 ms /    32 runs   (    0.56 ms per token,  1771.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4572.56 ms /   848 tokens (    5.39 ms per token,   185.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1272.54 ms /    32 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
            "llama_print_timings:       total time =    5891.38 ms /   880 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      81.92 ms /   122 runs   (    0.67 ms per token,  1489.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4678.76 ms /   870 tokens (    5.38 ms per token,   185.95 tokens per second)\n",
            "llama_print_timings:        eval time =    4870.13 ms /   121 runs   (   40.25 ms per token,    24.85 tokens per second)\n",
            "llama_print_timings:       total time =    9743.38 ms /   991 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      40.76 ms /    70 runs   (    0.58 ms per token,  1717.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3820.06 ms /   720 tokens (    5.31 ms per token,   188.48 tokens per second)\n",
            "llama_print_timings:        eval time =    2721.36 ms /    69 runs   (   39.44 ms per token,    25.35 tokens per second)\n",
            "llama_print_timings:       total time =    6625.09 ms /   789 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     430.15 ms\n",
            "llama_print_timings:      sample time =      81.04 ms /   133 runs   (    0.61 ms per token,  1641.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4237.44 ms /   786 tokens (    5.39 ms per token,   185.49 tokens per second)\n",
            "llama_print_timings:        eval time =    5241.10 ms /   132 runs   (   39.71 ms per token,    25.19 tokens per second)\n",
            "llama_print_timings:       total time =    9652.34 ms /   918 tokens\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-a3b0866e6308>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-cf91ac9d7519>\u001b[0m in \u001b[0;36mcalculate_results\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'yes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtotal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    }
  ]
}